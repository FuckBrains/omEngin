{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\omEngin\\AOmPy_o_\\lib_o_\\site_p1p2.csv\n",
      "D:\\omEngin\\AOmPy_o_\\lib_o_\n",
      "- - - - - - - - - - - - - - - - - -\n",
      "[      ____  __  __   _          \n",
      "      / __ \\|  \\/  | | |         \n",
      "     | |  | | \\  / | | |         \n",
      "     | |  | | |\\/| | | |         \n",
      "     | |__| | |  | | | |         \n",
      "      \\____/\\_|  |_| |_|        ]\n",
      "\n",
      "- - - - - - - - - - - - - - - - - -\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mapdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-412165da96b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\sclick.csv\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# data source,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo_rpa\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimecal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LASTOCCURRENCE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimefmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DUR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-412165da96b1>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mdf)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0modb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0momdb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolchk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmapdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0modb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"CDLO\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mapdata' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from datetime import *\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent.parent.absolute()))\n",
    "try:\n",
    "    from lib_o_.o_fn import *\n",
    "    from lib_o_.o_rpadef import *\n",
    "    from lib_o_.o_rpafn import *\n",
    "    import lib_o_.o_time as oT\n",
    "except:\n",
    "    from o_fn import *\n",
    "    from o_rpadef import *\n",
    "    from o_rpafn import *\n",
    "    import o_time as oT\n",
    "\n",
    "    \n",
    "\n",
    "def o_print(my_dict):\n",
    "    for key in my_dict.items():\n",
    "        x = my_dict.get(key)\n",
    "\n",
    "def getvalue(my_dict, ky):\n",
    "    if ky is not None:\n",
    "        for key, value in my_dict.items():\n",
    "            if key in str (ky):\n",
    "                return value\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "def codecorr(code,akey):\n",
    "    cd = code\n",
    "    if 'UNKNOW' in code:\n",
    "        for i in range(len(lss)):\n",
    "            vl = akey.find(lss[i])\n",
    "            if vl > 0 and vl is not None:\n",
    "                cd = akey[vl:vl+7]\n",
    "                break\n",
    "        else:\n",
    "            return cd\n",
    "    else:\n",
    "        return cd\n",
    "\n",
    "def msgprep_head_znwise(hd = \"Periodic Notification\"):\n",
    "    nw = datetime.now()\n",
    "    dt = nw.strftime(\"%d-%m-%Y\")\n",
    "    tm = nw.strftime(\"%H:%M\")\n",
    "    a1 = hd + \" at \" + tm + \" on \" + dt\n",
    "    return a1\n",
    "\n",
    "def catmap(df,omdb):\n",
    "    try:\n",
    "        dfdb = omdb\n",
    "    except:\n",
    "        dfdb = pd.read_csv(os.getcwd() + \"\\\\csv_o_\\\\OMDB.csv\")\n",
    "    df0 = df.rename (columns=str.upper)\n",
    "    ls = ['RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE','CLEARTIMESTAMP']\n",
    "    df1 = df0[ls]\n",
    "    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))\n",
    "    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))\n",
    "    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else \"XXXXXXXX\", axis=1))\n",
    "    df3 = df2.merge (dfdb, on='sCode')\n",
    "    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])\n",
    "    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])\n",
    "    df3 = df3.assign(CDLO = df3.apply (lambda x: x['CUSTOMATTR15'] + \": \" + x['LASTOCCURRENCE'], axis=1))\n",
    "    try:\n",
    "        dfp1p2 = pd.read_csv(os.getcwd() + \"\\\\csv_o_\\\\OMDB.csv\")\n",
    "        df4 = df3.merge (dfp1p2, on='CUSTOMATTR15')\n",
    "        return df4\n",
    "    except:\n",
    "        return df3\n",
    "\n",
    "def inner_list_to_dic(dic):\n",
    "    for key, value in dic.items(): \n",
    "        dic[key] = set(value)\n",
    "    return dic\n",
    "\n",
    "def joinls(l1,l2):\n",
    "    if len(l1)!=0 and len(l2)!=0:\n",
    "        lss = []\n",
    "        for i in l1:\n",
    "            for j in l2:\n",
    "                lss.append(str(i) + '$' + str(j))\n",
    "        return lss\n",
    "    elif len(l1)!=0 and len(l2)==0:\n",
    "        return l1\n",
    "    elif len(l1)==0 and len(l2)!=0:\n",
    "        return l2\n",
    "    else:\n",
    "        return l1\n",
    "    \n",
    "def colchk(df):\n",
    "    mcols = ['EQUIPMENTKEY','SITECODE','SUMMARY','ALERTKEY','LASTOCCURRENCE','CLEARTIMESTAMP']\n",
    "    ocols = ['RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE','CLEARTIMESTAMP']\n",
    "    df = df.rename (columns=str.upper)\n",
    "    cols = df.columns.to_list()\n",
    "    if cols.count('SITECODE') != 0:\n",
    "        df = df.rename(columns={'SITECODE':'CUSTOMATTR15'})\n",
    "    if cols.count('EQUIPMENTKEY') != 0:\n",
    "        df = df.rename(columns={'EQUIPMENTKEY':'RESOURCE'})\n",
    "    for i in ocols:\n",
    "        if ocols.count(i) == 0:\n",
    "            print('must have column needs in table: but missing !',chr(10),mcols,chr(10),'exiting .....')\n",
    "            exit(0)\n",
    "    else:\n",
    "        sx = chrstream()\n",
    "        omnm(sx)\n",
    "        print(chr(10))\n",
    "        return df\n",
    "\n",
    "def nested_dic_add(dc, k, v):\n",
    "    #map based on child dictionary and add new key value/append by key matching on clild\n",
    "    if len(dc)>0:\n",
    "        ln = len(list(dc))\n",
    "        for i in dc:\n",
    "            if k in list(dc[i]):\n",
    "                dc[i][k] = v if not list(dc[i]) else dc[i].get(k, []) + [v]\n",
    "                return dc\n",
    "        else:\n",
    "            if isinstance(v, list):\n",
    "                dc[ln+1] = {k:v}\n",
    "            else:\n",
    "                v1 = [v]\n",
    "                dc[ln+1] = {k:v1}\n",
    "            return dc\n",
    "    else:\n",
    "        if isinstance(v, list):\n",
    "            dc[1] = {k:v}\n",
    "        else:\n",
    "            v1 = [v]\n",
    "            dc[1] = {k:v1}\n",
    "        return dc    \n",
    "\n",
    "def mprep(df, dic, oncol):\n",
    "    heap = \"\"\n",
    "    gdc = defaultdict(dict)\n",
    "    for k, v in dic.items():\n",
    "        dff = df[df[k].isin(v)]\n",
    "        dff = dff.reset_index()\n",
    "        for i in range(len(v)):\n",
    "            hp = str(k) + \"|\" + str(dff.shape[0]) + chr(10) + dff[oncol].str.contains(v[i]).cat(sep=chr(10))\n",
    "            if heap == \"\":\n",
    "                heap = hp\n",
    "            else:\n",
    "                heap = heap + chr(10) + chr(10) + hp\n",
    "        else:\n",
    "            print(heap)\n",
    "    \n",
    "class o_rpa:\n",
    "    def __init__(self, mdf):\n",
    "        self.odb = omdb()\n",
    "        self.df0 = colchk(mdf)\n",
    "        self.df1 = mapdata(self.df0, self.odb)\n",
    "        self.df = self.df1\n",
    "        self.pickcols = \"CDLO\"\n",
    "        self.msgthread = defaultdict(dict)\n",
    "        self.mth = []\n",
    "        self.cond = defaultdict(dict)\n",
    "        self.lsky = []\n",
    "        self.lsvl = []\n",
    "        self.lsx = []\n",
    "        print(self.df.columns)\n",
    "    def regionwise(self, Name=[]):\n",
    "        self.msgthread = list(zn_dic())\n",
    "    def techwise(self):\n",
    "        self.msgthread = {'CAT': {'2G':\"\",\"3G\":\"\",\"4G\":\"\"}}\n",
    "    def msgcol(self, lscols):\n",
    "        fault = 0\n",
    "        col = self.df.columns.to_list()\n",
    "        for i in lscols:\n",
    "            if col.count(i)==0:\n",
    "                fault = 1\n",
    "        else:\n",
    "            if fault == 0:\n",
    "                self.df = self.df.assign(pk = self.df[lscols].apply(lambda x: '- '.join(x.values.astype(str)), axis=1))\n",
    "                self.pickcols = \"pk\"\n",
    "            else:\n",
    "                print(\"!!!!!!!!!!!!!!!!! column name not found\",chr(10),self.df.columns)\n",
    "    def csvmap(self, csvpath, match_col_name, column_to_pick = []):\n",
    "        try:\n",
    "            try:\n",
    "                dff = pd.read_csv(csvpath)\n",
    "            except:\n",
    "                dff = csvpath\n",
    "            if column_to_pick is not None:\n",
    "                dff = dff[column_to_pick]\n",
    "            ndf = self.df\n",
    "            self.df = ndf.merge (dff, on=match_col_name)\n",
    "        except:\n",
    "            print('csvpath not found')\n",
    "    def pnt(self):\n",
    "        print(self.df)\n",
    "    def getdf(self, current=True):\n",
    "        if current==False:\n",
    "            return self.df0\n",
    "        else:\n",
    "            return self.df\n",
    "    def sample(self):\n",
    "        print(self.df.head(5))\n",
    "    def summary(self):\n",
    "        print(\"COLUMN:\", self.df.columns, chr(10))\n",
    "        print(\"Current Row: \", self.df.shape[0],'--',\"Row Main:\", self.df1.shape[0], chr(10))\n",
    "        print(\"filtering conditions : \", dict((k, v) for k, v in self.cond.items()))\n",
    "        print(\"msgformat by pickcols: \", 'CUSTOMATTR15','LASTOCCURRENCE')\n",
    "        print(\"msgthread: \", self.msgthread)\n",
    "    def condition(self,colname,colval):\n",
    "        ndc = nested_dic_add(self.cond,colname,colval)\n",
    "        self.cond = ndc.copy()\n",
    "    def rwise(self, whichzn=False):\n",
    "        if whichzn == False:\n",
    "            whichzn = \"ALL\"\n",
    "        if len(self.cond) == 1:\n",
    "            colsMain = list(self.cond[1])\n",
    "            rval = parsing(self.df, whichzn,[],colsMain[0], self.cond[1].get(colsMain[0]), False, False)\n",
    "        elif len(self.cond) == 2:\n",
    "            colsMain = list(self.cond[1])\n",
    "            cl = list(self.cond[2])\n",
    "            rval = parsing(self.df, whichzn,self.pickcols,colsMain[0], self.cond[1].get(colsMain[0]), cl[0], \n",
    "                           self.cond[2].get(cl[0]))\n",
    "        else:\n",
    "            print('under development')\n",
    "    def regionwise_count(self, list_cat):\n",
    "        rv = zonewise_count(self.df1, list_cat)\n",
    "        print('----------------------------------------')\n",
    "        return rv\n",
    "    def update_cond_1(self, ky, vl):\n",
    "        self.cond.setdefault(ky, []).append(vl)\n",
    "    def update_cond_2(self, ky, vl):\n",
    "        if isinstance(vl,list):\n",
    "            self.cond[ky] = vl if not list(self.cond) else self.cond.get(ky, []) + vl\n",
    "        else:\n",
    "            vlx = [vl]\n",
    "            self.cond[ky] = vlx if not list(self.cond) else self.cond.get(ky, []) + vlx\n",
    "    def timecal(self, start_time_colname, end_time_colname=False):\n",
    "        self.df = oT.dfdiff(self.df, start_time_colname, end_time_colname)\n",
    "        print(\"new column name is 'DUR'\")\n",
    "    def timefmt(self, colname, fmt=\"%Y/%m/%d %H:%M:%S\"):\n",
    "        if len(fmt) <= 9:\n",
    "            self.df[colname] = self.df.apply(lambda x: oT.sec_to_dur(x[colname]), axis = 1)\n",
    "            print(self.df[colname])\n",
    "        else:\n",
    "            self.df[colname] = oT.datetime_convert_format(self.df, colname, fmt)\n",
    "            print(self.df[colname])\n",
    "    def add2(self, k, v):\n",
    "        self.df = self.df[self.df[k].isin(v)]\n",
    "        self.lsky.append(k)\n",
    "        self.lsvl.append(v)\n",
    "        xk = joinls(self.lsx,v)\n",
    "        self.lsx = xk\n",
    "        print(self.lsx)\n",
    "        try:\n",
    "            self.df = self.df[self.df[k].isin(v)]\n",
    "        except:\n",
    "            print('except trigger')\n",
    "    def gen3(self):\n",
    "        hpf = chr(10)\n",
    "        ndf = self.df\n",
    "        print(ndf.columns)\n",
    "        for i in range(len(self.lsx)):\n",
    "            spl = self.lsx[i].split('$')\n",
    "            if len(self.lsky) == len(spl):\n",
    "                xdf = self.df\n",
    "                for n in range(len(spl)):\n",
    "                    k = self.lsky\n",
    "                    v = spl[n]\n",
    "                    xdf = xdf[xdf[k[n]].isin([v])]\n",
    "                else:\n",
    "                    x11 = \" | \".join(spl) + \": \" + str(xdf.shape[0])\n",
    "                    if xdf.shape[0] != 0:\n",
    "                        x11 = x11 + chr(10) + xdf[self.pickcols].str.cat(sep=chr(10))\n",
    "                    print(x11, chr(10))\n",
    "    def pntcond(self):\n",
    "        L = list(self.cond.values())\n",
    "        Lx = []\n",
    "        if (len(L[0]))<=1:\n",
    "            L1 = [item for sublist in L[0] for item in sublist]\n",
    "            Lx.append(L1)\n",
    "        else:\n",
    "            Lx.append(L1)\n",
    "print(os.getcwd())\n",
    "df = pd.read_csv(os.getcwd() + \"\\\\sclick.csv\")  # data source, \n",
    "xx = o_rpa(df)\n",
    "xx.timecal('LASTOCCURRENCE')\n",
    "xx.timefmt('DUR','%H:%M:%S')\n",
    "xx.update_cond_1('sZone',['COM','NOA'])\n",
    "xx.update_cond_1('CAT',['2G','3G','4G'])\n",
    "xx.update_cond_1('P1P2',['P1','P2'])\n",
    "xx.sample()\n",
    "xx.msgcol(['CUSTOMATTR15','LASTOCCURRENCE','P1P2'])\n",
    "xx.pntcond()\n",
    "\n",
    "#xx.gen3()\n",
    "#rval = xx.rwise()\n",
    "#ST = xx.regionwise_count(['2G','3G','4G','MF','DL'])\n",
    "#print(ST)\n",
    "#dc = {'sZone':{0:{'COM':{'CAT':{0:'2G'}}}}}\n",
    "#print(dc)\n",
    "#slicedf(dx,dc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
