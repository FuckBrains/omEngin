

###d:\omEngin\Z_ALL_FILE\Py1\10102020-1833-XAQ-vbfn1.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = "E:\\GIT\\OmProject\\OmPY\\omfn4\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]




df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
#print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
#print(asq)

sm = sumifs(asq,'CUSTOMATTR15','AG')
print(sm)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10102020-253-XAQ-ipmap.py###
import pandas as pd
import numpy as np
import os
import csv
import requests
import io
import datetime as dt
import geoip2.database

#shift-ctrl-b

pt = os.getcwd()
dbmx = "/root/OmProject/OmSocks/ippro/GeoLite2-City.mmdb"
dbas2ip = "/root/OmProject/OmSocks/ippro/ip2asn.csv"

def mxdb(ip):
    with geoip2.database.Reader(dbmx) as reader:
        try:
            response = reader.city(ip)
            lst = response.city.name + ' -' + response.country.iso_code
            return lst
        except:
            lst = 'NA'
            return lst

def filename_maker():
    y = dt.datetime.now()
    x = y.strftime("%d%m%Y-%H%M")
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww

def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]


def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

def maincall(dpx1):
    df = pd.read_csv(dbas2ip)
    ls = []
    for r in range(dpx1.shape[0]):
        lst = []
        ip = dpx1.iloc[r,0]
        prt = dpx1.iloc[r,1]
        ipx = ip.split('.')
        ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
        aa = find_owner(ddf.to_numpy(),ip)
        lst.insert(0,ip)
        lst.insert(1,prt)
        lst.insert(2,mxdb(ip))
        lst.insert(3,aa)
        ls.append(lst)
    fdf = pd.DataFrame(ls,columns = ['ip','port','CityCountry','SL'])
    ffd = pd.merge(fdf,df,on ='SL',how ='left')
    fd = ffd[['ip','port','CityCountry','ISP','ASN','Country']]
    fd.to_csv(filename_maker())
    return fd

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10102020-253-XAQ-jsonrw.py###
#ref:https://pynative.com/python-json-dumps-and-dump-for-json-encoding/
import json
import os

def jsonMod(jsn,ip,port):
    with open(jsn, "r") as jsonFile:
        x = json.load(jsonFile)
        x['configs'][0]['server'] = ip
        x['configs'][0]['server_port'] = port
        print(x)
    with open(jsn, "w") as jsonFile:
        json.dump(x, jsonFile)

jp = os.getcwd() + "\\proxylist.json"
jsonMod(jp,'8.8.8.8','01010')

#demjson.decode(prot)
#(prot)
#print(usr)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10102020-253-XAQ-omprox.py###
import os
import geoip2.database
import pandas as pd
import api.omapi as oap
import api.lvblk as lv
import api.ipapi as iap
import ippro.ipmap as ipm
import csv
pd.options.mode.chained_assignment = None  # default='warn'

#shift-ctrl-b

def runner(df1,filename):
    df = df1[df1['Country'].str.contains('US')]
    rw = df.shape[0]
    n = 0
    for i in range(len(df)):
        try:
            df.loc[i,"status"] = lv.islive(str(df.loc[i,"ip"]), str(df.loc[i,"port"]))
        except:
            print('err')
        finally:
            break
        n = n + 1
        print('checking done: ' + str(n) + '/' + str(rw))
    df.to_csv('A.csv')
    return df

hme = oap.dailyproxy()
print(hme)
hme.columns = ['ip','port']
GT = ipm.maincall(hme)
df = GT[ (GT.ASN != 13335) & (GT.Country == 'US') ]
#df['ip']= df['ip'].astype(str)
df['port']= df['port'].astype(str)
ndf = df[['ip','port','ISP']]
print(ndf)
nr = ndf.to_numpy()
zz = ""
rw, col = nr.shape
ls = []
for r in range(rw):
    lst = []
    IP = nr[r][0]
    PORT = nr[r][1]
    lst.insert(0, str(IP) + ':' + str(PORT))
    lst.insert(1, nr[r][2])
    lst.insert(2, lv.islive(IP,PORT))
    ls.append(lst)
dfx = pd.DataFrame(ls, columns = ['ip_port','isp','status'])
dfx.to_csv('/root/OmProject/azsa.csv')
    
    


#dfop = oap.openproxy()
#dfdl = dailyproxy()
#dfprm = api_premproxy()



#prem.columns = ['ip','port']


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10112020-1432-XAQ-omapi.py###
import csv
import pandas as pd
import io
import requests
import nmap
import pydnsbl
import urllib
import socket
import json
import requests
socket.setdefaulttimeout(180)
import os

def api_hideme():
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + "730480402242392"
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

def api_premproxy():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    urlData = requests.get(z).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def dailyproxy():
    url = "https://proxy-daily.com/api/getproxylist?apikey=MHAvkX-UOWjz6vbT-t9cpK1&format=ipport&country=US&type=socks5&lastchecked=60"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def openproxy():
    url = "https://api.openproxy.space/premium/plain?amount=34999&apiKey=i9414-d994p4Pa29118LW-yfIl5-eBY64dMT5N16uDv-Vw10n&checksMore=354&countries=US&protocols=3&status=1&streak=1"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def auth0(ip):
    try:
        url = "https://signals.api.auth0.com/badip/" + ip
        headers = {
            'accept': "application/json",
            'x-auth-token': "51fac7a1-04c8-4c2f-8143-76c5fa498ff9"
            }
        response = r.request("GET", url, headers=headers)
        x = json.loads(response.text)
        return x['type']
    except:
        print('err')
    finally:
        return "NA"


def isblk(ip):
    ip_checker = pydnsbl.DNSBLIpChecker()
    x = str(ip_checker.check(ip))
    print(x)
    if 'BLACKLISTED' in x:
        a = x.rfind('(')
        b = x.rfind(')')
        ab = x[a+1:b]
        ap = auth0(ip)
        return 'black - ' + ab + ' - ' + str(ap)
    else:
        return 'fine'

def islive(ip,port):
    qry = 'nmap -p ' + str(port) + ' ' + str(ip)
    y = os.popen(qry).read()
    print(y)
    if 'open' in y:
        ab = isblk(ip)
        x = 'live' + '-' + str(ab)
    else:
        x = 'dead'
    return x

def ipdb_2(ip):
    url = "https://freegeoip.app/json/" + ip
    headers = {
        'accept': "application/json",
        'content-type': "application/json"
        }
    response = requests.request("GET", url, headers=headers)
    x = json.loads(response.text)
    y = x['city'] + ' -' + x['country_code']
    return y


islive('173.0.54.188','6888')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10142020-1240-XAQ-omdtfn.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()


def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str


def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def curr_day():
    return td.strftime('%d')


def curr_month():
    return td.strftime('%m')


def curr_year():
    return td.strftime('%Y')


def curr_date():
    return td.strftime('%Y-%m-%d')


def date_between(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2 - d1).days


def aging(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2 - d1)
    return mn


def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx + relativedelta(months=diff)
    return delt

def day_minus_dy(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d")
    return str_d

def day_minus(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def day_plus(diff):
    d = td + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def hrmin():
    str_d = n.strftime("%H:%M")
    return str_d

def dtmnyr():
    str_d = n.strftime("%Y-%m-%d")
    return str_d

# def date_str(dt):
# def fmt_to_datetime():
# def fmt_to_str():
# delta_month(nw(),-4)
# def month_delta(dt,diff):
# d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
# def day_delta(dt,diff):
# def date_minus(dt, diff):
# def month_minus(dt, diff):
# def year_minus(dt, diff):
# print(aging(nw(),'2020-06-13 00:00:00'))
# print(min_plus(500))
# print(min_minus(500))
# print(hr_plus(2))







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10162020-628-XAQ-vbfn2.py###
import pandas as pd
import numpy as np







def add_list_as_column(df,nlst):
    #ls = df.values.tolist()
    df = df.append(pd.DataFrame(nlst,columns=['col1','col2']),ignore_index=True)
    print(df)




l0 = ["0", "1", "2", "3", "4"]
l1 = ["Amar", "Barsha", "Barsha", "Tanmay", "Misbah"]
l2 = ["Alpha", "Bravo", "Charlie", "Tango", "Mike"]
l4 = [["Amar", "Barsha", "Carlos", "Tanmay", "Misbah"],["Alpha", "Bravo", "Charlie", "Tango", "Mike"]]
l5 = ['A','B','C','D','E']
l6 = ['DHK', 'RAJ', 'CTG', 'SYL', 'MYN']
l7 = [['DHK, P1'], ['DHK, P2'] , ['DHK, P3'] , ['DHK, P4'] , ['DHK, P5']]

df1 = join_list(l0, l1, l2)
df1.columns = ['1','2','3']
dc1 = conv_lst_dic(l0,l6)
#print(dc1)
dc2 = conv_lst_dic(l0,l7)
#print(dc2)
l8 = df1['1']
l9 = df1 [['2','3']]
l10 = l9.values.tolist()
dc3 = conv_lst_dic(l0,l7)
#print(dc3)
#print(df1)
df2 = pd.DataFrame(dc3)
#print(df2)

x = vlookup(df1,dc3,'1','TOTO')

#print(x)
ts = x['2']
lx = ts.values.tolist()
cnt = lx.count('Barsha')
#print(cnt)
x = countif(x,'2','2',"ONCOL2")
#p = add_col_df(df,'Test',1)
#add_list_as_column(df,l4)
#datatype_conversion = df['Customer Number'].astype('int')


def conct(a1,a2):
    ls = []
    strn = ""
    for i in range(len(a1)):
        strn = strn + str(a1[i]) + str(a2[i])
    return strn

def conct1(arg1,arg2):
    if isinstance(arg1, list) and isinstance(arg2, list):
        ls = []
        for i in range(arg1):
            ls.append(str([i]) + str(arg2[i]))
        return ls
    else:
        ag1 = arg1.values.tolist()
        ag2 = arg2.values.tolist()
        ls = []
        for i in range(ag1):
            ls.append(str([i]) + str(ag2[i]))
        return ls

def countifz(df,*argv):
    if isinstance(df,pd.DataFrame):
        if len(argv) % 2 != 0:
            print('need conditions for every ref range have')
        else:
            rng = len(argv) / 2
            i = 0
            j = 2
            A1 = ""
            B1 = ""
            X1 = []
            X2 = []
            while i < rng:
                if j > rng:
                    A1 = A1 + (df[argv[i]])
                    B1 = B1 + (df[argv[i+1]])
                    i = i + 2
                else:
                    A1 = A1 + (conct(df[argv[i]],df[argv[j]]))
                    B1 = B1 + (conct(df[argv[i+1]],df[argv[j+1]]))
                    i = i + 2
                    j = j + 2
                X1.append(A1)
                X2.append(B1)
            print(X1,X2)
    else:
        print('first parameter must be dataframe (full data range)')


countifz(x, '1', '1', '3', '3')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10182020-49-XAQ-omfn.py###
import pandas as pd
import numpy as np
import .db.db as sq

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('C2G' if ('2G CELL DOWN' in x) \
                else ('C3G' if ('3G CELL DOWN' in x) \
                else ('C4G' if ('4G CELL DOWN' in x) \
                else "NA"))))))))))))

def Lcut(mstr,cut_to):
    try:
        if len(mstr) >= cut_to:
            x = mstr[0:cut_to]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def Rcut(mstr,cut_to):
    try:
        if len(mstr) - cut_to >= 0:
            a = len(mstr) - cut_to
            b = len(mstr)
            x = mstr[a:b]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def src_in_str(mstr,lkstr):
    if lkstr in mstr:
        return mstr.find(lkstr)
    else:
        return 0

def code_corr(df0):
    df = df0
    for i in range(len(df)):
       Eky = df.loc[i,'EQUIPMENTKEY']
       A15 = df.loc[i,'CUSTOMATTR15']
       if A15 == 'UNKNOWN' and Eky != 'UNKNOWN' and len(Eky)<15:
           if len(Eky) == 7:
               df.loc[i,'CUSTOMATTR15'] = Eky
           elif '_' in Eky:
               x = Eky.find('_')
               if x > 4:
                   df.loc[i,'CUSTOMATTR15'] = Lcut(Eky,7)
               else:
                   df.loc[i,'CUSTOMATTR15'] = Rcut(Eky,7)
    return df

def catsemrw(df0):
    df = add_col_df(df0,'cat')
    df['cat'] = df.apply(lambda row: TS(row.SUMMARY), axis = 1)
    return df

def get_region(df):
    df4 = df
    df5 = flk.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df6.drop('ShortCode', axis='columns', inplace=True)
    return df6

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10242020-055-XAQ-vbdf.py###
import pandas as pd
import numpy as np
import os
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnstr as fst
import db.db as sq
from datetime import *


pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

df1 = pd.read_csv(pt1)
df0 = pd.read_csv(pt2)

def get_region(df):
    df4 = df
    df5 = flk.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df6.drop('ShortCode', axis='columns', inplace=True)
    return df6

def conv_to_datetime(df1,col):
    df1[col] = pd.to_datetime(df1[col], errors='coerce')
    return df1

def pick_by_day(df1,day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1,yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def datediff(df1,newcolname,col1,col2=False):
    if col2 != False:
        df1 = conv_to_datetime(df1,col1)
        df1 = conv_to_datetime(df1,col2)
        df1 = pick_except_year(df1,1970)
        df2 = fdt.add_col_df(df1,newcolname)
        df2[newcolname] = df2[col2] - df2[col1]
        df2[newcolname] = df2[newcolname].astype('timedelta64[m]')
        return df2
    else:
        df1 = conv_to_datetime(df1,col1)
        df2 = fdt.add_col_df(df1,'now',datetime.now())
        df2 = conv_to_datetime(df2,'now')
        df3 = fdt.add_col_df(df2,newcolname)
        df3[newcolname] = df3['now'] - df3[col1]
        df3[newcolname] = df3[newcolname].astype('timedelta64[m]')
        df3.drop('now', axis='columns', inplace=True)
        return df3

#print(df0)
#print(df0.columns)



def cntif(df,*argv):
    rngmod = len(argv) % 2
    n = 0
    if rngmod == 0:
        ls = []
        while n<=len(argv):
            col = 'c' + str(n) + str(n+1)
            if isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], pd.core.series.Series):
                ls1 = argv[n].to_list()
                ls2 = argv[n+1].to_list()
                #ls = [i + j for i, j in zip(ls1, ls2)]
                print(ls2)
            elif isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], str):
                print('x')
            elif isinstance(argv[n+1], str) and isinstance(argv[n], pd.core.series.Series):
                print('x')
                n = n + 2
        print(ls)
    else:
        print('no of reference and no of criteria must be equal')


dfy = fst.catsemrw(df0)
dfz = get_region(dfy)
print('OK')
cntif(dfz,dfz['Region'],dfz['cat'])


def cifz(df,*argv):
    rng = len(argv) / 2
    if rng>=1:
        n = 0
        ls = []
        lss = []
        while n<=rng:
            if isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], pd.core.series.Series):
                ls1 =  argv[n].to_list()
                ls2 =  argv[n+1].to_list()
                if len(lss)<1:
                    lss = ls1
                    ls = ls2
                else:
                    l1 = []
                    l2 = []
                    l1 = [i + j for i, j in zip(lss, ls1)]
                    l2 = [i + j for i, j in zip(ls, ls2)]
                    lss = l1
                    ls = l2
            elif isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], str):
                ls1 =  argv[n].to_list()
                ar = np.repeat(argv[n+1], len(ls1))
                ls2 = ar.tolist()
                ls3 = [i + j for i, j in zip(ls1, ls2)]
                if len(lss)<1:
                    lss = ls1
                    ls = ls2
                else:
                    l1 = []
                    l2 = []
                    l1 = [i + j for i, j in zip(lss, ls1)]
                    l2 = [i + j for i, j in zip(ls, ls2)]
                    lss = l1
                    ls = l2
            n = n + 2
        df1 = pd.DataFrame(list(zip(lss, ls)),columns =['refrng','criteria'])
        dff = pd.concat([df, df1], axis=1, sort=False)
        print(dff)
        dfx = df1.groupby(['refrng','criteria']).count().to_frame(name = 'cnt').reset_index()
        #dd = df1.value_counts(['refrng','criteria'])).counts()
        print(dfx)
        #dfy = dff.merge(dfx, on='refrng')
        #df2.drop(st, axis='columns', inplace=True)
        #print(dfx)

#cifz(dfz,dfz['Region'],dfz['cat'])

#dfx = datediff(df0,'datedff','LASTOCCURRENCE')

#print(dfz)
#cat Region

#dfz['rgcat'] = dfz['Region'] + dfz['cat']
#d1 = dfz.groupby(['rgcat'])['rgcat'].count().to_frame(name = 'counts').reset_index()
#ls = ['Region','cat']
#dx = countifs(dfz,ls,'count')
#print(dx)
#print(dfz['concat'])


#df3 = df2.groupby(['CUSTOMATTR15','diff'])['CUSTOMATTR15'].count()
#print(df3)
#dfx = df2.groupby(['CUSTOMATTR15']).CUSTOMATTR15.count().to_frame(name = 'SMX').reset_index()
#df3 = df2.groupby('CUSTOMATTR15')['diff'].sum().to_frame(name = 'SMX').reset_index()
#df3['SMX'] = df3['SMX'].astype(int)
#df3['SMX'] = df3['SMX'].astype(str).astype(int)
#df3['SMX'] = df3['SMX'].astype('int64').dtypes
#df3["SMX"] = df3["SMX"].astype(int)
#df3 = df2.groupby(df2['CUSTOMATTR15']).diff.sum().to_frame(name = 'SMX').reset_index()
#print(df3#)



#ds = df3.dtypes
#print(ds)
#print(type(df1['LASTOCCURRENCE']))
#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)














#print(pt)
#df0 = pd.read_csv(pt)
#cols = ['Serial','EquipmentKey','LastOccurrence','Summary','AssociatedCR','TTSequence','TTStatus','CustomAttr15','BCCH','AlertKey','CustomAttr3','ClearTimestamp']
#df1 = df0[cols]
#df2 = look.catsemrw(df1)
#print(df2.head(5))
#df3 = look.process_sem_raw(df2)
#df4 = look.code_corr(df3)
#print(df4['CustomAttr15'])
#df.astype({'col1': 'int32'}).dtypes


#df1 = look.add_col_df(df,'cnt')
#
#df2 = df0.value_counts(dropna=False)
#print(df2)
#print(df2.shape[0])
#ls = df2.values.tolist()
#print(df2)
#print(df2.shape[1])

#df4 = pd.DataFrame(df3, columns=['1','2'])
#print(df4)
#df3 = df.merge(df2,)
#df1 = look.timediff(df,'LASTOCCURRENCE','CLEARTIMESTAMP',"MTTR")
#print(df1)dropna=False
#print(df1)
#print(df)

#df0 = look.countif(df,'Summary','Summary',"CAT")
#print(df0)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10252020-194-XAQ-main.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs

tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=1)
tmnw = datetime.now() - timedelta(minutes=1)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
conx = pyodbc.connect(UserEx)

def sendsms(msisdn,txt):
    sURL1 = "http://10.101.11.164:10144/cgi-bin/sendsms?user=tester&pass=foobar&to="
    sURL2 = "&from=10144&text="
    sURL_pgon = sURL1 + msisdn + sURL2 + txt
    resp = rs.get(sURL_pgon)
    print(resp)

def smscheck():
    smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
    dfsms = pd.read_sql(smsinbox, conx)
    return dfsms


def main():
    df = smscheck()
    if df.shape[0] != 0:
        for i in range(len(df)):
            print(df.iloc[i,1])
    else:
        print('no sms')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10262020-221-XAQ-main.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs
import sqltdb as sqdb
import sitecount as st
import omfn as fn
import urllib3
import urllib.parse


tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=1)
tmnw = datetime.now() - timedelta(minutes=1)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')


def handdler(ussd,msg,msisdn):
    nw = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    rval = ""
    if msg !="":
        ms = msisdn[-10:len(msisdn)]
        ms4sms = msisdn[-11:len(msisdn)]
        code = fn.sitecode_pick(msg)
        if "ALL" in msg  or '2G' in msg or  "3G" in msg or "SC" in msg or  "4G" in msg:
            xx = st.siteinfo(msg)
            print(nw, xx)
            yy = st.sms(ms4sms,xx)
            rval = "S"
        elif "PGSTART" in msg and code != 'NA':
            xx = st.roc(ussd,code,ms,'PGSTART')
            print(nw,xx)
            if 'PGON_DONE' in xx:
                rval = "S"
            else:
                rval = "F"
        elif "PGSTOP" in msg and code != 'NA':
            xx = st.roc(ussd,code,ms,'PGSTOP')
            print(nw,xx)
            if 'PGOFF_DONE' in xx:
                rval = "S"
            else:
                rval = "F"
        else:
            rval = "Not Related Query"
    return rval

def main():
    nww = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    df = st.smscheck()
    if df.shape[0] != 0:
        for i in range(len(df)):
            msg1 = df.loc[i,"MESSAGE"]
            if isinstance(msg1, str):
                ussd = df.loc[i,"USDLogId"]
                msg = msg1.upper()
                msisdn = df.loc[i,"DESTADDR"]
                sqret = sqdb.queryussd(ussd)
                if sqret == 0:
                    st.general_qry()
                    rval = handdler(ussd,msg,msisdn)
                    st.general_qry()
                    if rval == 'S':
                        rv2 = sqdb.insertussd(ussd)
                        if rv2 == "S":
                            print('Cycle Complete for::::: ', nww, ussd, msg, msisdn)
                        else:
                            print("Cycle failed:::", nww, ussd, msg, msisdn)
                    else:
                        print(rval)
                else:
                    print('already served::', nww, ussd, msg, msisdn)
    else:
        print('no sms')
    return "done at " + nww
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10262020-356-XAQ-runner.py###
import asyncio
import main as m
from datetime import *

async def periodic():
    while True:
        nww = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print("start at ", nww)
        xx = m.main()
        print("ends at " , xx)
        await asyncio.sleep(30)

def stop():
    task.cancel()

loop = asyncio.get_event_loop()
task = loop.create_task(periodic())

try:
    loop.run_until_complete(task)
except asyncio.CancelledError:
    pass
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10302020-2358-XAQ-sitecount.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
import requests as rs
import db121 as d121
import sqltdb as sq

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
conn = pyodbc.connect(UserEx)

tday = date.today()

def smscheck():
    tmdlta = datetime.now() + timedelta(minutes=1)
    tmnw = datetime.now() - timedelta(minutes=2)
    qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
    qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')
    smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
    print(smsinbox)
    dfsms = pd.read_sql(smsinbox, conn)
    return dfsms

def sms(ms,text):
    url = "https://web1.robi.com.bd/apiresponse.php?user=robircouser&pass=Gqras@3789291&from=10144&to=" + str(ms) + "&text=" + text
    rs = requests.get(url)
    print(rs)


def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "ALL2G") or (txtwht == "2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "ALL3G") or (txtwht == "3G"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "4G") or (txtwht == "ALL4G"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "ALL") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        allnode = df2G.shape[0]
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "Radio Node: " + str(allnode) + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"
    

tmnw = datetime.now()
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')

def general_qry():
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    qry = "SELECT * from [dbo].[pglog4]"
    df = pd.read_sql(qry, conn)
    print(df)

def db_insert_pgon(ussd,code,msisdn):
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    in_qry = '''INSERT INTO dbo.pglog4 (SMSID, SITECODE, MSISDN) VALUES (?,?,?)'''
    in_qry_1 = (ussd, code, msisdn)
    curs.execute(in_qry, in_qry_1)
    conn.commit()
    sms(str(msisdn),"PGSTART ACK AT " + qryst + " CODE:" + code)

def db_query_duplicate(code):
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    select_qry = "SELECT * FROM pglog4 WHERE SITECODE = '"+ code +"' AND STATUS_ACTIVE= 'TRUE'"
    curs.execute(select_qry)
    rows = curs.fetchone()
    bol = bool(rows)
    if bol == True:
        return "ACT_CASE_FOUND"
    else:
        return "NO_ACT_CASE"

def db_update_pgoff(code,msisdn):
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    qry_1 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND STATUS_ACTIVE= 'TRUE')"
    qry1 = "UPDATE dbo.pglog4 SET END_DATETIME = CURRENT_TIMESTAMP WHERE " + qry_1
    qry2 = "UPDATE dbo.pglog4 SET CASE_STATUS = 'Closed' WHERE " + qry_1
    curs.execute(qry1)
    conn.commit()
    curs.execute(qry2)
    conn.commit()
    qry_2 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND CASE_STATUS= 'Closed')"
    qry3 = "UPDATE dbo.pglog4 SET STATUS_ACTIVE = '0' WHERE " + qry_2
    curs.execute(qry3)
    conn.commit()
    sms(msisdn,"PGSTOP ACK AT " + qryst + ' Code: '+ code)

def roc(ussd,code,msisdn,job):
    x = 0
    if job == "PGSTART":
        ans = db_query_duplicate(code)
        print("~~~~ ", ans, " ~~~~",code)
        if ans == "NO_ACT_CASE":
            try:
                db_insert_pgon(str(ussd),code,str(msisdn))
                print('DBUPDATE ROC SUCC')
                x = 1
            except:
                print('DBUPDATE ROC FAIL')
            try:
                d121.insert_pgon(str(ussd),code,str(msisdn))
                print('DBUPDATE 121 SUCC')
            except:
                print('DBUPDATE 121 FAIL')
            if x == 1:
                return 'PGON_DONE' + code
            else:
                return 'DBUPDATE FAIL ' + code
        else:
            sms(msisdn,"PGSTART ALREADY LOGGED (Duplicate Entry)")
            sq.insertussd(ussd)
            return "Duplicate Entry: " + code
    elif job == "PGSTOP":
        ans = db_query_duplicate(code)
        if ans == "ACT_CASE_FOUND":
            db_update_pgoff(code,str(msisdn))
            d121.update_pgoff(code,str(msisdn))
            return 'PGOFF_DONE'
        else:
            sms(msisdn,"NO PGON Found, Invalid PG OFF Request")
            sq.insertussd(ussd)
            return ""


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1042020-2217-XAQ-ipmap.py###
import pandas as pd
import numpy as np
import os
import MySQLdb
import csv
import requests
import io
import datetime as dt


def filename_maker():
    y = dt.datetime.now()
    x = y.strftime('%d%m%Y-%H%M')
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww

def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]

def api_hideme():
    hideme_access = "730480402242392"
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + hideme_access
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

def maincall(df_port_ip):
    df = pd.read_csv(path_ip2as)
    dpx1 = df_port_ip[['ip','port']]
    dpip = df_port_ip[['ip']]
    ls = []
    for r in range(dpx1.shape[0]):
        lst = []
        ip = dpx1.iloc[r,0]
        prt = dpx1.iloc[r,1]
        ipx = ip.split('.')
        ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
        aa = find_owner(ddf.to_numpy(),ip)
        lst.insert(0,ip)
        lst.insert(1,prt)
        lst.insert(2,aa)
        ls.append(lst)
        print(ls)
    fdf = pd.DataFrame(ls,columns = ['ip','port','SL'])
    ffd = pd.merge(fdf,df,on ='SL',how ='left')
    fd = ffd[['ip','port','ISP','ASN','Country']]
    print(fd)
    fd.to_csv(filename_maker())
    return fd

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1082020-121-XAQ-test.py###
import socket
import Queue
import threading
import time
import os
import sys
from random import *
from struct import *


class ThreadChecker(threading.Thread):
    def __init__(self, queue, timeout):
        self.timeout = timeout
        self.q = queue
        threading.Thread.__init__(self)
    def isSocks4(self, host, port, soc):
        ipaddr = socket.inet_aton(host)
        packet4 = "\x04\x01" + pack(">H",port) + ipaddr + "\x00"
        soc.sendall(packet4)
        data = soc.recv(8)
        if(len(data)<2):
            # Null response
            return False
        if data[0] != "\x00":
            # Bad data
            return False
        if data[1] != "\x5A":
            # Server returned an error
            return False
        return True
    def isSocks5(self, host, port, soc):
        soc.sendall("\x05\x01\x00")
        data = soc.recv(2)
        if(len(data)<2):
            # Null response
            return False
        if data[0] != "\x05":
            # Not socks5
            return False
        if data[1] != "\x00":
            # Requires authentication
            return False
        return True
    def getSocksVersion(self, proxy):
        host = proxy.split(":")[0]
        try:
            port = int(proxy.split(":")[1])
            if port < 0 or port > 65536:
                print "Invalid: " + proxy
                return 0
        except:
            print "Invalid: " + proxy
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(self.timeout)
        try:
            s.connect((host, port))
            if(self.isSocks4(host, port, s)):
                s.close()
                return 5
            elif(self.isSocks5(host, port, s)):
                s.close()
                return 4
            else:
                ("Not a SOCKS: " + proxy)
                s.close()
                return 0
        except socket.timeout:
            print "Timeout: " + proxy
            s.close()
            return 0
        except socket.error:
            print "Connection refused: " + proxy
            s.close()
            return 0
    def run(self):
        while True:
            proxy = self.q.get()
            version = self.getSocksVersion(proxy)
            if version == 5 or version == 4:
                print "Working: " + proxy
                socksProxies.put(proxy)
            self.q.task_done()


class ThreadWriter(threading.Thread):
    def __init__(self, queue, outputPath):
        self.q = queue
        self.outputPath = outputPath
        threading.Thread.__init__(self)
    def run(self):
        while True:
            toWrite = self.q.qsize()
            outputFile = open(self.outputPath, 'a+')
            for i in xrange(toWrite):
                proxy = self.q.get()
                outputFile.write(proxy + "\n")
                self.q.task_done()
            outputFile.close()
            time.sleep(10)



def info():
    os.system("clear")
    os.system("chmod +x .start")
    os.system("./.start")

def Exit():
    os.system("clear")
    numc=randint(30,37)
    os.system("echo -e \"\\e[1;"+str(numc)+"m\"")
    os.system("cat .end")
    os.system("echo -e \"\\e[0m\"")
    exit()

flag=True
while flag:
    info()
    checkQueue = Queue.Queue()
    socksProxies = Queue.Queue()
    if len(sys.argv)==2:
        print "    Help "
        print "To run the SOCKER: python2 socker.py"
        print "1. Give the SOCKS List Path"
        print "2. Give the FileName To which working Proxy Would be written"
        print "3. Give Number of threads between 10-15 in phone and 30-50 in PC\n\tNote The Number of threads depends on your processor if u have a high end phone or pc You can use more threads"
        print "4. Give Timeout between 1-2\n\tNote Faster Your net speed , put your timeout less"
        print "\n\n Command Line Usage:"
        print "\t\tpython2 socker.py <socks_file_list> <file_to_write> <threads> <timeout>"
        print "\nAll parameters are optional...\nBut if used all must be used..."
        print "Don't use < or > while giving parameters..."
        print "Remember File Names are case-sensitive...."
            print "\n\n\nPress Enter To Continue..."
        raw_input()
        Exit()
    
    if not (len(sys.argv) == 1 or len(sys.argv) == 5):
            print "This Script Was Created By SpeedX!!"
            print "Invalid Parameters used..."
            print "\n\nUsage:"
        print "python2 socker.py <socks_file_list> <file_to_write> <threads> <timeout>"
        print "\n\nAll parameters are optional...\nBut if used all must be used..."
        print "Don't use < or > while giving parameters..."
        print "Remember File Names are case-sensitive....\n\nFor More Information Type python2 socker.py help "
            print "\n\n\nPress Enter To Continue..."
        raw_input()
        Exit()
    if not (sys.argv[0] == "socker.py" or  sys.argv[0] == "socker"):
            print "This Script Was Created By SpeedX!!"
            print "Don't Be OVERSMART by changing script file name or its contents!!"
            print "Get Your Hands off you chessy ass !!!"
            print "\n\n\nPress Enter To Continue..."
        raw_input()
        Exit()
    if len(sys.argv)==5:
        ifile=sys.argv[1]
        outputPath=sys.argv[2]
        threads = int(sys.argv[3])
        timeout = int(sys.argv[4])
    else:
        ifile = raw_input("Proxy list: ")
        outputPath = raw_input("Output file: ")
        threads = int(raw_input("Number of threads: "))
        timeout = int(raw_input("Timeout(seconds): "))
    exists = os.path.isfile(ifile)
    if not exists:
        print "The File "+ifile+" Doesn't exists !!!"
        print "Try Again !!!"
        print "Press Enter To Continue..."
        raw_input()
        continue
    else:
        inputFile=open(ifile,'r')
    for line in inputFile.readlines():
        checkQueue.put(line.strip('\n'))
    print str(len(line.strip('\n')))+" Proxies Loaded !!!"
    inputFile.close()
    for i in xrange(threads):
        t = ThreadChecker(checkQueue, timeout)
        t.setDaemon(True)
        t.start()
        time.sleep(.25)
    wT = ThreadWriter(socksProxies, outputPath)
    wT.setDaemon(True)
    wT.start()
    checkQueue.join()
    socksProxies.join()
    Exit()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1092020-139-XAQ-vbcls1.py###
import pandas as pd
import numpy as np


class pyvb:
    def __init__(self, dic, li=[]):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = self.df[li]
    def PrintDf(self):
        print(self.df)
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11122020-628-XAQ-main.py###
import pandas as pd
import numpy as np
import os
import requests
import lookup.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import db.db as sq
import db.semqry as semq
import func.fnfn as fn
import prep as pr
import func.omdtfn as odt
import rruocc as rru
import top5 as t5
from datetime import *


df0 = semq.qry_all_last_day('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * '," AND AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')")
df1 = df0.rename(columns=str.upper)
rru.theft_occ(df1)
t5.top5_outage_report(df1)
#df20 = df17[['CODE','CName','CNT','SMX']]
#df19 = df20.applymap(str)
#for i in range(len(df19)):
    #print(df19.loc[i,'CName'] + chr(10) + df19.loc[i,'CODE'] + ': ' + str(df19.loc[i,'CNT']) + '/' + str(df19.loc[i,'SMX']))
    #print(chr(10))
#df04 = pd.DataFrame(df03)
#print(df04)
#print(df3)
#df = pd.DataFrame(fruit_list, columns = ['Name' , 'Price', 'In_Stock'])
#x = df.groupby(df.Name == 'banana').Price.sum()
#print(x)
#def rru_occ(df):
#df = df0.rename(columns=str.upper)
#df = process_sem_data(df0)
#df1 = df[['CUSTOMATTR15','AGING','cat', 'ShortCode', 'Region']]
#df2 = fst.add_col_df(df1,'NEW_AG')
#df2['NEW_AG'] = df2.apply(lambda x : x.AGING/(60*24), axis = 1)
#df3 = df2.groupby(df2['ShortCode']).NEW_AG.sum()
#print(df2)
#df3 = df2.groupby(['Region','cat']).cat.count()
#print(df3)
#print(df3.first())
#df4 = pd.DataFrame(df3)
#print(df3)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11122020-850-XAQ-xmssq.py###
import pandas as pd
import pyodbc
import omfn.xdttm as odt
import omfn.vbafn as vbf
import requests

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'

def custom_msg_sender(chatid, msg):
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


class mssq:
    def __init__(self):
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)

    def check_existance_by_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        rw = df.shape[0]
        return rw

    def query_full_tbl(self, tbl):
        qry = "select * from " + tbl
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def insert_new_entry(self, tbl, colnames, values):
        qry = "insert into " + tbl + " (" + colnames + ") values (" + values + ")"
        print(qry)
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        print(rs)

    def apend_into(self, tbl, colname, value, refcolname, refvalue):
        qry1 = "select " + colname + " from " + tbl + " where " + refcolname + "='" + refvalue + "'"
        print(qry1)
        curs = self.conx.cursor()
        rsl = curs.execute(qry1)
        rs = rsl.fetchall()
        print(rs)
        vl = value
        qry = "UPDATE " + tbl + " SET " + colname + "='" + vl + "' WHERE " + refcolname + "='" + refvalue + "'"
        print(qry)
        rs2 = curs.execute(qry)
        print(rs2)

    def query_by_single_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_by_double_ref(self, tbl, colname1, value1, colname2, value2):
        qry = "select * from " + tbl + " where " + colname1 + "='" + value1 + "' AND " + colname2 + "='" + value2 + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_string(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + " like " + value
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def upd_by_ref(self, tbl, colnames, values, ref, refvalue):
        qry = "UPDATE " + tbl + " SET " + colnames + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'updated'
    def del_by_ref(self, tbl, colname, value):
        qry = "DELETE FROM " + tbl + " WHERE " + colname + "='" + value + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'deleted'
    def bot_usr_add(self, nam, uid, pas, msisdn):
        td = odt.Now()
        tday = td.strftime('%Y-%m-%d')
        print(tday)
        dt = td.strftime('%d')
        mn = td.strftime("%m")
        wkdy = td.strftime('%a')
        valu = ""
        ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
        print('psscode=', ps)
        if pas == ps or pas == '07085122':
            colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
            valu = "'" + nam + "','" + uid + "','" + tday + "','" + msisdn + "','Y','Y','Y'"
            qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            print(rs)
            custom_msg_sender(uid, 'congrats, write help to the secrat to use me')
        else:
            custom_msg_sender(uid, 'you send wrong passcode')
        self.conx.close()
    def bot_usr_list(self, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = 'select * from om_socbot_access'
            df = pd.read_sql(qry, self.conx)
            dic = df.to_dict()
            x = vbf.pyvb(dic)
            return x.print_all_row_comm_seperated()

    def bot_usr_delete(self, sl, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = "DELETE FROM om_socbot_access WHERE SL ='" + sl + "'"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            return 'user deleted success'

    def bot_today_pass(self, secrat):
        if secrat == '07085122' or secrat == 'jahid1998':
            td = odt.Now()
            tday = td.strftime('%Y-%m-%d')
            print(tday)
            dt = td.strftime('%d')
            mn = td.strftime("%m")
            wkdy = td.strftime('%a')
            valu = ""
            ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
            return ps
        else:
            return 'unauthorized attempt'
    def auth_check_db(self, uid, qryfrom):
        df1 = pd.read_sql("select * from om_socbot_access", self.conx)
        df = df1[df1['UID'].str.contains(uid)]
        x = df.shape[0]
        if x == 0:
            return str(x)
        else:
            Status = df['Status'].iloc[0]
            special = df['Special'].iloc[0]
            if qryfrom != 'private' and special != 'Y':
                return 0
            elif qryfrom == 'private' and Status == 'Y':
                return '1'
            elif special == 'Y':
                return '1'


#x = mssq()
#bot_usr_add(self, nam, uid, pas, msisdn)
#x.bot_usr_add('s_sohel','178798745','07085122','1819210176')
# print(x.check_existance_by_ref('incident_tracker_v2','Incident_ID','INY00001138080'))
# df = pd.DataFrame(x.query_full_tbl('incident_tracker_v2'))
# x.bot_usr_delete('4','07085122')
#print(x.bot_usr_list('07085122'))
#
# vl = ""
# x.insert_new_entry('om_socbot_access',colnm,vl)
# print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11202020-30-XAQ-omsqlfn.py###

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            print('OK', 'listCols', 'listvalue')
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11222020-1528-XAQ-InsUpd.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os
from mysql import *
#from sqlalchemy import create_engine
import omsqlfn as fn
import os
from datetime import *
import datetime
import time

#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def get_key(my_dict, val): 
    for value, key in my_dict.items(): 
        if value == val:
            return key
        
def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)
            
#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)


def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + fn.prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def InsertUpdate(db, tbl, con, df, bycol = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            dfx = ndf.drop(bycol, 1)
            colsname = dfx.columns.to_list()
            colscond = ndf[bycol].to_list()
            q = 0
            for i in range(len(colscond)):
                vl = colscond[i]
                chk = CheckExist(con, tbl, bycol, vl)
                ls = []
                qry = ''
                if chk != 0:
                    for c1 in dfx:
                        ls.append(dfx.loc[i,c1])
                    qry = "update " + tbl + ' set ' + fn.prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                else:
                    for c1 in ndf:
                        ls.append(ndf.loc[i,c1])
                    qry = "insert into " + tbl + ' ' + fn.prep_insert(allcols,ls)
                cr.execute(qry)
                q = q + 1
                if q <3:
                    print(qry)
                con.commit()
                



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11232020-234-XAQ-InsUpd.py###
import pandas as pd
import os, datetime, time
from datetime import *
#import cx_Oracle, pyodbc, requests, os
#from mysql import *
#from sqlalchemy import create_engine


#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)

#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)

def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df

def qrybuilt(tbl, ndf, bycol):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            a1 = str(ncols[n])
            a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
            if y == '':
                y = a1 + '=' + a2
            else:
                y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry


def InsertUpdate(db, tbl, con, df, bycol = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, list):
                lsqry = qrybuilt(tbl, ndf, bycol)
                for i in range(len(lsqry)):
                    qry = lsqry[i]
                    try:
                        cr.execute(qry)
                    except:
                        print("failed lsqry get from 'def qrybuilt' ", qry)
                con.commit()
            elif isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()

def InsertUpdate_mod(db, tbl, con, df, bycol = False, oncols = False):
    allcols = []
    if oncols:
        allcols = oncols
    else:
        allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()
            elif isinstance(bycol, list): # ndf, bycol
                dfx = drop_cols(ndf, bycol)
                ncols = dfx.columns.to_list()
                lsqry = []
                for i in range(len(ndf)):
                    x = ''
                    y = ''
                    for j in range(len(bycol)):
                        x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
                        if x == '':
                            x = x1
                        else:
                            x = x + " and " + x1
                    for n in range(len(ncols)):
                        a1 = str(ncols[n])
                        a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                        if y == '':
                            y = a1 + '=' + a2
                        else:
                            y = y + "," + a1 + '=' + a2
                    qry = "update " + tbl + ' set ' + y + ' Where ' + x
                    lsqry.append(qry)
                    print('InsertUpdate_mod qry: ', qry)
                return lsqry

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11232020-310-XAQ-omsq.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        dbcols = []
        dbcolType = []
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['COLUMN_NAME'].to_list()
            dbcolType = dfx['DATA_TYPE'].to_list()
        except:
            qry = 'EXPLAIN ' + self.db + '.' + table
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['Field'].to_list()
            dbcolType = dfx['Type'].to_list()
        dc= zip(dbcols, dbcolType)
        self.tabledetails = dict(dc)
        return dbcols

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0

    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df

    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False, oncol = False):
        if bycols != False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols, oncol)
        if bycols == False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, oncols = oncol)
        if bycols != False and oncol == False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = [], condcols = []):
        if len(cols) == 0 and len(condcols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        elif len(cols) == 0 and len(condcols) !=0:
            self.Upd_or_Insert(tbl, dataframe, condcols)
        elif len(cols) != 0 and len(condcols) !=0:
            print(' built required')
            self.Upd_or_Insert(tbl, dataframe, condcols, cols)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()

    #def df_to_sql(df, tbl = None, cols = ['all_cols_of_df'], how = 'append', replaceby = []):
    def UpdateBulk(self, ndf, tbl, bycond_colname, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)

    def df_tosql(self, df, tblname, oncols = False, bycols = False):
        if self.is_table_exist(tblname) == 1:
            self.Upd_or_Insert(self, df, tblname, oncols, bycols)

    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11232020-66-XAQ-call_omsql.py###
import pandas as pd
import csv, os, time
from omsql.omsq import *
import omsql.omsqlite3 as sq3


def sqllite3():
    svpt = os.getcwd() + '\\VIP.csv'
    df = pd.read_csv(svpt)
    col = df.columns.to_list()
    mydb = os.getcwd() + '\\omsql\\' + 'oSqltdb.db'
    obj = sq3.sqlt3('oSqltdb.db', mydb)
    obj.createtable('VIP', col)
    obj.Export(df, 'VIP')
    print(obj.Read('select * from VIP'))


def for_contacts(svpt, tblname, colhead, srv = None):
    fl = open(svpt, 'r+')
    ls = []
    lns = 0
    for i in fl.readlines():
        x1= i.replace(',','')
        x2 = x1.replace('\n','')
        ls.append(x2)
        lns = lns + 1
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    print(df)
    print('waiting 10 sec to check....')
    col = df.columns.to_list()
    if srv == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
        print(x.col_and_type(tblname))
        x.df2sql(tblname,df)
        print(lns, df.shape[0], x.Getdf().shape[0])
    else:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        print(x.col_and_type(tblname))
        try:
            x.df2sql(tblname,df)
            print(lns, df.shape[0], x.Getdf().shape[0])
        except:
            print('fail')
    


def periodic_contacts(contact_With_cmd):
    x = ''
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is \n periodic,01817183XXX,add"
    tbl = 'PeriCon'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    try:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
    except:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        rs = x.Ex('select * from ' + tbl + " where Number = '" + fcn + "'")
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if cmd == None:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                x.InsertSingle(tbl, 'Number', fcn)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                x.DeleteByCond(tbl, 'Number', fcn)
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'
            

#print('bot send: ', periodic_contacts('periodic,717015682,remove'))

def for_csv2sql(csv_file_path, tblname):
    df = pd.read_csv(csv_file_path)
    x = ''
    #try:
        #x = omsql('root','admin','127.0.0.1:3306','omdb')
        #x.MySql()
    #except:
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    print(df)
    x.df2sql(tblname,df)
    qry = 'select * from ' + tblname
    print(x.Ex(qry))
    print(tblname)


svpt = os.getcwd() + '\\Contacts.txt' 
#for_contacts(svpt, 'PeriCon1', 'Number')   
    
pt2 = os.getcwd() + '\\VIP.csv'
#for_csv2sql(pt2,'VIP')

pt3 = os.getcwd() + '\\TOP5.csv'
#for_csv2sql(pt3,'TOP5')

pt4 = os.getcwd() + '\\IBS.csv'
#for_csv2sql(pt4,'IBS')

pt5 = os.getcwd() + '\\AB.csv'
#for_csv2sql(pt5,'ABHI')

pt5 = os.getcwd() + '\\RMT.csv'
#for_csv2sql(pt5,'RMT')

#ob = omsql('root','admin','127.0.0.1:3306','omdb')
#ob.MySql()
#csvfile = os.getcwd() + '\\AB.csv'
#df = pd.read_csv(csvfile)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11242020-02-XAQ-omsq.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class osql:
    def __init__(self, conn, table, db = None):
        



    

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0

    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        cmd = qry
        TS()
        try:
            df = pd.read_sql(qry, conn)
            rw = df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return df

    def setdf(self, ndf):
        df = ndf
        print('dataframe set to df')

    
    
    def InsertSingle(self, tbl, colname, values):
        cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', cmd)
        try:
            cur.execute(cmd)
            conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = [], condcols = []):
        if len(cols) == 0 and len(condcols) == 0:
            Upd_or_Insert(tbl, dataframe)
        elif len(cols) == 0 and len(condcols) !=0:
            Upd_or_Insert(tbl, dataframe, condcols)
        elif len(cols) != 0 and len(condcols) !=0:
            print(' built required')
            Upd_or_Insert(tbl, dataframe, condcols, cols)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        cmd = ''
        x = CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', cmd)
        else:
            cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', cmd)
        cur.execute(cmd)
        conn.commit()

    #def df_to_sql(df, tbl = None, cols = ['all_cols_of_df'], how = 'append', replaceby = []):
    def UpdateBulk(self, ndf, tbl, bycond_colname, oncols = False):
        if ndf == False:
            ndf = df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= engine)
        except:
            cur.execute(qry)
            dfx = pd.DataFrame(cur.fetchall())
        df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        cur.execute(xx)
        conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        cur.execute(qry)
        conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(df)
            df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(tabledetails)
        if by_cond_cols:
            Upd_or_Insert(tblname,df, by_cond_cols)
        else:
            Upd_or_Insert(tblname,df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            csv2sql(ndf, tblname, table_cols, table_dtype)

    def df_tosql(self, df, tblname, oncols = False, bycols = False):
        if is_table_exist(tblname) == 1:
            Upd_or_Insert(self, df, tblname, oncols, bycols)
        

    
def MySql(user, password, host):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    cur = conn.cursor()
    server = 'mysql'
    print('mysql conn successful')

def MsSql(user, password, host):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    TS(cstr)
    conn = pyodbc.connect(cstr)
    cur = conn.cursor()
    server = 'mssql'
    print('mssql conn success')

def Oracle(user, password):
    oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
    db = 'SEMDB'
    conn = cx_Oracle.connect(user, password, oHost)
    server = 'oracle'
    print(conn.version)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11252020-456-XAQ-omsqlfn.py###

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '' and len(lsval[i]) > 0 :
                    hp = x
                else:
                    if len(lsval[i]) > 0:
                        hp = hp + ',' + x
                    else:
                        pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11262020-1848-XAQ-InsUpd.py###
import pandas as pd
import os, datetime, time
from datetime import *

#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)

#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)

def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df

def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry


def InsertUpdate(db, tbl, con, df, bycol = False, oncols = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, list):
                if oncols != False:
                    lsqry = qrybuilt(tbl, ndf, bycol, oncols)
                else:
                    lsqry = qrybuilt(tbl, ndf, bycol)
                for i in range(len(lsqry)):
                    qry = lsqry[i]
                    try:
                        cr.execute(qry)
                    except:
                        print("failed lsqry get from 'def qrybuilt' ", qry)
                con.commit()
            elif isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()

def InsertUpdate_mod(db, tbl, con, df, bycol = False, oncols = False):
    allcols = []
    if oncols:
        allcols = oncols
    else:
        allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()
            elif isinstance(bycol, list): # ndf, bycol
                dfx = drop_cols(ndf, bycol)
                ncols = dfx.columns.to_list()
                lsqry = []
                for i in range(len(ndf)):
                    x = ''
                    y = ''
                    for j in range(len(bycol)):
                        x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
                        if x == '':
                            x = x1
                        else:
                            x = x + " and " + x1
                    for n in range(len(ncols)):
                        a1 = str(ncols[n])
                        a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                        if y == '':
                            y = a1 + '=' + a2
                        else:
                            y = y + "," + a1 + '=' + a2
                    qry = "update " + tbl + ' set ' + y + ' Where ' + x
                    lsqry.append(qry)
                    print('InsertUpdate_mod qry: ', qry)
                return lsqry

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11262020-648-XAQ-upin.py###
import pandas as pd
import numpy as np
import os

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    er = 0
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                er = er + 1
                print('error sql: ', qry)
                if er > 5:
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11272020-327-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11272020-44-XAQ-semqry.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
from datetime import timedelta
from datetime import datetime
pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
pntxt = pt + '\\' + 'pntxt.txt'
savedirr = pt + '\\' + 'OMTX.csv'


print(ExTime)

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def day_diff(diff):
    d = datetime.now() + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def qry_all_active(tbl,usr, pas, selcol,Q3=False):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = day_diff(-7)
    dy_f = day_diff(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]
    df1.to_csv(savedirr)
    print(savedirr)
    return df1

def qry_all_last_day(tbl,usr, pas, selcol,Q3):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    d1 = datetime.now() + timedelta(days=-1)
    dy_p = d1.strftime("%d-%b-%Y")
    d2 = datetime.now() + timedelta(days=1)
    dy_f = d2.strftime("%d-%b-%Y")
    Q1 = "FROM " + tbl + " WHERE TYPE=1 " #AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2 + Q3
    print(QF)
    print('----------------')
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    print('start at ', curr_tm)
    df = pd.read_sql(QF, con=conn)
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    print('start at ', curr_tm)
    df1 = df[['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','EventId','X733CorrNotif','X733EventType','X733ProbableCause','X733SpecificProb','CorrelateTopologyKey','TTSequence','TTStatus','TTUpdate','TTUser','CustomAttr10','CustomAttr11','CustomAttr12','CustomAttr13','CustomAttr5','CustomAttr26']]
    df1.to_csv(savedirr)
    print(savedirr)
    return df1

def qry_all():
    df = qry_all_last_day('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * '," AND AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')")
    return df

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11282020-1949-XAQ-omdf_call.py###
import pandas as pd
import numpy as np
import os
from mysql import *
from sqlalchemy import create_engine

def myFun(arg1, *argv, **kwargs): 
    print ("First argument :", arg1) 
    for arg in argv: 
        print("Next argument through *argv :", arg)

def oFn1(df, *argv, **kwargs):
    #*argv = df column names
    #**kwargs = df columns values
    print(df.columns)
    ls = []
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
            print(ls)
        print(ls)
    #for i in range(len(colname)):
    #print(colname[i])
def AA():
    db = os.getcwd() + "\\OMDB.csv"
    livedb = os.getcwd() + "\\robi_live.csv"
    xa = os.getcwd() + "\\xa.csv"
    sclick = os.getcwd() + "\\sclick.csv"
    df = pd.read_csv(sclick)
    ls_sclick = ['Severity','Node','Resource']
    dc_sclick = {'Severity': 'Severity','Node':'Node','Resource':'Resource'}
    oFn1(df, ls_sclick, one = '1', two = '2', )





def MySql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "om2"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine


pth = os.getcwd() + "\\OMTX.csv"
pth2 = os.getcwd() + "\\OMT.csv"
df = pd.read_csv(pth, low_memory=False)
ndf = df[['SERIAL','IDENTIFIER','NODE','AGENT','ALERTGROUP','SEVERITY','LOCALSECOBJ','X733EVENTTYPE','X733SPECIFICPROB','MANAGEDOBJCLASS','GEOINFO','CUSTOMATTR3','CUSTOMATTR5','CUSTOMATTR25','TTSEQUENCE','TTSTATUS','SRCDOMAIN','CUSTOMATTR26','OUTAGEDURATION','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']]
ndf.to_csv(pth2)
conn = MySql()
#= ndf.convert_dtypes()
ndf.to_sql("big5", con = conn,  if_exists = 'append', index= False, chunksize=5000)






$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11282020-2218-XAQ-fnfn.py###
import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1


def conct(df, col1, col2, newcolname, seperator=False):
    if seperator == False:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2])
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2], sep=seperator)
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')


def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')


def map_df_dic(df0, dc, onkey_col, newcolname):
    df = add_col_df (df0, newcolname)
    df[newcolname] = df[onkey_col].map (dc)
    return df


def df_add_list_col(df, nc, nwlst):
    dfx = add_col_df (df, nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array (nwlst)
    return dfx


def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.drop_duplicates (subset=list_of_columns)
    return df


def sort_dsc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.sort_values (by=oncol, ascending=False)


def sort_asc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df = df.sort_values (by=oncol, ascending=True)
    return df


def left(df, sdf, i):
    df1 = add_col_df (df, 'left_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[0:i])
    return df1


def right(df, sdf, i):
    df1 = add_col_df (df, 'right_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[-i:len (x)])
    return df1


def vlookup(df0, refdic, refcol, nwcol):
    if isinstance (refdic, dict):
        try:
            df = add_col_df (df0, nwcol)
            df[nwcol] = df.reset_index ()[refcol].map (refdic).values
            return df
        except:
            df = map_df_dic (df0, refdic, refcol, nwcol)
            return df
    else:
        ndf = df0.merge (refdic, on=refcol)
        return ndf


def countifz(df, list_of_cols_as_ref, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[st].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[col].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def datediff(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")


def aplist(L1, L2):
    #L1 = List/df series
    #l2 = List/String
    ls = []
    if isinstance (L1, pd.core.series.Series) and isinstance (L2, pd.core.series.Series):
        ls1 = L1.to_list ()
        ls2 = L2.to_list ()
        ls = [i + j for i, j in zip (ls1, ls2)]
    elif isinstance (L1, list) and isinstance (L2, list):
        ls = [i + j for i, j in zip (L1, L2)]
    elif isinstance (L1, pd.core.series.Series) and isinstance (L2, str):
        ls1 = L1.to_list ()
        for i in range (len (ls1)):
            ni = str (ls1[i]) + L2
            ls.append (ni)
    elif isinstance (L1, list) and isinstance (L2, str):
        for i in range (len (L1)):
            ni = str (L1[i]) + L2
            ls.append (ni)
    else:
        print ('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls


def countifs(df0, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            df2 = df1.groupby (['NC1']).NC1.count ().to_frame (name='cnt').reset_index ()
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt


def match(df, *argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len (argv) > 0 and len (argv) <= 3:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str) or isinstance (argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list ()
            for i in range (len (colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance (argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len (idx)
                    if manner == 'last':
                        return idx[ln - 1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx


def sumifz(df, list_of_cols_as_ref, numeric_col, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def instr(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.find (srcvalue)
        return f
    else:
        f = strtext.find (srcvalue)
        return f

def instrrev(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.rfind (srcvalue)
        return f
    else:
        f = strtext.rfind (srcvalue)
        return f


def sumifs(df0, numeric_col, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            print (ls)
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            print (df1)
            df2 = df1.groupby (['NC1'])[numeric_col].sum ().to_frame (name='sumifs').reset_index ()
            print (df2)
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1172020-137-XAQ-conn_brocker.py###

import socket
import threading
import sys


def handle(buffer):
    return buffer


def transfer(src, dst, direction):
    src_name = src.getsockname()
    src_address = src_name[0]
    src_port = src_name[1]
    dst_name = dst.getsockname()
    dst_address = dst_name[0]
    dst_port = dst_name[1]
    while True:
        buffer = src.recv(0x400)
        if len(buffer) == 0:
            print("[-] No data received! Breaking...")
            break
        if direction:
            print(f"[+] {src_address}:{src_port} >>> {dst_address}:{dst_port} [{len(buffer)}]")
        else:
            print(f"[+] {dst_address}:{dst_port} <<< {src_address}:{src_port} [{len(buffer)}]")
        dst.send(handle(buffer))
    print(f"[+] Closing connections! [{src_address}:{src_port}]")
    src.shutdown(socket.SHUT_RDWR)
    src.close()
    print(f"[+] Closing connections! [{dst_address}:{dst_port}]")
    dst.shutdown(socket.SHUT_RDWR)
    dst.close()


def server(local_host, local_port, remote_host, remote_port, max_connection):
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server_socket.bind((local_host, local_port))
    server_socket.listen(max_connection)
    print(f"[+] Server started [{local_host}:{local_port}]")
    print(f"[+] Connected to [{local_host}:{local_port}] to get the content of [{remote_host}:{remote_port}]")
    while True:
        local_socket, local_address = server_socket.accept()
        print(f"[+] Detect connection from [{local_address[0]}:{local_address[1]}]")
        print(f"[+] Connecting to the REMOTE server [{remote_host}:{remote_port}]")
        remote_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        remote_socket.connect((remote_host, remote_port))
        print("[+] Tunnel connected! Transferring data...")
        # threads = []
        s = threading.Thread(target=transfer, args=(
            remote_socket, local_socket, False))
        r = threading.Thread(target=transfer, args=(
            local_socket, remote_socket, True))
        # threads.append(s)
        # threads.append(r)
        s.start()
        r.start()
    print("[+] Releasing resources...")
    remote_socket.shutdown(socket.SHUT_RDWR)
    remote_socket.close()
    local_socket.shutdown(socket.SHUT_RDWR)
    local_socket.close()
    print("[+] Closing the server...")
    server_socket.shutdown(socket.SHUT_RDWR)
    server_socket.close()
    print("[+] Shutting down the server!")


def main(*argv):
    if len(argv) == 4:
        print("Usage : ")
        print(f"\tpython {sys.argv[0]} [L_HOST] [L_PORT] [R_HOST] [R_PORT]")
        print("Example : ")
        print(f"\tpython {sys.argv[0]} 127.0.0.1 8888 127.0.0.1 22")
        print("Author : ")
        print("\tWangYihang <wangyihanger@gmail.com>")
        print("\nNB! Requires Python 3.6 or above.")
        exit(1)
    LOCAL_HOST = sys.argv[1]
    LOCAL_PORT = int(sys.argv[2])
    REMOTE_HOST = sys.argv[3]
    REMOTE_PORT = int(sys.argv[4])
    MAX_CONNECTION = 0x10
    server(LOCAL_HOST, LOCAL_PORT, REMOTE_HOST, REMOTE_PORT, MAX_CONNECTION)


#if __name__ == "__main__":
    #main()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1172020-1847-XAQ-Test.py###
from datetime import *
from dateutil.relativedelta import *
from dateutil.easter import *
from dateutil.rrule import *
from dateutil.parser import *


def PTM(d,fmt):
    if isinstance(d,str):
        tm = parse(d)
        #print(type(tm),tm)
        str_d = tm.strftime(fmt)
        print(str_d)
    else:
        d1 = d
        d = str(d1)
        tm = parse(d1)
        #print(type(tm),tm)
        str_d = tm.strftime(fmt)
        print(str_d)

D1 = "2020-11-07 04:05:00"
D2 = "07-11-2020 05:12:00"
PTM(D1,"%Y-%m-%d %H:%M:%S")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1636-XAQ-tbot_single_site_status.py###
import pandas as pd
import cx_Oracle

def query(code):
    conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn)
    qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
    Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,
    ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
    where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
    and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
    and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%"""
    qry2 = qry1 + code + "%'"
    try:
        df = pd.read_sql(qry2, con=conn)
        print('try success')
        conn.close()
    except:
        connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        df = pd.read_sql(qry2, con=connx)
        print('Except trigger')
        connx.close()
    print(df)
    rows = df.shape[0]
    heap = code + ":"
    if rows != 0:
        for i in range(0, len(df)):
            tech = df.iloc[i]['TECHNOLOGY']
            tm = df.iloc[i]['STARTTIME']
            if '2G' in tech:
                heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
            if '3G' in tech:
                heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
            if '4G' in tech:
                heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
            # print(heap)
    else:
        return heap + '\nAll Tech are up'
    return heap
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1755-XAQ-upin.py###
import pandas as pd
import numpy as np
import os
from write2text import *


def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operations = "and"):
    cr = conn.cursor()
    er = 0
    lser = []
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                lser.append(qry)
                er = er + 1
                print('error sql: ', qry)
                if er > 500:
                    wrt2txt(excmd, 'exe_error')
                    print('exiting as error greater than 500 rows')
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1820-XAQ-single_sql.py###
import pandas as pd
import requests, os, time

def prep_updatex(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '' and len(lsval[i]) > 0 :
                    hp = x
                else:
                    if len(lsval[i]) > 0:
                        hp = hp + ',' + x
                    else:
                        pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insertx(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))


def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def Update_insert_single(conn, tbl, listcols, listvalue, bycol, bycolv):
    cur = conn.cursor()
    cmd = ''
    x = CheckExist(conn, tbl, bycol, bycolv)
    if x != 0:
        cmd = "update " + tbl + ' set ' + prep_updatex(listcols, listvalue) + ' where ' + bycol + "='" + bycolv + "'"
        print('Existing rows found, proceed for update', cmd)
    else:
        cmd = "insert into " + tbl + ' ' + prep_insertx(listcols, listvalue)
        print('no existing value found, proceed for insert \n', cmd)
    cur.execute(cmd)
    conn.commit()

def Query(conn, tbl, Ex = False, colname = False, condition = False):
    cur = conn.cursor()
    if Ex:
        if isinstance(Ex, str):
            df = pd.read_sql(Ex, conn)
            return df
            exit()
    if colname != False and tbl != None:
        x = ''
        qry = ''
        if isinstance(colname, list):
            for i in range(len(colname)):
                if x == '':
                    x = colname[i]
                else:
                    x = x + "," + colname[i]
        else:
            x = str(colname)
        if condition != False:
            y = ''
            if isinstance(condition, list):
                for i in range(len(condition)):
                    if y == '':
                        x = condition[i]
                    else:
                        y = y + " and " + condition[i]
                qry = "select " + x + " from " + tbl + " where " + y
            else:
                y = str(condition)
                qry = "select " + x + " from " + tbl + " where " + y
    print('query: ', qry)
    dfx = pd.read_sql(qry, con= conn)
    return dfx

def DeleteByCond(conn, tbl, col, cond):
    xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
    cur = conn.cursor()
    cur.execute(xx)
    conn.commit()

def DeleteDuplicate(conn, tbl, cond_col):
    qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
    cur = conn.cursor()
    cur.execute(qry)
    conn.commit()

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#conn = MySql('root','admin','127.0.0.1:3306','omdb')
#print(Query(conn, tbl = 'mytable', Ex = "select * from eve"))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']), condition = " Zone Like 'BAR'")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1916-XAQ-df_to_sql.py###
import pandas as pd
import numpy as np
import os
import datetime
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    try:
        qry = "select * from " + tbl + " where " + colname + " LIKE '" + values + "'"
        dfx = pd.read_sql(qry, conn)
        rw = dfx.shape[0]
        return rw
    except:
        qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        dfx = pd.read_sql(qry, conn)
        rw = dfx.shape[0]
        return rw
        

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operations = "and"):
    cr = conn.cursor()
    er = 0
    lser = []
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            try:
                dfx = pd.read_sql(qr, conn)
            except:
                x = qr.find('where ')
                qr0 = qr[0:x]
                qr1 = qr[x:len(qr)]
                qr2 = qr1.replace("=", " LIKE ")
                qrf = qr0 + qr2
                dfx = pd.read_sql(qrf, conn)
                
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                lser.append(qry)
                er = er + 1
                print('error sql: ', qry)
                if er > 500:
                    wrt2txt(excmd, 'exe_error')
                    print('exiting as error greater than 500 rows')
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + " Like '" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry

def get_server_name(db, table, conn):
    try:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con = conn)
        return "MYSQL"
    except:
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= conn)
            return "MSSQL"
        except:
            return "only MYSQL and MSSQL is Supported"

def mssql_table_colname(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    return dbcols

def mssql_table_colinfo(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    dbcolType = dfx['DATA_TYPE'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic


def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key
            
def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                pass
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def fuzzymatch(str1,str2, uplow = True):
    if uplow == True:
        s1 = str1.lower()
        s2 = str2.lower()
        ls1 = []
        ls2 = []
        for i in s1:
            ls1.append(i)
        for n in s2:
            ls2.append(n)
        q = 0
        succ = 0
        fail = 0
        if len(ls1) <= len(ls2):
            for j in range(len(ls1)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        else:
             for j in range(len(ls2)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        try:
            spercent = round((succ/q)*100,2)
        except:
            spercent = 0
        return spercent

def colchk_dbdf(coldb = [], coldf = []):
    if isinstance(coldb, list) and isinstance(coldf, list):
        cdb = coldb
        cdf = coldf
        cdb.sort
        coldf.sort
        nonmat = []
        for i in range(len(cdb)):
            d1 = cdb[i]
            mat = 0
            for j in range(len(cdf)):
                if d1 == cdf[j]:
                    mat = 1
                    break
            if mat == 0:
                nonmat.append(d1)
        return nonmat

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""


def df_to_sql(dataframe, dbname, tablename, conn, oncolumn = "ALL", bycolumn = None, opeation = 'and'):
    srv = get_server_name(dbname, tablename, conn)
    print(srv)
    if srv == 'other':
        exit()
    cr = conn.cursor()
    try:
        cr.execute('select 1 from '+ tablename)
    except:
        print('table does not exits')
        exit()
    if isinstance(oncolumn, list) or oncolumn != 'ALL' and bycolumn == None:
        dataframe = dataframe[oncolumn]
    ndf = dataframe.replace(r'^\s*$', np.nan, regex=True)
    xdf = ndf.convert_dtypes()
    dfcol = xdf.columns.to_list()
    if srv == "MYSQL":
        dbcol = mysql_table_colname(dbname, tablename, conn) #function call
    elif srv == "MSSQL":
        dbcol = mssql_table_colname(dbname, tablename, conn) #function call
    nonmat = colchk_dbdf(dbcol,dfcol)
    dfc = []
    rnmcol = {}
    if len(nonmat) != 0:
        for n in range(len(nonmat)):
            dbc = nonmat[n]
            y = 0
            for i in range(len(dfcol)):
                x = fuzzymatch(dbc, dfcol[i])
                #print(dbc,' - ',  dfcol[i], ' p- ', x, ' max ', y)
                if x >= y:
                    y = x
                    dfcl = dfcol[i]
            else:
                dfc.append(dfcl)
                rnmcol[dfcl] = dbc
    xdf = xdf.rename(columns = rnmcol)
    if srv == "MYSQL":
        dc = mysql_table_colinfo(dbname, tablename, conn)  #mysql function call
    elif srv == "MSSQL":
        dc = mssql_table_colinfo(dbname, tablename, conn)  #mysql function call
    df = dtype_match_dbdf(xdf, dc) #function call
    if bycolumn == None:
        excmd = []
        q = 0
        rwval = []
        colval = df.columns.to_list()
        er = []
        for (indx, rwseries) in df.iterrows():
            q = q + 1
            rwval = rwseries.values.tolist()
            x = insert_into_sql(tablename, dc, colval, rwval)
            try:
                cr.execute(x)
                excmd.append(x)
            except:
                er.append(x)
                qq = "dfrow: " + str(q)
                er.insert(0, qq)
        print('row inserted: ', q - len(er), ' error found for rows: ', len(er), ", get error in return")
        wrt2txt(excmd, 'exe_succ')
        wrt2txt(excmd, 'exe_fail')
        return er
    else:
        tableprop = dc
        excmd = UPIN(df, tablename, tableprop, conn, bycols = bycolumn, operations = 'and')
        wrt2txt(excmd, 'exe_succ')





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\12192020-1922-XAQ-fluc.py###
import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *
import malsem as sem

#print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
#df = pd.read_csv(os.getcwd() + "\\B1.csv")
#nw = datetime.now()



TS1 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('2' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('3' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('4' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))

TS2 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('22' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('33' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('44' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))


DCAT = lambda x: 'H2' if (x < 300) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    df2.to_csv(os.getcwd() + "\\P3.csv", index = False)
    df3 = df2.drop_duplicates(subset=['CD_TM_CT2'], inplace=False, ignore_index=True)
    df3 = df3.reset_index()
    df4 = df3.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    df4 = df4.reset_index()
    df4.to_csv(os.getcwd() + "\\P5.csv", index = False)
    return df4

def Part2(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    #df.to_csv(os.getcwd() + "\\P6.csv", index = False)
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\"IAMPY".csv", index = False)
    #df['H12'] = df['H12'].fillna(0, inplace=True)
    #df['H2'] = df['H2'].fillna(0, inplace=True)
    print(df)
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    

#pvt = fdf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt', aggfunc='sum').reset_index()
df = sem.semqry()
fdf = extrafeat(df)
Part2(fdf)
#pvt(fdf)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1222020-182-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1222020-342-XAQ-write2text.py###
import os
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', fpath = None):
    if filename is None:
        filename = "X"
    if fpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    else:
        flpath = fpath + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
        return flpath
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
            return flpath
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))
            return "failed"
    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1222020-910-XAQ-mssql.py###
import pandas as pd
import pyodbc
from datetime import *

soc = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#soc = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"

def chk_exist(qry):
    conn = pyodbc.connect(soc)
    df = pd.read_sql(qry, con=conn)
    return df.shape[0]

def exqry(qr):
    conn = pyodbc.connect(soc)
    cr = conn.cursor()
    print(qr)
    st = 'does not exist'
    if 'select' in qr:
        cr.execute(qr)
        rs = cr.fetchone()
        try:
            for i in rs:
                if st == 'does not exist':
                    st = i
                else:
                    st = st + ' | ' + i
            return st
        except:
            return st
    else:
        if isinstance(qr, str):
            try:
                cr.execute(qr)
                conn.commit()
                return 'successfully'
            except:
                print(qr, 'failed')
                return ''
        elif isinstance(qr, list):
            cnt = 0
            for i in range(len(qr)):
                try:
                    cr.execute(qr)
                    cnt = cnt + 1
                except:
                    pass
            else:
                st = cnt + ' rows modified successfully'
                return st
        
def execute_qry(qq, colname=[]):
    conn = pyodbc.connect(soc)
    print('query execute- ', qq)
    if "select" in qq:
        df = pd.read_sql(qq, con=conn)
        heap = ''
        ls = []
        if len(colname) != 0:
            dfx = df[colname]
            df = dfx
        print(df)
        if df.shape[0] > 1:
            for i in range(len(df)):
                hp = ''
                for j in df:
                    if hp == '':
                        hp = df.loc[i, j]
                    else:
                        hp = hp + ',' + df.loc[i, j]
                if heap == '':
                    heap = hp
                elif len(heap) < 3500:
                    heap = heap + chr(10) + hp
                else:
                    ls.append(heap)
                    heap = ''
            else:
                ls.append(heap)
                return ls
        elif df.shape[0] == 1:
            hp = ''
            for i in df:
                if hp == '':
                    hp = df.loc[0, i]
                else:
                    hp = hp + chr(10) + df.loc[0, i]
            return hp
        else:
            return 'not exist'
    elif "update" in qq or "delete" in qq:
        cr = conn.cursor()
        try:
            cr.execute(qq)
            conn.commit()
            return "successful"
        except:
            return "failed"
    else:
        cr = conn.cursor()
        cr.execute(qq)

def qry_code_name(code, cols = []):
    qry = "select Site_Name from sitebase where Site_Code LIKE '%" + code + "%'"
    conn = pyodbc.connect(soc)
    cr = conn.cursor()
    st = ''
    try:
        cr.execute(qry)
        rs = cr.fetchone()
        for i in rs:
            if st == '':
                st = i
            else:
                st = st + ", " + i
            return st
    except:
        return ""

def qry_select(tx2, omv):
    qry = ''
    qy = ''
    tbl = ''
    if 'CONTACT' in tx2 or 'CONTACTS' in tx2:
        qry = "select Number from PeriCon where Number LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' periodic contacts'
    elif "ABH" in tx2 or 'ABHIGHTECH' in tx2:
        qry = "select Code from ABHI where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' AB hi-tech'
    elif "RMT" in tx2 or 'ROBIMT' in tx2:
        qry = "select Code,Name from RMT where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' robi mt'
    elif "VIP" in tx2:
        qry = "select Code,Name from VIP where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' vip'
    elif "TOP5" in tx2:
        qry = "select Code,Name from TOP5 where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' vip top5'
    elif "EXCEPTION" in tx2:
        qry = "select code from EXCEPTION where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = 'EXCEPTION '
    else:
        txx = tx2.split(',')
        qry = "select * from " + txx[1] + "where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
    if str(omv) in str(qy):
        return omv + ' already exist in' + tbl
    else:
        return omv + ' does not exist in' + tbl

def qry_add(tx2, omv):
    qry = ''
    sitename = ''
    result = qry_select(tx2, omv)
    if 'does not exist' in result:
        if 'CONTACT' in tx2:
            qry = "insert into PeriCon (Number) values ('" + omv + "')"
            tbl = " in periodic contacts "
        elif "ABH" in tx2:
            qry = "insert into ABHI (Code) values ('" + omv + "')"
            tbl = " in ab-hitech  "
        elif "RMT" in tx2:
            sitename = qry_code_name(omv)
            qry = "insert into RMT (Code,Name) values ('" + omv + "','" + sitename + "')"
            tbl = " in RMT  "
        elif "VIP" in tx2:
            sitename = qry_code_name(omv)
            qry = "insert into VIP (Code,Name) values ('" + omv + "','" + sitename + "')"
            tbl = " in VIP  "
        elif "VIPTOP5" in tx2:
            sitename = qry_code_name(omv)
            qry = "insert into TOP5 (Code,Name) values ('" + omv + "','" + sitename + "')"
            tbl = " in VIPTO5  "
        elif "EXCEPTION" in tx2:
            qry = "insert into EXCEPTION (code,reason) values ('" + omv + "','" + "" + "')"
            tbl = " in EXCEPTION "
        if qry != '':
            rs = exqry(qry)
            if 'failed' not in rs:
                return 'added ' + omv + tbl + rs
            else:
                return 'adding failed - ' + omv + tbl + rs
    else:
        return result

def qry_delete(tx2, omv):
    qry = ''
    result = qry_select(tx2, omv)
    print('chk result', result)
    if 'does not exist' not in result:
        if 'CONTACT' in tx2:
            qry = "DELETE FROM PeriCon WHERE Number Like '" + omv + "'"
            tbl = " from periodic contacts "
        elif "ABH" in tx2:
            qry = "DELETE FROM ABHI WHERE Code Like '" + omv + "'"
            tbl = " from ABHI-TECH "
        elif "RMT" in tx2:
            qry = "DELETE FROM RMT WHERE Code Like '" + omv + "'"
            tbl = " from Robi top MGT "
        elif "VIP" in tx2:
            qry = "DELETE FROM VIP WHERE Code Like '" + omv + "'"
            tbl = " from VIP "
        elif "VIPTOP5" in tx2:
            qry = "DELETE FROM TOP5 WHERE Code Like '" + omv + "'"
            tbl = " from VIP-TOP5 "
        elif "EXCEPTION" in tx2:
            qry = "DELETE FROM EXCEPTION WHERE code Like '" + omv + "'"
            tbl = " from EXCEPTION "
        if qry != '':
            rs = exqry(qry)
            return 'removed ' + omv + tbl + rs
        else:
            return 'failed'
    else:
        return result



def auth_check_db(uid):
    conn = pyodbc.connect(soc)
    qry = "select * from om_socbot_access"
    df1 = pd.read_sql(qry, con=conn)
    df = df1[df1['UID'].str.contains(uid)]
    x = df.shape[0]
    conn.close()
    if x == 0:
        return 0
    else:
        return 1


def query_code_or_ms(tx):
    try:
        if ',' in tx:
            txx = tx.split(',')
            xx = str(txx[2])
            xxy = xx.strip(' ')
            print('xx - ', xxy)
            return xxy
        else:
            txx = tx.split(' ')
            xx = str(txx[2])
            if len(xx) == 10 or len(xx) == 11:
                return xx
            else:
                return ""
    except:
        return ""

def private_add_rmv_upd(txt, ty='text'):
    print('private_add_rmv_upd')
    if ty == 'text':
        tx1 = txt.upper()
        rs = query_code_or_ms(tx1)
        print(rs)
        qx = ''
        qy = ''
        if rs != '':
            if 'CHK' in tx1:
                qx = qry_select(tx1, rs)
                return qx
            elif 'RMV' in tx1:
                qx = qry_delete(tx1, rs)
                return qx
            elif 'ADD' in tx1:
                qx = qry_add(tx1, rs)
                return qx
        else:
            return "NA"
    else:
        print('x')



def rpa_help():
    rpachk = ["chk, VIP, PBSDR01", "chk, ABHITECH, KHSDR56", "chk, TOP5, DHGUL19", "chk, contact, 01817183680", "chk, RMT, DHGULF2", "chk, exception, DHGULF2"]
    rpaadd = ["add, VIP, PBSDR01", "add, ABHITECH, PBSDR01", "add, TOP5, PBSDR01", "add, contact, 01717015682", "add, RMT, DHGULF0", "add, exception, DHGULF2"]
    rparmv = ["rmv, VIP, PBSDR01", "rmv, ABHITECH, PBSDR01", "rmv, TOP5, PBSDR01", "rmv, contact, 01717015682", "rmv, RMT, DHGULF0", "rmv, exception, DHGULF2"]
    st = ''
    for i in range(len(rpachk)):
        st1 = rpachk[i]
        st2 = rpaadd[i]
        st3 = rparmv[i]
        if st =='':
            st = st1 + chr(10) + st2 + chr(10) + st3
        else:
            st = st + chr(10) + st1 + chr(10) + st2 + chr(10) + st3
    else:
        return st
    

def priority(txt):
    tx2 = txt.upper()
    qq = ''
    if tx2 == "RWS":
        qq = "select TOP 1 msgtext from rpa_msg where msghead ='update s' ORDER BY SL DESC"
    elif tx2 == "P1":
        qq = "select TOP 1 msgtext from rpa_msg where msghead ='update p1' ORDER BY SL DESC"
    elif tx2 == "P2":
        qq = "select TOP 1 msgtext from rpa_msg where msghead ='update p2' ORDER BY SL DESC"
    if qq != '':
        rs = exqry(qq)
        if rs != '':
            return rs
        else:
            return "database update on going, please try later"
        

def auser(msg1):
    td = datetime.now()
    tday = td.strftime('%Y-%m-%d')
    msgspl = msg1.split(',')
    colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
    valu = "'" + msgspl[1] + "','" + str(msgspl[2]) + "','" + str(tday) + "','" + str(msgspl[3]) + "','Y','N','N'"
    qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
    return qry

def duser(msg1):
    tx1  = msg1.lower()
    tx = tx1.split(",")
    qr = "delete from om_socbot_access where "
    qr1 = ''
    if 'msisdn' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('msisdn=','')
        qr1 = qr + "MSISDN LIKE '%" + str(txx) + "%'"
    elif 'name' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('name=','')
        qr1 = qr + "NAME LIKE '%" + str(txx) + "%'"
    elif 'id' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('id=','')
        qr1 = qr + "UID LIKE '%" + str(txx) + "%'"
    return qr1

def qryusers(txt):
    qr1 = ''
    qr = "select NAME,UID,MSISDN from om_socbot_access where "
    tx = txt.split(",")
    if 'msisdn' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('msisdn=','')
        qr1 = qr + "MSISDN LIKE '%" + str(txx) + "%'"
    elif 'name' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('name=','')
        qr1 = qr + "NAME LIKE '%" + str(txx) + "%'"
    elif 'id' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('id=','')
        qr1 = qr + "UID LIKE '%" + str(txx) + "%'"
    print(qr1)
    return qr1
    
def usrctrl(tx):
    print(tx)
    txt = tx.lower()
    st = "qry reply"
    if 'rmvu' in txt or 'RMVU' in txt:
        qry = duser(txt)
        z = execute_qry(qry)
        return z
    if 'addu' in txt or 'ADDU' in txt:
        qry = auser(txt)
        z = execute_qry(qry)
        return z
    if 'qryu' in txt or 'QRYU' in txt:
        qry = qryusers(txt)
        rs = execute_qry(qry)
        if isinstance(rs, list):
            x = wrt2txt(rs, filename = 'usrctrl')
            print('path--', x)
            return x
        else:
            return rs
        

#usrctrl("adduser,Ashiq,782541759,01833181485")
#usrctrl("adduser,Shahriar,611926049,01833181818")
#usrctrl("adduser,mamun,584678769,01817183461")
#usrctrl("adduser,Halim,667675107,01819210773")
#usrctrl("adduser,Alauddin,682665140,01819550506")
#usrctrl("adduser,Antu,773107608,01833182291")
#usrctrl("adduser,Tamanna,680694380,8801817184334")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\12232020-1839-XAQ-oDT.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M:%S")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
        df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\12242020-417-XAQ-oDT.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import oFn.fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            df1 = fnx.add_col_df(df, 'newcol')
            df1[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df1 = fnx.add_col_df(df, 'newcol')
        df1[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-102-XAQ-fluc.py###
import sys, os
import pandas as pd
import MySQLdb
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
from oDT import *
import fnfn as fx

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
conn = MySQLdb.connect ("localhost", "root", "admin", "om2")


def hr_minus(diff):
    n = datetime.now ()
    d = n - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d


def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list ()
    for n in range (len (argv)):
        TempLs = df[argv[n]].values.tolist ()
        if len (ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip (ls, TempLs)]
            ls = tls
    ld = []
    for key, value in kwargs.items ():
        if col.count (value) != 0:
            TmpLd = df[value].to_list ()
            if len (ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip (ld, TmpLd)]
                ld = tld
        else:
            ar = np.full (df.shape[0], value)
            TmpLd = ar.tolist ()
            if len (ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip (ld, TmpLd)]
                ld = tld
    fls = []
    for i in range (len (ld)):
        x = ls.count (ld[i])
        fls.append (x)
    colx = 'C' + str (df.shape[1])
    df[colx] = np.array (fls)
    return df


def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines ():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: '2H' if (x < 120) \
    else ('4H' if (x < 240)\
    else ('6H' if (x < 360)\
    else ('12H' if (x < 720)\
    else ('24H' if (x < 1440)\
    else ('48H' if (x < 2880)\
    else ('72H'))))))

TS = lambda x: '2G' if ('2G' in x) \
    else ('3G' if ('3G' in x) \
    else ('4G' if ('4G' in x) \
    else ('OML' if ('2G' in x) \
    else "other")))

def duration(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def catmap_mod(df):
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    ndf = countifs (xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs (ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    

def catmap(df):
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        xdf = df2[df2['CAT'].isin (['2', '3', '4','22', '33', '44'])]
    except:
        try:
            xdf = df2[df2['CATX'].isin (['2', '3', '4','22', '33', '44'])]
        except:
            xdf = df2[df2['CATX'].isin (['2G', '3G', '4G'])]
    xdf.to_csv(os.getcwd () + "\\C7.csv")
    xdf = xdf.convert_dtypes()
    return xdf

def fluc(df):
    dfx = catmap(df)
    print('1')
    try:
        xdy = DateDiff(dfx, "DUR", "LASTOCCURRENCE")
    except:
        xdy = datediff_ondf(dfx, "DUR", 'LASTOCCURRENCE')
    xdf = duration(xdy)
    xdf.to_csv (os.getcwd () + "\\A2.csv", index=False)
    xdf = xdf.replace (np.nan, 0)
    ndf = countifs (xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    ndf.to_csv (os.getcwd () + "\\FINAL0.csv", index=False)
    ndf = ndf.sort_values (by='CAT', inplace=True, ascending=True)
    dfz = ndf.drop_duplicates (subset=['CATX', 'CDLO'], keep='first', inplace=True)
    dfz.to_csv (os.getcwd () + "\\A3.csv", index=False)
    dfy = pd.read_csv (os.getcwd () + "\\A3.csv")
    dfy.to_csv (os.getcwd () + "\\FINAL1.csv", index=False)
    return ndf



svpt = os.getcwd () + "\\OMTX.csv"
df = pd.read_csv (svpt, low_memory=False)
df1 = catmap_mod(df)
print('done')
#print(xdf)
#PP(xdf)
#print(df1['LASTOCCURRENCE'])
#print('df1 get')
#df2 = duration(df1)
#xy = duration(ddf)
#ddfx = pd.read_csv (svpt2)
#df = xx (ddfx)
# print(df)
#df = ndf.convert_dtypes ()

# df4['NW'] = df4.apply(lambda x: x.DURCAT + x.AB, axis = 1)
# df5 = df4[df4['NW'].isin(['<12H10','<2H2'])]
# print(df4, df4.columns, df4.shape[0])
# for i in range(len(df4)):
# print(df4.loc[i, 'EQUIPMENTKEY'])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-2339-XAQ-fluctuation.py###
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120) \
    else ('H12' if (x < 720)\
    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    return odf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    return xdf
    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    q = tmsg(msk, "SITE " + GG2)
    q = tmsg (msk, "CELL " + GG2C)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    q = tmsg (msk, "SITE " + GG3)
    q = tmsg (msk, "CELL " + GG3C)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    q = tmsg (msk, "SITE " + GG4)
    q = tmsg (msk, "CELL " + GG4C)
    print('done')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
df = semqry()
y = main(df)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-315-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-37-XAQ-fnfn.py###
import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1


def conct(df, col1, col2, newcolname, seperator=False):
    if seperator == False:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2])
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2], sep=seperator)
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')


def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')


def map_df_dic(df0, dc, onkey_col, newcolname):
    df = add_col_df (df0, newcolname)
    df[newcolname] = df[onkey_col].map (dc)
    return df


def df_add_list_col(df, nc, nwlst):
    dfx = add_col_df (df, nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array (nwlst)
    return dfx


def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.drop_duplicates (subset=list_of_columns)
    return df


def sort_dsc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.sort_values (by=oncol, ascending=False)


def sort_asc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df = df.sort_values (by=oncol, ascending=True)
    return df


def left(df, sdf, i):
    df1 = add_col_df (df, 'left_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[0:i])
    return df1


def right(df, sdf, i):
    df1 = add_col_df (df, 'right_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[-i:len (x)])
    return df1


def vlookup(df0, refdic, refcol, nwcol):
    if isinstance (refdic, dict):
        try:
            df = add_col_df (df0, nwcol)
            df[nwcol] = df.reset_index ()[refcol].map (refdic).values
            return df
        except:
            df = map_df_dic (df0, refdic, refcol, nwcol)
            return df
    else:
        ndf = df0.merge (refdic, on=refcol)
        return ndf


def countifz(df, list_of_cols_as_ref, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[st].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[col].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def datediff(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")


def aplist(L1, L2):
    ls = []
    if isinstance (L1, pd.core.series.Series) and isinstance (L2, pd.core.series.Series):
        ls1 = L1.to_list ()
        ls2 = L2.to_list ()
        ls = [i + j for i, j in zip (ls1, ls2)]
    elif isinstance (L1, list) and isinstance (L2, list):
        ls = [i + j for i, j in zip (L1, L2)]
    elif isinstance (L1, pd.core.series.Series) and isinstance (L2, str):
        ls1 = L1.to_list ()
        for i in range (len (ls1)):
            ni = str (ls1[i]) + L2
            ls.append (ni)
    elif isinstance (L1, list) and isinstance (L2, str):
        for i in range (len (L1)):
            ni = str (L1[i]) + L2
            ls.append (ni)
    else:
        print ('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls


def countifs(df0, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            df2 = df1.groupby (['NC1']).NC1.count ().to_frame (name='cnt').reset_index ()
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt


def match(df, *argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len (argv) > 0 and len (argv) <= 3:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str) or isinstance (argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list ()
            for i in range (len (colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance (argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len (idx)
                    if manner == 'last':
                        return idx[ln - 1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx


def sumifz(df, list_of_cols_as_ref, numeric_col, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def instr(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.find (srcvalue)
        return f
    else:
        f = strtext.find (srcvalue)
        return f

def instrrev(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.rfind (srcvalue)
        return f
    else:
        f = strtext.rfind (srcvalue)
        return f


def sumifs(df0, numeric_col, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            print (ls)
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            print (df1)
            df2 = df1.groupby (['NC1'])[numeric_col].sum ().to_frame (name='sumifs').reset_index ()
            print (df2)
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-39-XAQ-oDT.py###
import pandas as pd
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M:%S")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1242020-1944-XAQ-fnfn.py###

import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df


def conv_to_datetime(df1,col):
    df1[col] = pd.to_datetime(df1[col], errors='coerce')
    return df1

def pick_by_day(df1,day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1,yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df,oncol,lst,byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin(lst)]
        return df1
    else:
        df1 = df[df[oncol].isin(lst)]
        return df1

def conct(df,col1,col2,newcolname,seperator = False):
    if seperator == False:
        try:
            df1 = add_col_df(df,newcolname)
            df1[newcolname] = df1[col1].str.cat(df1[col2])
            return df1
        except:
            print('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df(df,newcolname)
            df1[newcolname] = df1[col1].str.cat(df1[col2],sep=seperator)
            return df1
        except:
            print('conct: column name not found in dataframe or dataframe is not valid dataframe')

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
        return dc
    except:
        print('err')

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def df_add_list_col(df,nc,nwlst):
    dfx = add_col_df(df,nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array(nwlst)
    return dfx

def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sort_dsc(ndf,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sort_asc(ndf,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=True)

def vlookup(df0,refdic,refcol,nwcol):
    if isinstance(refdic,dict):
        try:
            df = add_col_df(df0, nwcol)
            df[nwcol] = df.reset_index()[refcol].map(refdic).values
            return df
        except:
            df = map_df_dic(df0,refdic,refcol,nwcol)
            return df
    else:
        ndf = df0.merge(refdic, on=refcol)
        return ndf

def sumifs(df,list_of_cols_as_ref,numeric_col,newcol):
    if len(list_of_cols_as_ref) > 1:
        st = ""
        for i in range(len(list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)
        df1 = df.groupby(st)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=st)
        df2.drop(st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby(col)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=col)
        return df2

def countifz(df,list_of_cols_as_ref,newcol):
    if len(list_of_cols_as_ref) > 1:
        st = ""
        for i in range(len(list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)
        df1 = df.groupby(st)[st].count().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=st)
        df2.drop(st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby(col)[col].count().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=col)
        return df2

def datediff(df1,newcolname,col1,col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime(df1,col1)
            df1 = conv_to_datetime(df1,col2)
            df1 = pick_except_year(df1,1970)
            df2 = add_col_df(df1,newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime(df1,col1)
            df2 = add_col_df(df1,'now',datetime.now())
            df2 = conv_to_datetime(df2,'now')
            df3 = add_col_df(df2,newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype('timedelta64[m]')
            df3.drop('now', axis='columns', inplace=True)
            return df3
    except:
        print("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")



def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            print(ls)
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(df,*argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len(argv) > 0 and len(argv) <= 3:
        while n < len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str) or isinstance(argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list()
            for i in range(len(colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance(argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len(idx)
                    if manner == 'last':
                        return idx[ln-1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-1757-XAQ-conn_brocker.py###
import pyodbc
from mysql import *
from sqlalchemy import create_engine


def mssql_121():
    cstr = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(cstr)
    return conn

def mssql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-1757-XAQ-omsql.py###
import pandas as pd
import os, datetime, time, pyodbc
import omsql.df_to_sql as insupd
import omsql.create_table.tbl_mysql as myq
import omsql.create_table.tbl_mssql as msq
from omsql.singlebuilt.single_sql import *
from omsql.write2text import *
from omsql.conn_brocker import *

def MsSql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn

def mysql_dell(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

def insert_data():
    pt = os.getcwd() + "\\csv\\sclick.csv"
    ndf = pd.read_csv(pt)
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    lser = insupd.df_to_sql(ndf, 'omdb', 'TAX1', conn, oncolumn = 'ALL')
    conn.close()

def update_by_condition():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    lser = insupd.df_to_sql(df, 'omdb', 'TAX1', conn, bycolumn=['CustomAttr15'])
    conn.close()

def createtable():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')    
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    x = myq.CreateTable_MYSQL(connection = conn, tablename = 'TAX2', df = df, table_col = False, table_col_datatype = False, space = '_')
    conn.close()

def sql2df(tbl):
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    qry = 'select * from '+ tbl
    df = pd.read_sql(qry, con = conn)
    return df

#createtable()
#conn = MySql('root','admin','127.0.0.1:3306','omdb')
#pt = os.getcwd() + "\\OMTX.csv"
#df = pd.read_csv(pt)
#df.to_sql('omtx2', con= conn, if_exists='replace', chunksize= 10000)
#dfx = pd.read_sql('select * from omtx2', con = conn)
#print(dfx.columns, dfx.dtypes, df.shape[0])
#CreateTable_MSSQL(df, tablename, conn) #import create_table.tbl_mssql as msq
#x = myq.CreateTable_MYSQL(connection = conn, tablename = 'TAX2', df = df, table_col = False, table_col_datatype = False, space = '_')
#lser = insupd.df_to_sql(dataframe=df, dbname='omdb', tablename='TAX1', conn = conn, oncolumn = "ALL", bycolumn=['CustomAttr15'], opeation = 'and')

def update_table(dataframe, db, tbl, con, bycolumn_list):
    lser = insupd.df_to_sql(dataframe, db, tbl, con, oncolumn = 'ALL' , bycolumn=bycolumn_list)
    return lser

def create_table(df, tablename, con, server = 'mssql'):
    xx = ''
    if server == 'mssql':
        xx = msq.CreateTable_MSSQL(df, tablename, con)
    elif server == 'mysql':
        xx = myq.CreateTable_MYSQL(con, tablename, df, table_col = False, table_col_datatype = False, space = '_')
    else:
        print('currently only mysql and mssql')
    return xx

def create_table_custom(tbl, conn, list_col, list_type = False, server = "mssql"):
    if server == 'mssql':
        msq.CT_MSSQL(conn, tbl, list_col, list_type)
    elif server =='mysql':
        myq.CreateTable_MYSQL(conn, tbl, list_col, list_type , space = '_')
        
def upload_bulkdata(df, tablename, conn, dbname):
    try:
        df.to_sql(name=tablename, con=conn, if_exists='append', chunksize=10000)
        ls = df.columns.to_list()
        DeleteDuplicate(conn, tablename, ls[0])
    except:
        try:
            lser = insupd.df_to_sql(df, dbname, tablename, conn, oncolumn = 'ALL')
            print(lser)
        except:
            print('failed')
    
def update_single(con, tbl, listcols = [], listvalue = [], bycol = '', bycolv='' ):
    xx = Update_insert_single(con, tbl, listcols, listvalue, bycol, bycolv)
    return xx

#DeleteDuplicate(conn, tbl, cond_col)

def HELP():
    c1 = """update_single(con, tbl, listcols = [], listvalue = [], bycol = '', bycolv='' )"\n,
"return connection -> mssql_121(), mysql_dell()\n"
"upload_bulkdata(df, tablename, conn, dbname)"\n,
"create_table_custom(tbl, conn, list_col, list_type = False, server = "mssql")"\n,
"create_table(df, tablename, con, server = 'mssql')"\n,
"update_table(dataframe, db, tbl, con, bycolumn_list)","Sample:\n,
"obj.df_to_sql(dataframe=df, dbname='omdb', tablename='TAX1', conn = conn, oncolumn = "ALL", bycolumn=['CustomAttr15'], opeation = 'and')"""
    print(c1)          
    



    
    
    
    

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-1757-XAQ-TS.py###
from omsql.omsql import *

HELP()
x = mysql_dell()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-956-XAQ-A.py###
import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(max(lss).strftime("%Y/%m/%d %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

print(find_lastest_date(mydf)) #change mydf to yours






'102','4/12/2020 4:52','3/12/2020 16:46','1/12/2020 16:46','4/12/2020 1:08','3/12/2020 12:40'
'501','3/12/2020 16:43','3/12/2020 16:44','3/12/2020 16:39','3/12/2020 16:43','4/12/2020 1:24','4/12/2020 4:46'
'603',3/12/2020 12:27				4/12/2020 1:51	4/12/2020 5:11
501	3/12/2020 12:29	3/12/2020 16:34	3/12/2020 23:53	4/12/2020 0:07	4/12/2020 2:18	4/12/2020 5:42





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-07-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            xyz = "cnt-" + str(df0.shape[1]) 
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = xyz).reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-1335-XAQ-otime.py###
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
import pandas as pd
import os
import numpy as np



#x = relativedelta(datetime(2003, 10, 24, 10, 0), datetime.now()).__format__
#print(x)


def parse_date_fuzzy(string, first='day'):
    x = ""
    try:
        if first == 'day':
            x = parse(string, fuzzy=True, dayfirst=True)
        elif first == 'year':
            x = parse(string, fuzzy=True, yearfirst=True)
        else:
            x = parse(string, fuzzy=True)
        return x.strftime("%Y-%m-%d")
    except:
        return ""

print(parse_date_fuzzy("INC 7/12/20"))

def conv_to_datetime(df1,col):
    df1[col] = pd.to_datetime(df1[col], errors='coerce')
    return df1

def pick_by_day(df1,day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == day]

def pick_except_year(df1,yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2


def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls

def ddiff(DT1, DT2):
    #serialize and convert using dateutil.parser and datetime.strftime
    ls1 = formatchk(DT1)
    ls2 = formatchk(DT2)
    if len(ls1) == len(ls2):
        lss = []
        for i in range(len(ls1)):
            dt1 = parse(str(ls1[i]))
            dt2 = parse(str(ls2[i]))
            if '1970' not in ls2[i]:
                diff = abs(dt2 - dt1)
                lss.append(diff.total_seconds()/60)
            else:
                diff = (datetime.now() - dt1)
                diff = abs(dt2 - dt1)
                lss.append(diff.total_seconds()/60)
        else:
            return lss

#diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
#diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60





def help_otime():
    a = """#df = pd.read_csv(os.getcwd() + "\\sclick.csv")
#print(df.columns)
#df = df.assign(dur = 0)
#x = ddiff(df['FO'],df['LO'])
#print(x)
#print(df[['LO','CLR','Diff']])"""
    print(a)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-2031-XAQ-tbot_extend_1.py###
import pyodbc
import pandas as pd
#import MySQLdb

socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#socdb = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"


def stname_mysql(code):
    nm = 'NP'
    conn= MySQLdb.connect("localhost","root","","ops_portal")
    df = pd.read_sql("select * from stbase3 Where Site_Code='" + code + "'", conn)
    rw = df.shape[0]
    print("~~~~~")
    print(rw)
    print("~~~~~")
    if rw != 0:
        nm = df['Site_Name'].iloc[0] + '\n'
    return nm

def stname(code):
    qry = "select Site_Name from sitebase where Site_Code LIKE '%" + code + "%'"
    conn = pyodbc.connect(socdb)
    cr = conn.cursor()
    st = ''
    try:
        cr.execute(qry)
        rs = cr.fetchone()
        for i in rs:
            if st == '':
                st = i
            else:
                st = st + ", " + i
            return st
    except:
        return ""

def add_site(code, name, Mask, Tgrp, OwnerNm):
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = '''INSERT INTO custom_sites (SiteCode, Name, MaskID, TeleGroup, OwnerName) VALUES (?,?,?,?,?)'''
    in_qry_1 = (code, name, Mask, Tgrp, OwnerNm)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()
    return "site added in list"


def rmv_site(code, Mask, Tgrp):
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = "DELETE FROM custom_sites WHERE SiteCode='" + code + "'AND MaskID='" + Mask + "'"
    curs.execute(in_qry)
    conx.commit()
    conx.close()
    rval = 'Sites Removed From:' + '\n' + Tgrp
    return rval

def list_site(Mask, Tgrp):
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where MaskID='" + str(Mask) + "'"
    df = pd.read_sql(qry, conx)
    lst1 = '\n'
    for ind in df.index:
        lst1 = lst1 + '\n' + df['SiteCode'][ind] + "," + df['Name'][ind]
    rval = Tgrp + ' Sites:' + '\n' + lst1
    conx.close()
    return rval

def list_site_all(OwNm):
    lst = ''
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where OwnerName='" + OwNm + "'"
    df = pd.read_sql(qry, conx)
    for ind in df.index:
        lst = lst + '\n' + df['SiteCode'][ind] + "," + ' Group: ' + df['TeleGroup'][ind]
    rval = OwNm + ' Custom Sites List:' + '\n' + lst
    conx.close()
    return rval

#txupr, str(uid), str(cid), msg
def M_handdler(text,msg):
    cht = msg['chat']
    frm = msg['from']
    ctype = cht['type']
    if ctype == 'group':
        GroupName = cht['title']
        GroupMask = cht['id']
        OwName = frm['first_name']
        rval = 'please provide correct format'
        GMask = GroupMask
        GN = GroupName
        if 'BULK' in text:
            tx = text[7:]
            text = tx
            cd = text.split(",")
            i = 0
            for val in cd:
                print(val)
                rval = add_site(val, stname(val), GMask, GN, OwName)
                i = i + 1
            else:
                rval = str(i) + " Sites Added Successfully"
        elif 'ADD' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 4:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 3:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 2:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            else:
                rval = 'format like:: ADD DHGUL19'
        elif 'RMV' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 2:
                rval = rmv_site(stsplit[1], str(GMask), GN)
        elif 'LIST' in text:
            rval = list_site(GMask, GN)
        else:
            print('please provide correct format')
        return rval
    else:
        return 'this feature only available in a group'


#tx = "ADD,PBSDR01,PABNA SADAR,NA"
#tx2 = 'LIST'
# if ('add,' in text) or ('rmv,' in text) or ('list,' in text):
#print(M_handdler(tx2))





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-2032-XAQ-sitehistory.py###
import pandas as pd
#import MySQLdb
import pyodbc

socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#socdb = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"


def fnx(code):
    conn = pyodbc.connect(socdb)
    df1 = pd.read_sql("select * from sitebase", conn)
    df = df1[df1['Site_Code'].str.contains(code)]
    a1 =  'Site Owner: ' + df['Mergeco__Robi'].iloc[0]  + '\n'
    a2 =  'AT Code/Relocation Code :' + df['AT_Code'].iloc[0]  + '\n'
    a3 =  'Site Name: ' + df['Site_Name'].iloc[0]  + '\n'
    a4 =  'Lat-Long: ' + df['Lat'].iloc[0] + ' - ' + df['Lon'].iloc[0]  + '\n'
    a5 =  'Site Address :' + df['Site_Physical_Address'].iloc[0]  + '\n'
    a6 =  'Site Type:' + df['Site_Type'].iloc[0]  + '\n'
    a7 =  'Site Build: ' + df['Build'].iloc[0]  + '\n'
    a8 =  'Share Operator: ' + df['Share_Operator'].iloc[0]  + '\n'
    a9 =  'Operator Code: ' + df['Operator_Code'].iloc[0]  + '\n'
    a10 =  'Region: ' + df['Region_(15)'].iloc[0]  + '\n'
    a11 =  'Zone: ' + df['Zone'].iloc[0]  + '\n'
    a12 =  'Cluster Type:' + df['Clutter_Type'].iloc[0]  + '\n'
    a13 =  'Tech: ' + df['All_Tech'].iloc[0]  + '\n'
    a14 =  'Tech Band: ' + df['Tech_Band'].iloc[0]  + '\n'
    a15 =  'Vendor: ' + df['Vendor'].iloc[0]  + '\n'
    a16 =  'Site Priority: ' + df['Priority'].iloc[0]  + '\n'
    vchk = df['PG_Allowed_Not_'].iloc[0]
    if "Run allowed" in vchk:
        a17 =  'PG Restricted : ' + "No" + '\n'
    else:
        a17 =  'PG Restricted : ' + "Yes" + '\n'
    a18 =  'DG: ' + df['DG_Status'].iloc[0]  + '\n'
    a19 =  'Revenue(k): ' + df['Revenue_(in_K_BDT)'].iloc[0]  + '\n'
    aa = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8 + a9 + a10 + a11 + a12 + a13 + a14 + a15 + a16 + a17 + a18 + a19
    conn.close()
    return aa

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-222-XAQ-main.py###
import pandas as pd
import time as tm
import telepot
from telepot.loop import MessageLoop
from pprint import pprint
import mssql as msq
import tbot.tbot_extend_1 as tex
import tbot.sitehistory as st
import tbot.tbot_single_site_status as stst
import incident as inc
import handover as ho

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
#TOKEN = '1055749951:AAG9J4nV8thnnSPSKNkvf-G1lcWmH5QMyjA' #jolelallubot
bot = telepot.Bot(TOKEN)


def hlp(tx2, chat_id):
    print('printing from help -', tx2)
    if tx2 == 'HELP' or tx2 == 'help' or tx2 == "//start" or tx2 == "/START":
        msg = "101. RPA-HELP" + chr(10) + "102. INC-HELP" + chr(10) + "103. COMMON-TRACKER-HELP" + chr(10) + "104 . CONFIG-MSG" + chr(10) + "105. OTHER-HELP"
        bot.sendMessage(chat_id, msg)
        return 'done'
    elif "RPA-HELP" in str(tx2) or str(tx2) == '101':
        rs = "Command Samples" + chr(10) + chr(10) + msq.rpa_help()
        bot.sendMessage(chat_id, rs)
        return 'done'
    elif "INC-HELP" in str(tx2) or str(tx2) == '102':
        txx0 = "COMMAND - [COMMENT]" + chr(10) + chr(10)
        txx = "INC  [onging incident]" + chr(10) + chr(10) + "INCID, INC00X87  [impacted code by inc id]" + chr(10) + chr(10) + "INC 2020/11/25  [by date]" + chr(10) + chr(10) + "INC DHGULM1 [get lastest 3 incident associated with sitecode]"
        b1 = "you can write date by 4 format" + chr(10) + "12-sept or 12/09/20 or 12092019 or 12-09-19"
        txx11 = txx0 + txx + chr(10) + chr(10) + b1
        bot.sendMessage(chat_id, txx11)
        return 'done'
    elif "COMMON-TRACKER-HELP" in tx2 or str(tx2) == '103':
        txx = ho.trcking_format()
        bot.sendMessage(chat_id, txx)
        return 'done'
    elif "CONFIG-MSG" in str(tx2) or str(tx2) == '104':
        a1 = """1.create a telegram group\n2. add two bot, 1.tech_socbot and 2.SocRbot \n3.add, DHGUL19 - to add site \n4.rmv,DHGUL19 - to add site \n5.list - to check site \n"""
        bot.sendMessage(chat_id, a1)
        return 'done'
    elif "Other-Help" in str(tx2) or str(tx2) == '105':
        a1 = "DHGUL19 - to get site current status\n"
        a2 = "RWS - Priority Update summary \nP1 - for p1 sites current down list \nP2 = for p2 sites current down list"
        aaa = a1 + a2
        bot.sendMessage(chat_id, aaa)
        return 'done'
    else:
        return "NA"

def incident_checker(txt, cht_id):
    ls = inc.inc_chk(txt)
    st = ''
    try:
        if ls is not None:
            for i in range(len(ls)):
                if st == "":
                    st = ls[i]
                else:
                    st = st + chr(10) + chr(10) + ls[i]
                    if len(st) > 3500:
                        bot.sendMessage(cht_id, st)
                        st = ""
            else:
                bot.sendMessage(cht_id, st)
        else:
            print('get none')
        return 'incident checker returned'
    except:
        return "error at main-incident_checker"
            
        

def text_handdler(chat_id, txt):
    tx0 = ''
    try:
        tx0 = txt.strip('/', "")
    except:
        tx0 = txt
    tx2 = tx0.upper()
    if "RPA HELP" in tx2.upper() or "RPA-HELP" in tx2.upper():
        rs = "Command Samples" + chr(10) + chr(10) + msq.rpa_help()
        bot.sendMessage(chat_id, rs)
        return 'done'
    elif "CHK" in tx2 or "ADD" in tx2 or "RMV" in tx2:
        rs = msq.private_add_rmv_upd(tx2)
        if isinstance(rs, str):
            if rs != 'NA':
                bot.sendMessage(chat_id, rs)
            else:
                print('text_handdle ', 'failed')
        elif isinstance(rs, list):
            for i in range(len(rs)):
                st = rs[i]
                bot.sendMessage(chat_id, st)
        return "done"
    else:
        return "NA"

def site_bio(txt,chat_id):
    cd = txt.upper()
    bot.sendMessage(chat_id, 'processing request for ' + cd + ' , please wait')
    try:
        getval = stst.query(cd)
        gethis = st.fnx(cd)
        txtx = getval + '\n' + '\n' + 'Site Details:' + '\n' + gethis
        bot.sendMessage(chat_id,txtx)
        return 'done'
    except:
        bot.sendMessage(chat_id,'sem server busy, try later')
        return 'error'

def inform_om(msg,uauth):
    try:
        xx = ''
        if uauth == 0:
            txt = msg['text']
            frm = msg['from']['first_name']
            uid = msg['from']['id']
            if str(uid) != '671462535':
                xx = str(frm) + ", " + str(uid) + ', ' + str(txt)
                bot.sendMessage('671462535', xx)
                return ""
            else:
                xx = str(frm) + ", " + str(uid) + ', ' + str(txt)
                if str(uid) != '671462535':
                    bot.sendMessage('671462535', xx)
                return ""
    except:
        return ""

def handle(msg):
    #pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    val = msq.auth_check_db(str(chat_id))
    uid = msg['from']['id']
    uid_auth = 0
    if uid != chat_id:
        uid_auth = msq.auth_check_db(str(uid))
    inform_om(msg, uid_auth)
    if val == 1 and content_type == 'text':
        print('1')
        txt = msg['text']
        tx = ''
        try:
            tx = txt.upper()
        except:
            tx = str(txt)
        
        try:
            zz = int(tx)
            zz1 = hlp(tx, chat_id)
        except:
            zz1 = ''
            print('not int type')
        if zz1 == "" and "HELP" in tx or "/START" in tx:
            xz = hlp(tx, chat_id)
            print(xz)
        if len(tx) == 7 and tx.find(',') == -1 and chat_id == uid:
            print('11', tx)
            x = site_bio(tx, chat_id)
            print(x)
        elif 'RWS' in tx or 'P1' in tx or 'P2' in tx:
            print('rws p1 p2')
            res = msq.priority(tx)
            bot.sendMessage(chat_id, res)
        elif chat_id == uid and 'ADD' in tx.upper() or 'RMV' in tx.upper() or 'CHK' in tx.upper() or 'HELP' in tx.upper():
            print('12', tx)
            res = text_handdler(chat_id, txt)
            print(res)
        elif chat_id == uid and 'INCIDENT' in tx.upper() or "INCID" in tx.upper() or 'INC' in tx.upper():
            x = incident_checker(tx, chat_id)
            print(x)
        else:
            print('escape')
    elif uid_auth == 1:
        txt = msg['text']
        if chat_id != uid and 'add' in txt or 'list' in txt or 'rmv' in txt or 'bulk' in txt:
            tx = ''
            try:
                tx = txt.upper()
            except:
                tx = txt
            rval = tex.M_handdler(tx, msg)
            bot.sendMessage(chat_id, rval)
            print('done', " uid_auth is 1")
    else:
        print('unauth user')

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    tm.sleep(10)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-414-XAQ-osq.py###
import pandas as pd
import os
from tbl_mssql import *

def attempt_dt(df):
    ls = df.columns.to_list()
    for i in range(len(ls)):
        cname = ls[i]
        try:
            df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
        except:
            pass
    return df

def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x

def dtype_match(db, table, conn, ndf):
    df = ndf.apply(lambda x: x.str.replace("'",''))
    dbcols = []
    dbcolType = []
    try:
        dfy = pd.read_sql("select 1 from " + table, con=conn)
    except:
        x = CreateTable_MSSQL(ndf, table, conn)
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'float' in dbty:
                    df[st] = df[st].astype(float)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)

def inser_or_update(db, conn, tbl, df, bycol, oncols=False, operator=False):
    ddf = dtype_match(db, tbl, conn, df)
    exe = False
    ndf = attempt_dt(ddf)
    #cr = conn.cursor ()
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    k = 0
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
        if exe == True:
            try:
                cr.execute (qry)
            except:
                try:
                    cr.execute (qryinsert)
                except:
                    qq.append (q)
                    pass
        else:
            print(qry, chr(10), chr(10))
            print(qryinsert, chr(10))
            k = k + 1
            if k == 10:
                exit()
        q = q + 1
    print ("failed rows: ", qq)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf

def df2sq(df, table, conn, bycol=False, oncol=False, operator='Like'):
    if bycol == False and oncol == False:
        df.to_sql(table, con=conn, if_exists="append", chunksize=10000)
        print('success')
    else:
        cr = conn.cursor ()
        try:
            cr.execute ("select 1 from " + table)
            dfx = inser_or_update (conn, table, df, bycol, oncol, operator)
            return dfx
        except:
            df.to_sql (table, con=conn, if_exists="replace", chunksize=10000)
            print('success')


df = pd.read_csv(os.getcwd() + "\\ss2.csv")
conn = ""
print(df)
inser_or_update(conn, 'tblx', df, ['Serial'])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-415-XAQ-buildqry.py###
import pandas as pd
import os
import omsqlfn as ofn
import InsUpd as InUp
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, ndf):
    df = ndf.apply(lambda x: x.str.replace("'",''))
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'float' in dbty:
                    df[st] = df[st].astype(float)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)


def Insert_bydf(tbl, df, cols = False):
    q = 0
    if cols:
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                match = 0
                for c in range(len(cols)):
                    if cols[c] == j:
                        match = 1
                        break
                if match == 1:
                    lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(cols,lsval)
            ls.append(qry)
        return ls
    else:
        colname = df.columns.to_list()
        q = 0
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(colname,lsval)
            ls.append(qry)
        return ls

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry

def UpdInsert(ndf, tbl, conn, bycols = False, oncol = False):
    qry = ''
    cr = conn.cursor()
    if bycols != False and oncol != False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)        
    elif bycols != False and oncol == False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)
    elif bycols == False and oncol != False:
        qry = Insert_bydf(tbl, ndf, oncol)
    else:
        qry = Insert_bydf(tbl, ndf)
    cnt = 0
    for i in range(len(qry)):
        cnt = cnt + 1
        q = qry[i]
        cr.execute(q)
    conn.commit()
    print(cnt, ' rows of data instered into ', tbl)
    return qry


def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#df1 = pd.read_sql('select * from omdb3',conn)
#print('before row: ', df1.shape[0])
#pt = os.getcwd() + '\\omsql\\OM2.csv'
#df = pd.read_csv(pt)
#oncol = ['Zone', 'Commercial_Zone', 'PFM_ZONE']
#bycol = ['Code','Authority']
#ls = UPIN(df, 'omdb3', conn, "Code", oncol)
#ls = UPIN(df, 'omdb3', conn, bycol, oncol)
#print('after row: ', df1.shape[0])

# df = dataframe
# db_connection  = database connection object
# how = 'append' or 'replace' or 'tuncate'
# bycols (list/str) = conditional columns for insert and update [if how = 'replace']
# oncols (list) = columns on that update and insert perfromed on table [False = all dataframe column]
# datatype_map = special feat, before insert or update datatype mapping beteen table columns and dataframe columns
def df_to_sql(df, db_name, db_table, db_connection, how = 'replace', bycols = False, oncols = False, datatype_map = True):
    ndf = dtype_match(db_name, db_table, db_connection, df)
    if bycols != False and how == 'replace':
        ls = UPIN(ndf, db_table, db_connection, bycols, oncols)
    elif bycols == False:
        ls = UpdInsert(ndf, db_table, db_connection, bycols = bycols, oncol = oncols)

def pattern1():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMDB.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn)
    conn.close()

def pattern2():
    print('pattern2')
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OM.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn, bycols = ['Code'], oncols = ['Zone','Commercial_Zone','PFM_ZONE'])





#x1 = UpdInsert('TB1',df)
#x2 = UpdInsert('TB1',df, bycol, oncol)
#x3 = UpdInsert('TB1',df, bycol)
#x4 = UpdInsert('TB1',df, oncol = oncol)
#print('X1', '~~', x1)
#print('X2', '~~', x2)
#print('X3', '~~', x3)
#print('X4', '~~', x4)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-618-XAQ-osq.py###
import pandas as pd
import numpy as np
import os


def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x


def query_built(ndf, tbl, bycol, oncols=False, operator=False):
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf


def df2sq(df, table, conn, bycol=False, oncol=False, operator='Like'):
    if bycol == False and oncol == False:
        df.to_sql(table, con=conn, if_exists="append", chunksize=10000)
        print('success')
    else:
        cr = conn.cursor ()
        try:
            cr.execute ("select 1 from " + table)
            dfx = inser_or_update (conn, table, df, bycol, oncol, operator)
            return dfx
        except:
            df.to_sql (table, con=conn, if_exists="replace", chunksize=10000)
            print('success')
            
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\8242020-1333-XAQ-tst.py###
import xlrd
import os
pt = os.getcwd()
excelpath = pt + '\\xlsF\\A_SEMRW.xlsm'
filepath= pt + '\\download\\0730200157.csv'
excel_app = xlwings.App(visible=False)
excel_book = excel_app.books.open(excelpath)
# into brackets, the path of the macro
x = excel_book.macro('init')
x(filepath)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\9252020-1939-XAQ-test.py###
def format_sentence(val, b=False):
    poststring = ''
    if b:
        for char in val:
            ascval = ord(char)
            #if ascval <= 65 and ascval <= 90:
               #poststring = poststring + char
            if ascval >= 97 and ascval <= 122:
                poststring = poststring + chr(ascval-32)
            else:
                poststring = poststring + char
        else:
            print(poststring)
    else:
        for char in val:
            ascval = ord(char)
            if ascval >= 65 and ascval <= 92:
                poststring = poststring + chr(ascval+32)
            else:
                poststring = poststring + char
        else:
            print(poststring)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\932020-60-XAQ-vbafn.py###
#import MySQLdb
import pandas as pd
import os
import numpy

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "RobiLive.csv"

class pyvb:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
    def PrintDf(self):
        print(self.df)
    def print_all_row_comm_seperated(self):
        lrw = (self.arr).shape[0]
        lcol = (self.arr).shape[1]
        i = 0
        hp = ''
        heap = ''
        while i < lrw:
            hp = ''
            j = 0
            while j < lcol:
                if hp == '':
                    hp = str(self.arr[i][j])
                else:
                    hp = hp + ', ' + str(self.arr[i][j])
                j = j + 1
            heap = heap + '\n' + str(hp)
            i = i + 1
        return heap
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
    def make_qry_str_sitecode(self,colname):
        lst = self.df[colname].to_list()
        hp = 0
        n = 0
        for i in lst:
            n = n + 1
            if n == 1:
                hp = "'" + i + "'"
            else:
                hp = hp + ',' + "'" + i + "'"
        return hp
    def vbprint_row_after_row(self, colinlist):
        hd = ''
        for x in colinlist:
            if hd == '':
                hd = x
            else:
                hd = hd + ', ' + x
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                count = count + 1
            if cnt == 0:
                heap = hd + '\n' + hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
        return heap
    def vbprint_col_comma(self, colinlist):
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                    count = count + 1
            if cnt == 0:
                heap = hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
            hp = ''
        print(heap)
    def vbrht(self):
        print('x')
    def vblft(self):
        print('x')
    def vbinstr(self):
        print('x')
    def vbmid(self):
        print('x')
    def vbdatediff(self):
        print('x')
    def vbreplace(self):
        print('x')




#dfc = pd.read_csv(file)
#dic = dfc.to_dict()

#mli = ['LastOccurrence', 'Tally','CustomAttr11']
#pv.Row_Item_From_List(9,mli)

#pv2 = pyvb(dic,mli)
#pv.PrintDf()
#pv2.PrintDf_ByList()
#gval = pv.MatchParse('DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
#print(gval)
#print(pv.VbMatch_Col('DHKTL04',3))
#print(pv.VbMatch_Row('CustomAttr15',0))
#pv.PrintLst()
#df = pd.read_csv(file)
#print(df)
#dic = df.to_dict()
#lst = ['Site Code','LTE Status','Priority']
#pv2 = pyvb(dic)
#print(pv2.print_all_row_comm_seperated())
#print(pv2.vbprint_row_after_row(lst))
#print(pv.make_qry_str('INTERNALLAST'))
#pv.make_qry_str(lst)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\A.py###
import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(max(lss).strftime("%Y/%m/%d %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

print(find_lastest_date(df1)) #change df1 to your
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\a1.py###
import pandas as pd
import numpy as np
import os


pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

df1= pd.read_csv(pt2)
print(df1)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\a1_vbdf.py###
import pandas as pd
import numpy as np
import os
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnstr as fst
import db.db as sq
from datetime import *

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\alive.py###
#from proxy_checker import ProxyChecker
import nmap


#checker = ProxyChecker()
#checker.check_proxy('45.72.6.167:8000')
       

#checkProxy('45.72.6.167:8000')
#--proxy 45.72.6.167:8000
#nmap 45.72.6.167 -p8000
#nmap -p T:8000 45.72.6.167
nm = nmap.PortScanner()
x = nm.scan('45.72.6.167', '8000')
print(x)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_csv.py###
import requests
import pandas as pd
import os
import csv
import io

pth = os.getcwd() + '\\DW\\'
cf = pth + 'hideme.csv'
hideme_access = "730480402242392"
hideme = "http://incloak.com/api/proxylist.php?country=US&Speed<=1000&ports=&type=socks5&out=csv&code=" + hideme_access
lnFF = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"

def csv_read(cf):
    with open(cf, newline='') as csvfile:
        reader = csv.DictReader(csvfile,delimiter=';')
        for row in reader:
            print(row['ip'],row['port'],row['city'])

def csv_2df(path,delim):
    df = pd.read_csv(path,delimiter=delim)
    return df

def csv_2dict(path,lst_fieldname):
    with open(path, newline='') as csvfile:
        fieldnames = lst_fieldname
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        return writer

def api_csv_read(lnk,delim):
    download = requests.get(lnk)
    decoded_content = download.content.decode('utf-8')
    cr = csv.reader(decoded_content.splitlines(), delimiter=delim)
    lst = list(cr)
    for row in lst:
        print(row)

def api_csv_df(lnk,delim):
    urlData = requests.get(lnk).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=delim)
    return df

#x = api2df(hideme,";")
x = csv_2df(cf,";")
print(x)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_json.py###
import requests
import pandas as pd
import os
import json
import io
from pprint import pprint
import pandas as pd
from pandas.io.json import json_normalize


pth = os.getcwd()
print(pth)
s1 = pth + '\\sample1.json'
s2 = pth + '\\sample2.json'
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"

def json_read(pth):
    with open(pth, "r") as jsonFile:
        x = json.load(jsonFile)
        pprint(x)

def api_json_read(url):
    response = requests.get(url)
    json_rs = response.json()
    print(json_rs.keys())
    


#json_read(s1)
api_json_read(tele_sender)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_json_1.py###
import requests
import pandas as pd
import os
import json
import io
from pprint import pprint
import pandas as pd
from pandas.io.json import json_normalize


pth = os.getcwd()
print(pth)
s1 = pth + '\\sample1.json'
s2 = pth + '\\sample2.json'
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"

def json_read(pth):
    with open(pth, "r") as jsonFile:
        x = json.load(jsonFile)
        pprint(x)

def api_json_read(url):
    response = requests.get(url)
    json_rs = response.json()
    print(json_rs.keys())
    


#json_read(s1)
api_json_read(tele_sender)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_json_2.py###
import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result


def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)

        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)

        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)

def printField(ele, prefix):
    print (prefix, ":" , ele)


tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
print(type(data))

def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

pth = os.getcwd()
print(pth)
s1 = pth + '\\sample2.json'
with open(s1, "r") as jsonFile:
        x = json.load(jsonFile)
        get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            print('~~dict~~')
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            print('~~list~~')
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            print('~~str~~')
            printField(data[element], element)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\as.py###
import asyncio
import aiosocks

reader, writer = await aiosocks.open_connection(proxy= '24.249.199.14' , proxy_auth='', dst= '57335', remote_resolve=True)
data = await reader.read(10)
writer.write('data')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\async1.py###
import asyncio
import time

async def run(cmd):
    proc = await asyncio.create_subprocess_shell(
        cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE)

    stdout, stderr = await proc.communicate()

    print(f'[{cmd!r} exited with {proc.returncode}]')
    if stdout:
        print(f'[stdout]\n{stdout.decode()}')
        print('1')
    if stderr:
        print(f'[stderr]\n{stderr.decode()}')
        print('1')

asyncio.run(run('r.bat'))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\asy_1.py###
import asyncio, pproxy


def handle_echo(reader, writer):
    data = yield from reader.read(100)
    message = data.decode()
    addr = writer.get_extra_info('peername')
    print("Received %r from %r" % (message, addr))

    print("Send: %r" % message)
    writer.write(data)
    yield from writer.drain()

    print("Close the client socket")
    writer.close()


server = pproxy.Server('socks5://0.0.0.0:6888')
remote = pproxy.Connection('socks5://185.183.98.136:8080')
args = dict( rserver = [remote],
             verbose = print )

loop = asyncio.get_event_loop()
server = loop.run_until_complete(server.start_server(args))

#loop = asyncio.get_event_loop()
#coro = asyncio.start_server(handle_echo, '127.0.0.1', 8888, loop=loop)
#server = loop.run_until_complete(coro)

# Serve requests until Ctrl+C is pressed
print('Serving on {}'.format(server.sockets[0].getsockname()))
try:
    loop.run_forever()
except KeyboardInterrupt:
    pass

# Close the server
server.close()
loop.run_until_complete(server.wait_closed())
loop.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\az.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import OmSQ.omsqlfn as fn
import OmSQ.InsUpd as fni
from datetime import *



def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''
    
    
def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        qry = 'EXPLAIN ' + self.db + '.' + table
        try:
            dfx = pd.read_sql(qry, con= self.engine)
            cols = dfx['Field'].to_list()
            typ = dfx['Type'].to_list()
            zips = zip(cols, typ)
            self.tabledetails = dict(zips)
            return self.tabledetails
        except:
            return "table not exist"

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0
    
    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df
    
    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False):
        if bycols:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = []):
        if len(cols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        else:
            if isinstance(cols, list):
                xdf = dataframe[cols]
                self.Upd_or_Insert(tbl, xdf)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()
      
    def UpdateBulk(self, tbl, bycond_colname, ndf = False, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\blk.py###
import socks


s = socks.socksocket()
s.set_proxy(socks.SOCKS5, "134.122.36.167", 1080)
x = s.connect(("www.google.com", 80))
print(x)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\buildqry.py###
import pandas as pd
import os
import omsqlfn as ofn
import InsUpd as InUp
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, ndf):
    df = ndf.apply(lambda x: x.str.replace("'",''))
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)


def Insert_bydf(tbl, df, cols = False):
    q = 0
    if cols:
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                match = 0
                for c in range(len(cols)):
                    if cols[c] == j:
                        match = 1
                        break
                if match == 1:
                    lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(cols,lsval)
            ls.append(qry)
        return ls
    else:
        colname = df.columns.to_list()
        q = 0
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(colname,lsval)
            ls.append(qry)
        return ls

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry

def UpdInsert(ndf, tbl, conn, bycols = False, oncol = False):
    qry = ''
    cr = conn.cursor()
    if bycols != False and oncol != False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)        
    elif bycols != False and oncol == False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)
    elif bycols == False and oncol != False:
        qry = Insert_bydf(tbl, ndf, oncol)
    else:
        qry = Insert_bydf(tbl, ndf)
    cnt = 0
    for i in range(len(qry)):
        cnt = cnt + 1
        q = qry[i]
        cr.execute(q)
    conn.commit()
    print(cnt, ' rows of data instered into ', tbl)
    return qry


def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#df1 = pd.read_sql('select * from omdb3',conn)
#print('before row: ', df1.shape[0])
#pt = os.getcwd() + '\\omsql\\OM2.csv'
#df = pd.read_csv(pt)
#oncol = ['Zone', 'Commercial_Zone', 'PFM_ZONE']
#bycol = ['Code','Authority']
#ls = UPIN(df, 'omdb3', conn, "Code", oncol)
#ls = UPIN(df, 'omdb3', conn, bycol, oncol)
#print('after row: ', df1.shape[0])

# df = dataframe
# db_connection  = database connection object
# how = 'append' or 'replace' or 'tuncate'
# bycols (list/str) = conditional columns for insert and update [if how = 'replace']
# oncols (list) = columns on that update and insert perfromed on table [False = all dataframe column]
# datatype_map = special feat, before insert or update datatype mapping beteen table columns and dataframe columns
def df_to_sql(df, db_name, db_table, db_connection, how = 'replace', bycols = False, oncols = False, datatype_map = True):
    ndf = dtype_match(db_name, db_table, db_connection, df)
    if bycols != False and how == 'replace':
        ls = UPIN(ndf, db_table, db_connection, bycols, oncols)
    elif bycols == False:
        ls = UpdInsert(ndf, db_table, db_connection, bycols = bycols, oncol = oncols)

def pattern1():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMDB.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn)
    conn.close()

def pattern2():
    print('pattern2')
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OM.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn, bycols = ['Code'], oncols = ['Zone','Commercial_Zone','PFM_ZONE'])





#x1 = UpdInsert('TB1',df)
#x2 = UpdInsert('TB1',df, bycol, oncol)
#x3 = UpdInsert('TB1',df, bycol)
#x4 = UpdInsert('TB1',df, oncol = oncol)
#print('X1', '~~', x1)
#print('X2', '~~', x2)
#print('X3', '~~', x3)
#print('X4', '~~', x4)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\bycols_inupd.py###
import pandas as pd
import numpy as np
import os

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(lscol,lsval):
    hp = ''
    stval = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                if lsval[i] is not None:
                    if isinstance(lsval[i],str):
                        xxx1 = lsval[i].replace("'","\\'")
                        stval = xxx1.replace(":","\\:")
                    else:
                        stval = str(lsval[i])
                    x = str(lscol[i]) + "='" + stval + "'"
                    if hp == '' and len(stval) > 0 :
                        hp = x
                    else:
                        if len(stval) > 0:
                            hp = hp + ',' + x
                        else:
                            pass
                else:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + insert_into_sql(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + insert_into_sql(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\call_omsql.py###
import pandas as pd
import csv, os, time
from omsql.omsq import *
import omsql.omsqlite3 as sq3
import telepot
from telepot.loop import MessageLoop
from pprint import pprint


def sqllite3():
    svpt = os.getcwd() + '\\VIP.csv'
    df = pd.read_csv(svpt)
    col = df.columns.to_list()
    mydb = os.getcwd() + '\\omsql\\' + 'oSqltdb.db'
    obj = sq3.sqlt3('oSqltdb.db', mydb)
    obj.createtable('VIP', col)
    obj.Export(df, 'VIP')
    print(obj.Read('select * from VIP'))


def for_contacts(svpt, tblname, colhead, srv = None):
    fl = open(svpt, 'r+')
    ls = []
    lns = 0
    for i in fl.readlines():
        x1= i.replace(',','')
        x2 = x1.replace('\n','')
        ls.append(x2)
        lns = lns + 1
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    print(df)
    print('waiting 10 sec to check....')
    col = df.columns.to_list()
    if srv == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
        print(x.col_and_type(tblname))
        x.df2sql(tblname,df)
        print(lns, df.shape[0], x.Getdf().shape[0])
    else:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        print(x.col_and_type(tblname))
        try:
            x.df2sql(tblname,df)
            print(lns, df.shape[0], x.Getdf().shape[0])
        except:
            print('fail')
    






def periodic_contacts(conn, contact_With_cmd):
    x = ''
    cur = conn.cursor()
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is \n periodic,01817183XXX,add"
    tbl = 'PeriCon'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    cr = conn.cursor()        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        qry = 'select * from ' + tbl + " where Number = '" + fcn + "' or  Number like '" + fcn + "'"
        rs = pd.read_sql(qry, con = conn)
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if 'check' in cmd or 'check' in contact_With_cmd:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                qry = "insert into " + tbl + " (Number) values ('" + fcn + "')"
                cur.execute(qry)
                conn.commit
                print(qry)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                xx = "DELETE FROM " + tbl + " WHERE Number Like '" + fcn + "'"
                cur.execute(xx)
                conn.commit
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'
            

#print('bot send: ', periodic_contacts('periodic,717015682,remove'))

def for_csv2sql(csv_file_path, tblname):
    df = pd.read_csv(csv_file_path)
    x = ''
    #try:
        #x = omsql('root','admin','127.0.0.1:3306','omdb')
        #x.MySql()
    #except:
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    print(df)
    x.df2sql(tblname,df)
    qry = 'select * from ' + tblname
    time.sleep(2)
    print(x.Ex(qry))
    print(tblname)


svpt = os.getcwd() + '\\Contacts.txt' 
#for_contacts(svpt, 'PeriCon1', 'Number')   
    
pt2 = os.getcwd() + '\\VIP.csv'
#for_csv2sql(pt2,'VIP')

pt3 = os.getcwd() + '\\TOP5.csv'
#for_csv2sql(pt3,'TOP5')

pt4 = os.getcwd() + '\\IBS.csv'
#for_csv2sql(pt4,'IBS')

pt5 = os.getcwd() + '\\AB.csv'
#for_csv2sql(pt5,'ABHI')

pt5 = os.getcwd() + '\\RMT.csv'
#for_csv2sql(pt5,'RMT')

#ob = omsql('root','admin','127.0.0.1:3306','omdb')
#ob.MySql()
#csvfile = os.getcwd() + '\\AB.csv'
#df = pd.read_csv(csvfile)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\call_omsql_bottest.py###
import csv, os
import telepot
from telepot.loop import MessageLoop
from pprint import pprint
from call_omsql import *
import time as tm
from datetime import *


TOKEN = '1055749951:AAG9J4nV8thnnSPSKNkvf-G1lcWmH5QMyjA'
bot = telepot.Bot(TOKEN)

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if content_type == 'text':
        txt = msg['text']
        chtid = msg['chat']['id']
        if 'periodic' in txt.lower():
            x = periodic_contacts(txt.lower())
            if len(x) < 1:
                bot.sendMessage(chat_id, 'please send correctly')
            else:
                bot.sendMessage(chat_id, x)
        else:
            bot.sendMessage(chat_id, txt + ' ' + str(chtid))
    else:
        try:
            x = msg['document']['file_id']
            bot.sendMessage(chat_id, x.replace('%0a','/n'))
        except:
            bot.sendMessage(chat_id, 'can not read file id')

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    tm.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\checktest.py###
zn = "ABC"
p1p2 ="P1"
pg = "ACT"
owner = "ulka"
smsid = "123"
thn ="TH"
pwaut="REB"
qryupd = "UPDATE [dbo].[omidb] SET (REGION=" + zn + ", P1P2=" + p1p2 + ", PG=" + pg + ", OWNER=" + owner + ") WHERE SMSID=" + smsid
print(qryupd)

qryupd2 = "UPDATE [dbo].[pglog4] SET REGION='" + zn +"', PRIORITY='" + p1p2 + "',SITETYPE_PG='" + pg + \
          "', POWER_AUTH='" + pwaut + "', THANA='" + thn + "', OWNER='" + owner + "' WHERE SMSID='" + smsid +"'"
print(qryupd2)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\checktest2.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
from datetime import datetime
from datetime import timedelta
import win32com.client
from dateutil.relativedelta import *

today = date.today()
td1 = today.strftime('%Y%m')
lastmnth = datetime.now() - relativedelta(months=1)
td2 = lastmnth.strftime('%Y%m')

def filename():
    pt = os.getcwd() + "\\" + "csv_download\\"
    t = time.localtime()
    folderName1 = today.strftime('%m%d%y')
    folderName2 = time.strftime("%H%M", t)
    pth = os.path.join(pt + folderName1 + folderName2 + '.csv')
    return pth

def qry_delta(from_min,to_min): 
    tday = date.today()
    tmdlta_from_now = datetime.now() - timedelta('minutes='+ int(from_min))
    tmdlta_to_now = datetime.now() - timedelta('minutes='+ int(to_min))
    qry_from = tmdlta_from_now.strftime('%Y-%m-%d %H:%M:%S')
    qry_to = tmdlta_to_now.strftime('%Y-%m-%d %H:%M:%S')
    dyn_date = "TO_DATE('" + qry_from + "','dd/mm/yyyy hh:mi:ss') AND TO_DATE('" + qry_to + "','dd/mm/yyyy hh:mi:ss')"
    return dyn_date


col = '*'
smry = "'2G SITE DOWN'"
query_p1 = 'SELECT ' + col + ' FROM ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + td1 + ') WHERE '
query_p2 = "(TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970') AND (SUMMARY=" + smry + ')'
query_p3 = 'IN (SELECT ' + col + 'FROM ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + td2 + ') WHERE '
query_p4 = 'SUMMARY=' + smry + " AND (TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970')) AND CUSTOMATTR15!='UNKNOWN')"

qry_type1 = query_p1 + query_p2
print(qry_type1)




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\check_test.py###
import os
scrpt_name = "ErrorHanddle_VBS.vbs"
fpth_0 = os.getcwd() + "\\" + scrpt_name
os.system(fpth_0)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\class_call_test.py###
import pandas as pd
import csv, os, time
from omsql.omsq import *
import omsql.omsqlite3 as sq3

def sqllite3():
    svpt = os.getcwd() + '\\VIP.csv'
    df = pd.read_csv(svpt)
    col = df.columns.to_list()
    mydb = os.getcwd() + '\\omsql\\' + 'oSqltdb.db'
    obj = sq3.sqlt3('oSqltdb.db', mydb)
    obj.createtable('VIP', col)
    obj.Export(df, 'VIP')
    print(obj.Read('select * from VIP'))

sqllite3()

def for_contacts(svpt, tblname, colhead, srv = None):
    fl = open(svpt, 'r+')
    ls = []
    lns = 0
    for i in fl.readlines():
        x1= i.replace(',','')
        x2 = x1.replace('\n','')
        ls.append(x2)
        lns = lns + 1
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    print(df)
    print('waiting 10 sec to check....')
    col = df.columns.to_list()
    if srv == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
        print(x.col_and_type(tblname))
        x.df2sql(tblname,df)
        print(lns, df.shape[0], x.Getdf().shape[0])
    else:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        print(x.col_and_type(tblname))
        try:
            x.df2sql(tblname,df)
            print(lns, df.shape[0], x.Getdf().shape[0])
        except:
            print('fail')
    


def periodic_contacts(contact_With_cmd):
    x = ''
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is %0a-periodic,01817183XXX,add"
    tbl = 'Periodic_Contacts'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    try:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
    except:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        rs = x.Ex('select * from ' + tbl + " where Number = '" + fcn + "'")
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if cmd == None:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                x.InsertSingle(tbl, 'Number', fcn)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                x.DeleteByCond(tbl, 'Number', fcn)
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'
            

#print('bot send: ', periodic_contacts('periodic,717015682,remove'))

def for_csv2sql(csv_file_path, tblname):
    df = pd.read_csv(csv_file_path)
    x = ''
    #try:
        #x = omsql('root','admin','127.0.0.1:3306','omdb')
        #x.MySql()
    #except:
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    print(df)
    x.df2sql(tblname,df)
    qry = 'select * from ' + tblname
    time.sleep(2)
    print(x.Ex(qry))
    print(tblname)


svpt = os.getcwd() + '\\Contacts.txt' 
#for_contacts(svpt, 'PeriCon', 'Number', 'mssql')   
    
pt2 = os.getcwd() + '\\VIP.csv'
#for_csv2sql(pt2,'VIP')

pt3 = os.getcwd() + '\\TOP5.csv'
#for_csv2sql(pt3,'TOP5')

pt4 = os.getcwd() + '\\IBS.csv'
#for_csv2sql(pt4,'IBS')

pt5 = os.getcwd() + '\\AB.csv'
#for_csv2sql(pt5,'ABHI')

pt5 = os.getcwd() + '\\RMT.csv'
#for_csv2sql(pt5,'RMT')

ob = omsql('root','admin','127.0.0.1:3306','omdb')
ob.MySql()
csvfile = os.getcwd() + '\\AB.csv'
df = pd.read_csv(csvfile)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\code_qry.py###
import pandas as pd
import os



#opt = itertools.islice(ls, len(ls))
#st = map(lambda x : )

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    code = []
    q = 0
    for i in range(len(ls)):
        text = txt
        if ls[i] in text:
            n = text.find(ls[i])
            st = text[n:n+7]
            code.append(st)
            txt = txt.replace(ls[i],'')
            q = q + 1
    else:
        if q == 0:
            return ''
        else:
            return code
        
def qry_by_code(code, tbl = None, col = None):
    if tbl is None and col is None:
        a1 = "select Incident_Notification,Down_Time,Up_Time,Major_Cause,Action_Taken,Link_ID_Site_ID,Incident_ID from incident_tracker_v2 where ("
        a2 = " No_of_2G_Impacted_sites Like '%" + code + "%' or No_of_3G_Impacted_sites like '%" + code + "%' or No_of_4G_Impacted_Sites like '%" + code + "%' or Incident_Notification Like '%" + code 
        a3 = "%') order by Down_Time desc"
        aa = a1 + a2 + a3
        return aa
    else:
        return ""

def codechk(txt):          
    rs = parsecode(txt.upper())
    st = 0
    print('ret val', rs)
    if len(rs) == 1:
        code = rs[0]
        rn = 0
        try:
            cd = int(code[6:7])
            qry = qry_by_code(code)
            conn = pyodbc.connect(soc)
            df = pd.read(qry, con = conn)
            if df.shape[0] != 0:
                if df.shape[0] > 3:
                    st = "last 3 incident out of " + df.shape[0]
                    rn = 3
                else:
                    st = "incident found " + df.shape[0] + chr(10)
                    rn = df.shape[0]
                for i in range(rn):
                    tmp = chr(10)
                    for j in df:
                        tmp = tmp + chr(10) + df.loc[i,j]
                    else:
                        st = st + chr(10) + str(i) + tmp
        except:
            print('not code')
        return st
    else:
        return st



    

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\conn_brocker.py###
import pyodbc
from mysql import *
from sqlalchemy import create_engine


def mssql_121():
    cstr = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(cstr)
    return conn

def mssql_115():
    cstr = "Driver={SQL Server};SERVER=192.168.0.115;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"
    conn = pyodbc.connect(cstr)
    return conn

def mssql_host(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn

def mysql(user = 'root', password = 'root', host = '127.0.0.1:3306', db = "omdb"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


con = mssql_115()
con2 = mysql()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\create_table.py###
import pandas as pd
import os
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

def CreateTable_MSSQL(tablename, list_col, list_type=None):
    st = ""
    finalstr = ''
    x = ""
    for i in range(len(list_col)):
        if list_type != None:
            x = list_col[i] + "' " + list_type[i]
        else:
            x = list_col[i] + "' TEXT NULL"
        if st == "":
            addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
            st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
            # st = "CREATE TABLE '" + tablename + "' ( '" + x
        else:
            st = st + ', ' + "'" + x
    else:
        finalstr = st + ' )'
        return finalstr

def CreateTable_MYSQL(tablename, list_col, list_type =None):
    st = ""
    finalstr = ''
    x = ""
    for i in range(len(list_col)):
        if list_type != None:
            x = list_col[i] + "` " + list_type[i]
        else:
            x = list_col[i] + "` text NULL DEFAULT NULL"
        if st == "":
            addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
            st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
        else:
            st = st + ', ' + "`" + x
    else:
        finalstr = st + ' )'
        print(finalstr)
        return finalstr

def is_table_exist(tbl, conn):
    qry = "SELECT 1 FROM " + tbl
    print(qry)
    try:
        cr = conn.cursor()
        rs = cr.execute(qry)
        return 1
    except:
        return 0

def create_table_mysql(csv_or_df, new_table_name, db_conn, columns_remane = True):
    exist = is_table_exist(new_table_name, db_conn)
    if exist == 0:
        df = ''
        if isinstance(csv_or_df, str):
            df = pd.read_csv(csv_or_df)
        else:
            df = csv_or_df
        if columns_remane:
            ndf = mod_cols_name(df)
            cols = ndf.columns.to_list()
            try:
                qry = CreateTable_MYSQL(new_table_name,cols)
                cr = db_conn.cursor()
                cr.execute(qry)
                db_conn.commit()
                print('table creation successful')
            except:
                print('table creation failed')
        else:
            cols = ndf.columns.to_list()
            CreateTable_MYSQL(new_table_name,cols)
    else:
        print('table already exist')

def create_table_mssql(csv_or_df, new_table_name, db_conn, columns_remane = True, infer_datatype = True):
    if is_table_exist(new_table_name, db_conn) == 0:
        df = ''
        if isinstance(csv_or_df, str):
            df = pd.read_csv(csv_or_df)
        else:
            df = csv_or_df
        if columns_remane:
            ndf = mod_cols_name(df)
            cols = ndf.columns.to_list()
            try:
                qry = CreateTable_MSSQL(new_table_name,cols)
                cr = db_conn.cursor()
                cr.execute(qry)
                db_conn.commit()
                print('table creation successful')
            except:
                print('table creation failed')
        else:
            cols = ndf.columns.to_list()
            CreateTable_MYSQL(new_table_name,cols)
    else:
        print('table already exist')

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn

def change_dtype(df, colnm, to_type):
    ndf = pd.DataFrame([])
    if to_type == "dt":
        try:
            df[colnm] = df.apply(lambda x : pd.to_datetime(x[colnm]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            return df
        except:
            return ndf
    if to_type == "integer":
        try:
            df[colnm] = df[colnm].astype(str)
            return df
        except:
            return ndf
    if to_type == "string":
        try:
            df[colnm] = df[colnm].apply(lambda _: str(_))
            return df
        except:
            return ndf


#create_table_mysql(df, 'mytable1', conn)
#qry = "select * from mytable"
#print(pd.read_sql(qry ,con = conn))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\db - Copy.py###
import pandas as pd
import os
import sqlite3

pt = os.getcwd()
csvpt = ""
sqdb = ""

if "db" in pt:
    csvpt = os.getcwd() + "\\omdb.csv"
    sqdb = os.getcwd() + "\\omdb.db"
else:
    csvpt = os.getcwd() + "\\db\\omdb.csv"
    sqdb = os.getcwd() + "\\db\\omdb.db"

conn = sqlite3.connect(sqdb)
c = conn.cursor()

def comm_create(sql):
    c.execute(sql)
    conn.commit()
    print('successful commit')

def comm_read(sql):
    c.execute(sql)
    rw = []
    for row in c.fetchall():
        rw.append(row)
    df = pd.DataFrame(rw)
    return df
#df.to_sql('SITEDB', conn, if_exists='replace', index = False)

def sitedb_col():
    col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
    return col

def omdb(col = False, tbl = False):
    if col == False:
        col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
        c.execute('''SELECT * FROM SITEDB''')
        df = pd.DataFrame(c.fetchall(), columns=[col])
        return df
    else:
        if tbl == False:
            tbl = 'SITEDB'
        sql = "SELECT " + col + " FROM " + tbl
        c.execute(sql)
        lst = col.split(',')
        df = pd.DataFrame(c.fetchall())
        df.columns = lst
        return df

def replace_data(df,tbl):
    sql = "DELETE FROM " + tbl + ';'
    c.execute(sql)
    df.to_sql('SITEDB', conn, if_exists='replace', index = False)

#cols = "ECO,ULKA"
#sql = "SELECT " + cols + " FROM SITEDB"
#comm_read(sql)
#print(omdb(cols,'SITEDB'))


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\db.py###
import pandas as pd
import os
import sqlite3

pt = os.getcwd()
csvpt = ""
sqdb = ""

if "db" in pt:
    csvpt = os.getcwd() + "\\omdb.csv"
    sqdb = os.getcwd() + "\\omdb.db"
else:
    csvpt = os.getcwd() + "\\db\\omdb.csv"
    sqdb = os.getcwd() + "\\db\\omdb.db"

conn = sqlite3.connect(sqdb)
c = conn.cursor()

def comm_create(sql):
    c.execute(sql)
    conn.commit()
    print('successful commit')

def comm_read(sql):
    c.execute(sql)
    rw = []
    for row in c.fetchall():
        rw.append(row)
    df = pd.DataFrame(rw)
    return df
#df.to_sql('SITEDB', conn, if_exists='replace', index = False)

def sitedb_col():
    col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
    return col

def omdb(col = False, tbl = False):
    if col == False:
        col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
        c.execute('''SELECT * FROM SITEDB''')
        df = pd.DataFrame(c.fetchall(), columns=[col])
        return df
    else:
        if tbl == False:
            tbl = 'SITEDB'
        sql = "SELECT " + col + " FROM " + tbl
        c.execute(sql)
        lst = col.split(',')
        df = pd.DataFrame(c.fetchall())
        df.columns = lst
        return df

def replace_data(df,tbl):
    sql = "DELETE FROM " + tbl + ';'
    c.execute(sql)
    df.to_sql('SITEDB', conn, if_exists='replace', index = False)

#cols = "ECO,ULKA"
#sql = "SELECT " + cols + " FROM SITEDB"
#comm_read(sql)
#print(omdb(cols,'SITEDB'))


df = pd.DataFrame([['Iphone','DHDEM26',
'11-09-2020 12:14','11-20-2020 12:24',
'400'],['Iphone','CGHTZ09',
'11-09-2020 12:14','11-20-2020 12:24',
'400'],['dell','LXRGN32',
'11-09-2020 12:14','11-20-2020 12:24',
'300'],['dell','DHDEM39',
'11-09-2020 12:13','11-20-2020 12:24',
'300'],['Samsung ','SGSJP04',
'11-09-2020 12:12','11-20-2020 12:24',
'250'],['Samsung ','CXMHK36',
'11-09-2020 12:11','11-20-2020 12:24',
'250'],['Samsung ','CGFTK29',
'11-09-2020 12:10','11-20-2020 12:24',
'250'],['dell','CGKTLB6',
'11-09-2020 12:10','11-20-2020 12:24',
'300'],['dell','CMBRR57',
'11-09-2020 12:10','11-20-2020 12:24',
'300']],columns=('PRODUCT','ZIPCODE',
            'SHIPMENT','DELIVERY','PRICE'))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\db121.py###
import time
from datetime import date
from datetime import datetime
from datetime import timedelta
import pyodbc
import requests as rs
import pandas as pd

tmnw = datetime.now()
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')

def generalqry():
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    qry = "SELECT * from [dbo].[pglog4]"
    df = pd.read_sql(qry, conx)
    print(df)
    print(df.shape[0])

def insert_pgon(ussd,code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    in_qry = '''INSERT INTO dbo.pglog4 (SMSID, SITECODE, MSISDN) VALUES (?,?,?)'''
    in_qry_1 = (ussd, code, msisdn)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()

def update_pgoff(code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    qry_1 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND STATUS_ACTIVE= 'TRUE')"
    qry1 = "UPDATE dbo.pglog4 SET END_DATETIME = CURRENT_TIMESTAMP WHERE " + qry_1
    qry2 = "UPDATE dbo.pglog4 SET CASE_STATUS = 'Closed' WHERE " + qry_1
    curs.execute(qry1)
    conx.commit()
    curs.execute(qry2)
    conx.commit()
    qry_2 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND CASE_STATUS= 'Closed')"
    qry3 = "UPDATE dbo.pglog4 SET STATUS_ACTIVE = '0' WHERE " + qry_2
    curs.execute(qry3)
    conx.commit()
    conx.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dbpull.py###
from datetime import *
import time as tm
import pandas as pd
import numpy as np
import os
from mysql import *
from sqlalchemy import create_engine
from sqlalchemy import update
import subprocess
import conn_brocker

engine = create_engine('mysql+mysqlconnector://akomi:1q2w3eaz$@38.70.234.101:3306/omdb', echo=False)
conn = engine.raw_connection()
cursor = conn.cursor()

def dbup(df0):
    df1 = df0.applymap(str)
    ls = ['ip','port','ISP','ASN','country','prot','prot_status','blkchk','blk_status','priority']
    df2 = df1[ls]
    df2.to_sql(name='live', con=engine, if_exists = 'append', index=False)
    print('db update done')

def dbdw():
    qry = "select * from live where blk_status='fine'"
    df = pd.read_sql(qry, con=engine)
    return df
    
def dbupd(ip):
    live.update().where(ip==ip).values(name="some name")
    
    
def netcat(ip,port):
    qry = "timeout 5 nc -v -N  -w 5 " + ip + ' ' + str(port)
    process = subprocess.Popen(qry, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    err = str(process.stderr.read())
    if 'succeeded' in err:
        return 'success'
    else:
        return 'fail'

def getip_port():
    df = dbdw()
    print(df)
    df = df.fillna(0)
    df2 = df[df.blk_status.str.contains('fine')]
    df2 = df2.drop_duplicates(subset='ip',keep='last', inplace = False)
    dfp1 = df2[(df2.priority == "P1")]
    dfp2 = df2[(df2.priority != "P1")]
    ippr = ""
    for i in range(len(dfp1)):
        ip = dfp1.iloc[i][1]
        port = dfp1.iloc[i][2]
        status = netcat(ip,port)
        if status == 'success':
            nip = ip
            nport = port
            ippr = ip + "," + str(port)
            break
    return ippr

def connint():
    ipr = getip_port()
    ipx = ipr.split(',')
    nip = ipx[0]
    nport = ipx[1]
    conn_brocker.server('0.0.0.0', 12876, nip, int(nport), 2)



nip = '142.93.245.242'
nport = '30588'
conn_brocker.server('0.0.0.0', 12876, nip, int(nport), 2)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dbqry.py###
import sqlite3

con = sqlite3.connect('omdb.db')
cr = con.cursor()
def create_tbl():
    cr.execute("CREATE TABLE hs(SERIAL,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,CUSTOMATTR3)")
    con.commit()
def uoload_data(df1,dbname):
    df1.to_sql("'" + dbname + "'", con)
def delete_data(tblName):
    sql = "DELETE FROM " + tblName + ';'
    con.execute(sql)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\DBUP.py###
import os
import MySQLdb
import csv

pt = os.getcwd()
fl = pt + '\\A2S.csv'
conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
cr = conn.cursor()
try:
    csv_data = csv.reader(open(fl))
    print(csv_data.text)
    # execute and insert the csv into the database.
    for row in csv_data:
        cr.execute('INSERT INTO ipasn10 (IP1, IP2, ASN, Country, ISP, IPMOD)''VALUES(%s, %s, %s, %s, %s , %s)',row)
        print(row)
    cr.commit()
except:
    conn.rollback()
finally:
    conn.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dbup_test.py###
import pandas as pd
import numpy as np
import os
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnstr as fst
import db.db as sq
from datetime import *
from dateutil.relativedelta import *
from dateutil.easter import *
from dateutil.rrule import *
from dateutil.parser import *
import db.omdb as od

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"
df1 = pd.read_csv(pt1)
df0 = pd.read_csv(pt2)

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"

def get_date(d1):
    tm = parse(d1)
    dt = tm.date()
    return str(dt)

def PTM(d,fmt=False):
    if fmt == False:
        fmt = "%Y-%m-%d %H:%M:%S"
    if isinstance(d,str):
        tm = parse(d)
        str_d = tm.strftime(fmt)
        return str_d
    elif isinstance(d,datetime):
        d1 = d
        d = str(d1)
        tm = parse(d1)
        str_d = tm.strftime(fmt)
        return str_d
    else:
        return 0

def dateformat(d1):
    if isinstance(d1, str):
        d = datetime.strptime(d1)
        return d.strftime("%Y-%d-%m %H:%M:%S")
    if isinstance(d1, datetime):
        d = d1.strftime("%Y-%d-%m %H:%M:%S")
        return d

conn = od.MySql_3('127.0.0.1','root','admin','om1')
cr = conn.cursor()
x = od.prep_query("tm1")

def lp():
    for i in range(len(df0)):
        CL = df0.loc[i,"CLEARTIMESTAMP"]
        LO = PTM(df0.loc[i,"LASTOCCURRENCE"])
        CLR = PTM(df0.loc[i,"CLEARTIMESTAMP"])
        ls = []
        if '1970' not in CL:
            AG = datediff("",LO,CLR)
            DT = get_date(LO)
            st = "'" + DT + "','" + LO + "','" + CLR + "','" + AG + "','" + df0.loc[i,"CUSTOMATTR15"] + "'"
            print(st)
            x.q_insert("`TODAY`, `LO`, `CLR`, `AG`, `CODE`",st)
            ist = x.get()
            cr.execute(ist)
            conn.commit()
lp()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dfmtd.py###
import pandas as pd
import numpy as np
import os
import sys

def conv_datatype():
    print('x')

def dfmt1(arg):
    x = isinstance(arg, (str, float, int, str, list, dict, tuple, pd.DataFrame, np.ndarray))
    if type(x) == pd.DataFrame:
        df0 = arg
    elif type(x) ==np.ndarray:
        nar = arg
    elif type(x) == dict:
        df0 = pd.Dataframe(arg)
        print(df0)

def dfmt2(df, whatto):
    if whatto == 'col':
        print('df frame columns name')
        print('1 . df columns \n', df.columns)
        print('\n 2. columns into list \n' ,list(df.columns))
        print('\n No of Colummns', df.shape[1])
        print('\n slice columns ', df0)
    if whatto == 'row':
        print(df.shape[0])








FL1 = "E:\\GIT\\OmProject\\OmPY\\omfn\\sem_raw.csv"
dff = pd.read_csv(FL1)
dic = dff.to_dict()
nar = dff.to_numpy()
dk = dff.columns[['Severity','PG_Restricted']]
#df0 = dff.columns[['Serial','Summary']]
#dfmt2(dff,'col')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_dic.py###
import MySQLdb
import pandas as pd
try:
    conn= MySQLdb.connect("localhost","root","admin","omdb")
except:
    print("Can't connect to database")
#cursor = conn.cursor()








#filename = os.getcwd() + '//inc.csv'
#df = pd.read_csv(filename)
##dic = df.to_dict()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_dict.py###
#df to dic
import pandas as pd
filename = 'Book1.csv'
df = pd.read_csv(filename)
dic = df.to_dict()
#print(df)
#print(dic)
#for col in dic:  #print header
    #print(col)
#for rw in dic.values():  #print header
    #print(rw)
#for col in dic.items():
    #print(dic['Site_Code'])
j = 0
for i in dic.values():
    j = j + 1
    #print(j)
   # print(dic['Site_Code'][j])
    
#for i in dic:
    #print(i)
#for i in dic.values():
    #print(i)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_dict_list.py###
import pandas as pd
filename = 'Book1.csv'
dic = {0:'zero',1:'one',2:'two'}
print(dic)
def df_2_lst():
    lst = df.values.tolist()
    
def df_2_dic():
    dic = df.to_dict()

def df_2_series():
    dic = df.to_dict()
    
def df_2_numpy_arr():
    dic = df.to_dict()
    
dfrm = pd.read_csv(filename)
df = pd.DataFrame(list(dic.items()))
dic1 = df.to_dict()

print(df)
#print_from_lst()
#print_from_dic()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_insupd.py###
import pandas as pd
import numpy as np
import os
import omsqlfn as ofn
import InsUpd as InUp
import create_table as ct
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, ndf):
    df = ndf.replace (np.nan, '')
    dfcol = df.columns.to_list()
    for i in range(len(dfcol)):
        df = df.rename(columns={dfcol[i]:dfcol[i].replace(' ', '_')})
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        colunmatch = []
        q = 0
        Y = 1
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            q = q + 1
            try:
                xdf = df[st]
            except:
                Y = 0
                notmat = 'column not matched: - ' + st
                print(notmat)
            if Y == 1:
                print('dtype_match: ', dbty)
                try:
                    if dbty == 'int':
                        df[st] = df[st].astype(int)
                    elif dbty == 'float':
                        df[st] = df[st].astype(float)
                    elif dbty == 'datetime':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                    elif dbty == 'date':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                    else:
                        df = df.apply(lambda x: x.replace("'","\'"))
                except:
                    pass
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)


def Insert_bydf(tbl, df, cols = False):
    print(df)
    colname = df.columns.to_list()
    q = 0
    if cols:
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                match = 0
                for c in range(len(cols)):
                    if cols[c] == j:
                        match = 1
                        break
                if match == 1:
                    lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(cols,lsval)
            ls.append(qry)
        return ls
    else:
        q = 0
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(colname,lsval)
            ls.append(qry)
        return ls

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry


def UpdInsert(ndf, tbl, conn, bycols = False, oncol = False):
    qry = ''
    cr = conn.cursor()
    if bycols != False and oncol != False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)        
    elif bycols != False and oncol == False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)
    elif bycols == False and oncol != False:
        qry = Insert_bydf(tbl, ndf, oncol)
    else:
        qry = Insert_bydf(tbl, ndf)
    cnt = 0
    er = 0
    for i in range(len(qry)):
        cnt = cnt + 1
        q = qry[i]
        try:
            cr.execute(q)
        except:
            er = er + 1
            print("a error found for query - :" , q, " at row num ", cnt)
    conn.commit()
    print(cnt, ' rows of data instered into ', tbl)
    print('error found for rows ', er)
    return qry


def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#df1 = pd.read_sql('select * from omdb3',conn)
#print('before row: ', df1.shape[0])
#pt = os.getcwd() + '\\omsql\\OM2.csv'
#df = pd.read_csv(pt)
#oncol = ['Zone', 'Commercial_Zone', 'PFM_ZONE']
#bycol = ['Code','Authority']
#ls = UPIN(df, 'omdb3', conn, "Code", oncol)
#ls = UPIN(df, 'omdb3', conn, bycol, oncol)
#print('after row: ', df1.shape[0])

# df = dataframe
# db_connection  = database connection object
# how = 'append' or 'replace' or 'tuncate'
# bycols (list/str) = conditional columns for insert and update [if how = 'replace']
# oncols (list) = columns on that update and insert perfromed on table [False = all dataframe column]
# datatype_map = special feat, before insert or update datatype mapping beteen table columns and dataframe columns
def df_to_sql(df, db_name, db_table, db_connection, how = 'replace', bycols = False, oncols = False, datatype_map = True):
    ndf = dtype_match(db_name, db_table, db_connection, df)
    print(ndf['LastOccurrence'])
    if isinstance(ndf, pd.DataFrame):
        if bycols != False and how == 'replace':
            ls = UPIN(ndf, db_table, db_connection, bycols, oncols)
        elif bycols == False:
            ls = UpdInsert(ndf, db_table, db_connection, oncol = oncols)
    else:
        print('check column name between db and dataframe')

def pattern1():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMDB.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn)
    conn.close()

def pattern2():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OM.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn, bycols = ['Code'], oncols = ['Zone','Commercial_Zone','PFM_ZONE'])

def pattern3():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMTX.csv'
    df = pd.read_csv(pt)
    ct.create_table_mysql(df, 'eve', conn )
    df_to_sql(df, 'omdb', 'eve', conn)
    conn.close()


#x1 = UpdInsert('TB1',df)
#x2 = UpdInsert('TB1',df, bycol, oncol)
#x3 = UpdInsert('TB1',df, bycol)
#x4 = UpdInsert('TB1',df, oncol = oncol)
#print('X1', '~~', x1)
#print('X2', '~~', x2)
#print('X3', '~~', x3)
#print('X4', '~~', x4)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_to_sql.py###
import pandas as pd
import numpy as np
import os
import datetime
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import df_to_sql.upin as upd
import df_to_sql.write2text as wrt

def get_server_name(db, table, conn):
    try:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con = conn)
        return "MYSQL"
    except:
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= conn)
            return "MSSQL"
        except:
            return "only MYSQL and MSSQL is Supported"

def mssql_table_colname(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    return dbcols

def mssql_table_colinfo(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    dbcolType = dfx['DATA_TYPE'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic



def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key
            
def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                pass
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def fuzzymatch(str1,str2, uplow = True):
    if uplow == True:
        s1 = str1.lower()
        s2 = str2.lower()
        ls1 = []
        ls2 = []
        for i in s1:
            ls1.append(i)
        for n in s2:
            ls2.append(n)
        q = 0
        succ = 0
        fail = 0
        if len(ls1) <= len(ls2):
            for j in range(len(ls1)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        else:
             for j in range(len(ls2)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        try:
            spercent = round((succ/q)*100,2)
        except:
            spercent = 0
        return spercent

def colchk_dbdf(coldb = [], coldf = []):
    if isinstance(coldb, list) and isinstance(coldf, list):
        cdb = coldb
        cdf = coldf
        cdb.sort
        coldf.sort
        nonmat = []
        for i in range(len(cdb)):
            d1 = cdb[i]
            mat = 0
            for j in range(len(cdf)):
                if d1 == cdf[j]:
                    mat = 1
                    break
            if mat == 0:
                nonmat.append(d1)
        return nonmat

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""


def df_to_sql(dataframe, dbname, tablename, conn, oncolumn = "ALL", bycolumn = None, opeation = 'and'):
    srv = get_server_name(dbname, tablename, conn)
    print(srv)
    if srv == 'other':
        exit()
    cr = conn.cursor()
    try:
        cr.execute('select 1 from '+ tablename)
    except:
        print('table does not exits')
        exit()
    if oncolumn != 'ALL' and bycolumn == None:
        dataframe = dataframe[oncolumn]
    ndf = dataframe.replace(r'^\s*$', np.nan, regex=True)
    xdf = ndf.convert_dtypes()
    dfcol = xdf.columns.to_list()
    if srv == "MYSQL":
        dbcol = mysql_table_colname(dbname, tablename, conn) #function call
    elif srv == "MSSQL":
        dbcol = mssql_table_colname(dbname, tablename, conn) #function call
    nonmat = colchk_dbdf(dbcol,dfcol)
    dfc = []
    rnmcol = {}
    if len(nonmat) != 0:
        for n in range(len(nonmat)):
            dbc = nonmat[n]
            y = 0
            for i in range(len(dfcol)):
                x = fuzzymatch(dbc, dfcol[i])
                #print(dbc,' - ',  dfcol[i], ' p- ', x, ' max ', y)
                if x >= y:
                    y = x
                    dfcl = dfcol[i]
            else:
                dfc.append(dfcl)
                rnmcol[dfcl] = dbc
    xdf = xdf.rename(columns = rnmcol)
    if srv == "MYSQL":
        dc = mysql_table_colinfo(dbname, tablename, conn)  #mysql function call
    elif srv == "MSSQL":
        dc = mssql_table_colinfo(dbname, tablename, conn)  #mysql function call
    df = dtype_match_dbdf(xdf, dc) #function call
    if bycolumn == None:
        excmd = []
        q = 0
        rwval = []
        colval = df.columns.to_list()
        er = []
        for (indx, rwseries) in df.iterrows():
            q = q + 1
            rwval = rwseries.values.tolist()
            x = insert_into_sql(tablename, dc, colval, rwval)
            try:
                cr.execute(x)
                excmd.append(x)
            except:
                er.append(x)
                qq = "dfrow: " + str(q)
                er.insert(0, qq)
        print('row inserted: ', q - len(er), ' error found for rows: ', len(er), ", get error in return")
        wrt.wrt2txt(excmd, 'exe_succ')
        wrt.wrt2txt(excmd, 'exe_fail')
        return er
    else:
        tableprop = dc
        excmd = upd.UPIN(df, tablename, tableprop, conn, bycols = bycolumn, operations = 'and')
        wrt.wrt2txt(excmd, 'exe_succ')





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dt.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from oFn.fn import *
import oFn.fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            df1 = fnx.add_col_df(df, 'newcol')
            df1[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df1 = fnx.add_col_df(df, 'newcol')
        df1[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fileprocess.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = pt + "\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]



def df_add_list_col(dfx,nc,nwlst):
    dfx[nc] = np.nan
    dfx[nwcol] = np.array(nwlst)
    return dfx

def vlookup(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values 
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df
            
        
def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx
    
def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        lst = df[dt_col1]
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        lst = df[dt_col1]
        clr = df[dt_col2]
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    df[nwcol] = np.nan
    df[nwcol] = np.array(ls)
    print('In Minutes')
    return df
        
def process_sem_raw(df):
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CUSTOMATTR15']
    LL2 = df1['LASTOCCURRENCE']
    LL3 = df1['CLEARTIMESTAMP']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    print(ndf3)

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , Ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(df, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(df,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs():
    pass
def match():
    pass

df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
print(asq)




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\finally.py###
import subprocess
import time
import threading
import urllib
import requests
import queue

#def output_reader(proc, outq):
    #for line in iter(proc.stdout.readline, b''):
        #print('got line: {0}'.format(line.decode('utf-8')), end='')

def output_reader(proc, outq):
    for line in iter(proc.stdout.readline, b''):
        outq.put(line.decode('utf-8'))
        try:
            ln = outq.get(block=False)
            print('got line from outq: {0}'.format(ln), end='')
        except queue.Empty:
            print('could not get line from queue')

def main():
    #['python3', '-u', '-m', 'http.server', '8070']
    proc = subprocess.Popen(["gost","-L","socks5://0.0.0.0:11126","-D"],
                            stdout=subprocess.PIPE,
                            stderr=subprocess.STDOUT)
    outq = queue.Queue()
    t = threading.Thread(target=output_reader, args=(proc,outq))
    t.start()

    try:
        proc.wait(timeout=0.2)
        print('== subprocess exited with rc =', proc.returncode)
    except subprocess.TimeoutExpired:
        print('subprocess did not terminate in time')
    t.join()
    
main()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluc.py###
import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *
import flucsem as sem
import requests

#print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
#df = pd.read_csv(os.getcwd() + "\\B1.csv")
#nw = datetime.now()

n = datetime.now ()
td = n.today()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

TS1 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('2' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('3' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('4' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))

TS2 = lambda x: 'G2' if ('2G SITE DOWN' in x) \
    else ('C2' if ('2G CELL DOWN' in x) \
    else ('G3' if ('3G SITE DOWN' in x) \
    else ('C3' if ('3G CELL DOWN' in x) \
    else ('G4' if ('4G SITE DOWN' in x) \
    else ('C4' if ('4G CELL DOWN' in x) \
    else ('C2' if ('OML' in x) \
    else "0"))))))


DCAT = lambda x: 'H2' if (x < 90) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    #df4 = df2.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    #df4 = df2.reset_index()
    df2.to_csv(os.getcwd() + "\\T1.csv")
    return df2

def pivt(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)
    return pv
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    
def techwise(df, colnm, catby, fld0, fld1, fld2):
    hp = chr(10)
    q = 0
    for i in range(len(df)):
        n1 = df.loc[i,colnm]
        if catby in n1:
            hp = hp + chr(10) + df.loc[i,fld0] + ": " + str(df.loc[i,fld1]) + " | "  + str(df.loc[i,fld2])
    else:
        return catby + ":" + hp
    

df = sem.semqry_dummy()
print(df)
#fdf = extrafeat(df)
#ndf = pivt(fdf)

df2 = datediff_ondf(df, "DUR", 'LASTOCCURRENCE')
df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
df3 = df2[df2['SUMMARY'].str.contains('SITE DOWN') | df2['SUMMARY'].str.contains('CELL DOWN')]
df4 = df3.assign(CT1 = np.where(df3['SUMMARY'].str.contains('SITE DOWN'), 'SITE', 'CELL'))
df4 = df4.sort_values(by=['CT1'], ascending=False)
df4['CT2'] = df4.apply (lambda x: TS1 (x.SUMMARY), axis=1)
df4 = df4.astype(str)
df4['UNQ'] = df4['CUSTOMATTR15'].map(str) + '_' + df4['LO'].map(str) + "_" + df4['CT2'].map(str)
df5 = df4.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
df6 = df5.reset_index()
df6 = df6[~df6['CUSTOMATTR15'].isin(['UNKNOWN'])]
df6 = df6[~df6['CUSTOMATTR15'].isnull()]
#df[~df['var2'].isnull()]
df6['CT3'] = df6.apply (lambda x: TS2 (x.SUMMARY), axis=1)
df6['CT4'] = df6['CUSTOMATTR15'].map(str) + '_' + df6['CT3'].map(str)
df6['CT5'] = df6['CT4'].map(str) + "_" + df6['DCT'].map(str)
ls1 = df6['CT5'].to_list()
print(ls1)
print(df6.columns)
df6.to_csv(os.getcwd() + "\\Tju1.csv")
df6 = df6.drop_duplicates(subset=['CT5'], inplace=False, ignore_index=True)
df6 = df6.reset_index()
st = chr(10)
lss = []
G2 = "2G:"
G3 = "3G:"
G4 = "4G:"
cnt = 0
for i in range(len(df6)):
    x = df6.loc[i,"CT4"]
    y1 = x + "_H12"
    y2 = x + "_H2"
    ab = df6.loc[i,"CUSTOMATTR15"] + ' - ' + df6.loc[i,"CT3"] + " - " + str(ls1.count(y2)) + "/" + str(ls1.count(y1))
    ac = df6.loc[i,"CUSTOMATTR15"] + ' - ' + str(ls1.count(y1)) + " | " + str(ls1.count(y2))
    st = st + chr(10) + ab
    if ls1.count(y1)>9 and ls1.count(y2)>0 and df6.loc[i,"CUSTOMATTR15"] is not None:
        cnt = 1
        if df6.loc[i,"CT3"] == "G2":
            G2 = G2 + chr(10) + ac
        elif df6.loc[i,"CT3"] == "G3":
            G3 = G3 + chr(10) + ac
        elif df6.loc[i,"CT3"] == "G4":
            G4 = G4 + chr(10) + ac
else:
    if len(G2)<5:
        G2 = "2G:" + chr(10) + "NA"
    if len(G3)<5:
        G3 = "3G:" + chr(10) + "NA"
    if len(G4)<5:
        G4 = "4G:" + chr(10) + "NA"
    FG = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4 + chr(10) + chr(10)
    th1 = "Site Fluctuation Status" + chr(10) + "at " + "20:01 on 12-18-2020" + chr(10)
    th2 = "Tech: fluctuations count 00hr to last hr|only last hr count" + chr(10)
    FM = th1 + chr(10) + th2 + chr(10) + FG
    print(FM)
    msk = '-475120904'
    q1 = tmsg (msk, FM)
    

#df8 = df8.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
#df8.to_csv(os.getcwd() + "\\AA5.csv", index = False)
#site = df6[df6['SUMMARY'].str.contains('SITE DOWN')]
#cell = df6[df6['SUMMARY'].str.contains('CELL DOWN')]
#dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
#pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
#df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
#pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)










$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\flucsem.py###
import os, cx_Oracle
import time as ti
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *
from datetime import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"

nw = datetime.now()
td = nw.strftime("%Y_%b_%d")
mylog = os.getcwd() + "\\log"
todaylog = os.getcwd() + "\\log\\" + td
print(todaylog)

try:
    os.makedirs(mylog)
    os.makedirs(todaylog)
    print("folder created successfully")
except:
    try:
        os.makedirs(todaylog)
    except:
        print(" todayslog folder exits + ")

n = datetime.now ()
td = n.today()
#print(str(td) + "00:00:00")
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")


def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def lasthr(diff = 1):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%H")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,X733EVENTTYPE,X733SPECIFICPROB,CLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR26,TTSEQUENCE,ALARMDETAILS,EQUIPMENTKEY,SITECODE,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    #cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    x = n
    hr = x.strftime('%H')
    STDT = timedelt(-int(hr))
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    lscol = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']
    ddf = df[lscol]
    ddf.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    return ddf

def semqry_dummy():
    df = pd.read_csv(os.getcwd () + "\\SEMQRY.csv")
    return df
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\flucSlave.py###
import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *
import flucsem as sem
import requests

#print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
#df = pd.read_csv(os.getcwd() + "\\B1.csv")
#nw = datetime.now()

n = datetime.now ()
td = n.today()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

TS1 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('2' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('3' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('4' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))

TS2 = lambda x: 'G2' if ('2G SITE DOWN' in x) \
    else ('C2' if ('2G CELL DOWN' in x) \
    else ('G3' if ('3G SITE DOWN' in x) \
    else ('C3' if ('3G CELL DOWN' in x) \
    else ('G4' if ('4G SITE DOWN' in x) \
    else ('C4' if ('4G CELL DOWN' in x) \
    else ('C2' if ('OML' in x) \
    else "0"))))))


DCAT = lambda x: 'H2' if (x < 90) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    #df4 = df2.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    #df4 = df2.reset_index()
    df2.to_csv(os.getcwd() + "\\T1.csv")
    return df2

def pivt(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)
    return pv
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    
def techwise(df, colnm, catby, fld0, fld1, fld2):
    hp = chr(10)
    q = 0
    for i in range(len(df)):
        n1 = df.loc[i,colnm]
        if catby in n1:
            hp = hp + chr(10) + df.loc[i,fld0] + ": " + str(df.loc[i,fld1]) + " | "  + str(df.loc[i,fld2])
    else:
        return catby + ":" + hp
    

#df = sem.semqry_dummy()
#print(df)
#fdf = extrafeat(df)
#ndf = pivt(fdf)
def flucslave(df0):
    lscol = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']
    df = df0[lscol]
    df2 = datediff_ondf(df, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df3 = df2[df2['SUMMARY'].str.contains('SITE DOWN') | df2['SUMMARY'].str.contains('CELL DOWN')]
    df4 = df3.assign(CT1 = np.where(df3['SUMMARY'].str.contains('SITE DOWN'), 'SITE', 'CELL'))
    df4 = df4.sort_values(by=['CT1'], ascending=False)
    df4['CT2'] = df4.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df4 = df4.astype(str)
    df4['UNQ'] = df4['CUSTOMATTR15'].map(str) + '_' + df4['LO'].map(str) + "_" + df4['CT2'].map(str)
    df5 = df4.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
    df6 = df5.reset_index()
    df6 = df6[~df6['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df6 = df6[~df6['CUSTOMATTR15'].isnull()]
    #df[~df['var2'].isnull()]
    df6['CT3'] = df6.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df6['CT4'] = df6['CUSTOMATTR15'].map(str) + '_' + df6['CT3'].map(str)
    df6['CT5'] = df6['CT4'].map(str) + "_" + df6['DCT'].map(str)
    ls1 = df6['CT5'].to_list()
    print(ls1)
    print(df6.columns)
    df6.to_csv(os.getcwd() + "\\Tju1.csv")
    df6 = df6.drop_duplicates(subset=['CT5'], inplace=False, ignore_index=True)
    df6 = df6.reset_index()
    st = chr(10)
    lss = []
    G2 = "2G:"
    G3 = "3G:"
    G4 = "4G:"
    cnt = 0
    for i in range(len(df6)):
        x = df6.loc[i,"CT4"]
        y1 = x + "_H12"
        y2 = x + "_H2"
        ab = df6.loc[i,"CUSTOMATTR15"] + ' - ' + df6.loc[i,"CT3"] + " - " + str(ls1.count(y2)) + "/" + str(ls1.count(y1))
        ac = df6.loc[i,"CUSTOMATTR15"] + ' - ' + str(ls1.count(y1)) + " | " + str(ls1.count(y2))
        st = st + chr(10) + ab
        if ls1.count(y1)>9 and ls1.count(y2)>0 and df6.loc[i,"CUSTOMATTR15"] is not None:
            cnt = 1
            if df6.loc[i,"CT3"] == "G2":
                G2 = G2 + chr(10) + ac
            elif df6.loc[i,"CT3"] == "G3":
                G3 = G3 + chr(10) + ac
            elif df6.loc[i,"CT3"] == "G4":
                G4 = G4 + chr(10) + ac
    else:
        if len(G2)<5:
            G2 = "2G:" + chr(10) + "NA"
        if len(G3)<5:
            G3 = "3G:" + chr(10) + "NA"
        if len(G4)<5:
            G4 = "4G:" + chr(10) + "NA"
        FG = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4 + chr(10) + chr(10)
        th1 = "Site Fluctuation Status" + chr(10) + "at " + "20:01 on 12-18-2020" + chr(10)
        th2 = "Tech: fluctuations count 00hr to last hr|only last hr count" + chr(10)
        FM = th1 + chr(10) + th2 + chr(10) + FG
        print(FM)
        msk = '-475120904'
        q1 = tmsg (msk, FM)
    

#df8 = df8.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
#df8.to_csv(os.getcwd() + "\\AA5.csv", index = False)
#site = df6[df6['SUMMARY'].str.contains('SITE DOWN')]
#cell = df6[df6['SUMMARY'].str.contains('CELL DOWN')]
#dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
#pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
#df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
#pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)










$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation - Copy.py###
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120) \
    else ('H12' if (x < 720)\
    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('extrafeat',df.shape[0])
    return df

def filter_rmvdup_cnt(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    xdf = xdf.reset_index()
    xdf = xdf.sort_values(by=['CAT','CDLO'], ascending=True)
    xdf = xdf.reset_index()
    df1 = xdf.drop_duplicates(subset=['CDLOTECH'], ignore_index=True)
    ndf = countifs(df1, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    return odf
    

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    df5 = filter_rmvdup_cnt(df4)
    

    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    q = tmsg(msk, "SITE " + GG2)
    q = tmsg (msk, "CELL " + GG2C)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    q = tmsg (msk, "SITE " + GG3)
    q = tmsg (msk, "CELL " + GG3C)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    q = tmsg (msk, "SITE " + GG4)
    q = tmsg (msk, "CELL " + GG4C)
    print('done')

def filter_rmvdup_cnt(df):
    print(df.columns)
    #xdf = df.reset_index()
    #xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    #xdf = xdf.reset_index()
    df2 = df[~df['CATX'].isin(['other'])]
    df = df2.reset_index()
    xdf = df.sort_values(by=['CAT','CDLO'], ascending=True)
    xdf = xdf.reset_index()
    df1 = xdf.drop_duplicates(subset=['CDLOTECH'], ignore_index=True)
    ndf = countifs(df1, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf)
    return odf

def catmap_md(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    df1 = df0
    #ls = text2list (semcol)
    #df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    df5 = filter_rmvdup_cnt(df4)
    return df5


print(os.getcwd())
svpt = os.getcwd () + "\\OMTX.csv"
df = pd.read_csv (svpt, low_memory=False)
catmap_md(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation.py###
import os, cx_Oracle
import time as ti
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *
from datetime import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"

nw = datetime.now()
td = nw.strftime("%Y_%b_%d")
mylog = os.getcwd() + "\\log"
todaylog = os.getcwd() + "\\log\\" + td
print(todaylog)

try:
    os.makedirs(mylog)
    os.makedirs(todaylog)
    print("folder created successfully")
except:
    try:
        os.makedirs(todaylog)
    except:
        print(" todayslog folder exits + ")

n = datetime.now ()
td = n.today()
#print(str(td) + "00:00:00")
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")


def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def lasthr(diff = 1):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%H")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,X733EVENTTYPE,X733SPECIFICPROB,CLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR26,TTSEQUENCE,ALARMDETAILS,EQUIPMENTKEY,SITECODE,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    #cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    x = n
    hr = x.strftime('%H')
    STDT = timedelt(-int(hr))
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    df.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    df2 = pd.read_csv(os.getcwd () + "\\SEMQRY.csv")
    print(df2)
    return df2

def wrt2txt(contents, filename = 'excmd', flpath = None):
    print('contets', contents)
    filename =  n.strftime("%Y%m%d%H%M%S")
    if flpath == None:
        flpath = tm + '.txt'
    else:
        flpath = flpath + "\\" + filename + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 60) else ('H12')

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('extrafeat')
    return df

def prob(df):
    df.to_csv (os.getcwd () + "\\FINAL15.csv", index=False)
    xdf = pd.read_csv(os.getcwd () + "\\FINAL15.csv")
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    
    print(odf.shape[0])
    try:
        fdf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        fdf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', fdf.shape[0])
    print(fdf.columns)
    pvt = fdf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt', aggfunc='sum').reset_index()
    pvt.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    pvt = pd.read_csv(os.getcwd () + "\\pvt.csv")
    ndf = pvt[(pvt['H2'] > 1) & (pvt['H12'] > 10)]
    return ndf

def append_dic_value(dict_obj, key, value):
    if key in dict_obj:
        if not isinstance(dict_obj[key], list):
            dict_obj[key] = [dict_obj[key]]
        dict_obj[key].append(value)
    else:
        dict_obj[key] = value

def dic_by_key(dc, ky):
    hp = ky + " : "
    for key in dc:
        if key == ky:
            ls = dc[key]
            if isinstance(ls, list):
                for i in range(len(ls)):
                    if ls[i] not in hp:
                        hp = hp + chr(10) + ls[i]
                    else:
                        pass
                else:
                    if len(hp) < 8:
                        return "3G - 0"
                    else:
                        return chr(10) + hp
                    exit()
            elif ls is None or ls == '':
                return hp + " 0" + chr(10)
                exit()
            else:
                try:
                    hp = chr(10) + hp + chr(10) + ls
                    return hp
                    exit()
                except:
                    return hp + " 0" + chr(10)
                    exit()


def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    df3 = pd.DataFrame([])
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    print(df3)
    xdf = filter_p(df3, ['2G', '3G', '4G'], 'CATX')
    xdf.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(xdf)
    return df4

def sort_rvmdup(df):
    print('sort_rvmdup')
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    df1 = pd.read_csv(os.getcwd () + "\\FINAL13.csv")
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    return df1


def nonechk(tech, x):
    try:
        y = len(x)
        print(y)
        return x
    except:
        return chr(10) + tech + ': NA'

def final_mod(xdf):
    shp = xdf.shape[0]
    print('fmod start- ', shp)
    df1 = xdf.sort_values(by=['LASTOCCURRENCE'], ascending=True)
    df1 = df1.reset_index()
    print('fmod after reset index at line 266 - ', df1.shape[0])
    df1 = df1.assign(hr = '0')
    df1['hr'] = df1.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%H"), axis=1)
    hr = lasthr(1)
    dfh = df1[df1['hr'].isin([hr])]
    print('pick for last hour line 171 and found shape ', dfh.shape[0], ' checking hour ', hr)
    dff = dfh.reset_index()
    print('save file asdff after reset index at line 273- found row length', dff.shape[0])
    df = dff[['EQUIPMENTKEY','CUSTOMATTR15','CAT','CATX']]  ##-------------------df1 = all------------df = this hour
    df.to_csv(os.getcwd () + "\\OKOK.csv", index = False)
    print("\n \n")
    site = {}
    cell = {}
    A = {}
    B = {}
    df = df.astype(str)   #this hour
    df1 =  df1.astype(str)
    hpp = []
    qn = 0
    for i in range(len(df)):
        cat = df.loc[i,'CAT']
        qn = qn + 1
        if int(cat) == 2 or int(cat) == 3 or int(cat) == 4:
            ctx = df.loc[i,'CATX']
            code = df.loc[i, 'CUSTOMATTR15']
            this_hr = countifs(df, df['CUSTOMATTR15'], code, df['CAT'], str(cat))
            all_hr = countifs(df1, df1['CUSTOMATTR15'], code, df1['CAT'], str(cat))
            rest_hr = int(all_hr) - int(this_hr)
            #print(this_hr, all_hr, rest_hr)
            heap1 = code + "-" + str(ctx) + " running for Hour: " + str(hr) + " ~count for thishour-"  + str(this_hr) + "- all hour-" + str(all_hr)
            #print(heap1)
            hpp.append(heap1)
            if rest_hr >= 10:
                st = code + " - " + str(all_hr)
                #print(ctx , st)
                append_dic_value(site, ctx, st)
            else:
                #print('~~~~~~~', ctx, code)
                pass
        elif int(cat) == 22 or int(cat) == 33 or int(cat) == 44:
            ctx = df.loc[i,'CATX'] + " Cell"
            code = df.loc[i, 'EQUIPMENTKEY']
            this_hr = countifs(df, df['EQUIPMENTKEY'], code, df['CAT'], str(cat))
            all_hr = countifs(df1, df1['EQUIPMENTKEY'], code, df1['CAT'], str(cat))
            heap1 = code + " (" + str(ctx) + ") - last Hour fluc: " + str(this_hr) + ", fluc from 00:" + str(all_hr)
            hpp.append(heap1)
            rest_hr = int(all_hr) - int(this_hr)
            #print(this_hr, all_hr, rest_hr)
            if rest_hr >= 10:
                st = code + " - " + str(all_hr)
                #print(ctx , st)
                append_dic_value(cell, ctx, st)
            else:
                #print('~~~~~~~', ctx ,code)
                pass
        else:
            print('else')
    wrt2txt(hpp, "fluc_process", todaylog)       
    G2 = nonechk("2G ", dic_by_key(site, "2G"))
    G3 =  nonechk("3G ", dic_by_key(site, "3G"))
    G4 =  nonechk("4G ",dic_by_key(site, "4G"))
    G22 = nonechk("2G Cell ", dic_by_key(cell, "2G Cell"))
    G33 = nonechk("3G Cell ", dic_by_key(cell, "3G Cell"))
    G44 = nonechk("4G Cell ", dic_by_key(site, "4G Cell"))
    sitewise = G2 + chr(10) + G3 + chr(10) + G4
    cellwise = G22 + chr(10) + G33 + chr(10) + G44
    HD1 = "Site Fluctuation Status" + chr (10) + "at " + tm + chr (10) + sitewise
    HD2 = "Cell Fluctuation Status" + chr (10) + "at " + tm + chr (10) + cellwise
    print(HD1)
    print(HD2)
    msk = '-1001199723504'
    q1 = tmsg (msk, HD1)
    q2 = tmsg (msk, HD2)
    wrt2txt(hpp)

    
def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        





def save2db(df):
    soc ="Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(soc)
    xx = df2sq(df, 'fluc1', conn, bycol='SERIAL')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
#conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
#print (conn.version)
#conn.close()
#import qrybuilt as qr
#from omsql.create_table.tbl_mssql import *

def main(df):
    #cols = ["SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"]
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    #try:
        #CreateTable_MSSQL(df1, 'fluc1', con)
        #dfqry = qr.qbuilt(df1,'fluc1',['SERIAL'])
        #dfqry.to_csv(os.getcwd () + "\\qry.csv", index=False)
    #except:
        #pass
    df2 = sort_rvmdup(df1)
    df4 = final_mod(df2)
    #con = qr.mssql_121()
    #cr= con.cursor()
    #for i in range(len(dfqry)):
        #a1 = dfqry.iloc[i,1]
        #a2 = dfqry.iloc[i,2]
        #try:
            #cr.execute(a1)
        #except:
            #cr.execute(a2)
    #else:
        #con.commit()
    
    #con = mssql_121()
    #print(updf.shape[0])
    #updf = updf.reset_index()
    #updf.to_csv(os.getcwd () + "\\updf.csv", index = False)
    #udf = pd.read_csv(os.getcwd () + "\\updf.csv")
    #ud = udf[['NODE','AGENT','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','EQUIPMENTKEY','CUSTOMATTR15','CAT','CATX','CODE','ZONE','DUR','DURCAT','LO','CDLO','CDLOTECH','SERIAL']]
    #sq.create_table(ud, 'fromfluc2', con)
    #try:
        #sq.update_table(ud, 'SOC_Roster', 'fromfluc2', con, ['SERIAL'])
    #except:
        #sq.upload_bulkdata(ud,'fromfluc2', con, 'SOC_Roster')
        

df = semqry()
y = main(df)
    
#xdf = pd.read_csv(os.getcwd () + "\\FINAL13.csv")
#print(xdf)
#df4 = final_mod(xdf)



#ls = ['NODE','AGENT','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','EQUIPMENTKEY','CUSTOMATTR15','CAT','CATX','CODE','ZONE','DUR','DURCAT','LO','CDLO','CDLOTECH','SERIAL']
#df1 = pd.read_csv(os.getcwd () + "\\updf.csv")
#dfx = df1[ls]
#conn = sq.mssql_121()
#sq.df_to_sql(dfx, 'SOC_Roster', 'fromfluc2', conn, bycolumn=['CDLOTECH'])
#a.to_csv(os.getcwd () + "\\aa.csv")
#df = pd.read_sql("select * from fromfluc2", con = conn)
#print(df)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation1.py###
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d


def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: '2H' if (x < 120) \
    else ('4H' if (x < 240)\
    else ('6H' if (x < 360)\
    else ('12H' if (x < 720)\
    else ('24H' if (x < 1440)\
    else ('48H' if (x < 2880)\
    else ('72H'))))))

TS = lambda x: '2G' if ('2G' in x) \
    else ('3G' if ('3G' in x) \
    else ('4G' if ('4G' in x) \
    else ('OML' if ('2G' in x) \
    else "other")))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    return odf

def sort_rvmdup(df):
    df1 = df[~df['CATX'].isin(['other']) & ~df['CAT'].isin(['other'])]
    df1 = df1.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['72H'] > 10) & (pvt['48H'] > 2)]
    return ndf

def fmtmsg_techwise(df, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    heap = ''
    hp = ""
    hpx = ""
    for n in range(len(df)):
        code = df.loc[n, name_thread_col]
        cat = df.loc[n, name_catcol]
        if str(cat) == str(cat_text):
            for i in range(len(ls_datacol)):
                if hp == "":
                    hp = df.loc[n, ls_datacol[i]]
                else:
                    hp = hp + " | " + df.loc[n, ls_datacol[i]]
            hpx = code + ": " + hp
            if heap == "":
                heap = hpx
                hp = ""
            else:
                heap = heap + chr(10) + hpx
                hp = ""
    return heap

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    df1.to_csv(os.getcwd () + "\\SEMQRY.csv")
    return df1

def main(df):
    ls = ['2H', '12H']
    df1 = catmap_mod(df)
    df2 = sort_rvmdup(df1)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ls, 'CAT', '2') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ls, 'CAT', '3') + chr (10) + chr (10)
    G4 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ls, 'CAT', '4') + chr (10) + chr (10)
    HD1 = "SITE FLUCTUATION COUNT" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | 12Hr" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates 2+ in last 2hr and 10+ in last 12hr"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    msk = '-407548960'
    q = tmsg(msk, GG2)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    q = tmsg (msk, GG3)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    q = tmsg (msk, GG4)
    print('done')

#svpt = os.getcwd () + "\\OMTX.csv"
df = semqry()
xxx = main(df)
#svpt = os.getcwd () + "\\pvt.csv"
#df = pd.read_csv (svpt, low_memory=False)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation2.py###
import os, cx_Oracle
import time as ti
from datetime import *
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *


livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    STDT = timedelt(-23)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    df.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    df2 = pd.read_csv(os.getcwd () + "\\SEMQRY.csv")
    print(df2)
    
    return df2

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120) \
    else ('H12' if (x < 720)\
    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('extrafeat')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    xdf.to_csv (os.getcwd () + "\\FINAL15.csv", index=False)
    xdf = pd.read_csv(os.getcwd () + "\\FINAL15.csv")
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    pvt = odf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    pvt.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    pvt = pd.read_csv(os.getcwd () + "\\pvt.csv")
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    df3 = pd.DataFrame([])
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    print(df3)
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    return df4
    

def sort_rvmdup(df):
    print('sort_rvmdup')
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    df1 = pd.read_csv(os.getcwd () + "\\FINAL13.csv", index = False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    return df1

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df2 = sort_rvmdup(df0)
    df0 = prob(df1)
    
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    q = tmsg(msk, "SITE " + GG2)
    q = tmsg (msk, "CELL " + GG2C)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    q = tmsg (msk, "SITE " + GG3)
    q = tmsg (msk, "CELL " + GG3C)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    q = tmsg (msk, "SITE " + GG4)
    q = tmsg (msk, "CELL " + GG4C)
    print('done')

def save2db(df):
    soc ="Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(soc)
    xx = df2sq(df, 'fluc1', conn, bycol='SERIAL')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
#conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
#print (conn.version)
#conn.close()

df = semqry()
y = main(df)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,newcolname,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,newcolname)
            df1[newcolname] = pd.Series(ls)
            xyz = "cnt-" + str(df0.shape[1]) 
            df2 = df1.groupby([newcolname])[newcolname].count().to_frame(name = xyz).reset_index()
            df = df1.merge(df2, on=newcolname)
            df = df.drop(newcolname, axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fndatetime.py###
import pandas as pd
import numpy as np
from datetime import *


nw = datetime.now().strftime("%d/%m/%Y %H:%M:%S")

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def timediff(df,c1,c2,newcol):
    df[c1] = pd.to_datetime(df[c1])
    df[c2] = pd.to_datetime(df[c2])
    df1 = add_col_df(df,newcol)
    df1[newcol] = abs(df1[c2] - df1[c1])
    df1[newcol] = df1[newcol].astype("i8")/1e9
    df1[newcol] = df1[newcol] / 60
    return df1

def timediff_2(df,c1,c2,newcol):
    df[c1] = pd.to_datetime(df[c1])
    df[c2] = pd.to_datetime(df[c2])
    df1 = add_col_df(df,newcol)
    df1[newcol] = abs(df1[c2] - df1[c1])
    df1[newcol] = df1[newcol].astype('timedelta64[m]')
    return df1

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        df1 = add_col_df(df,'NOW',nw)
        df2 = timediff(df1,dt_col1,'NOW',nwcol)
        df3 = df2.drop(['NOW'], axis = 1)
        return df3
        #lst = df[dt_col1]
        #ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        df2 = timediff(df,dt_col1,dt_col2,nwcol)
        return df2
        #ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    #df[nwcol] = np.nan
    #df[nwcol] = np.array(ls)
    #print('In Minutes')


def datediff(unit,Time1,Time2):
    print(type(Time1))
    print(type(Time2))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnfn.py###
import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1


def conct(df, col1, col2, newcolname, seperator=False):
    if seperator == False:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2])
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2], sep=seperator)
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')


def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')


def map_df_dic(df0, dc, onkey_col, newcolname):
    df = add_col_df (df0, newcolname)
    df[newcolname] = df[onkey_col].map (dc)
    return df

def df_add_list_col(df, nc, nwlst):
    dfx = add_col_df (df, nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array (nwlst)
    return dfx


def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.drop_duplicates (subset=list_of_columns)
    return df


def sort_dsc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.sort_values (by=oncol, ascending=False)


def sort_asc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df = df.sort_values (by=oncol, ascending=True)
    return df


def left(df, sdf, i):
    df1 = add_col_df (df, 'left_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[0:i])
    return df1


def right(df, sdf, i):
    df1 = add_col_df (df, 'right_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[-i:len (x)])
    return df1


def vlookup(df0, refdic, refcol, nwcol):
    if isinstance (refdic, dict):
        try:
            df = add_col_df (df0, nwcol)
            df[nwcol] = df.reset_index ()[refcol].map (refdic).values
            return df
        except:
            df = map_df_dic (df0, refdic, refcol, nwcol)
            return df
    else:
        ndf = df0.merge (refdic, on=refcol)
        return ndf


def countifz(df, list_of_cols_as_ref, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[st].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[col].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def datediff(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")


def aplist(L1, L2):
    ls = []
    if isinstance (L1, pd.core.series.Series) and isinstance (L2, pd.core.series.Series):
        ls1 = L1.to_list ()
        ls2 = L2.to_list ()
        ls = [i + j for i, j in zip (ls1, ls2)]
    elif isinstance (L1, list) and isinstance (L2, list):
        ls = [i + j for i, j in zip (L1, L2)]
    elif isinstance (L1, pd.core.series.Series) and isinstance (L2, str):
        ls1 = L1.to_list ()
        for i in range (len (ls1)):
            ni = str (ls1[i]) + L2
            ls.append (ni)
    elif isinstance (L1, list) and isinstance (L2, str):
        for i in range (len (L1)):
            ni = str (L1[i]) + L2
            ls.append (ni)
    else:
        print ('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls


def countifs(df0, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            df2 = df1.groupby (['NC1']).NC1.count ().to_frame (name='cnt').reset_index ()
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt


def match(df, *argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len (argv) > 0 and len (argv) <= 3:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str) or isinstance (argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list ()
            for i in range (len (colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance (argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len (idx)
                    if manner == 'last':
                        return idx[ln - 1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx


def sumifz(df, list_of_cols_as_ref, numeric_col, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def instr(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.find (srcvalue)
        return f
    else:
        f = strtext.find (srcvalue)
        return f

def instrrev(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.rfind (srcvalue)
        return f
    else:
        f = strtext.rfind (srcvalue)
        return f


def sumifs(df0, numeric_col, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            print (ls)
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            print (df1)
            df2 = df1.groupby (['NC1'])[numeric_col].sum ().to_frame (name='sumifs').reset_index ()
            print (df2)
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnlook.py###
import pandas as pd
import numpy as np
import os
from datetime import *


def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
        return dc
    except:
        print('err')

def vlookup(df0,refdic,refcol,nwcol):
    if isinstance(refdic,dict):
        try:
            df = add_col_df(df0, nwcol)
            df[nwcol] = df.reset_index()[refcol].map(refdic).values
            return df
        except:
            df = map_df_dic(df0,refdic,refcol,nwcol)
            return df
    else:
        ndf = df0.merge(refdic, on=refcol)
        return ndf

def sumif(df2,refcol,numeric_col,newcol):
    df3 = df2.groupby(refcol)[numeric_col].sum().to_frame(name = newcol).reset_index()
    dic = conv_lst_dic(df3[refcol],df3[newcol])
    df4 = map_df_dic(df2,dic,refcol,'sumif')
    return df4

def countif(df0,refcolumn,datacol,newcolname = False):
    if isinstance(refcolumn,str):
        df = add_col_df(df0, newcolname)
        rdf = df[refcolumn]
        reflst = rdf.values.tolist()
        vdf = df[datacol]
        nwlst = []
        for i in vdf:
            try:
                count = reflst.count(i)
                nwlst.append(count)
            except:
                nwlst.append('0')
    df[newcolname] = nwlst
    return df

df = pd.read_csv("C:\\Users\\kabir.omi\\Desktop\\B2.csv")
print(df.columns)
#df["N1"] = df.apply(lambda x : x.Cat + x.CustomAttr11, axis=1) #using 
#x = type(df)
##print(type(df['Cat']))
#print(type(df))
#print(df['Cat'])
print(df['Cat'].to_list().count('2G'))
print(df['Cat'].value_counts())

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnsem.py###
import pandas as pd
import numpy as np
from datetime import *
import os
import fnfn as fn

pt = os.getcwd()

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('C2G' if ('2G CELL DOWN' in x) \
                else ('C3G' if ('3G CELL DOWN' in x) \
                else ('C4G' if ('4G CELL DOWN' in x) \
                else "NA"))))))))))))

def vlookup(df0,refdic,refcol,nwcol):
    if isinstance(refdic,dict):
        try:
            df = add_col_df(df0, nwcol)
            df[nwcol] = df.reset_index()[refcol].map(refdic).values
            return df
        except:
            df = map_df_dic(df0,refdic,refcol,nwcol)
            return df
    else:
        ndf = df0.merge(refdic, on=refcol)
        return ndf

def catsemrw(df0):
    df = add_col_df(df0,'cat')
    df['cat'] = df.apply(lambda row: TS(row.SUMMARY), axis = 1)
    return df

def get_region(df,column_contains_code):
    codemap = ""
    if "\func" in pt:
        codemap = os.getcwd() + "\\scode_map.csv"
    else:
        codemap = os.getcwd() + "\\func\\scode_map.csv"
    dmap = pd.read_csv(codemap)
    df1 = add_col_df(df,'scode')
    df1['scode'] = df1[column_contains_code].apply(lambda x : x[0:5])
    df3 = vlookup(df1,dmap,'scode','NA')
    df3 = df3.drop('scode', axis='columns')
    return df3

def cat_region(df):
    df1 = catsemrw(df)
    df2 = get_region(df1)
    print(df2)

def code_corr(df):
    ndf = df
    for i in range(len(ndf)):
        Eky = str(ndf.loc[i,'EQUIPMENTKEY'])
        A15 = str(ndf.loc[i,'CUSTOMATTR15'])
        if A15 == 'UNKNOWN' and len(Eky) < 15:
            if len(Eky) == 7:
                df.loc[i,'CUSTOMATTR15'] = Eky
            elif len(Eky) == 10:
                df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
            elif '_' in str(Eky):
                fnd =  Eky.find('_')
                if fnd > 7:
                    df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
                else:
                    try:
                        df.loc[i,'CUSTOMATTR15'] = Eky[fnd:7]
                    except:
                        df.loc[i,'CUSTOMATTR15'] = "UNKNOWN"
    return df


def techwise(df0):
    G2 = ""
    G3 = ""
    G4 = ""
    df = df0.applymap(str)
    print(len(df))
    colcode = fn.match(df,'CUSTOMATTR15')
    colLo = fn.match(df,'LASTOCCURRENCE')
    colcat = fn.match(df,'cat')
    for i in range(len(df)):
        try:
            ct = df.iloc[i,colcat]
            if df.iloc[i,colcat] == "2G":
                if G2 == "":
                    ls = df.iloc[:,colcat].to_list()
                    cnt2 = ls.count("2G")
                    G2 = "2G: " + str(cnt2) + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
                else:
                    G2 = G2 + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
            elif df.iloc[i,colcat] == "3G":
                if G3 == "":
                    ls = df.iloc[:,colcat].to_list()
                    cnt3 = ls.count("3G")
                    G3 = "3G: " + str(cnt3) + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
                else:
                    G3 = G3 + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
            elif df.iloc[i,colcat] == "4G":
                if G4 == "":
                    ls = df.iloc[:,colcat].to_list()
                    cnt4 = ls.count("4G")
                    G4 = "4G: " + str(cnt4) + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
                else:
                    G4 = G4 + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
        except:
            print(i)
    G = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4
    print(G)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnstr.py###
import pandas as pd
import numpy as np

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('C2G' if ('2G CELL DOWN' in x) \
                else ('C3G' if ('3G CELL DOWN' in x) \
                else ('C4G' if ('4G CELL DOWN' in x) \
                else "NA"))))))))))))

def Lcut(mstr,cut_to):
    try:
        if len(mstr) >= cut_to:
            x = mstr[0:cut_to]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def Rcut(mstr,cut_to):
    try:
        if len(mstr) - cut_to >= 0:
            a = len(mstr) - cut_to
            b = len(mstr)
            x = mstr[a:b]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def src_in_str(mstr,lkstr):
    if lkstr in mstr:
        return mstr.find(lkstr)
    else:
        return 0

def code_corr(df0):
    df = df0
    for i in range(len(df)):
       Eky = df.loc[i,'EQUIPMENTKEY']
       A15 = df.loc[i,'CUSTOMATTR15']
       if A15 == 'UNKNOWN' and Eky != 'UNKNOWN' and len(Eky)<15:
           if len(Eky) == 7:
               df.loc[i,'CUSTOMATTR15'] = Eky
           elif '_' in Eky:
               x = Eky.find('_')
               if x > 4:
                   df.loc[i,'CUSTOMATTR15'] = Lcut(Eky,7)
               else:
                   df.loc[i,'CUSTOMATTR15'] = Rcut(Eky,7)
    return df

def catsemrw(df0):
    df = add_col_df(df0,'cat')
    df['cat'] = df.apply(lambda row: TS(row.SUMMARY), axis = 1)
    return df

def get_region(df):
    df4 = df
    df5 = flk.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df6.drop('ShortCode', axis='columns', inplace=True)
    return df6

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnx.py###
import pandas as pd
import numpy as np
from datetime import *


df0 = pd.DataFrame([['Iphone','DHDEM26','30-10-2020 12:14','25-11-2020 12:24','400'],['Iphone','CGHTZ09','11-09-2020 12:14','22-11-2020 12:24','400'],
['dell','LXRGN32','11-09-2020 12:14','19-11-2020 12:24','300'],['dell','LXRGN31', '11-09-2020 12:13','11-20-2020 12:24','300'],
['Samsung ','SGSJP04', '11-09-2020 12:12','11-20-2020 12:24','250'],['Samsung ','CXMHK36', '11-09-2020 12:11','11-20-2020 12:24','250'],
['Samsung ','CGFTK29', '11-09-2020 12:10','11-20-2020 12:24','250'],['dell','CGKTLB6','11-09-2020 12:10','11-20-2020 12:24','300'],
['dell','null', '11-09-2020 12:10','11-20-2020 12:24','300']],columns=('PRODUCT','ZIPCODE','SHIPMENT','DELIVERY','PRICE'))

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def sumifs(df,numeric_col,list_of_cols_as_ref):
    if len(list_of_cols_as_ref) > 1:
        st = ""
        for i in range(len(list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)
        df1 = df.groupby(st)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=st)
        df2.drop(st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby(col)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=col)
        return df2


def cntff(df, numeric_col, *argv):
    rngmod = len(argv) % 2
    if len(argv) > 0 and rngmod == 0:
        n = 0
        lscnt = 0
        stcnt = 0
        lsTmp = []
        ls = []
        st = ""
        while n < len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                if len(ls) < 1:
                    ls = argv[n]
                else:
                    lsTmp = aplist(ls,argv[n])
                    ls = lsTmp
                lscnt = lscnt + 1
            else:
                stcnt = stcnt + 1
                st = st + str(argv[n])
            n = n + 1
        df['NC1'] = pd.Series(ls)
        if stcnt == lscnt:
            df1 = df.groupby(st)[numeric_col].sum().to_frame(name = "X").reset_index()
        elif stcnt == 0:
            df1 = df.groupby([ls])[numeric_col].sum().to_frame(name = "X").reset_index()
        print(df1)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\Fomdf.py###
import pandas as pd
import numpy as np
import os
import sqlite3

pt = os.getcwd()
alarm = pt + "\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]


con = sqlite3.connect('omdb.db')
def create_tbl():
    cr = con.cursor()
    cr.execute("CREATE TABLE hs(SERIAL,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,CUSTOMATTR3)")
    con.commit()

def uoload_data(df1,dbname):
    df1.to_sql("'" + dbname + "'", con)

def delete_data(dbname):
    pass



def concat(v1,v2):
    z = str(v1) + '-' + str(v2)
    return z

CDCT = lambda x : x[:4] if (len(x) >= 6) else "NF"

def df_add_col(dff,nwcol,whichfn):
    df = dff.replace(r'^\s*$', np.NaN, regex=True)
    if whichfn == 'concat':
        for i in range(len(df)):
            df.loc[i,nwcol] = concat(df.loc[i,"CUSTOMATTR15"],df.loc[i,"SUMMARY"])
        return df
    elif whichfn == 'codecut':
        dfx = df.convert_dtypes()
        dfx = dfx.assign(scode = lambda x: CDCT(x.CUSTOMATTR15), axis=1)
        return dfx
    elif whichfn == 'datediff':
        df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].astype('datetime64[ns]')
        print(df)



x = df_add_col(df1,'scode','datediff')
print(x)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\get_groups_details_om.py###
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from pprint import pprint
import os

api_id = 628127
api_hash = 'db7fa09d585d6eedddd0df5973f3239b'
phone = '+8801817184338'
client = TelegramClient(phone, api_id, api_hash)
client.connect()

if not client.is_user_authorized():
    client.send_code_request(phone)
    client.sign_in(phone, input('Enter the code: '))
    print("success")



def group_participant(target_group):
    all_participants = client.get_participants(target_group, aggressive=True)
    print('GroupName: ', target_group, "total member: ", len(all_participants))
    print("serial | firstname | lastname | phone")
    n = 0
    for i in all_participants:
        n = n + 1
        x = 'adduser, halim, 23421435, 01817123123'
        x1 = 'adduser,' + str(i.first_name) + "," + str(i.id) + "," + str(i.phone)
        print(x1)
        #if i.last_name == 'none':
            #print(n, '. name: ' , i.first_name, ' | ' , "Phone: ", i.phone, i.id)
        #else:
            #print (n, '. name: ', i.first_name, i.last_name , ' | ', "Phone: ", i.phone, 'ID - ', i.id)
    #print(all_participants)

x = group_participant('VIP Sites Update')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\group_member_smpool.py###
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from pprint import pprint
import os


api_id = 1621549
api_hash = '6b06c3cf6e7004803b11c79f80e1b8bf'
phone = '+8801817183680'
client = TelegramClient(phone, api_id, api_hash)
client.connect()

if not client.is_user_authorized():
    client.send_code_request(phone)
    client.sign_in(phone, input('Enter the code: '))
    print("success")

def group_participant(target_group):
    all_participants = client.get_participants(target_group, aggressive=True)
    print('GroupName: ', target_group, "total member: ", len(all_participants))
    print("serial | firstname | lastname | phone")
    n = 0
    for i in all_participants:
        n = n + 1
        if i.last_name == 'none':
            print(n, '. name: ' , i.first_name, ' | ' , "Phone: ", i.phone)
        else:
            print (n, '. name: ', i.first_name, i.last_name , ' | ', "Phone: ", i.phone)

x = group_participant()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\handover.py###
import pandas as pd
import re

#SOCCOM = ["infoadd, 'subject'; 'body'; 'msgcat'; 'concern(optional)'; 'code (optional)'; 'tag (optional)'",
#"handover, No# 'subject'; 'body';'msgcat'; 'concern(optional)'; 'code (optional)'; 'tag (optional)",
#"query, 'text/code/category', date(optional)"]


#def insert_msg(dt, src, subject, body, concern = "", unit = "" code = "", tag = ""):
#    from =

def trcking_format():
    SOCCOM_HELP = """
@infoadd,
subject: mandatory;
body: mandatory;
concern: (optional);
unit: TNR (optional);
code: (optional);
tag: (optional);
date: (optional)
..
            
@infoadd,
subject: DHBDD32 Locked;
body: due to stolen issue, sites locked;
date: 2020-11-20
..
            
@hadover,
1#
subject: tx issue at DHGUL02;
body: due to TNR NCR Activity/other information;
concern: sudipta (optional);
unit: TNR (optional);
code: (optional);
tag: (optional)
..
            
2#
subject: fauction issue of DHGUL02;body: fls is checking, need followup;concern: TBA
.."""
    return SOCCOM_HELP


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\hidemy.py###
import requests
import pandas as pd
import os
import csv
import io

pth = os.getcwd() + '\\DW\\'
cf = pth + 'hideme.csv'
hideme_access = "730480402242392"
hideme = "http://incloak.com/api/proxylist.php?country=US&Speed<=1000&ports=&type=socks5&out=csv&code=" + hideme_access
hideme2 = "http://incloak.com/api/proxylist.php?out=csv&code=" + hideme_access
lnFF = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"

def csv_read(cf):
    with open(cf, newline='') as csvfile:
        reader = csv.DictReader(csvfile,delimiter=';')
        for row in reader:
            print(row['ip'],row['port'],row['city'])

def csv_2df(path,delim):
    df = pd.read_csv(path,delimiter=delim)
    return df

def csv_2dict(path,lst_fieldname):
    with open(path, newline='') as csvfile:
        fieldnames = lst_fieldname
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        return writer

def api_csv_read(lnk,delim):
    download = requests.get(lnk)
    decoded_content = download.content.decode('utf-8')
    cr = csv.reader(decoded_content.splitlines(), delimiter=delim)
    lst = list(cr)
    for row in lst:
        print(row)

def api_csv_df(lnk,delim):
    urlData = requests.get(lnk).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=delim)
    return df

#x = api2df(hideme,";")
x = api_csv_df(hideme2,";")
print(x)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\incident.py###
import pyodbc,os
import pandas as pd
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from dateutil.relativedelta import *
from dateutil.parser import parse

n = datetime.now()
td = date.today()

soc = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#soc = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"


#opt = itertools.islice(ls, len(ls))
#st = map(lambda x : )

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    code = []
    q = 0
    #print(ls)
    for i in range(len(ls)):
        text = txt
        if ls[i] in text.upper():
            n = text.find(ls[i])
            st = text[n:n+7]
            code.append(st)
            txt = txt.replace(ls[i],'')
            q = q + 1
    else:
        if q == 0:
            return ''
        else:
            return code
        
def qry_by_code(code, tbl = None, col = None):
    if tbl is None and col is None:
        a1 = "select Incident_Notification,Down_Time,Up_Time,Major_Cause,Action_Taken,Link_ID_Site_ID,Incident_ID from incident_tracker_v2 where ("
        a2 = " No_of_2G_Impacted_sites Like '%" + code + "%' or No_of_3G_Impacted_sites like '%" + code + "%' or No_of_4G_Impacted_Sites like '%" + code + "%' or Incident_Notification Like '%" + code 
        a3 = "%') order by Down_Time desc"
        aa = a1 + a2 + a3
        return aa
    else:
        return ""

def colsmod(txt):
    if txt == 'Incident_Notification':
        return ''
    elif txt == 'Down_Time':
        return "FT: "
    elif txt == 'Up_Time':
        return "RT: "
    elif txt == 'Major_Cause':
        return "Cause:"
    elif txt == 'Incident_ID':
        return "ID: "
    elif txt == 'Link_ID_Site_ID':
        return "Link: "
        

def codechk(txt):
    print('code checking init')
    rs = parsecode(txt.upper())
    st = 0
    print('ret val', rs)
    if len(rs) == 1:
        code = rs[0]
        rn = 0
        qry = qry_by_code(code)
        conn = pyodbc.connect(soc)
        df = pd.read_sql(qry, con = conn)
        print(qry, df)
        cols = df.columns.to_list()
        conn.close()
        if df.shape[0] != 0:
            if df.shape[0] > 3:
                st = "last 3 incident out of " + str(df.shape[0])
                rn = 3
            else:
                st = "incident found " + df.shape[0] + chr(10)
                rn = df.shape[0]
            for i in range(rn):
                tmp = chr(10)
                for j in range(len(cols)):
                    x = df.loc[i, cols[j]]
                    if x is not None  and x !='':
                        try:
                            tmp = tmp + chr(10) + colsmod(cols[j]) + str(x)
                        except:
                            print(type(x),type(cols[j]), cols[j])
                else:
                    st = st + ". " + tmp
        print('single code check', len(st), st)
        return st
    else:
        print('single code ELSE', st)
        return st
    



def incident_q(dt = None, incid = None):
    conn = pyodbc.connect(soc)
    qry = ''
    if dt is None and incid is None :
        qry = "select Incident_Notification,Down_Time,Incident_ID from incident_tracker_v2 where Status='Pending'"
    elif dt is not None and incid is None:
        qry = "select Incident_Notification,Down_Time,Up_Time,Reason,Incident_ID from incident_tracker_v2 where Incident_Date = '" + str(dt) + "'"
    elif dt is None and incid is not None and incid != '':
        qry = "select Incident_Notification,Down_Time,Up_Time,impacted_site_list from incident_tracker_v2 where Incident_ID='" + incid + "'"
    else:
        return 'format is like: "incident" or "incident, 2020-11-25" or "incident, today" or "incident, yesterday" or "incid, INC000012310663'
    conn = pyodbc.connect(soc)
    df = pd.read_sql(qry, con=conn)
    conn.close()
    ls = []
    st = ''
    q = 0
    cols = df.columns.to_list()
    if df.shape[0] != 0:
        for i in range(df.shape[0]):
            q = q + 1
            for j in range(len(cols)):
                xx = df.loc[i, cols[j]]
                if xx == "":
                   xx = "No Data"
                if st == '':
                    st = str(q) + ". " + str(xx)
                else:
                    st = st + chr(10) + cols[j] + ":" + str(xx)
            ls.append(st)
            st = ''
        else:
            return ls
    else:
        ls = ['no incident found']
        return ls

def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str

def parse_dt(tx):
    approval = 0
    try:
        int(tx[3])
        approval = 1
    except:
        try:
            int(tx[4])
            approval = 1
        except:
            try:
                int(tx[5])
                approval = 1
            except:
                return 0
                exit()
    txt = tx.upper()
    n = datetime.now()
    yr = n.strftime("%y")
    succ = 0
    try:
        pdt = parse(txt, fuzzy=True)
        print('parse print', pdt)
        x = pdt.strftime("%Y-%m-%d")
        succ = 1
    except:
        succ = 0
    if succ == 1:
        pdtx = parse(txt, dayfirst=True, fuzzy=True)
        dts = pdtx.strftime("%Y-%m-%d")
        print('returning as succ=1', dts)
        return dts
    elif 'TODAY' in txt:
        str_d = n.strftime("%Y-%m-%d")
        return str_d
    else:
       return 0

def inc_chk(txt):
    tx = ''
    xx = []
    xyz = codechk(txt.upper())
    find_dt = parse_dt(txt)
    if 'incid ' in txt or 'INCID ' in txt:
        idd = txt.split(',')
        incid = idd[1]
        incids = incid.strip(' ')
        xx = incident_q(dt = None, incid = incids)
        msg = "info associated with \n" + incid + chr(10) + chr(10)
        xx.insert(0,msg)
    elif xyz != 0:
        xx.append(xyz)
    else:
        if find_dt == '0' or find_dt == 0 :
            xx = incident_q()
            xx.insert(0,"Please have the current incident \n")
        else:
            xx = incident_q(find_dt)
            sss = "Please have the incident on date \n" + str(find_dt) + "\n"
            xx.insert(0,sss)
    return xx
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\insert_db.py###
import MySQLdb
import pandas as pd
try:
    conn= MySQLdb.connect("localhost","root","root","ops1")
except:
    print("Can't connect to database")
#cursor = conn.cursor()

df = pd.read_csv("F:\\MYDB.csv",delimiter = ',')
df.to_sql('OMIDB2', conn, if_exists = 'append', index = False)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\InsUpd.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os
from mysql import *
#from sqlalchemy import create_engine
import omsqlfn as fn
import os
from datetime import *
import datetime
import time

#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def get_key(my_dict, val): 
    for value, key in my_dict.items(): 
        if value == val:
            return key
        
def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
       
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)
            
#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)


def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + fn.prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def InsertUpdate(db, tbl, con, df, bycol = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            dfx = ndf.drop(bycol, 1)
            colsname = dfx.columns.to_list()
            colscond = ndf[bycol].to_list()
            q = 0
            for i in range(len(colscond)):
                vl = colscond[i]
                chk = CheckExist(con, tbl, bycol, vl)
                ls = []
                qry = ''
                if chk != 0:
                    for c1 in dfx:
                        ls.append(dfx.loc[i,c1])
                    qry = "update " + tbl + ' set ' + fn.prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                else:
                    for c1 in ndf:
                        ls.append(ndf.loc[i,c1])
                    qry = "insert into " + tbl + ' ' + fn.prep_insert(allcols,ls)
                cr.execute(qry)
                q = q + 1
                if q <3:
                    print(qry)
                con.commit()
                



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\ipapi.py###
import requests as r
import json
from pprint import pprint
import os

def ipdb_1(ip):
    #https://app.ipgeolocation.io/
    ipgeolocation = "ec875907f0da48b3ac1859a1096c5971"
    apilink = 'https://api.ipgeolocation.io/ipgeo?apiKey=' + ipgeolocation + "&ip=" + ip
    G = r.get(apilink)
    print(G.text)
    return G.text


def ipdb_2(ip):
    url = "https://freegeoip.app/json/" + ip
    headers = {
        'accept': "application/json",
        'content-type': "application/json"
        }
    response = r.request("GET", url, headers=headers)
    print(type(response))
    print(response.text)

def ipdb_filefab():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    G = r.get(z)
    print(G)

def ip_geojs(ip):
    os.system("curl https://get.geojs.io/v1/ip/geo/{" + ip + "}.js")

def ip_db3(ip):
    rs = r.get('https://bgp.tools/ip?q=' + ip).text
    print(rs)


#x = ipdb_1('45.156.24.78')
#ipdb_2('45.156.24.78')
ipdb_2('45.156.24.78')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\ipmap.py###
import pandas as pd
import numpy as np
import os
import MySQLdb
import csv
import requests
import io
import datetime as dt
import geoip2.database

#shift-ctrl-b

pt = os.getcwd()
dbmx = "E:\\GIT\\OmProject\\OmSocks\\ippro\\GeoLite2-City.mmdb"
dbas2ip = "E:\\GIT\\OmProject\\OmSocks\\ippro\\ip2asn.csv"

def mxdb(ip):
    with geoip2.database.Reader(dbmx) as reader:
        try:
            response = reader.city(ip)
            lst = response.city.name + ' -' + response.country.iso_code
            return lst
        except:
            lst = 'NA'
            return lst

def filename_maker():
    y = dt.datetime.now()
    x = y.strftime("%d%m%Y-%H%M")
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww

def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]


def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

def maincall(df_port_ip):
    df = pd.read_csv(dbas2ip)
    dpx1 = df_port_ip[['ip','port']]
    ls = []
    for r in range(dpx1.shape[0]):
        lst = []
        ip = dpx1.iloc[r,0]
        prt = dpx1.iloc[r,1]
        ipx = ip.split('.')
        ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
        aa = find_owner(ddf.to_numpy(),ip)
        lst.insert(0,ip)
        lst.insert(1,prt)
        lst.insert(2,mxdb(ip))
        lst.insert(3,aa)
        ls.append(lst)
    fdf = pd.DataFrame(ls,columns = ['ip','port','CityCountry','SL'])
    ffd = pd.merge(fdf,df,on ='SL',how ='left')
    fd = ffd[['ip','port','CityCountry','ISP','ASN','Country']]
    fd.to_csv(filename_maker())
    return fd

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\jsonrw.py###
#ref:https://pynative.com/python-json-dumps-and-dump-for-json-encoding/
import json
import os

def jsonMod(jsn,ip,port):
    with open(jsn, "r") as jsonFile:
        x = json.load(jsonFile)
        x['configs'][0]['server'] = ip
        x['configs'][0]['server_port'] = port
        print(x)
    with open(jsn, "w") as jsonFile:
        json.dump(x, jsonFile)

jp = os.getcwd() + "\\proxylist.json"
jsonMod(jp,'8.8.8.8','01010')

#demjson.decode(prot)
#(prot)
#print(usr)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\json_rewt.py###
#ref:https://pynative.com/python-json-dumps-and-dump-for-json-encoding/
import json
import os

def jsonMod(jsn,ip,port):
    with open(jsn, "r") as jsonFile:
        x = json.load(jsonFile)
        x['configs'][0]['server'] = ip
        x['configs'][0]['server_port'] = port
        print(x)
    with open(jsn, "w") as jsonFile:
        json.dump(x, jsonFile)

jp = os.getcwd() + "\\proxylist.json"
jsonMod(jp,'8.8.8.8','01010')

#demjson.decode(prot)
#(prot)
#print(usr)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\lookup.py###
import pandas as pd
import numpy as np
import os
from datetime import *



def join_list(ls1, ls2, ls3):
    ToDf = pd.DataFrame(zip(ls1, ls2, ls3))
    return ToDf

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
        return dc
    except:
        print('err')

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def df_add_list_col(df,nc,nwlst):
    dfx = add_col_df(df,nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array(nwlst)
    return dfx

def vlookup1(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls



def process_sem_raw(df1):
    #df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CustomAttr15']
    LL2 = df1['LastOccurrence']
    #LL3 = df1['ClearTimestamp']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    #agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    #ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    ndf4 = catsemrw(ndf2)
    return ndf4

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(ndf,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs(df,refcol,numeric_col):
    df['agsum'] = df.groupby(refcol)[numeric_col].sum()
    return df
    #df['agsum'] = df.groupby('pet').treats.transform('sum')

def match(df,indx,typ):
    pass

#### Custom For SEM DATA Process ###

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\main.py###
import pandas as pd
import os, datetime, time, pyodbc
from mysql import *
from sqlalchemy import create_engine
import df_to_sql.df_to_sql as insupd
import create_table.tbl_mysql as myq
import create_table.tbl_mssql as msq
#from conn_brocker import *

def mssql_115():
    cstr = "Driver={SQL Server};SERVER=192.168.0.115;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"
    conn = pyodbc.connect(cstr)
    return conn

def MsSql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn

def mysql_self(user = 'root', password = 'root', host = '127.0.0.1:3306', db = "omdb"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

def insert_data():
    pt = os.getcwd() + "\\csv\\sclick.csv"
    ndf = pd.read_csv(pt)
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    lser = insupd.df_to_sql(ndf, 'omdb', 'TAX1', conn, oncolumn = 'ALL')
    conn.close()

def update_by_condition():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    lser = insupd.df_to_sql(df, 'omdb', 'TAX1', conn, bycolumn=['CustomAttr15'])
    conn.close()

def createtable():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')    
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    x = myq.CreateTable_MYSQL(connection = conn, tablename = 'TAX2', df = df, table_col = False, table_col_datatype = False, space = '_')
    conn.close()

def sql2df(tbl):
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    qry = 'select * from '+ tbl
    df = pd.read_sql(qry, con = conn)
    return df

#createtable()
#conn = MySql('root','admin','127.0.0.1:3306','omdb')
pt = os.getcwd() + "\\sclick2.csv"
df = pd.read_csv(pt)
conn = mssql_115()
#df.to_sql("t12", con = conn)
#msq.CreateTable_MSSQL(df, "t33", conn)
#lser = insupd.df_to_sql(df, 'SOC_Roster', 't22', conn, oncolumn = 'ALL')
#conn.commit()
#
#dfx = pd.read_sql('select * from omtx2', con = conn)
#print(dfx.columns, dfx.dtypes, df.shape[0])
dfx = pd.read_sql("select * from t22", con=conn)
print(dfx.columns, dfx)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\maintest.py###


def main():
    print("Hello World!")

def omi():
    print('balsal')

if __name__ == "__main__":
    main()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\main_caller.py###
import subprocess
import time
import runpy
#def prnt():
   # print("running.....")
   # runpy.run_module('F:\PG\PgOnOFF\PGMAIN1406.py')
   # return "waiting"
#call("F:\\PG\\PgOnOFF\\Scripts\\python.exe","F:\\PG\\PgOnOFF\\pgmain_2.py")
#os.system('‪F:\PG\PgOnOFF\Scripts\python.exe pgmain_2.py')

def mcall():
    print("running.....")
    subprocess.call([r"F:\Python\Proj1\runbat.bat"])
    return "waiting"

while True:
    print(mcall())
    time.sleep(45)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\malsem.py###
import os, cx_Oracle
import time as ti
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *
from datetime import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"

nw = datetime.now()
td = nw.strftime("%Y_%b_%d")
mylog = os.getcwd() + "\\log"
todaylog = os.getcwd() + "\\log\\" + td
print(todaylog)

try:
    os.makedirs(mylog)
    os.makedirs(todaylog)
    print("folder created successfully")
except:
    try:
        os.makedirs(todaylog)
    except:
        print(" todayslog folder exits + ")

n = datetime.now ()
td = n.today()
#print(str(td) + "00:00:00")
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")


def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def lasthr(diff = 1):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%H")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,X733EVENTTYPE,X733SPECIFICPROB,CLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR26,TTSEQUENCE,ALARMDETAILS,EQUIPMENTKEY,SITECODE,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    #cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    x = n
    hr = x.strftime('%H')
    STDT = timedelt(-int(hr))
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    lscol = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']
    ddf = df[lscol]
    ddf.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    return ddf
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mapper.py###
import os
import omt as om
import textfl as tx
from datetime import *

nw = datetime.now()
filename = nw.strftime("%d%m%Y-%h%m")

rpa_mask = os.getcwd() + "//rpa_group//grpmask.txt"
rpa_mask_head = os.getcwd() + "//rpa_group//grmask_head.txt"
omgrp = os.getcwd() + "//omgroup//omgrp.txt"
mask_grp = os.getcwd() + "//mask_group_map//"+ filename + "_rpa_mask_grp.txt"
rpa_mask_grp_name = os.getcwd() + "//mask_group_map//21102020-Oct10_rpa_mask_grp.txt"
rpagrpmap = os.getcwd() + "//rpa_group_map//maksmap.txt"
rpagrpnm = os.getcwd() + "//rpa_group_map//grpname.txt"

def update_files_rpa():
    tx.pick_rpa_group()

def update_file_omgrp():
    om.client_run()

def map_text_by_mask(f1,f2):
    st = ""
    file1 = tx.rdall(f1)
    file2 = tx.rdline(f2)
    for line in file2:
        if len(line)>5:
            msk = line[0:line.find(",")-1]
            if msk in file1:
                st = st + "\n" + line
    tx.wrt(mask_grp,st)
    
def map_by_groupname(f1):
    f2 = om.client_run()
    st = ""
    m = ""
    file1 = tx.rdline(f1)
    file2 = tx.rdline(f2)
    for line in file2:
        if len(line)>5:
            msk = line[0:line.find(",")-1]
            grpname = line[line.find(",")+1:len(line)-1]
            for ln in file1:
                gn = ln[ln.find(",")+1:len(ln)-1]
                old_msk = ln[0:ln.find(",")-1]
                print(gn)
                if gn == grpname:
                    print(gn,grpname)
                               

def src_in_file(content,srcstr):
    for ln in content:
        lnx = ln.replace("\n","")
        comma = lnx.find(',')
        msk = lnx[0:comma]
        gnm = lnx[comma+1:len(lnx)]
        if gnm == srcstr:
            return msk
            break

def old_new_mask_map():
    oldref = tx.rdline(rpa_mask_grp_name)
    f2 = om.client_run()
    fl2 = tx.rdline(f2)
    n = 0
    st = ""
    currgrp = ""
    for ln in oldref:
        if len(ln)>5:
            n = n + 1
            lnx = ln.replace("\n","")
            comma = lnx.find(',')
            msk = lnx[0:comma]
            gnm = lnx[comma+1:len(lnx)]
            ms = src_in_file(fl2,gnm)
            if type(ms) != 'NoneType':
                if st == "":
                    st = str(msk) + "," + str(ms)
                    currgrp = str(n) + ". " + gnm
                else:
                    st = st + chr(10) + str(msk) + "," + str(ms)
                    currgrp = currgrp + chr(10) + str(n) + ". " + gnm
    tx.wrt(rpagrpmap,st)
    tx.wrt(rpagrpnm,currgrp)
    
old_new_mask_map()








$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\minifn.py###
import time as tm
import pandas as pd
import numpy as np
from datetime import *
import os

# getkey(my_dict, ky)



def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "key not found"

def append_dic_value(dict_obj, key, value):
    if key in dict_obj:
        if not isinstance(dict_obj[key], list):
            dict_obj[key] = [dict_obj[key]]
        dict_obj[key].append(value)
    else:
        dict_obj[key] = value

def dic_by_key(dc, ky):
    hp = ky + " : "
    for key in dc:
        if key == ky:
            ls = dc[key]
            if isinstance(ls, list):
                for i in range(len(ls)):
                    if ls[i] not in hp:
                        hp = hp + chr(10) + ls[i]
                    else:
                        pass
                else:
                    if len(hp) < 8:
                        return "3G - 0"
                    else:
                        return chr(10) + hp
                    exit()
            elif ls is None or ls == '':
                return hp + " 0" + chr(10)
                exit()
            else:
                try:
                    hp = chr(10) + hp + chr(10) + ls
                    return hp
                    exit()
                except:
                    return hp + " 0" + chr(10)
                    exit()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mproxy.py###
import asyncio
import pproxy

ipport = "185.183.98.136:5030"

server = pproxy.Server('socks5://173.0.54.188:6888')
remote = pproxy.Connection('socks5://45.72.6.167:8000#HsQ1hf:jEcN8w')
args = dict( rserver = [remote],verbose = print )

loop = asyncio.get_event_loop()
handler = loop.run_until_complete(server.start_server(args))
try:
    loop.run_forever()
except KeyboardInterrupt:
    print('exit!')

handler.close()
loop.run_until_complete(handler.wait_closed())
loop.run_until_complete(loop.shutdown_asyncgens())
loop.close()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mrg.py###
import pandas as pd
import numpy as np
import os
import MySQLdb
import csv
import requests
import io
import datetime as dt


def api_hideme():
    hideme_access = "730480402242392"
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + hideme_access
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
cur = conn.cursor()
pt = os.getcwd()
proxy = pt + '\\hideme.csv'
db = pt + '\\kkk.csv'
db2 = pt + '\\i2a.csv'
qqq = pt + '\\QQQQAQA.csv'

def split_col(npary,splitby,colname):
    rw, col = npary.shape
    flist = []
    for i in range(rw):
        lst = []
        x = npary[i][0]
        lst = x.split(splitby)
        lst.insert(0,x)
        flist.append(lst)
    df = pd.DataFrame(flist,columns = colname)
    return df

def add_col(dA,c):
    rw, col = dA.shape
    lst = []
    for i in range(rw):
        x = dA[i][c]
        y = x.rfind('.')
        s = x[0:y]
        lst.append(s)
    dA = np.append(dA, np.array([lst]).transpose(), axis=1)
    return dA

def api_ip2asn(ip):
    url = "https://api.iptoasn.com/v1/as/ip/" + ip
    x = requests.get(url)
    y = x.json()
    as_owner = y["as_description"]
    return as_owner

def missing(z):
    rw, col = z.shape
    lst = []
    dic = {}
    cnt = 0
    for i in range(rw):
        lst2 = []
        lst.append([z[i][0],z[i][1],z[i][2]])
        for c in range(col):
            lst2.append(z[i][c])
        ipmd = z[i][2]
        ip = z[i][0]
        df = ddb[ddb['IPMOD'].str.contains(ipmd)]
        if df.shape[0] > 0:
            rs = api_ip2asn(ip)
            print(rs)
            cnt = cnt + 1
        else:
            print(df)
        dic.update( {i : lst2} )
        if cnt == 5:
            break
    print(dic)
    #for c in range(col):
        #print(z[i][c])
        
    #x = z[i][2]
    #print(x)
   
#df1 = pd.DataFrame(z,columns=['ip','port','IPMOD'])
#print(df1)

#cur = conn.cursor()
#for row in df1():

#dpx = api_hideme()
def nearest(lst, K): 
     lst = np.asarray(lst) 
     idx = (np.abs(lst - K)).argmin() 
     return lst[idx]
    
def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

x = 0
if x == 1:
    qq = pd.read_csv(qqq)
    dpx1 = qq[['ip']]
    listformat = ['ip','i1','i2','i3','i4']
    getlist = split_col(dpx1.to_numpy(),".",listformat)
    print(getlist)
    df = pd.DataFrame(getlist,columns = listformat)
    dff = pd.merge(qq,df,on ='ip',how ='left')


def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        #print(I1,xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]

def filename_maker():
    y = dt.datetime.now()
    x = y.strftime('%d%m%Y-%H%M')
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww
    
proxy = pt + '\\hideme.csv'
db = pt + '\\kkk.csv'
df = pd.read_csv(db)
#qq = pd.read_csv(proxy,delimiter=';')
qq = api_hideme()
dpx1 = qq[['ip','port']]
ls = []
for r in range(dpx1.shape[0]):
    lst = []
    ip = dpx1.iloc[r,0]
    prt = dpx1.iloc[r,1]
    ipx = ip.split('.')
    ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
    aa = find_owner(ddf.to_numpy(),ip)
    lst.insert(0,ip)
    lst.insert(1,prt)
    lst.insert(2,aa)
    ls.append(lst)
    
fdf = pd.DataFrame(ls,columns = ['ip','port','SL'])
ffd = pd.merge(fdf,df,on ='SL',how ='left')
fd = ffd[['ip','port','ISP','ASN','Country']]
fd.to_csv(filename_maker())


p = 0
if p == 1:
    B12 = ddf.columns.get_loc("IP1-B2")
    B22 = ddf.columns.get_loc("IP2-B2")
    B13 = ddf.columns.get_loc("IP1-B3")
    B23 = ddf.columns.get_loc("IP2-B3")
    for r in range(ddf.shape[0]):
        iB12 = ddf.iloc[r,B12]
        iB22 = ddf.iloc[r,B22]
        iB13 = ddf.iloc[r,B13]
        iB23 = ddf.iloc[r,B23]
        B2 = matching_point(50,iB12,iB22)
     
    

#rw, col = npar1.shape
#for i in range(rw):
    #B2_1 = npar1[i]['IP1-B2']
    #B2_2 = npar1[i]['IP2-B2']

#for i,j in getlist:
    #lstt= j
    #lstt.insert(0, i)
    #print(lstt)
#ddb = pd.read_csv(db)
#narr = split_col(ddb.to_numpy(),0)


#ddb2 = pd.read_csv(db2)
#dA = dpx1.to_numpy()
#narr = add_col(dA,0)
#df1 = pd.DataFrame(narr,columns=['ip','port','IPMOD'])
#RJ = pd.merge(df1,ddb2,on ='IPMOD',how ='left')

#missing(narr)

#df = pd.read_sql("select * from ipasn10",conn)
#print(df)
#fdf = df1.merge(df, on='IPMOD')
#fdf.to_csv(pt + '\\merged.csv')
#print(fdf)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\msq.py###
import os
import csv
import mysql.connector

skipHeader = True
pt = os.getcwd()
fl = pt + '\\i.csv'
#conn= mysql.connector.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
conn = mysql.connector.connect(user='akomi', password='1q2w3eaz$', host='23.152.224.49', database='omdb')
cur = conn.cursor()
tbl = "ipasn10"
csv_data = csv.reader(fl)

for row in csv_data:
    if skipHeader:
        skipHeader = False
        continue
    cur.execute('INSERT INTO ipasn3 (IP1, IP2, ASN, Country, ISP, IPMOD) VALUES (%s, %s, %s, %s, %s, %s)', row)

#query = "LOAD DATA INFILE 'C:/python/python-insert-csv-data-into-mysql/students-header.csv' INTO TABLE student FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' IGNORE 1 LINES (student_id, student_name, student_dob, student_email, student_address)"

#query = "LOAD DATA INFILE 'C:/python/python-insert-csv-data-into-mysql/students.csv' INTO TABLE student FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' (student_id, student_name, student_dob, student_email, student_address)"

#cur.execute(query)

conn.commit()

conn.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\msq2.py###
import MySQLdb
import os
import string

db = MySQLdb.connect (host="23.152.224.49",
    user="akomi",
    passwd="1q2w3eaz$",
    db="omdb",
    local_infile = 1) #Grants permission to write to db from an input file. Without this you get sql Error: (1148, 'The used command is not allowed with this MySQL version')

print("Connection to DB established")

#The statement 'IGNORE 1 LINES' below makes the Python script ignore first line on csv file
#You can execute the sql below on the mysql bash to test if it works
sqlLoadData = """load data local infile 'i.csv' into table ipasn FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' IGNORE 1 LINES;"""

curs = db.cursor()   
curs.execute(sqlLoadData)
db.commit()   
print("SQL execution complete")
resultSet = curs.fetchall()

print("Data loading complete")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mssql.py###
import pyodbc
import pandas as pd

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
UserRd = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=rocuser;Pwd=Roc@072$123"
UserSMS = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"

conn = pyodbc.connect(socdb)
df = pd.read_csv("F:\\MYDB.csv",delimiter = ',')
cursor = conn.cursor()
for index, row in df.iterrows():
	#print(row)
	cursor.execute("INSERT INTO 'omidb' ([SITECODE],[THANA],[DISTRICT],[REGION],[LON],[LAT],[P1P2],[OWNER],[LINK],[PG],[PWR_AUT]) values (?,?,?,?,?,?,?,?,?,?,?)",
    (row['SITECODE'], row['THANA'], row['DISTRICT'], row['REGION'], row['LON'], row['LAT'], row['P1P2'], row['OWNER'], row['LINK'], row['PG'], row['PWR_AUT']))
conn.commit()

cursor.close()
conn.close()



#df.to_sql(name = "omidb",con = conn, if_exists = 'append', chunksize = 100000)
#cursor.execute(sql)  # table created
#conn.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\myq3.py###

import os
import csv
import mysql.connector

skipHeader = True
pt = os.getcwd()
fl = pt + '\\i.csv'
#conn= mysql.connector.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
conn = mysql.connector.connect(user='akomi', password='1q2w3eaz$', host='23.152.224.49', database='omdb')
cur = conn.cursor()


with open(fl, newline='') as csvfile:
    customer_data = csv.reader(csvfile)
    for row in customer_data:
        sql = """INSERT INTO ipasn3 (IP1, IP2, ASN, Country, ISP, IPMOD) VALUES (%s, %s, %s, %s, %s, %s)"""
        cur.execute(sql, tuple(row))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mysq.py###
import pandas as pd
import pyodbc
import requests
from sqlalchemy import *

class mssq:
    def __init__(self):
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)


def telegram_send(chatid, msg):
    TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    try:
        requests.get(url)
    except:
        print('can not initiate first msg to a user')


class orsq:
    

class mysq:
    def __init__(self):
        


class mssq:
    def __init__(self):
        
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)

    def check_existance_by_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        rw = df.shape[0]
        return rw

    def query_full_tbl(self, tbl):
        qry = "select * from " + tbl
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def insert_new_entry(self, tbl, colnames, values):
        qry = "insert into " + tbl + " (" + colnames + ") values (" + values + ")"
        print(qry)
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        print(rs)

    def apend_into(self, tbl, colname, value, refcolname, refvalue):
        qry1 = "select " + colname + " from " + tbl + " where " + refcolname + "='" + refvalue + "'"
        print(qry1)
        curs = self.conx.cursor()
        rsl = curs.execute(qry1)
        rs = rsl.fetchall()
        print(rs)
        vl = value
        qry = "UPDATE " + tbl + " SET " + colname + "='" + vl + "' WHERE " + refcolname + "='" + refvalue + "'"
        print(qry)
        rs2 = curs.execute(qry)
        print(rs2)

    def query_by_single_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_by_double_ref(self, tbl, colname1, value1, colname2, value2):
        qry = "select * from " + tbl + " where " + colname1 + "='" + value1 + "' AND " + colname2 + "='" + value2 + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_string(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + " like " + value
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def upd_by_ref(self, tbl, colnames, values, ref, refvalue):
        qry = "UPDATE " + tbl + " SET " + colnames + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'updated'
    def del_by_ref(self, tbl, colname, value):
        qry = "DELETE FROM " + tbl + " WHERE " + colname + "='" + value + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'deleted'
    def bot_usr_add(self, nam, uid, pas, msisdn):
        td = odt.Now()
        tday = td.strftime('%Y-%m-%d')
        print(tday)
        dt = td.strftime('%d')
        mn = td.strftime("%m")
        wkdy = td.strftime('%a')
        valu = ""
        ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
        print('psscode=', ps)
        if pas == ps or pas == '07085122':
            colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
            valu = "'" + nam + "','" + uid + "','" + tday + "','" + msisdn + "','Y','Y','Y'"
            qry = 'insert into om_socbot_access (' + colnm + ") values ('" + valu + "')"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            print(rs)
            custom_msg_sender(uid, 'congrats, write help to the secrat to use me')
        else:
            custom_msg_sender(uid, 'you send wrong passcode')
        self.conx.close()
    def bot_usr_list(self, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = 'select * from om_socbot_access'
            df = pd.read_sql(qry, self.conx)
            dic = df.to_dict()
            x = vbf.pyvb(dic)
            return x.print_all_row_comm_seperated()

    def bot_usr_delete(self, sl, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = "DELETE FROM om_socbot_access WHERE SL ='" + sl + "'"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            return 'user deleted success'

    def bot_today_pass(self, secrat):
        if secrat == '07085122' or secrat == 'jahid1998':
            td = odt.Now()
            tday = td.strftime('%Y-%m-%d')
            print(tday)
            dt = td.strftime('%d')
            mn = td.strftime("%m")
            wkdy = td.strftime('%a')
            valu = ""
            ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
            return ps
        else:
            return 'unauthorized attempt'
    def auth_check_db(self, uid, qryfrom):
        df1 = pd.read_sql("select * from om_socbot_access", self.conx)
        df = df1[df1['UID'].str.contains(uid)]
        x = df.shape[0]
        if x == 0:
            return str(x)
        else:
            Status = df['Status'].iloc[0]
            special = df['Special'].iloc[0]
            if qryfrom != 'private' and special != 'Y':
                return 0
            elif qryfrom == 'private' and Status == 'Y':
                return '1'
            elif special == 'Y':
                return '1'


#x = mssq()
#bot_usr_add(self, nam, uid, pas, msisdn)
#x.bot_usr_add('s_sohel','178798745','07085122','1819210176')
# print(x.check_existance_by_ref('incident_tracker_v2','Incident_ID','INY00001138080'))
# df = pd.DataFrame(x.query_full_tbl('incident_tracker_v2'))
# x.bot_usr_delete('4','07085122')
#print(x.bot_usr_list('07085122'))
#
# vl = ""
# x.insert_new_entry('om_socbot_access',colnm,vl)
# print(df)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mysql.py###
#ref: https://www.geeksforgeeks.org/mysqldb-connection-python/
import MySQLdb
import os
import pymysql
import pandas as pd
from sqlalchemy import create_engine

engin = create_engine('pymysql+mysqlconnector://' + 'root' + ':' + 'root' + '@' + '127.0.0.1' + ':' + '3306', echo=False)

#try:
    #conn= MySQLdb.connect("localhost","root","root","ops1")
#except:
    #print("Can't connect to database")
#cursor = conn.cursor()

sql = """CREATE TABLE `ops1`.`OMIDB2` ( `SITECODE` VARCHAR(255) NOT NULL , 
`THANA` VARCHAR(255) NULL DEFAULT NULL , `DISTRICT` VARCHAR(255) NULL DEFAULT NULL , 
`REGION` VARCHAR(255) NULL DEFAULT NULL , `LON` DOUBLE NULL DEFAULT NULL , 
`LAT` DOUBLE NULL DEFAULT NULL , `P1P2` VARCHAR(255) NULL DEFAULT NULL , 
`OWNER` VARCHAR(255) NULL DEFAULT NULL , `LINK` VARCHAR(255) NULL DEFAULT NULL , 
`PG` VARCHAR(255) NULL DEFAULT NULL , `PWR_AUT` VARCHAR(255) NULL DEFAULT NULL , 
UNIQUE (`SITECODE`(255))) ENGINE = InnoDB;"""

df = pd.read_csv("F:\\MYDB.csv")
df.to_sql(name='OMIDB2', con=engin, if_exists = 'append', index=False)
#df.to_sql('OMIDB2', con = conn, if_exists = 'append', chunksize = 1000)
#cols = "`,`".join([str(i) for i in df.columns.tolist()])
# Insert DataFrame recrds one by one.
#for i,row in df.iterrows():
    #sql = "INSERT INTO `OMIDB2` (`" + cols + "`) VALUES (" + "%s,"*(len(row)-1) + "%s)"
    #cursor.execute(sql, tuple(row))
    #conn.commit()
conn.close()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\N1.py###

import itertools
import operator
import itertools as it
from itertools import *

def pntx(op):
    q = 0
    try:
        print(type(op), "--", op, chr(10))
    except:
        pass
    if op is not None:
        q = q + 1
        try:
            for i in op:
                print(type(i), " output: ", i)
        except:
            try:
                print("loop not worked but direct -" , op)
                try:
                    for i in range(len(op)):
                        print('loop with range worked: ' , op[i])
                except:
                    print("anther loop attempt - ")
            except:
                print("failed for: ", q)
    else:
        print('input stored None -', type(op))

class p1:
    def __init__(self, *argv):
        if argv is not None:
            for i in range(len(argv)):
                print(type(argv[i]))
            self.arg = argv
        self.opt = ''
        print("-----------------------------------")
    def printx(self):
        q = 0
        if self.opt is not None:
            q = q + 1
            try:
                for i in self.opt:
                    print(type(i), " output: ", i)
            except:
                print("failed for: ", q)
    def f2(self, ls = None):
        if ls is None:
            self.opt = itertools.accumulate(self.arg[0], operator.mul)
        else:
            self.opt = itertools.accumulate(ls4, operator.mul)
        self.printx()
    def f3(self, ls = None):
        if ls is None:
            self.opt = map(lambda x: "$" + str(x) + "$", self.arg[0])
        else:
            self.opt = map(lambda x: "$" + str(x) + "$", ls)
        self.printx()
    def f4(self, ls = None):
        self.opt = itertools.islice(ls, len(ls))
        self.printx()

ls1 = ['CXTKN80','CXTKN80','CPMTB03','NGSNG49','RPPBT09','CMDBD56','NGRPG18','NGSNG49','CPMTB21','MDSDR02']
ls2 = ['6404','6406','6542','6691','6763','7088','7105','6406','8386','7268']
ls3 = ['5/12/2020  11:54:00 AM','5/12/2020  1:07:00 PM','2020/12/5  1:43:00 PM','5/12/2020  1:46:00 PM',
        '6763','7088','7105','RPPBT09','CMDBD56','NGRPG18']
ls4 = [4,7,9]
dc1 = dict(zip(ls1,ls2))
dc2 = dict(zip(ls2,ls3))

#x = p1(ls1,ls2)
#x.f3()

OM = lambda x : map(lambda y : "'" + y + "'", ls)

def mapper(ls1,ls2):
    ls = list(map(lambda x, y: x + "='" + str(y) + "'", ls1, ls2))
    return ls

def xmapper(ls1,ls2):
    ls = list(map(lambda x, y: x + "='" + str(y) + "'", ls1, ls2))
    return ls

def f3(ls):
    op = map(lambda x: "$" + str(x) + "$", ls)



TS = lambda x : itertools.islice(x, len(x))

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    for i in range(len(ls)):
        if ls[i] in txt:
            txt.find(ls[i])


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\odf.py###
import pandas as pd
import os
from datetime import *
import numpy as np
from fn import *
from mysql import *
from sqlalchemy import create_engine

def MySql(user='root',password='admin',host='127.0.0.1:3306',db='om2'):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

pt = os.getcwd () + "\\"
def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines ():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DURCAT = lambda x : '<2H' if (x < 120) \
                else ('<12H' if (x < 240) \
                else ('<6H' if (x < 360) \
                else ('<12H' if (x < 720) \
                else ('<24H' if (x < 1440) \
                else ('48H+')))))

class fluc:
    def __init__(self, mdf):
        self.df = mdf
        self.col = mdf.columns.to_list()
        self.tdf = pd.DataFrame([])
    def initial(self, df):
        db = os.getcwd () + "\\OMDB.csv"
        dfdb = pd.read_csv(db)
        semcol = os.getcwd () + "\\semcols.txt"
        cat = os.getcwd () + "\\catdef.txt"
        df0 = df.rename(columns=str.upper)
        ls = text2list(semcol)
        df1 = df0[ls]
        dc = text2dic(cat)
        df1 = df1.assign(cat = "0")
        df1 = df1.assign(Code = "0")
        df1['cat'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
        df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
        df2 = df1.merge(dfdb, on='Code')
        df2['LASTOCCURRENCE'] = pd.to_datetime (df2['LASTOCCURRENCE'], errors='coerce')
        #df2['CLEARTIMESTAMP'] = pd.to_datetime(df2['CLEARTIMESTAMP'], errors='coerce')
        df2['DUR'] = df2.apply (lambda x: abs (datetime.now () - x['LASTOCCURRENCE']), axis=1)
        #df2['DUR'] = df2['DUR'].astype ('timedelta64[m]')
        #df2['DURCAT'] = df2.apply (lambda x: DURCAT (x.DUR), axis=1)
        #df2['LO'] = df2.apply(lambda x : pd.to_datetime(x['LASTOCCURRENCE']).strftime("%y%m%d%H%M"), axis = 1)
        #df2['CDLO'] = df2['LO'].str.cat(df2['CUSTOMATTR15'])
        #df3 = df2[~df2['cat'].isin(['other'])]
        #df4 = df3[['SERIAL','CUSTOMATTR3','CUSTOMATTR5','OUTAGEDURATION','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','cat','Code','Zone','DUR','DURCAT','CDLO']]
        #print(df4[['LASTOCCURRENCE']])
        df2.to_csv(pt + "\\A10.csv")


df1 = pd.read_csv(pt + 'OMT1.csv')
x = fluc(df1)
x.initial(df1)
#conn = MySql()
#df = pd.read_csv (pt + 'A10.csv')
#df.to_sql('adb10', con = conn, if_exists='replace', chunksize= 10000)

#dfx = df.groupby(['CUSTOMATTR15','DURCAT'])['DURCAT'].count()
#print(df[['DURCAT']])
#df1 = countifs(df,df['CUSTOMATTR15'],df['CUSTOMATTR15'],df['DURCAT'],'48H+')
#print(df1)
#df1.to_csv(pt + "\\A6.csv")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\oDT.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M:%S")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\ofn1.py###
from datetime import *
import os
import pandas as pd
import numpy as np

def help_ofn1():
    ls =["write_into_text(contents, operation='write', filename = 'excmd', fpath = None) content can be list/string\n"]
    print(ls)

#df = df2.reset_index()

def append_into_textfile(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
            print(file2)
        except:
            f = open(file1, 'a+')
            print(file1)
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    return ""


def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def write_into_text(contents, operation="write", filename = 'excmd', fpath = None):
    f = ''
    if filename is None:
        filename = "X"
    if fpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    else:
        flpath = fpath + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    
    try:
        if operation == "write":
            f = open(flpath, 'w+')
        else:
            f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
        return flpath
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        try:
            if operation == "write":
                f = open(flpath, 'w+')
            else:
                f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
            return flpath
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))
            return "failed"


    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omapi.py###
import csv
import pandas as pd
import io
import requests

def api_hideme():
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + "730480402242392"
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

def api_premproxy():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    urlData = requests.get(z).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def dailyproxy():
    url = "https://proxy-daily.com/api/getproxylist?apikey=MHAvkX-UOWjz6vbT-t9cpK1&format=ipport&country=US&type=socks5&lastchecked=60"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def openproxy():
    url = "https://api.openproxy.space/premium/plain?amount=34999&apiKey=i9414-d994p4Pa29118LW-yfIl5-eBY64dMT5N16uDv-Vw10n&checksMore=354&countries=US&protocols=3&status=1&streak=1"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omapi_ip.py###
import requests as r
import json
from pprint import pprint
import os

def ipdb_1(ip):
    #https://app.ipgeolocation.io/
    ipgeolocation = "ec875907f0da48b3ac1859a1096c5971"
    apilink = 'https://api.ipgeolocation.io/ipgeo?apiKey=' + ipgeolocation + "&ip=" + ip
    G = r.get(apilink)
    print(G.text)
    return G.text


def ipdb_2(ip):
    url = "https://freegeoip.app/json/" + ip
    headers = {
        'accept': "application/json",
        'content-type': "application/json"
        }
    response = r.request("GET", url, headers=headers)
    print(response.text)

def ipdb_filefab():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    G = r.get(z)
    print(G)

def ip_geojs(ip):
    os.system("curl https://get.geojs.io/v1/ip/geo/{" + ip + "}.js")

def ip_db3(ip):
    rs = r.get('https://bgp.tools/ip?q=' + ip).text
    print(rs)


#x = ipdb_1('45.156.24.78')
#ipdb_2('45.156.24.78')
ip_geojs('58.212.41.124')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdb.py###
import pandas as pd
import os
import sqlite3
import pyodbc
import mysql.connector #pip install mysql-connector-python
import MySQLdb
from mysql import *
from sqlalchemy import create_engine
from sqlalchemy import update
from pypika import Query, Table, Field

def MySql_1(hPort,user,pas,db):
    conn_str = 'mysql+mysqlconnector://' + user + ':' + pas + '@' + hPort + '/' + db
    engine = create_engine(conn_str, echo=False)
    conn = engine.raw_connection()
    return conn

def MySql_3(host_name, user_name, user_password,db):
    conn = MySQLdb.connect(host_name,user_name,user_password,db)
    return conn


class prep_query:
    def __init__(self, tablename):
        self.cols = "*"
        self.tbl = tablename
        self.qry = ""
    def q_select(self, cond = False, cols=False):
        if cols == False and cond != False:
            self.qry = "select " + self.cols + " from " + self.tbl + " where " + cond
        elif cols != False and cond != False:
            self.qry = "select " + cols + " from " + self.tbl + " where " + cond
        elif cols != False and cond == False:
            self.qry = "select " + cols + " from " + self.tbl
        elif cols == False and cond == False:
            self.qry = "select " + self.cols + " from " + self.tbl
    def q_delete(self, cols , value):
        self.qry = "DELETE FROM " + self.tbl + " WHERE " + cols + "='" + value + "'"
    def q_insert(self, cols, values):
        self.qry = "insert into " + self.tbl + " (" + cols + ") values (" + values + ")"
    def q_update(self, cols, values, ref, refvalue):
        self.qry = "UPDATE " + self.tbl + " SET " + cols + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
    def get(self):
        return self.qry


#x = prep_query("omtb")
##x.q_select()
#print(x.get())
#print(x.q_sel("asn = '123' and gsn = '5'", "col1, col2"))



def prep_qry(tbl, cond, column = False, vals = False):
    if column == False:
        cols = "*"
    else:
        cols = column
    #s_select = 'select ' + col + ' from ' + tbl + ' where ' + cond
    #s_update = 'update from ' + tbl + ' from ' + tbl + ' where ' cond
    #s_insert = "insert into " + tbl + " (" + col + ") values (" + values + ")"
    #qry = "UPDATE " + tbl + " SET " + col + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"


class oMySql:
    def __init__(self, connection, tablename):
        self.conn = connection
        self.cr = connection.cursor()
        self.tbl = tablename
    def q_row_count(self):
        sql = "select * from " + self.tbl
        df = pd.read_sql(sql, self.conn)
        print(sql,'-' , df.shape[0])
    def q_fetch_all_row(self):
        sql = 'select * from ' + self.tbl
        self.cr.execute(sql)
        rs = self.cr.fetchall()
        ls = []
        for r in rs:
            ls1 = list(r)
            ls.append(ls1)
        print(ls)


#q = Query.from_('asdb').select('id', 'fname', 'lname', 'phone')
#Query.from_('asdb').select('id', 'fname', 'lname', 'phone').orderby('id', order=Order.desc)


#cn = MySql_1('38.70.234.101','akomi','1q2w3eaz$','omdb')
#x = oMySql(cn,'live')
#x.q_fetch_all_row()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdf5.py###
import pandas as pd

dates=['April-10', 'April-11', 'April-12', 'April-13','April-14','April-16']
income1=[10,20,10,15,10,12]
income2=[20,30,10,5,40,13]

df=pd.DataFrame({"Date":dates,
                "Income_1":income1,
                "Income_2":income2})



print(df.apply(lambda row: "Total income in "+ row["Date"]+ " is:"+str(row["Income_1"]+row["Income_2"]),axis=1))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdf_call.py###
import pandas as pd

def oFun(df = None, *colname, **col_criteria):
    print('colnam', colname)
    print('col_criteria', col_criteria)

def myFun(arg1, *argv, **kwargs): 
    print ("First argument :", arg1) 
    for arg in argv: 
        print("Next argument through *argv :", arg)

myFun('Hello', 'Welcome', 'to', 'GeeksforGeeks') 
a = ['1','2','3']
b = {'one':'1','two':'2','three':'3'}
c = ('x','y')
s1 = "omi"
s2 = "ona"
s3 = "himi"
s4 = "babu"

oFun(s1, a, x = '1', y = '2' )
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdt.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()

def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str
def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def curr_day():
    return td.strftime('%d')
def curr_month():
    return td.strftime('%m')
def curr_year():
    return td.strftime('%Y')
def curr_date():
    return td.strftime('%Y-%m-%d')
def date_between(date1,date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2-d1).days
def aging(date1,date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2- d1)
    return mn
def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx+relativedelta(months=diff)
    return delt


#def date_str(dt):
#def fmt_to_datetime():
#def fmt_to_str():
#delta_month(nw(),-4)
#def month_delta(dt,diff):
#d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
#def day_delta(dt,diff):
#def date_minus(dt, diff):
#def month_minus(dt, diff):
#def year_minus(dt, diff):
#print(aging(nw(),'2020-06-13 00:00:00'))
#print(min_plus(500))
#print(min_minus(500))
#print(hr_plus(2))





    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdtfn.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()


def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str


def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def curr_day():
    return td.strftime('%d')


def curr_month():
    return td.strftime('%m')


def curr_year():
    return td.strftime('%Y')


def curr_date():
    return td.strftime('%Y-%m-%d')


def date_between(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2 - d1).days


def aging(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2 - d1)
    return mn


def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx + relativedelta(months=diff)
    return delt


def day_minus(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def day_plus(diff):
    d = td + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def hrmin():
    str_d = n.strftime("%H:%M")
    return str_d

def dtmnyr():
    str_d = n.strftime("%Y-%m-%d")
    return str_d

# def date_str(dt):
# def fmt_to_datetime():
# def fmt_to_str():
# delta_month(nw(),-4)
# def month_delta(dt,diff):
# d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
# def day_delta(dt,diff):
# def date_minus(dt, diff):
# def month_minus(dt, diff):
# def year_minus(dt, diff):
# print(aging(nw(),'2020-06-13 00:00:00'))
# print(min_plus(500))
# print(min_minus(500))
# print(hr_plus(2))







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omfn.py###

def sitecode_pick(txt):
    stcnt = 0
    numcnt = 0
    lp = 1
    prelp = 0
    indx = 0
    for i in txt:
        try:
            ix = int(i)
        except:
            ix = i
        if isinstance(ix,str):
            stcnt = stcnt + 1
        elif isinstance(ix,int):
            numcnt = numcnt + 1
            if lp - prelp == 1 and indx ==0:
                indx = lp
            else:
                prelp = lp
        lp = lp + 1
    if indx != 0:
        code = txt[indx-7:indx]
        return code
    else:
        return "NA"
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omishadowbot.py###


TK = "1196095594:AAGjCMyqdc-62Yabj9Bdyn3_s5H5MkBmDC"
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omprox.py###
import os
import geoip2.database
import pandas as pd
import api.omapi as oap
import ippro.ipmap as ipm
import csv

#shift-ctrl-b
pt = os.getcwd()
hme = oap.api_hideme()
GT = ipm.maincall(hme)
#hme = oap.openproxy(
GT.to_csv(pt + "//ONA3.csv")
#hme.columns = ['ip','port']
print(hme)
#df = hme.loc[(hme['country_code']=='US') & (hme['socks5']==1)]
#GT = ipm.maincall(prem)
#print(GT)
#print(GT)
#GT1 = GT[ (GT.ASN != 13335) & (GT.Country == 'US') ]

#getas.to_csv(pt + '\\KJ1.csv')
#print(prem)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsc.py###
import socket

sock_obj = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print ('Socket Initialized')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsq.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''
    
def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        qry = 'EXPLAIN ' + self.db + '.' + table
        try:
            dfx = pd.read_sql(qry, con= self.engine)
            cols = dfx['Field'].to_list()
            typ = dfx['Type'].to_list()
            zips = zip(cols, typ)
            self.tabledetails = dict(zips)
            return self.tabledetails
        except:
            return "table not exist"

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0
    
    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df
    
    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False):
        if bycols:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = []):
        if len(cols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        else:
            if isinstance(cols, list):
                xdf = dataframe[cols]
                self.Upd_or_Insert(tbl, xdf)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()
      
    def UpdateBulk(self, tbl, bycond_colname, ndf = False, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsq3.py###
import pandas as pd
import os
import sqlite3
import omsqlfn as fn

dbname = os.getcwd() + '\\SQL\\omsq.db'
try:
    conn = sqlite3.connect(dbname)
    cursor = conn.cursor()
    print("Database created and Successfully Connected to SQLite")
except sqlite3.Error as error:
    print("Error while connecting to sqlite", error)

def replace_data(df,tbl):
    sql = "DELETE FROM " + tbl + ';'
    cursor.execute(sql)
    df.to_sql('SITEDB', conn, if_exists='replace', index = False)

def Export(df, tbl):
    df.to_sql(tbl, conn, if_exists='replace', index = False)

def Read(sql):
    cursor.execute(sql)
    rw = []
    for row in cursor.fetchall():
        rw.append(row)
    df = pd.DataFrame(rw)
    return df

def createtable(tblname, cols):
    sql = "CREATE TABLE " + tblname
    hp = ""
    fsql = ''
    for i in range(len(cols)):
        x = str(cols[i]) + ' TEXT NULL'
        if hp =='':
            hp = sql + ' (' + x
        else:
            hp = hp + ', ' + x
    else:
        fsql = hp + ' )'
        print(fsql)
    try:
        cursor.execute(fsql)
        conn.commit()
        print('success')
    except:
        print('table already exist')
    


svpt = os.getcwd() + '\\robi_live_oct_20.csv'
df = pd.read_csv(svpt)
col = df.columns.to_list()
createtable('test', col)
Export(df, 'test')
print(Read('select * from test'))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsql.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os
from mysql import *
from sqlalchemy import create_engine
import OmSQ.omsqlfn as fn
import OmSQ.InsUpd as fni
import os

def about():
        print('initiate class: ', "x = omsql('root','admin','127.0.0.1:3306','omdb')")
        print('Class method : connection ', "MySql(self), MsSql(Self), def Oracle(self)")
        print('class method* : col_and_type(self, table)', 'Return dictionary key as colname and type as value')
        print('class method : Query(self, tbl, colname = False, condition = False)')
        print('class method : Update(self, tbl, listcols, listvalue, bycol, bycolv):')
        print('class method : Insert(self, tbl, colname, values):')
        print('class method : GetResult(self)',' returns dataframe')
        print('class method : SaveToCsv(self, path_with_filename):')
        print('class method : SaveToCsv(self, path_with_filename):')
        print('class method* : Ex(self, arg = False, ret_type = False)', ' for any custom type execution')
        print('every will save at self.df every time and get with GetResult')
        print('few calling example are below in source file')
        print("class Method: CreateTable(self, tablename, list_col, list_type = None, servername = 'mysql')")


def for_contacts(svpt, tblname, colhead):
    fl = open(svpt, 'r+')
    ls = []
    for i in fl.readlines():
        x = i.strip('\n')
        ls.append(x)
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    col = df.columns.to_list()
    #x = omsql('root','admin','127.0.0.1:3306','omdb')
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    x.CreateTable(tblname,col, None,'mssql')
    print(x.col_and_type(tblname))
    x.Export(tblname,df)

def corp_db(csvpt, tblname, colhead):
    df = pd.read_csv(csvpt)
    df = df.astype(str)
    col = df.columns.to_list()
    #x = omsql('root','admin','127.0.0.1:3306','omdb')
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    x.CreateTable(tblname, col, None,'mssql')
    print(x.col_and_type(tblname))
    x.Export(tblname,df)

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.engin = ''
        self.conn = ''
        self.cur = ''
        self.rw = 0
        self.qry = ''
        self.colv_coltyp = {}
        self.df = pd.DataFrame([''])
        self.dftemp = pd.DataFrame([''])
    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        print('mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db)
        try:
            self.engine = create_engine(constr, echo=False)
            self.conn = self.engine.raw_connection()
            self.cur = self.conn.cursor()
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        print(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        print(self.conn.version)
    
    def Ex(self, arg = False, ret_type = False):
        print('ret_type = dataframe/(fetchone/row), so get data as object')
        if arg != False:
            if ret_type == 'dataframe' or ret_type == 'df':
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            elif ret_type == 'fetchone' or ret_type == 'row':
                self.cur.execute(arg)
                rs = self.cur.fetchall()
                return rs
            elif ret_type == False:
                cr = self.conn.cursor()
                cr.execute(arg)
                cr.commit()
        else:
            if self.qry != '':
                try:
                    self.cur.execute(self.qry)
                    self.conn.commit()
                    print('qry executed')
                except:
                    print('error')
    
    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx
    
    def CheckExist(self, tbl, colname, values):
        qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        print(qry)
        dfx = pd.read_sql(qry, self.conn)
        rw = dfx.shape[0]
        return rw
    
    def Update(self, tbl, listcols, listvalue, bycol, bycolv):
        self.qry = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.qry = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "=" + bycolv
            print('Existing rows found, proceed for insert', self.qry)
        else:
            self.qry = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.qry)
        self.cur.execute(self.qry)
        self.conn.commit()
    
    def Insert(self, tbl, colname, values):
        self.qry = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.qry)
        try:
            self.cur.execute(self.qry)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def col_and_type(self, table):
        qry = 'EXPLAIN ' + self.db + '.' + table
        dfx = pd.read_sql(qry, con= self.engine)
        cols = dfx['Field'].to_list()
        typ = dfx['Type'].to_list()
        zips = zip(cols, typ)
        self.colv_coltyp = dict(zips)
        return self.colv_coltyp

    def SaveToCsv(self, path_with_filename):
        try:
            self.df.to_csv(path_with_filename, index = False)
            print('save successfully: ', path_with_filename)
        except:
            print('could not saved to path : ', path_with_filename)

    def GetResult(self):
        dfx = self.df
        return dfx

    def Export(self, tbl, dfx, delim = False):
        try:
            dfx.to_sql(name = tbl, con = self.conn, if_exists='replace', index = False)      
        except:
            cols = list(self.colv_coltyp.keys())
            cnt = 0
            insertrow = 0
            for i in range(len(dfx)):
                ls = []
                x = ""
                cnt = cnt + 1
                for j in dfx:
                    x = dfx.loc[i,j]
                    if x == '':
                        ls.append('NA')
                    else:
                        ls.append(dfx.loc[i,j])
                qry = "insert into " + tbl + ' ' + fn.prep_insert(cols,ls)
                print(qry)
                self.cur.execute(qry)
                insertrow = insertrow + 1
            self.conn.commit()
            print('row inserted: ' + str(insertrow))

    def CreateTable(self, tablename, list_col, list_type = None, servername = 'mysql'):
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    st = "CREATE TABLE `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
    def Upd_or_Insert(self, tbl, ndf, bycols = False):
        if bycols:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)
    def Close(self):
        self.conn.close()

def csv2sql(csvfile, tblname, by_cond_cols = False , table_cols = 'csvhead', table_dtype = 'TEXT' , dbname = None, host = None, user = None, password = None, dbserver = 'mysql'):
    x = ''
    df = pd.read_csv(csvfile)
    if dbname == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
    else:
        x = omsql(user, password, host, dbname)
    if dbserver == 'mysql':
        x.MySql()
    else:
        x = dbserver
    if table_cols == 'csvhead':
        cols = df.columns.to_list()
    else:
        cols = table_cols
    try:
        if isinstance(table_dtype, str):
            x.CreateTable(tblname,cols,None,'mysql')
        elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
            x.CreateTable(tblname,cols,table_dtype,'mysql')
        else:
            print('table cols and table_dtype field not same')
            exit()
    except:
        print('table already exist')
    print(x.col_and_type(tblname))
    if by_cond_cols:
        x.Upd_or_Insert(tblname,df, by_cond_cols)
    else:
        x.Upd_or_Insert(tblname,df)
    return x

S2 = os.getcwd() + '\\SQL\\OmSQ\\bk1.csv'
ob = csv2sql(S2,'test_time')
S0 = os.getcwd() + '\\SQL\\s0.csv'
S1 = os.getcwd() + '\\SQL\\s1.csv' 
#ob = csv2sql(S0,'ONA_2')
#ob = csv2sql(S1,'ONA_2', 'CustomAttr11')

#x.upin('ARABI_2',df, "CustomAttr15")
#SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&
#print(x.Ex("selct * from omdb.ARABI_2", 'df'))

#print(x.CheckExist('sitedb','Site_Code','sfsdgsdfgdfgdsg'))
#x.CreateTable('oTest1',col,coltype,'mysql')
#x = omsql('SOC_READ', 'soc_read')
#x.Oracle()
#x.Query('sitedb')
#print(x.GetResult())
#rs = x.Ex('select * from sitedb', 'row')
#fn.fetchone_read(rs)
#df = x.Ex('select * from sitedb', 'df')
#print(df)


#x = omsql('root','admin','127.0.0.1:3306','omdb')
#x.MySql()
#x.Ex('select * from sitedb')
#print(x.col_and_type('ABC'))
#C1 = ['A1','A2','A3']
#V1 = ['X1','X2','X3']
#C2 = ['A1','A3']
#V2 = ['OMI','ARABI']
#x.Insert('ABC',C1,V1)
#x = omsql('root','admin','127.0.0.1:3306','omdb')
#x.MySql()
#x.Update('ABC',C2,V2,"A2","'ONA'")
#x.Ex('select * from ABC')
#x.column_details('sitedb')
#x.Query('sitedb','LTE_Status', "LTE_Status = 'NA'")
###x.SaveToCsv(svpt)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsqlfn.py###

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsqlite3.py###
import pandas as pd
import os
import sqlite3
import omsql.omsqlfn as fn


class sqlt3:
    def __init__(self, dbname, bdpath):
        self.db = dbname
        self.conn = sqlite3.connect(bdpath)
        self.cur = self.conn.cursor()
        print("Successfully Connected to SQLite with database name: ", self.db)

    def replace_data(self, df, tbl):
        sql = "DELETE FROM " + tbl + ';'
        self.cur.execute(sql)
        df.to_sql('SITEDB', self.conn, if_exists='replace', index = False)

    def Export(self, df, tbl):
        df.to_sql(tbl, self.conn, if_exists='replace', index = False)

    def Read(self, sql):
        self.cur.execute(sql)
        rw = []
        for row in self.cur.fetchall():
            rw.append(row)
        df = pd.DataFrame(rw)
        return df

    def createtable(self, tblname, cols):
        sql = "CREATE TABLE " + tblname
        hp = ""
        fsql = ''
        for i in range(len(cols)):
            x = str(cols[i]) + ' TEXT NULL'
            if hp =='':
                hp = sql + ' (' + x
            else:
                hp = hp + ', ' + x
        else:
            fsql = hp + ' )'
            print(fsql)
        try:
            self.cursor.execute(fsql)
            self.conn.commit()
            print('success')
        except:
            print('table already exist')
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omt.py###
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from pprint import pprint
import os

api_id = 628127
api_hash = 'db7fa09d585d6eedddd0df5973f3239b'
phone = '+8801817184338'
client = TelegramClient(phone, api_id, api_hash)
client.connect()
if not client.is_user_authorized():
    client.send_code_request(phone)
    client.sign_in(phone, input('Enter the code: '))


async def main():
    st = ""
    async for dialog in client.iter_dialogs():
        try:
            st1 = str(dialog.id)
            st2 = st1[0]
            if st2 == chr(45):
                st = st + "\n" + str(dialog.id) + ',' + str(dialog.name)
        except:
            pass
    return st

def wrt_content(st):
    try:
        file = os.getcwd() + "//omgroup//omgrp.txt"
        fl = open(file, "w+", encoding="utf-8")
        fl.write(st)
        fl.close()
    except:
        file = os.getcwd() + "//omgrp.txt"
        fl = open(file, "w+", encoding="utf-8")
        fl.write(st)
        fl.close()
    return file

def client_run():
    with client:
        sx = client.loop.run_until_complete(main())
        fl = wrt_content(sx)
        return fl

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omtime.py###
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
import os
import pandas as pd
import numpy as np

def datetime_re_format(ls, fmt='%Y/%m/%d %H:%M'):
    #serialize and convert using dateutil.parser and datetime.strftime
    if ls is not None and isinstance(ls, list):
        lss = []
        for i in range(len(ls)):
            try:
                dt = parse(str(ls[i])).strftime(fmt)
                lss.append(dt)
            except:
                lss.append(ls[i])
        else:
            return lss

#diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diffdate = lambda T1, T2 : datetime(T2-T1).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def makelist_dttm_now(ln):
    nw = datetime.now()
    st = nw.strftime("%d/%m/%Y %H:%M")
    ls = []
    for i in range(ln):
        ls.append(st)
    return ls

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls
        

def DateDif(DT1, DT2 = None):
    TM1 = formatchk(DT1)
    if DT2 is None:
        TM2 = makelist_dttm_now(len(DT1))
    else:
        TM2 = formatchk(DT2)
    try:
        TM11 = datetime_re_format(TM1)
        TM22 = datetime_re_format(TM2)
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM11, TM22))
        return dur
    except:
        print("except")
        return []



def help_omtime():
    a1 = """#------------dataframe calclate datetime difference ---------------------\n#
# main function -> DateDif(DT1, DT2 = None) DT1 & DT2 can 'pandas series/list', return 'list'
    - if DT2 = None, it will find difference from 'now - DT1'
    - if DT3 provided but value contains '1970' then, calculate diff as 'now - DT1'
    - any datetime format can be handdled, even DT1 and DT2 format is different as using dateut
#----------- Example -------------------#
# df.assign(dur = 'x')
# df['dur'] = np.array(DateDif(df['LASTOCCURRENCE'],df['CLEARTIMESTAMP']))
# lst = DateDif(df['LASTOCCURRENCE']) 
# df['DUR'] = np.array(lst)
#--------------------------------------#"""
    print(a1)

#help_omtime()


def parse_dt(txt):
    n = datetime.now()
    yr = n.strftime("%y")
    print(yr)
    if 'TODAY' in txt:
        str_d = n.strftime("%Y-%m-%d")
        return str_d
    else:
        try:
            x = parse(txt, fuzzy=True, dayfirst = True)
            yx = x.strftime("%Y-%m-%d")
            return yx
        except:
            return 0

b1 = "you can write date by 4 format" + chr(10) + "12-sept or 12/09/20 or 12092019 or 12-09-19"
b2 = "12-sept"
print(parse_dt(b2))



#df = pd.read_csv(os.getcwd() + "\\FINAL15.csv")
#df['Diff'] = np.array(DateDif(df['LO'],df['CLR']))
#print(df[['LO','CLR','Diff']])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\OmWmi.py###
import os
import wmi
import winreg
import subprocess

ip = '173.0.54.190'
username = 'OMI'
password = '1q2w3eaz$'
from socket import *
#connection = wmi.WMI(ip, user=username, password=password)

r = wmi.Registry()
result, names = r.EnumKey (hDefKey=0x80000001,sSubKeyName=r"Software")
#for ky in names:
    #print(ky)

def netsh_proxy(ip,port):
    x = 'netsh winhttp set proxy ' + ip + ':' + port
    print(x)
    os.system(x)

def addkey(ip,prt):
    x1 = "reg add 'HKLM\Software\Microsoft\Windows\CurrentVersion\Internet Settings / v ProxyEnable / t REG_DWORD / d 1'"
    x2 = "reg add 'HKLM\Software\Microsoft\Windows\CurrentVersion\Internet Settings /v ProxyServer /t REG_SZ /d '" + ip + ':' + prt
    os.system(x1)
    os.system(x2)

#addkey('23.160.192.180','2016')


def read_reg(arg1,arg2):
    command = os.popen('cscript regrd.vbs "' +  arg1 + '"' + ' "' + arg2 + '"').read()
    print(command)

def addky(kpath,kname,ktype,kvalue):
    x = 'reg add' + ' "' + kpath + '" /v "' +  kname + '" /t "' + ktype + '" /d "' + kvalue + '"'
    print(x)
    os.system(x)

def editky(kpath,kname,ktype,kvalue):
    x = 'reg add' + ' "' + kpath + '" /v "' +  kname + '" /t "' + ktype + '" /d "' + kvalue + '" /F'
    print(x)
    os.system(x)

kp = "HKCU\Software\Microsoft\Windows\CurrentVersion\Internet Settings"
#knm = "ProxyEnable"
#kty = "REG_DWORD"
#kvl ="1"

knm = "ProxyServer"
kty = "REG_SZ"
kvl = "23.160.192.180:2016"


read_reg("Software\Microsoft\Windows\CurrentVersion\Internet Settings","HKCU")
#netsh_proxy('23.160.192.180','2016')
#addky(kp, knm, kty, kvl)
editky(kp, knm, kty, kvl)


def qryky(pth,keyname):
    x = 'reg query \HKLU\Software\"  /ve'


#REG QUERY HKLM\SOFTWARE /ve
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\om_dfloop.py###
import pandas as pd
import numpy as np
import os

##https://www.delftstack.com/howto/python-pandas/how-to-iterate-through-rows-of-a-dataframe-in-pandas/

pt = os.getcwd()
FL1 = "E:\\GIT\\OmProject\\OmSocks\\T3.csv"
dff = pd.read_csv(FL1)

#Procedure 1: index
def dflp_rw_using_index(df):
    for i in df.index:
        print(df['ip'][i], df['port'][i])

#Procedure 2: loc
def dflp_rw_using_loc(df):
    for i in range(len(df)):
        print(df.loc[i,"ip"])

#Procedure 3: iloc
def dflp_rw_using_iloc(df):
    for i in range(len(df)):
        print(df.iloc[i,0])

#Procedure 4: iterrows
def dflp_rw_using_iterrows(df):
    for indx, row in df.iterrows():
        print(row['ip'],row['port'])

#addcol type 1
def df_add_col_1(df):
    for i in range(len(df)):
        df.loc[i,"NWcol"] = df.loc[i,"port"] + 4
    return df

def addtest(x,y):
    z = x + ":" + str(y)
    return z

#addcol type 2
def df_add_col_2(df):
    for i in range(len(df)):
        df.loc[i,"ip_port"] = addtest(df.loc[i,"ip"], df.loc[i,"port"])
    return df

#addcol type 3
def df_add_col_3(df,colname):
    df = df.assign(colname = lambda row: row['port'] + 4 , axis=1)
    return df

def df_add_row_1(df,content_lst):
    df.loc[df.shape[0]+1] = content_lst
    return df

def df_del_row_cond_1(df,colname,ontxt):
    df.replace('', np.nan)
    indx = df[ df[colname] != ontxt ].index
    df.drop(indx , inplace=True)
    return df

#dff['NWcol'] = np.nan
#derive_col_with_cond(dff)
#df_add_row_1
#lst = ['0.0.0.0','1111','Kiskunlachaza -HU','1111','0.0','188.6','29582','us']
#print(df_add_row_1(dff,lst))
#print(df)
dx = df_del_row_cond_1(dff,"ip",'41.76.157.202')
print(dx.columns.to_list())
print(dx.columns.values.tolist())

#xd.to_csv("E:\\GIT\\OmProject\\OmSocks\\T4.csv")
#print(dff)
# dff.columns = ['ip','port'] #(set columns names)
# dff.iloc[0,0] = "New Val" #(change values in df cells using iloc)
# dff.loc[1,"ip"] = "XXXXX" #(change values in df cells using loc)
# print(dff)

#dff['NWcol'] = np.nan #(add empty column)
#print(dflp_add_col_2(dff))
def df_col_2_list_1(df):
    xx = df.apply(lambda row: row['port'] + 4 , axis=1)
    print(xx.to_list())

def df_2_list(df):
    df0 = df['ip']  #serialization
    df1 = df['port']  #serialization
    lst1 = df0.to_list()  #Convert into list
    lst2 = df1.to_list()  #Convert into list
    lst1.append(lst2)

df_2_list(dff)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\om_notes.py###

TSS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else "other"
                ))

df['cat'] = df.apply(lambda row: TSS(row.SUMMARY) , axis = 1)
df['Status'] = np.where(df['Name'].str.contains('Hisil'), 'HH', 'KK')
df2 = df[~df['cat'].isin(['other','NA'])]
df7 = df6[df6.DT.str.contains(dd) & df6.CLRYR.str.contains('2020')]
df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
df0 = df.drop_duplicates(subset=list_of_columns)
df1 = df1.sort_values(by=['CAT','CDLO'], ascending=True)
df4 = df4.rename(columns={'CUSTOMATTR15':'CODE'})
lst = list(df.columns.values)
dic = {'PBSDR': 'KHU', 'DHGUl': 'DHK_M'}
df[newcolname] = df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
df = pd.DataFrame(nparry,columns = ['ip','port','con','prot'])
dfx[nc] = np.nan
dfx[nwcol] = np.array(nwlst)
df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, ['1/12/2020  3:04:51','1/12/2020  8:34:04']))
df2 = df1[df1['LASTOCCURRENCE'].dt.day == 15 & df1['LASTOCCURRENCE'].dt.day == 16]
df["AB"] = df["A"] + df["B"]
df = ndf.replace(r'^\s*$', np.nan, regex=True)
df2['diff'] = df2['diff'].dt.components['minutes'] #hour
df['diff'] = df['diff'].round(decimals=3)
ndf = df1.append([df2, df3],ignore_index=True, sort=False)  #adding rows
ndf = pd.concat([s3, s4, s5], axis=1)  #Adding columns
ndf = pd.concat([s3, s4, s5])
df[newcol] = df[newcol].astype(float).round(2)


#df datatypes
ds = df6.dtypes
print(ds)
df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'], errors='coerce')
df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'], format="%m/%d/%Y, %H:%M:%S")
df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)
df1[newcol] = df1[newcol].astype('timedelta64[m]')
df3['SMX'] = df3['SMX'].astype(int)
df1[newcol] = df1[newcol].astype("i8")/1e9
df = df.applymap(str)

#df big functions
df['nwcol'] = df.reset_index()['refcol'].map(refdic).values
df.insert(indx, colname, colval, allow_duplicates=False)
ndf = df.assign(coln = 'NWC')
df[newcolname] = df['scode'].map(dic)
df17 = df7.merge(df15, on='CODE')
df4['DT'] = df4.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%b-%Y"), axis = 1)
dataframe1 = dataframe.where((dataframe==80)|(dataframe<50), other= 0)
df['ipport'] = df['ip'].str.cat(df['port'],sep=":")
df['col1col2'] = df['col1','col2'].apply(lambda x: ''.join(map(str,x)),axis=1)

#df special groupby
https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html
https://wesmckinney.com/blog/groupby-fu-improvements-in-grouping-and-aggregating-data-in-pandas/
dfx = df2.groupby(['CUSTOMATTR15']).CUSTOMATTR15.count().to_frame(name = 'SMX').reset_index()
df3 = df2.groupby('CUSTOMATTR15')['diff'].sum().to_frame(name = 'SMX').reset_index()
df15 = df14.groupby(df14['CODE']).MTTR.sum().to_frame(name = 'SMX').reset_index()
pvt = df1.pivot_table(index='CUSTOMATTR15', columns='DURCAT', values='cnt', aggfunc='sum')

https://wellsr.com/python/python-group-data-with-pandas-groupby/
dfx = grades.groupby("Type", as_index=False).mean()
df.groupby(‘species’).apply(lambda gr: gr.sum())

#NumPy:
arr = df.to_numpy()
rw, col = arr.shape
lst3 = []
for i in range(rw):
    lst3.append(arr[i][0], arr[i][1])
ar = np.append(arr, np.array([lst3]).transpose(), axis=1)
df['new_col'] = np.array(mylist)


#List:
dff = pd.Series(df['CustomAttr15'])
lst1 = dff.to_list()
lst2 = df.values.tolist()
lst3 = df.columns.values.tolist()
lst4 = df['Summary'].values.tolist()
lst5 = df[['Summary','LastOccurrence']].values.tolist()
fruits = ['apple', 'banana', 'cherry','banana']
fruits.append("orange")
fruits.insert(0,'guava')
print(fruits.count("banana"))
print(fruits.index("cherry"))
cars = ['bmw','porshe']
fruits.extend(cars)


#Dictionary:
dic1 = {}
dic2 = {1: 'apple', 2: 'ball'}
dic4 = dict({1:'apple', 2:'ball'})
df = pd.DataFrame(list(dic4.items()),columns = ['key','val'])


#LIST 2 DF
df = pd.DataFrame(zip(ls1, ls2, ls3))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\oracle.py###
import cx_Oracle
conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\osq.py###
import pandas as pd
import os

def attempt_dt(df):
    ls = df.columns.to_list()
    for i in range(len(ls)):
        cname = ls[i]
        try:
            df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
        except:
            pass
    return df

def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x


def inser_or_update(conn, tbl, df, bycol, oncols=False, operator=False):
    ndf = attempt_dt(df)
    cr = conn.cursor ()
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
        if ccr == 1:
            try:
                cr.execute (qry)
            except:
                try:
                    cr.execute (qryinsert)
                except:
                    qq.append (q)
                    pass
        q = q + 1
    print ("failed rows: ", qq)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf

def df2sq(df, table, conn, bycol=False, oncol=False, operator='Like'):
    if bycol == False and oncol == False:
        df.to_sql(table, con=conn, if_exists="append", chunksize=10000)
        print('success')
    else:
        cr = conn.cursor ()
        try:
            cr.execute ("select 1 from " + table)
            dfx = inser_or_update (conn, table, df, bycol, oncol, operator)
            return dfx
        except:
            df.to_sql (table, con=conn, if_exists="replace", chunksize=10000)
            print('success')
            
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\osql.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        dbcols = []
        dbcolType = []
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['COLUMN_NAME'].to_list()
            dbcolType = dfx['DATA_TYPE'].to_list()
        except:
            qry = 'EXPLAIN ' + self.db + '.' + table
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['Field'].to_list()
            dbcolType = dfx['Type'].to_list()
        dc= zip(dbcols, dbcolType)
        self.tabledetails = dict(dc)
        return dbcols

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0

    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df

    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False, oncol = False):
        if bycols != False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols, oncol)
        if bycols == False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, oncols = oncol)
        if bycols != False and oncol == False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = [], condcols = []):
        if len(cols) == 0 and len(condcols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        elif len(cols) == 0 and len(condcols) !=0:
            self.Upd_or_Insert(tbl, dataframe, condcols)
        elif len(cols) != 0 and len(condcols) !=0:
            print(' built required')
            self.Upd_or_Insert(tbl, dataframe, condcols, cols)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()

    #def df_to_sql(df, tbl = None, cols = ['all_cols_of_df'], how = 'append', replaceby = []):
    def UpdateBulk(self, ndf, tbl, bycond_colname, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)

    def df_tosql(self, df, tblname, oncols = False, bycols = False):
        if self.is_table_exist(tblname) == 1:
            self.Upd_or_Insert(self, df, tblname, oncols, bycols)
        

    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\oTime.py###
import pandas as pd
from datetime import *
import os

def sec_to_dur(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def dfdiff(df, LO, CLR = False):
    df = df.astype (str)
    if CLR == False:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df = df.assign (DUR=df.apply (lambda x: pd.Timedelta (datetime.now() - x[LO]).seconds / 60, axis=1))
        return df
    else:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df[CLR] = df.apply (lambda x: pd.to_datetime (x[CLR]), axis=1)
        df = df.assign(DUR=df.apply (lambda x: pd.Timedelta (x[LO] - x[CLR]).seconds / 60 if (
                x[CLR].year >= 2019) else "ACT", axis=1))
        return df

def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def datetime_convert_format(df, col, fmt="%Y/%m/%d %H:%M:%S"):
    try:
        df[col] = df[col].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime(fmt))
        return df
    except:
        df[col] = df[col].apply(lambda x: pd.to_datetime (x, errors='coerce', yearfirst=True, cache=True).strftime(fmt))
        return df

def vL(df_Main, df_Ref, col='Code', pick_from_ref = ['Zone']):
    ls = df_Main.columns.to_list ()
    df1 = df_Main.merge (df_Ref, how='right', on=col)
    for i in pick_from_ref:
        ls.append(str(i))
    else:
        dfx = df1[ls]
        return dfx

def ofn():
    print("func")
    print("dfdiff(df, LO, CLR = False) #if CRL=False, calcute from now, return minutes")
    print("sec_to_dur(sec), convert second into hh:mm:ss")
    print("""datetime_convert_format(df, col, fmt="%Y/%m/%d %H:%M:%S")""")
    print("vL(df, db, col='Code', pick_from_ref=['Zone','Cluster'])")
    
print("moduel 'oTime': on datetime, call ofn() to see function")
#vlook = vL(df, db, col='Code', pick_from_ref=['Zone','Cluster'])
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\otree.py###
import os
import shutil

def w2tx(dirName,xx):
    fp = open(dirName, "w")
    fp.write(xx)
    fp.close()

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def getFiles(dirName):
    listOfFile = os.listdir(dirName)
    completeFileList = list()
    for file in listOfFile:
        completePath = os.path.join(dirName, file)
        if os.path.isdir(completePath):
            completeFileList = completeFileList + getFiles(completePath)
        else:
            completeFileList.append(completePath)
    return completeFileList

def cpyfile(original,target):
    shutil.copyfile(original, target)

dirName = os.getcwd()
listOfFiles = getFiles(dirName)
xx = ""
for i in range(len(listOfFiles)):
    a1 = listOfFiles[i]
    if ".ipynb" in a1 or ".py" in a1:
        if "init" not in a1 and ".pyc" not in a1 and "__" not in a1:
            xx = xx + chr(10) + a1

w2tx(os.getcwd() + "\\B.txt",xx)
#os.system('copy file1.txt file7.txt')
#cpyfile(os.getcwd() + "\\TBOT\\omfn\\Untitled.ipynb","C:\\Users\\kabir.omi\\omom")
    
    
    
    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pgfndb.py###
import time
from datetime import date
from datetime import datetime
from datetime import timedelta
import pyodbc
import requests as rs
import pandas as pd

tmnw = datetime.now()
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')

def general_qry():
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    qry = "SELECT * from [dbo].[pglog4]"
    df = pd.read_sql(qry, conx)
    print(df)
    print(df.shape[0])

def sms(msisdn,txt):
    sURL1 = "http://10.101.11.164:10144/cgi-bin/sendsms?user=tester&pass=foobar&to="
    sURL2 = "&from=10144&text="
    sURL_pgon = sURL1 + msisdn + sURL2 + txt
    resp = rs.get(sURL_pgon)
    print(resp)

def db_insert_pgon(ussd,code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    in_qry = '''INSERT INTO dbo.pglog4 (SMSID, SITECODE, MSISDN) VALUES (?,?,?)'''
    in_qry_1 = (ussd, code, msisdn)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    sms(str(msisdn),"PGSTART ACK AT " + qryst + " CODE:" + code)
    conx.close()

def db_query_duplicate(code):
        conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
        curs = conx.cursor()
        select_qry = "SELECT * FROM pglog4 WHERE SITECODE = '"+ code +"' AND STATUS_ACTIVE= 'TRUE'"
        curs.execute(select_qry)
        rows = curs.fetchone()
        bol = bool(rows)
        if bol == True:
            return "ACT_CASE_FOUND"
            conx.close()
        else:
            return "NO_ACT_CASE"
            conx.close()

def db_update_pgoff(code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    qry_1 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND STATUS_ACTIVE= 'TRUE')"
    #qryussd = "SELECT SMSID FROM pglog4 WHERE " + qry_1
    #ussd = curs.execute(qryussd)
    qry1 = "UPDATE dbo.pglog4 SET END_DATETIME = CURRENT_TIMESTAMP WHERE " + qry_1
    qry2 = "UPDATE dbo.pglog4 SET CASE_STATUS = 'Closed' WHERE " + qry_1
    curs.execute(qry1)
    conx.commit()
    curs.execute(qry2)
    conx.commit()
    qry_2 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND CASE_STATUS= 'Closed')"
    qry3 = "UPDATE dbo.pglog4 SET STATUS_ACTIVE = '0' WHERE " + qry_2
    curs.execute(qry3)
    conx.commit()
    #print(ussd)
    #ftime = "SELECT START_DATEDATE FROM pglog4 WHERE SMSID = ? "
    #st = curs.execute(ftime,ussd)
    #pgruntime = 'From' + qryst + ' To '+ str(st)
    conx.close()
    sms(msisdn,"PGSTOP ACK AT " + qryst + ' Code: '+ code)

def main(ussd,code,msisdn,job):
    if job == "PGSTART":
        ans = db_query_duplicate(code)
        if ans == "NO_ACT_CASE":
            db_insert_pgon(str(ussd),code,str(msisdn))
            return 'PGON_DONE'
        else:
            #sms(msisdn,"PGSTART ALREADY LOGGED (Duplicate Entry)")
            return ""
    elif job == "PGSTOP":
        ans = db_query_duplicate(code)
        if ans == "ACT_CASE_FOUND":
            db_update_pgoff(code,str(msisdn))
            return 'PGOFF_DONE'
        else:
            #sms(msisdn,"NO PGON Found, Invalid PG OFF Request")
            return ""

#db_insert_pgon('223','DHGUL36','8801817184338')
#x = db_query_duplicate('PBSDR11')
#print(x)
#general_qry()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pgfunc.py###
import os
import time
from datetime import date
import requests as rs
import pyodbc

def served_check(flname,ussd):
    fo = open(flname,"r+")
    txt = fo.read()
    fo.close()
    if ussd in txt:
        return "old"
    else:
        return "new"

def served_entry(flname,ussd):
    fo = open(flname,"a")
    ussdmod = "," + ussd
    txt = fo.write(ussdmod)
    fo.close()

def db_insert_pgrun(ussd,code,mobile):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_query = "INSERT INTO dbo.pglog1 ( SMSID, SITECODE, MSISDN) VALUES (" + ussd + "," + code + "," + mobile + ");"
    curs.execute(in_query)
    curs.commit
    conx.close()
    print('sql table updated')

def filepath(flname):
    t = time.localtime()
    today = date.today()
    Name1 = today.strftime('%m%d%y')
    Name2 = time.strftime("%H%M", t)
    filenameExt = Name1 + "_" + Name2
    filepaths = os.getcwd() + "\\smple_download\\" + flname + filenameExt + ".csv"
    return filepaths

def sendsms(msisdn,txt):
    sURL1 = "http://10.101.11.164:10144/cgi-bin/sendsms?user=tester&pass=foobar&to="
    sURL2 = "&from=10144&text="
    sURL_pgon = sURL1 + msisdn + sURL2 + txt
    resp = rs.get(sURL_pgon)
    print(resp)

def txt_readbyline(ms, filepath):
    cnt = 0
    mstype = isinstance(ms,str)
    if mstype == False:
        ms = str(ms)
    with open(filepath) as f:
        for line in f:
            ln = line.strip()
            if ln in ms:
                cnt += 1
    return cnt
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pgmain.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs
import pg.pgfunc as fn
import pg.pgfndb as fndb
import pg.read_db as rdwt
import os

file = os.getcwd() + "\\" + "served.txt"
pgon = os.getcwd() + "\\" + "pgon.txt"
empnum = os.getcwd() + '\\msisdn_series.txt'

tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=2)
tmnw = datetime.now() - timedelta(minutes=2)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
UserRd = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=rocuser;Pwd=Roc@072$123"
UserSMS = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
conn = pyodbc.connect(UserEx)

def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "All2g") or (txtwht == "all2g") or (txtwht == "All2G") or (txtwht == "all2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "All3G") or (txtwht == "all3G") or (txtwht == "All3g") or (txtwht == "all3g"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "All4G") or (txtwht == "all4G") or (txtwht == "All4g") or (txtwht == "all4g"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "AllCount") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"

smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
dfsms = pd.read_sql(smsinbox, conn)
print(dfsms)
smsno = dfsms.shape[0]
if smsno != 0:
    for i in range(len(dfsms)):
        ussd = dfsms.loc[i, "USDLogId"]
        msisdn = dfsms.loc[i, "DESTADDR"]
        txt = dfsms.loc[i, "MESSAGE"]
        tm = dfsms.loc[i, "INSERT_TIME"]
        if len(txt) != 7 :
            if ("PGSTART" in txt) or ("pgstart" in txt) or ("Pgstart" in txt):
                code = txt[8:]
                codex = code.strip()
                xy = fndb.main(ussd,codex,msisdn,'PGSTART')
                print(xy)
                xz = rdwt.code_attr_update(code,ussd)
                print(xz)
            elif ("PGSTOP" in txt) or ("pgstop" in txt) or ("Pgstop" in txt):
                code = txt[7:]
                codex = code.strip()
                xy = fndb.main(ussd, codex, msisdn, 'PGSTOP')
                print(xy)
            elif ('All' in txt) or ('all' in txt) or ('SC' in txt) or ('count' in txt):
                ansr = fn.served_check(file, str(ussd))
                gval = fn.txt_readbyline(msisdn, empnum)
                if ansr == 'new' and gval == 1:
                    getval = siteinfo(txt)
                    if getval != "#" :
                        fn.sendsms(msisdn,getval)
                        fn.served_entry(file, str(ussd))
            else:
                print('No Need to Entertain')
else:
    print("no new sms")
conn.close()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\PGMAIN1406.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs
import pgfunc as fn
import pgfndb as fndb
import read_db as rdwt
import os

file = os.getcwd() + "\\" + "served.txt"
pgon = os.getcwd() + "\\" + "pgon.txt"
empnum = os.getcwd() + '\\empnumchk.txt'

tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=2)
tmnw = datetime.now() - timedelta(minutes=2)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
UserRd = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=rocuser;Pwd=Roc@072$123"
UserSMS = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
conn = pyodbc.connect(UserEx)

def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "All2g") or (txtwht == "all2g") or (txtwht == "All2G") or (txtwht == "all2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "All3G") or (txtwht == "all3G") or (txtwht == "All3g") or (txtwht == "all3g"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "All4G") or (txtwht == "all4G") or (txtwht == "All4g") or (txtwht == "all4g"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "AllCount") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"

smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
dfsms = pd.read_sql(smsinbox, conn)
print(dfsms)
smsno = dfsms.shape[0]
if smsno != 0:
    for i in range(len(dfsms)):
        ussd = dfsms.loc[i, "USDLogId"]
        msisdn = dfsms.loc[i, "DESTADDR"]
        txt = dfsms.loc[i, "MESSAGE"]
        tm = dfsms.loc[i, "INSERT_TIME"]
        if len(txt) != 7 :
            if ("PGSTART" in txt) or ("pgstart" in txt) or ("Pgstart" in txt):
                code = txt[8:]
                codex = code.strip()
                xy = fndb.main(ussd,codex,msisdn,'PGSTART')
                print(xy)
                xz = rdwt.code_attr_update(code,ussd)
                print(xz)
            elif ("PGSTOP" in txt) or ("pgstop" in txt) or ("Pgstop" in txt):
                code = txt[7:]
                codex = code.strip()
                xy = fndb.main(ussd, codex, msisdn, 'PGSTOP')
                print(xy)
            elif ('All' in txt) or ('all' in txt) or ('SC' in txt) or ('count' in txt):
                ansr = fn.served_check(file, str(ussd))
                gval = fn.txt_readbyline(msisdn, empnum)
                if ansr == 'new' and gval == 1:
                    getval = siteinfo(txt)
                    if getval != "#" :
                        fn.sendsms(msisdn,getval)
                        fn.served_entry(file, str(ussd))
            else:
                print('No Need to Entertain')
else:
    print("no new sms")
conn.close()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pn.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import rpa_shift.omdt as odt

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
pntxt = pt + '\\' + 'pntxt.txt'
savedirr = pt + '\\' + 'dw\sem_data.csv'

print(ExTime)

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('CELL' if ('CELL' in x) \
                else "NA"))))))))))

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    df_all.to_csv(savedirr)
    print()
    return df_all.to_dict()

def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()
    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()
    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt,txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\prep.py###

import pandas as pd
import numpy as np
import os
import lookup.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import db.db as sq
import func.fnfn as fn
from datetime import *




def top10(df0):
    pt = os.getcwd() + "\\T10.csv"
    dfx = pd.read_csv(pt)
    if 'CUSTOMATTR15' in df0.columns:
        df0 = df0.rename(columns={'CUSTOMATTR15':'CODE'})
    df3 = flk.vlookup(df0,dfx,'CODE','NA')
    df4 = fst.add_col_df(df3,'NEMTTE')
    df4['NWMTTR'] = df4.apply(lambda x : x.MTTR/60, axis = 1)
    df5 = df4.groupby(df4['CODE']).NWMTTR.sum()
    df6 = pd.DataFrame(df5,columns=['CODE','SMM'])
    df7 = flk.vlookup(df4,df6,'CODE','NA')
    df8 = flk.countif(df7,'CODE','CODE','CNT')
    print(df8)

def process_sem_data(df0):
    if 'CLEARTIMESTAMP' in df0.columns:
        df2 = fdt.datedif(df0,'MTTR','LASTOCCURRENCE','CLEARTIMESTAMP')
    else:
        df2 = fdt.datedif(df0,'AGING','LASTOCCURRENCE')
    df3 = fst.code_corr(df2)
    df4 = fst.catsemrw(df3)
    df5 = fst.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df7 = fn.conct(df6,'CUSTOMATTR15','cat','CODECAT')
    df8 = df7.drop_duplicates(subset='CODECAT', keep="first", inplace=False)
    return df8
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\PyOra.py###
import pandas as pd
import cx_Oracle

conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)
qry = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from sia_alerts_status
            where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
            and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
            and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and
            SITECODE like '%DHPLB01%'"""
df = pd.read_sql(qry, con=conn)
print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\PyOracle.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
from datetime import datetime
from datetime import timedelta
import win32com.client

pt = os.getcwd() + "\\" + "csv_download\\"
today = date.today()
t = time.localtime()
td = today.strftime('%Y%m')
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt + folderName1 + folderName2 + '.csv')

def qry_delta(from_min,to_min): 
    tday = date.today()
    tmdlta_from_now = datetime.now() - timedelta('minutes='+ int(from_min))
    tmdlta_to_now = datetime.now() - timedelta('minutes='+ int(to_min))
    qry_from = tmdlta_from_now.strftime('%Y-%m-%d %H:%M:%S')
    qry_to = tmdlta_to_now.strftime('%Y-%m-%d %H:%M:%S')
    dyn_date = "TO_DATE('" + qry_from + "','dd/mm/yyyy hh:mi:ss') AND TO_DATE('" + qry_to + "','dd/mm/yyyy hh:mi:ss')"
    return dyn_date

conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

single_clk = """Select * from alerts_status where Summary IN ('2G SITE DOWN','3G SITE DOWN','4G SITE DOWN','HUW-MAINS FAILURE','HUW-DC VOLTAGE LOW','ERI-DC LOW VOLTAGE','ERI-AC MAINS FAILURE','ERI-AC MIANS FILT') 
and Summary not like 'Synthetic_Fluc' and Severity>0 and Type=1"""

query = "SELECT * FROM ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_" + td + ") WHERE " + qry_delta(300,0)
print(query)
print(qry_delta('400','0'))
#df = pd.read_sql(query, con=conn)
#print(df)
#df.to_csv(pth)













$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pytext.py###
import os
pt = os.getcwd()
filename = pt + "\\python_created.txt"
f = open(filename,"w+")
f.write("This is line")
f.close()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\qbuilt.py###
import pandas as pd
import numpy as np
import os


def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x

def qbuilt(ndf, tbl, bycol, oncols=False, operator=True):
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf

df = pd.read_csv(os.getcwd() + "\\ss.csv")
df = df.astype(str)
x = qbuilt(df,'xyz',['SERIAL'])
x.to_csv(os.getcwd() + "\\ssbuilt.csv")



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\raw_download.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import omdt as odt
import subprocess
import xlwings

print("RPA is Runnig in BackGround, Don't CLose")
scrpt_name = "ErrorHanddle_VBS.vbs"
#fpth_0 = os.getcwd() + "\\" + scrpt_name
#os.system(fpth_0)
#time.sleep( 3 )

pt = os.getcwd()
pt2 = pt + "\\download\\"
t = time.localtime()
today = date.today()
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt2 + folderName1 + folderName2 + '.csv')
pth2 = os.path.join(pt2 + folderName1 + '.csv')
print(pth)
conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

def timex():
    t = time.localtime()
    folderName2 = time.strftime("%H%M", t)
    return folderName2

selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,
            RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qstr4 = "WHERE Severity>0 and Type=1"
#qstr4 = "WHERE (TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970')"
YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")
qst1_1 = 'Select' + "*" + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '
qry_un1 = qst1_1 + qstr4
qry_un2 = qst2_2 + qstr4
tm1 = timex()
df = pd.read_sql(qry_un1, con=conn)
tm2 = timex()
print("downloaded")
df.to_csv(pth2)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rdwrt.py###
import os


def o_read(filepath):
    file1 = open(filepath,"r+")  
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\read_db.py###
import pandas as pd
import pyodbc

def code_attr_update(code,smsid):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(socdb)
    qry = "SELECT * FROM [dbo].[omidb] WHERE SITECODE='" + code + "'"
    qryans = pd.read_sql(qry, conn)
    rowno = qryans.shape[0]
    if rowno != 0:
        zn = qryans.loc[1,"REGION"]
        p1p2 = qryans.loc[1,"P1P2"]
        pg = qryans.loc[1,"PG"]
        owner = qryans.loc[1,"OWNER"]
        pwaut = qryans.loc[1,"PWR_AUT"]
        thn = qryans.loc[1,"THANA"]
        qryupd = "UPDATE [dbo].[pglog4] SET REGION='" + zn + "', PRIORITY='" + p1p2 + "',SITETYPE_PG='" + pg + \
                  "', POWER_AUTH='" + pwaut + "', THANA='" + thn + "', OWNER='" + owner + "' WHERE SMSID='" + str(smsid) + "'"
        cursor = conn.cursor()
        cursor.execute(qryupd)
        conn.commit()
        conn.close()
        return qryupd
    else:
        return 'sitecode not found: ' + code
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\Reg.py###
import sys
import Registry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\robisocbot.py###




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rocsms.py###
import requests


def rocsms(ms,text):
    url = "https://web1.robi.com.bd/apiresponse.php?user=robircouser&pass=Gqras@3789291&from=10144&to=" + str(ms) + "&text=" + text
    rs = requests.get(url)
    print(rs)

rocsms('+8801817184338','from py xx')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rpa_ahift_main.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import rpa_shift.omdt as odt

start = time.time()

t = time.localtime()
today = date.today()
f1 = today.strftime('%m%d%y')
f2 = time.strftime("%H%M", t)
pt = os.getcwd() + "\\T\\" + f1 + f2 + '.csv'


YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")

#selcol = ' * '
selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qst1_1 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '

conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

Code = "('DHMRP25','CGPCH19')"
P1 = "Select * from alerts_status where Summary IN " + Code
P2 = "Select" + selcol + "from alerts_status where"
Q1 = " and (TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970')"
Q2 = " and Severity>0 and Type=1"
Q3 = " Severity>0 and Type=1"
Qr1 = P2 + Q3
print(Qr1)
df = pd.read_sql(Qr1, con=conn)
end = time.time()
print('TIme Required: ')
print(end - start)
df.to_csv(pt)
print("file name: " + pt)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rpa_alert_status.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import omdt as odt
import xlwings
import wait_handdle as wth

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"

# lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('MF' if ('MAIN' in x) \
    else ('DC' if ('VOLTAGE' in x) \
    else "NA"))))

ExTime = int(time.strftime("%M"))
print(ExTime)

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def MACRO_RUN(fpth,comnd):
    if comnd=='EX':
        excelpath = os.getcwd() + '\\xlsF\\A_SEMRW.xlsm'
        filepath = fpth
        excel_app = xlwings.App(visible=False)
        excel_book = excel_app.books.open(excelpath)
        x = excel_book.macro('init')
        x(filepath)
        time.sleep( 30 )
        return 'success'
    else:
        return 'Not Executed'


def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    return df_all.to_dict()


def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()


class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []

    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()

    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()

    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()

    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.read_csv(single)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt, txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))


#single = os.getcwd() + "\\" + "single.csv"
#pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rruocc.py###
import pandas as pd
import numpy as np
import os
import requests
import func.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnfn as fn
import db.db as sq
import prep as pr
import func.omdtfn as odt
from datetime import *

def custom_msg_sender(chatid,msg):
    TOKEN = "961035316:AAGWIlt5GjIkBz1QI1s6WKbwVnfubmn0m6E"
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


def code_corr(df):
    ndf = df
    for i in range(len(ndf)):
        Eky = str(ndf.loc[i,'EQUIPMENTKEY'])
        A15 = str(ndf.loc[i,'CUSTOMATTR15'])
        if A15 == 'UNKNOWN' and len(Eky) < 15:
            if len(Eky) == 7:
                df.loc[i,'CUSTOMATTR15'] = Eky
            elif len(Eky) == 10:
                df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
            elif '_' in str(Eky):
                fnd =  Eky.find('_')
                if fnd > 7:
                    df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
                else:
                    try:
                        df.loc[i,'CUSTOMATTR15'] = Eky[fnd:7]
                    except:
                        df.loc[i,'CUSTOMATTR15'] = "UNKNOWN"
    return df


def smsprep_znwise(df,znname, c1,c2):
    zn = ['DHK_M','DHK_N','DHK_S','CTG_M','CTG_N','CTG_S','COM','BAR','KHL','KUS','MYM','NOA','RAJ','RANG','SYL']
    fst = ""
    for i in zn:
        st = ""
        for j in range(len(df)):
            if i == df.loc[j,znname]:
                if st == "":
                    st = i + ' XXX ' + chr(10) + df.loc[j,c1] + ': ' + str(df.loc[j,c2])
                else:
                    st = st + chr(10) + df.loc[j,c1] + ': ' + str(df.loc[j,c2])
        if len(st)> 10:
            ch10 = st.count(chr(10))
            stx = st.replace('XXX', ' || ' + str(ch10))
            if fst == "":
                fst = stx
            else:
                fst = fst + chr(10) + chr(10) + stx
            st = ""
            stx = ""
    return fst

def get_region(df):
    df4 = df
    df5 = fst.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    return df6


def theft_occ(df1):
    df = fst.add_col_df(df1,'cat')
    df['cat'] = df.apply(lambda row: 'TH' if ('THEFT' in row.SUMMARY) else "other", axis = 1)
    df2 = df[~df['cat'].isin(['other'])]
    df4 = fst.add_col_df(df2,'DT')
    df4['DT'] = df4.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%b-%Y"), axis = 1)
    df6 = df4.reset_index()
    ddx = code_corr(df6)
    dd = odt.day_minus(1)
    df7 = ddx[ddx['DT'].isin([dd])]
    df8 = df7[~df7['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df9 = df8.reset_index()
    df10 = flk.countif(df9,'CUSTOMATTR15','CUSTOMATTR15','CNT')
    df10 = df10.drop_duplicates(subset='CUSTOMATTR15', keep='first')
    df11 = fst.add_col_df(df10,'GTLT')
    df11['GTLT'] = df11.apply(lambda row: 'GT10' if (row.CNT>=10) else "LT10", axis = 1)
    df11 = df11[df11['GTLT'].isin(['GT10'])]
    df12 = df11[['CUSTOMATTR15','CNT']]
    df13 = get_region(df12)
    getsms = smsprep_znwise(df13,'Region','CUSTOMATTR15','CNT')
    chtid = "-1001213797107"
    msghead1 = "RRU Theft Alarm Occurance 10 Plus"
    msghead2 = "on " + odt.day_minus(1)
    msghead = msghead1 + chr(10) + msghead2 + chr(10) + chr(10) + "SiteCode: Counts " + chr(10) + chr(10) + getsms
    fmsg = msghead.replace(chr(10),"%0a")
    custom_msg_sender("-1001213797107",fmsg)
    return 'done'

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rru_report.py###
import pandas as pd
import numpy as np
import os
from datetime import date
import win32com.client
import subprocess
import time

def rru_lastday(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()

td = date.today()
pt = os.getcwd() + "\\rru_download\\" + "RRU_" + td.strftime('%Y-%m-%d') + ".csv"
ptmacro = os.getcwd() + "\\rru_download\\rru_mac.xlsm"
xlcls = os.getcwd() + "\\rru_download\\xlcls.vbs"

cols = ["SERIAL","EQUIPMENTKEY","CUSTOMATTR15","SUMMARY","LASTOCCURRENCE","CLEARTIMESTAMP","ALARMDETAILS"]
single = os.getcwd() + "\\" + "DWRRU.csv"
dcc1 = rru_lastday('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dcc1)
df2 = df[cols]
code= [df2['CUSTOMATTR15'].value_counts(dropna=False)]
ndf = pd.DataFrame(code).T
ndf.to_csv(pt)

print(pt)
xl = win32com.client.Dispatch("Excel.Application")
xl.Visible = True
book = xl.Workbooks.Open(ptmacro)
time.sleep( 50 )
xl.Application.Run("rru_mac.xlsm!init_rru", pt) #With Parameter
time.sleep( 10 )
xl.Application.Quit()
print('all sucess with python')
time.sleep( 10 )
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\runner.py###
import asyncio

async def periodic():
    while True:
        print('periodic')
        await asyncio.sleep(60)

def stop():
    task.cancel()

loop = asyncio.get_event_loop()
task = loop.create_task(periodic())

try:
    loop.run_until_complete(task)
except asyncio.CancelledError:
    pass
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\saymyname.py###


import os
import time

nam = ['42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','42','42','95','95','95','95','42','42','95','95','42','42','95','95','42','42','32','95','42','42','32','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','32','47','32','95','95','32','92','124','32','32','92','47','32','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','124','32','124','32','32','124','32','124','32','92','32','32','47','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','124','32','124','32','32','124','32','124','32','124','92','47','124','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','124','32','124','95','95','124','32','124','32','124','32','32','124','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','42','92','95','95','95','95','47','92','95','124','42','42','124','95','124','42','124','95','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','1045','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','10']

def str2list(st):
    lsx = []
    try:
        ls = st.split()
        for n in range(len(ls)):
            lsx.append(ls[n])
        return lsx
    except:
        return lsx
    
def st2ls(st):
    ls = []
    for i in range(len(st)):
        ls.append(ord(st[i]))
    return ls

def ls2st(ls):
    hp = ""
    for i in range(len(ls)):
        if hp == "":
            hp = chr(ls[i])
        else:
            hp = hp + chr(ls[i])
    return hp

def aptxt(lsst,filename):
    fin = open(os.getcwd() + "\\" + filename + ".txt", "a+")
    hp = []
    if isinstance(lsst,list):
        for i in range(len(lsst)):
            hp.append(str(lsst[i]))
        xx = ",".join(list(hp)) + chr(10)
        fin.write(xx)
    else:
        fin.write(lsst)
    fin.close()

def prep(pth):
    fp = open(pth,"r")
    xx = fp.read()
    xy = xx.split("\n")
    ls1 = []
    ls2 = []
    xx=""
    for i in range(len(xy)):
        a1 = st2ls(xy[i])
        a2 = ls2st(a1)
        aptxt(a1,"A8")

sx = """91,42,42,42,42,42,42,95,95,95,95,42,42,95,95,42,42,95,95,42,42,32,95,42,42,32,42,42,42,42,42,42,42,33
42,42,42,42,42,32,47,32,95,95,32,92,124,32,32,92,47,32,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,124,32,124,32,32,124,32,124,32,92,32,32,47,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,124,32,124,32,32,124,32,124,32,124,92,47,124,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,124,32,124,95,95,124,32,124,32,124,32,32,124,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,42,92,95,95,95,95,47,92,95,124,42,42,124,95,124,42,124,95,124,42,42,42,42,42,42,42,42,93,33"""

def say_my_name():
    print("----------------------------------")
    time.sleep(1)
    xx = sx.replace("42","32")
    yy = xx.replace("33","xx")
    ls = yy.split("xx")
    hp = ""
    for i in range(len(ls)):
        xz = ls[i].split(",")
        hp = ""
        for n in range(len(xz)):
            if xz[n] == "":
                print(hp)
                hp = ""
            else:
                hp = hp + chr(int(xz[n]))
    print("---------------------------------")
        
say_my_name()
time.sleep(5)


#prep(os.getcwd() + "\\N2.txt")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry-checkpoint.py###
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2.0.4.0\n",
      "<class 'datetime.datetime'>\n",
      "select * FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE  AGENT LIKE 'U2000 IP' and LASTOCCURRENCE BETWEEN TO_DATE('26-12-2020 00:08:00','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('26-12-2020 23:50:00','DD-MM-YYYY HH24:MI:SS')\n",
      "Stat Time:  27-12-2020 21:26:12\n",
      "End Time:  27-12-2020 21:26:41\n",
      "Time Consumed:  218.3  mins\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cx_Oracle\n",
    "import os\n",
    "from datetime import *\n",
    "from dateutil.parser import *\n",
    "from dateutil.tz import *\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "nw = datetime.now()\n",
    "dtst = nw.strftime (\"%d%m%Y%H%M%S\")\n",
    "fl = os.getcwd() + \"\\\\dw\\\\\" + dtst + \".csv\"\n",
    "#print(fl)\n",
    "\n",
    "def sem_view_filter_cols():\n",
    "    df = pd.read_csv(os.getcwd() + \"\\\\col_filter_semdb_view_non_macro.csv\")\n",
    "    ls = df.iloc[:,0].to_list()\n",
    "    x = \",\".join(list(ls))\n",
    "    return x\n",
    "\n",
    "def timedelt(diff):\n",
    "    x = datetime.now ()\n",
    "    d = x + timedelta (hours=diff)\n",
    "    str_d = d.strftime (\"%d-%m-%Y %H:%M:%S\")\n",
    "    return str_d\n",
    "\n",
    "def tmx(t1=False):\n",
    "    nw = datetime.now()\n",
    "    dtst = nw.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    if t1 == False:\n",
    "        print(\"Stat Time: \", dtst)\n",
    "        return nw\n",
    "    else:\n",
    "        x = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "        print(\"End Time: \", dtst)\n",
    "        print(\"Time Consumed: \", x, \" mins\")\n",
    "        \n",
    "conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')\n",
    "print (conn.version)\n",
    "    \n",
    "def qryex(qr = False, flname = fl):\n",
    "    q = \"\"\n",
    "    if qr == False:\n",
    "        q1 = \"select \" + sem_view_filter_cols() + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0\"\n",
    "    else:\n",
    "        q1 = \"select \" + \"*\" + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE \" + str(qr)\n",
    "    print(q1)\n",
    "    st = tmx()\n",
    "    df = pd.read_sql(q1, con = conn)\n",
    "    et = tmx(st)\n",
    "    df.to_csv(os.getcwd() + \"\\\\dw\\\\\" + flname)\n",
    "    return df\n",
    "    \n",
    "def timebetween(t1,t2):\n",
    "    d1 = parse(t1)\n",
    "    d2 = parse(t2)\n",
    "    print(type(d1))\n",
    "    dd = \"LASTOCCURRENCE BETWEEN TO_DATE('\" + d1.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('\" +  d2.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS')\"\n",
    "    return dd\n",
    "\n",
    "#######################################################################################\n",
    "def qr1():\n",
    "    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')\n",
    "    Y21= qryex(x21,'EFDSDFSDFS.csv')\n",
    "\n",
    "def qr2():\n",
    "    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')\n",
    "    x22 = \" CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and \" + x21 \n",
    "    df= qryex(x22,'all_oneday_ip.csv')\n",
    "\n",
    "qr2()\n",
    "\n",
    "#xx = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "#print(xx)\n",
    "#x = relativedelta(\n",
    "    #print(datetime.strptime(\"22-12-2020 01:05\",\"%d-%m-%Y %H:%M:%S\"))- datetime.strptime(datetime.now(),\"%d-%m-%Y %H:%M:%S\").seconds / 60\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry.py###
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2.0.4.0\n",
      "<class 'datetime.datetime'>\n",
      "select * FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE  AGENT LIKE 'U2000 IP' and LASTOCCURRENCE BETWEEN TO_DATE('26-12-2020 00:08:00','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('26-12-2020 23:50:00','DD-MM-YYYY HH24:MI:SS')\n",
      "Stat Time:  27-12-2020 21:26:12\n",
      "End Time:  27-12-2020 21:26:41\n",
      "Time Consumed:  218.3  mins\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cx_Oracle\n",
    "import os\n",
    "from datetime import *\n",
    "from dateutil.parser import *\n",
    "from dateutil.tz import *\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "nw = datetime.now()\n",
    "dtst = nw.strftime (\"%d%m%Y%H%M%S\")\n",
    "fl = os.getcwd() + \"\\\\dw\\\\\" + dtst + \".csv\"\n",
    "#print(fl)\n",
    "\n",
    "def sem_view_filter_cols():\n",
    "    df = pd.read_csv(os.getcwd() + \"\\\\col_filter_semdb_view_non_macro.csv\")\n",
    "    ls = df.iloc[:,0].to_list()\n",
    "    x = \",\".join(list(ls))\n",
    "    return x\n",
    "\n",
    "def timedelt(diff):\n",
    "    x = datetime.now ()\n",
    "    d = x + timedelta (hours=diff)\n",
    "    str_d = d.strftime (\"%d-%m-%Y %H:%M:%S\")\n",
    "    return str_d\n",
    "\n",
    "def tmx(t1=False):\n",
    "    nw = datetime.now()\n",
    "    dtst = nw.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    if t1 == False:\n",
    "        print(\"Stat Time: \", dtst)\n",
    "        return nw\n",
    "    else:\n",
    "        x = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "        print(\"End Time: \", dtst)\n",
    "        print(\"Time Consumed: \", x, \" mins\")\n",
    "        \n",
    "conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')\n",
    "print (conn.version)\n",
    "    \n",
    "def qryex(qr = False, flname = fl):\n",
    "    q = \"\"\n",
    "    if qr == False:\n",
    "        q1 = \"select \" + sem_view_filter_cols() + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0\"\n",
    "    else:\n",
    "        q1 = \"select \" + \"*\" + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE \" + str(qr)\n",
    "    print(q1)\n",
    "    st = tmx()\n",
    "    df = pd.read_sql(q1, con = conn)\n",
    "    et = tmx(st)\n",
    "    df.to_csv(os.getcwd() + \"\\\\dw\\\\\" + flname)\n",
    "    return df\n",
    "    \n",
    "def timebetween(t1,t2):\n",
    "    d1 = parse(t1)\n",
    "    d2 = parse(t2)\n",
    "    print(type(d1))\n",
    "    dd = \"LASTOCCURRENCE BETWEEN TO_DATE('\" + d1.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('\" +  d2.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS')\"\n",
    "    return dd\n",
    "\n",
    "#######################################################################################\n",
    "def qr1():\n",
    "    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')\n",
    "    Y21= qryex(x21,'EFDSDFSDFS.csv')\n",
    "\n",
    "def qr2():\n",
    "    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')\n",
    "    x22 = \" CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and \" + x21 \n",
    "    df= qryex(x22,'all_oneday_ip.csv')\n",
    "\n",
    "qr2()\n",
    "\n",
    "#xx = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "#print(xx)\n",
    "#x = relativedelta(\n",
    "    #print(datetime.strptime(\"22-12-2020 01:05\",\"%d-%m-%Y %H:%M:%S\"))- datetime.strptime(datetime.now(),\"%d-%m-%Y %H:%M:%S\").seconds / 60\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry_by_timestamp.py###
import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
print(flname)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        

def qryex(qr = False, flname = fl):
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(flname)
    conn.close()
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd
    
def qmain():
    x3 = timebetween("17-12-2020 00:00","19-12-2020 23:59")
    x1 = timebetween("20-12-2020 00:00","22-12-2020 23:59")
    x2 = timebetween("23-12-2020 00:00","25-12-2020 15:45")
    y1 = qryex(x1,"23_25.csv")
    y2 = qryex(x2,"20_22.csv")
    y3 = qryex(x3,"17_19.csv")

qmain()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry_test.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client

pt = os.getcwd() + '//T.csv'
conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
Qr1 = "SELECT IDENTIFIER,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE FROM alerts_status WHERE Severity!='0'"
print(Qr1)
df = pd.read_sql(Qr1, con=conn)
end = time.time()
print('TIme Required: ')
print(end - start)
df.to_csv(pt)
print("file name: " + pt)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sem_rw_from_oracle.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import omdt as odt
import subprocess

pt = os.getcwd()
pt2 = pt + "\\"
ptxls = pt + "\\xlsF\\RW.xlsm"
ptbat = pt + "\\closexl.vbs"
subprocess.call("cscript closexl.vbs")
t = time.localtime()
today = date.today()
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt2 + folderName1 + folderName2 + '.csv')
print(pth)
print(conn.version)

def timex():
    t = time.localtime()
    folderName2 = time.strftime("%H%M", t)
    return folderName2

selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,
            RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qstr4 = "WHERE Severity>0 and Type=1"
YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")
qst1_1 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '
qry_un1 = qst1_1 + qstr4
qry_un2 = qst2_2 + qstr4
tm1 = timex()
df1 = pd.read_sql(qry_un1, con=conn)
tm2 = timex()
df2 = pd.read_sql(qry_un2, con=conn)
tm3 = timex()
print('execution start, mid, end: ' + tm1 + ',' + tm2 + ',' + tm3)
conn.close()
df3 = [df1,df2]
df = pd.concat(df3)
df.to_csv("F://Python//RPA_SHIFT//TestData//testdata.csv")
df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
dfmf = df[df['SUMMARY'].str.contains('MAIN')]
dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
df_cnct = [df2g,df3g,df4g,dfmf,dfdl]
df_all = pd.concat(df_cnct)
df_all.to_csv(pth)
df_final = df_all.rename(columns={'EQUIPMENTKEY':'Resource','CUSTOMATTR26':'AssociatedCR',
                                    'CUSTOMATTR24':'BCCH',
                                    'OWNERGID':'Incident Owner',
                                    'EVENTID':'Frequency',
                                    'TTREQUESTTIME':'TT Creation Time',
                                    'CUSTOMATTR19':'HVC_STATUS'})

print(df_final.columns)
#df_final.to_csv(pth)
parm = pth
#xl = win32com.client.Dispatch("Excel.Application")
#xl.Visible = False
#book = xl.Workbooks.Open(ptxls, False, False, None, '2986')
#xl.Application.Run("RW.xlsm!init", parm) #With Parameter
#time.sleep( 10 )
#subprocess.call("cscript closexl.vbs")
print('all sucess with python')
#xl.Application.Quit()
time.sleep( 3 )
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sem_rw_mod.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import omdt as odt
import subprocess
import xlwings

print("RPA is Runnig in BackGround, Don't CLose")
scrpt_name = "ErrorHanddle_VBS.vbs"
#fpth_0 = os.getcwd() + "\\" + scrpt_name
#os.system(fpth_0)
#time.sleep( 3 )

pt = os.getcwd()
pt2 = pt + "\\download\\"
t = time.localtime()
today = date.today()
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt2 + folderName1 + folderName2 + '.csv')
pth2 = os.path.join(pt2 + folderName1 + '.csv')
print(pth)
conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

def timex():
    t = time.localtime()
    folderName2 = time.strftime("%H%M", t)
    return folderName2

selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,
            RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qstr4 = "WHERE Severity>0"
YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")
qst1_1 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '
qry_un1 = qst1_1 + qstr4
qry_un2 = qst2_2 + qstr4
tm1 = timex()
df = pd.read_sql(qry_un1, con=conn)
tm2 = timex()
print("downloaded")
#df2 = pd.read_sql(qry_un2, con=conn)
#tm3 = timex()
#print('execution start, mid, end: ' + tm1 + ',' + tm2 + ',' + tm3)
#conn.close()
#df3 = [df1,df2]
#df = pd.concat(df3)
df.to_csv(pth2)
df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN', na=False)]
df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN', na=False)]
df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN', na=False)]
dfmf = df[df['SUMMARY'].str.contains('MAIN', na=False)]
dfdl = df[df['SUMMARY'].str.contains('DC LOW', na=False)]
dftmp = df[df['SUMMARY'].str.contains('TEMP', na=False)]
dfcell = df[df['SUMMARY'].str.contains('CELL DOWN', na=False)]
dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT', na=False)]
dfsmoke = df[df['SUMMARY'].str.contains('SMOKE ALARM', na=False)]
df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth,dfsmoke]
df_all = pd.concat(df_cnct)
df_final = df_all.rename(columns={'EQUIPMENTKEY':'Resource','CUSTOMATTR26':'AssociatedCR',
                                    'CUSTOMATTR24':'BCCH',
                                    'OWNERGID':'Incident Owner',
                                    'EVENTID':'Frequency',
                                    'TTREQUESTTIME':'TT Creation Time',
                                    'CUSTOMATTR19':'HVC_STATUS'})

#print(df_final.columns)
df_final.to_csv(pth)
parm = pth
print('csv download successfully')
excelpath = pt + '\\xlsF\\A_SEMRW.xlsm'
filepath= pth
excel_app = xlwings.App(visible=False)
excel_book = excel_app.books.open(excelpath)
# into brackets, the path of the macro
x = excel_book.macro('init')
x(filepath)
time.sleep( 3 )
conn
print('Closing Success')



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\single_sql.py###
import pandas as pd
import omsqlfn as fn
import pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def Update_insert_single(conn, tbl, listcols, listvalue, bycol, bycolv):
    cur = conn.cursor()
    cmd = ''
    x = CheckExist(conn, tbl, bycol, bycolv)
    if x != 0:
        cmd = "update " + tbl + ' set ' + fn.prep_update(listcols, listvalue) + ' where ' + bycol + "='" + bycolv + "'"
        print('Existing rows found, proceed for update', cmd)
    else:
        cmd = "insert into " + tbl + ' ' + fn.prep_insert(listcols, listvalue)
        print('no existing value found, proceed for insert \n', cmd)
    cur.execute(cmd)
    conn.commit()

def Query(conn, tbl = None, Ex = False, colname = False, condition = False):
    cur = conn.cursor()
    if Ex:
        if isinstance(Ex, str):
            df = pd.read_sql(Ex, conn)
            return df
            exit()
    if colname != False and tbl != None:
        x = ''
        qry = ''
        if isinstance(colname, list):
            for i in range(len(colname)):
                if x == '':
                    x = colname[i]
                else:
                    x = x + "," + colname[i]
        else:
            x = str(colname)
        if condition != False:
            y = ''
            if isinstance(condition, list):
                for i in range(len(condition)):
                    if y == '':
                        x = condition[i]
                    else:
                        y = y + " and " + condition[i]
                qry = "select " + x + " from " + tbl + " where " + y
            else:
                y = str(condition)
                qry = "select " + x + " from " + tbl + " where " + y
    print('query: ', qry)
    dfx = pd.read_sql(qry, con= conn)
    return dfx

def DeleteByCond(conn, tbl, col, cond):
    xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
    cur = conn.cursor()
    cur.execute(xx)
    conn.commit()

def DeleteDuplicate(conn, tbl, cond_col):
    qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
    cur = conn.cursor()
    cur.execute(qry)
    conn.commit()

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


conn = MySql('root','admin','127.0.0.1:3306','omdb')
#print(Query(conn, tbl = 'mytable', Ex = "select * from eve"))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']), condition = " Zone Like 'BAR'")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sitecount.py###
import pandas as pd
import pyodbc

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
conn = pyodbc.connect(UserEx)

def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "All2g") or (txtwht == "all2g") or (txtwht == "All2G") or (txtwht == "2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "All3G") or (txtwht == "all3G") or (txtwht == "All3g") or (txtwht == "3G"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "All4G") or (txtwht == "all4G") or (txtwht == "All4g") or (txtwht == "4G"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "AllCount") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        allnode = df2G.shape[0]
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "Radio Node: " + str(allnode) + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sitehistory.py###
import pandas as pd
import MySQLdb
import pyodbc

def fnx(code):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(socdb)
    df1 = pd.read_sql("select * from sitebase", conn)
    df = df1[df1['Site_Code'].str.contains(code)]
    a1 =  'Site Owner: ' + df['Mergeco__Robi'].iloc[0]  + '\n'
    a2 =  'AT Code/Relocation Code :' + df['AT_Code'].iloc[0]  + '\n'
    a3 =  'Site Name: ' + df['Site_Name'].iloc[0]  + '\n'
    a4 =  'Lat-Long: ' + df['Lat'].iloc[0] + ' - ' + df['Lon'].iloc[0]  + '\n'
    a5 =  'Site Address :' + df['Site_Physical_Address'].iloc[0]  + '\n'
    a6 =  'Site Type:' + df['Site_Type'].iloc[0]  + '\n'
    a7 =  'Site Build: ' + df['Build'].iloc[0]  + '\n'
    a8 =  'Share Operator: ' + df['Share_Operator'].iloc[0]  + '\n'
    a9 =  'Operator Code: ' + df['Operator_Code'].iloc[0]  + '\n'
    a10 =  'Region: ' + df['Region_(15)'].iloc[0]  + '\n'
    a11 =  'Zone: ' + df['Zone'].iloc[0]  + '\n'
    a12 =  'Cluster Type:' + df['Clutter_Type'].iloc[0]  + '\n'
    a13 =  'Tech: ' + df['All_Tech'].iloc[0]  + '\n'
    a14 =  'Tech Band: ' + df['Tech_Band'].iloc[0]  + '\n'
    a15 =  'Vendor: ' + df['Vendor'].iloc[0]  + '\n'
    a16 =  'Site Priority: ' + df['Priority'].iloc[0]  + '\n'
    vchk = df['PG_Allowed_Not_'].iloc[0]
    if "Run allowed" in vchk:
        a17 =  'PG Restricted : ' + "No" + '\n'
    else:
        a17 =  'PG Restricted : ' + "Yes" + '\n'
    a18 =  'DG: ' + df['DG_Status'].iloc[0]  + '\n'
    a19 =  'Revenue(k): ' + df['Revenue_(in_K_BDT)'].iloc[0]  + '\n'
    aa = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8 + a9 + a10 + a11 + a12 + a13 + a14 + a15 + a16 + a17 + a18 + a19
    return aa

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\socksi_py_online_chk.py###
#ref: https://stem.torproject.org/tutorials/to_russia_with_love.html
import socks  # SocksiPy module
import socket
import urllib

SOCKS_PORT = 7000

# Set socks proxy and wrap the urllib module

socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, '127.0.0.1', SOCKS_PORT)
socket.socket = socks.socksocket

# Perform DNS resolution through the socket

def getaddrinfo(*args):
  return [(socket.AF_INET, socket.SOCK_STREAM, 6, '', (args[0], args[1]))]

socket.getaddrinfo = getaddrinfo

def query(url):
  """
  Uses urllib to fetch a site using SocksiPy for Tor over the SOCKS_PORT.
  """

  try:
    return urllib.urlopen(url).read()
  except:
    return "Unable to reach %s" % url
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\socks_srv.py###
#ref: https://rushter.com/blog/python-socks-server/
from socketserver import ThreadingMixIn, TCPServer, StreamRequestHandler

class ThreadingTCPServer(ThreadingMixIn, TCPServer):
    pass

class SocksProxy(StreamRequestHandler):
    def handle(self):
        # Our main logic will be here
        pass

if __name__ == '__main__':
    with ThreadingTCPServer(('127.0.0.1', 9011), SocksProxy) as server:
        server.serve_forever()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\socks_stat.py###
#ref: https://stem.torproject.org/api/connection.html

import requests as r

def sockchk_1(ip):
    proxycheck_io = "830284-700030-f06940-3c6410"
    apilink = "http://proxycheck.io/v2/" + ip + "?key=830284-700030-f06940-3c6410&asn=1"
    rs = r.get(apilink)
    jsonResponse = rs.json()
    print(jsonResponse)
    
    
sockchk_1('45.72.6.167')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sqdev.py###
import pandas as pd
import os
import omsql.InsUpd as ii



pt = os.getcwd() + '\\OMDB.csv'
df = pd.read_csv(pt)
cond = ['Zone', 'ULKA']
dfx = df[cond]
print(dfx)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sql.py###
import pandas as pd
import time
import pyodbc
import omfn.xdttm as odt
#from omsql.omsq import *

td = odt.Now()
tday = td.strftime('%Y-%m-%d')
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"

def auser(msg1):
    conx = pyodbc.connect(socdb)
    print(msg1)
    msgspl = msg1.split(',')
    colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
    valu = "'" + msgspl[1] + "','" + str(msgspl[2]) + "','" + tday + "','" + msgspl[3] + "','Y','Y','Y'"
    qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
    qry2 = """insert into om_socbot_access (NAME,UID,JOIN_DATE,MSISDN) values ('" + msgspl[1] + "','" + msgspl[2] + "','2020-11-01','" + msgspl[3] "')"""
    print(qry)
    cr = conx.cursor()
    try:
        cr.execute(qry)
    except:
        cr.execute(qry2)
    cr.commit()
    return "user added successfully"
    #except:
        #return "useradd,halim vai,667675107,01819210773"

def botusrlist():
    conx = pyodbc.connect(socdb)
    qry = 'select * from om_socbot_access'
    df = pd.read_sql(qry, conx)
    st2 = "list of user"
    for i in range(len(df)):
        if df.loc[i,'MSISDN'] is None:
            msisd = 'NA'
        else:
            msisd = df.loc[i,'MSISDN']
        st = str(i) + '. ' + df.loc[i,'NAME'] + ', ' + df.loc[i,'UID'] + ", " + msisd
        st2 = st2 + chr(10) + st
    return st2


def periodic_contacts(contact_With_cmd):
    conn = pyodbc.connect(socdb)
    x = ''
    cur = conn.cursor()
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is \n periodic,01817183XXX,add"
    tbl = 'PeriCon'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    cr = conn.cursor()        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        qry = 'select * from ' + tbl + " where Number = '" + fcn + "' or  Number like '" + fcn + "'"
        rs = pd.read_sql(qry, con = conn)
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if 'check' in cmd or 'check' in contact_With_cmd:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                qry = "insert into " + tbl + " (Number) values ('" + fcn + "')"
                cur.execute(qry)
                conn.commit
                print(qry)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                xx = "DELETE FROM " + tbl + " WHERE Number Like '" + fcn + "'"
                cur.execute(xx)
                conn.commit
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'


#print(botusrlist())
#adduser('adduser,SMx2,615558497,0181817183680')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sqltdb.py###
import sqlite3
import os
import pandas as pd

pt = os.getcwd()
mydb = pt + "//served.db"
cn = sqlite3.connect(mydb)
c = cn.cursor()

def createtbl():
    c.execute('''CREATE TABLE ussdlg (ussd text, tm text);''')
    cn.commit()

def insertussd(ussd):
    try:
        usd = str(ussd)
        sql = "INSERT INTO ussdlg (ussd, tm) VALUES ('" + usd + "','NAAA')"
        count = c.execute(sql)
        cn.commit()
        return "S"
    except:
        return "F"
    
def queryussd(ussd):
    usd = str(ussd)
    c.execute('''SELECT * FROM ussdlg''')
    df = pd.DataFrame(c.fetchall(), columns=['ussd','tm'])
    if df.shape[0] != 0:
        df1 = df[df['ussd'].isin([usd])]
        if df1.shape[0] != 0:
            return 1
        else:
            return 0

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sshlogin.py###
import paramiko
import sys
import time
import os

def Write2TxtList(dr,filename,content):
    flpath = dr + '\\' + filename
    print(flpath)
    fl = open(flpath, 'w')
    cont = "".join(content)
    fl.write(cont + '\n')
    fl.close()

class server():
    def __init__(self,HOST):
        self.USER = "ak2986"
        self.PASS = "Robi@123"
        self.PORT = 22
        self.c1 = paramiko.SSHClient()
        self.c1.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        self.c1.connect(HOST,port=self.PORT,username=self.USER,password=self.PASS)
        print ("SSH connection to %s established" %HOST)
    def excmd(self,cmd):
        c1 = self.c1
        stdin, stdout, stderr = c1.exec_command(cmd)        
        output = stdout.readlines()
        opt = "".join(output)
        print(opt)
        return opt
    def conn_cls(self):
        c1 = self.c1
        c1.close()
        print('connection close successfully')

#Write2TxtList(os.getcwd(), 'OutputLog.txt', opt)
ossip = "10.16.214.103"
x = server(ossip)
#y = x.excmd('ls')
#Write2TxtList(os.getcwd(), 'OutputLog.txt', y)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\T1.py###
import pandas as pd
from datetime import *
import os
import TD1 as td

class omidf:
    def __init__(self, dfx):
        self.df = dfx
    def DateTime(self, ndf = pd.DataFrame([])):
        if len(ndf) <= 1:
            print(self.df)
        else:
            print(ndf)

def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (minutes=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

#db = pd.read_csv(os.getcwd() + "\\OMDB.csv")
df = pd.read_csv(os.getcwd() + "\\csv\\DT.csv")
#df = df.rename(columns={'CUSTOMATTR15':'Code'})
#print(df)
df.set_index('LASTOCCURRENCE')['16/11/2020':'30/11/2020'].head()
print(df)
#pickcols()
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)








#df1 = dfdiff(df,'LASTOCCURRENCE')
#df1 = datetime_convert_format(df,'CLEARTIMESTAMP')
#df2 = datetime_convert_format(df1,'CLEARTIMESTAMP',"%d/%m/%Y %H:%M:%S")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tapi.py###
import pandas as pd
from datetime import *
import os
import TD1 as td

class omidf:
    def __init__(self, dfx):
        self.df = dfx
    def DateTime(self, ndf = pd.DataFrame([])):
        if len(ndf) <= 1:
            print(self.df)
        else:
            print(ndf)

def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (minutes=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

#db = pd.read_csv(os.getcwd() + "\\OMDB.csv")
df = pd.read_csv(os.getcwd() + "\\csv\\DT.csv")
#df = df.rename(columns={'CUSTOMATTR15':'Code'})
#print(df)
df.set_index('LASTOCCURRENCE')['16/11/2020':'30/11/2020'].head()
print(df)
#pickcols()
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)








#df1 = dfdiff(df,'LASTOCCURRENCE')
#df1 = datetime_convert_format(df,'CLEARTIMESTAMP')
#df2 = datetime_convert_format(df1,'CLEARTIMESTAMP',"%d/%m/%Y %H:%M:%S")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbl_mssql.py###
import pandas as pd
import pyodbc, os
import datetime

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

def sql_lstyp(d_type):
    addID = "NULL"
    if d_type == 'Int64':
        return "INT " + addID
    elif d_type == 'datetime64[ns]':
        return "DATETIME " + addID
    elif d_type == 'Float64':
        return "FLOAT " + addID
    else:
        return "TEXT " + addID

def CT_MSSQL(conn, tablename, list_col, list_type = []):
    st = ""
    finalstr = ''
    x = ""
    cur = conn.cursor()
    try:
        cur.execute('select 1 from ' + tablename)
        print('table already exist')
        exit
    except:
        for i in range(len(list_col)):
            x = ''
            col = list_col[i]
            if len(list_type) != 0:
                lsty = list_type[i]
                x =  '"' + col.replace(" ","_") + '" ' + str(lsty)
            else:
                x = '"' + col.replace(" ","_") + '" TEXT NULL'
            if st == "":
                addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                st = 'CREATE TABLE "' + tablename + '" (' + str(x)
            else:
                st = st + ',' + str(x)
        else:
            finalstr = st + ')'
            try:
                cur.execute(finalstr)
                conn.commit()
                print('table created succssfully with cmd', finalstr)
            except:
                print('table creation failed', finalstr)

def df_dtype_conv(df):
    ndf = df.convert_dtypes()
    cols = ndf.columns.to_list()
    for i in range(len(cols)):
        col = cols[i]
        if ndf[col].dtypes == 'string':
            try:
                ndf[col] = ndf.apply(lambda x : pd.to_datetime(x[col]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                ndf[col] = pd.to_datetime(ndf[col])
            except:
                pass
    return ndf

def is_table_exist(tbl, conn):
    qry = "SELECT 1 FROM " + tbl
    try:
        cr = conn.cursor()
        rs = cr.execute(qry)
        print('table already exist')
    except:
        print('table creation failed')

def CreateTable_MSSQL(df, tablename, conn):
    dfx = mod_cols_name(df)
    ndf = df_dtype_conv(dfx)
    lscol = ndf.columns.to_list()
    lstype = []
    q = 0
    for col in range(len(lscol)):
        q = q + 1
        try:
            cl = lscol[col]
            dtyp = ndf[cl].dtypes
            lstype.append(sql_lstyp(dtyp))
        except:
            print('error for ', q, ' ', ndf[cl].dtypes)        
    CT_MSSQL(conn, tablename, lscol, lstype)
        
def MsSql(user, password, host, db):
    #socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn
    


#lser = df_to_sql(ndf, 'om1', 'TAXW3', conn, oncolumn = 'ALL', bycolumn = ['CustomAttr15'])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbl_mysql.py###
import pandas as pd
import os, time
import datetime
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def df_dtype_conv(dfn):
    df = dfn.apply(lambda x: x.replace("'",''))
    ndf = df.convert_dtypes()
    cols = ndf.columns.to_list()
    for i in range(len(cols)):
        col = cols[i]
        if ndf[col].dtypes == 'string':
            try:
                ndf[col] = ndf.apply(lambda x : pd.to_datetime(x[col]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                ndf[col] = pd.to_datetime(ndf[col])
            except:
                pass
    return ndf

def mysql_lstyp(d_type):
    addID = "NULL DEFAULT NULL"
    if d_type == 'Int64':
        return "INT " + addID
    elif d_type == 'datetime64[ns]':
        return "DATETIME " + addID
    elif d_type == 'Float64':
        return "FLOAT " + addID
    else:
        return "TEXT " + addID

def is_table_exist(tbl, conn):
    qry = "SELECT 1 FROM " + tbl
    try:
        cr = conn.cursor()
        rs = cr.execute(qry)
        print('table already exist')
    except:
        print('table creation failed')

def CreateTable_MYSQL(connection, tablename, df = None, table_col = False, table_col_datatype = False, space = '_'):
    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
    addID = ""
    st = ""
    cr = connection.cursor()
    try:
        cr.execute()
    except:
        if table_col != False:
            if table_col_datatype == False:
                typ = 'TEXT NULL DEFAULT NULL'
                for i in range(len(table_col)):
                    x = "`" + table_col[i].replace(' ',space) + "` " + typ
                    if st == "":
                        st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + x
                    else:
                        st = st + ', ' + x
                return st
            else:
                for i in range(len(table_col)):
                    x = "`" + table_col[i].replace(' ',space) + "` " + table_col_datatype[i]
                    if st == "":
                        st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + x
                    else:
                        st = st + ', ' + x
                return st
        elif df.shape[0] != 0 and table_col == False:
            xdf = df_dtype_conv(df)
            df = xdf
            table_col = df.columns.to_list()
            for i in range(len(table_col)):
                x = "`" + table_col[i].replace(' ',space) + "` " + mysql_lstyp(df[table_col[i]].dtypes)
                if st == "":
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + x
                else:
                    st = st + ', ' + x
        else:
            print("please pass, df = True or table_col = True")
            return ""
            exit
        sst = st + ") ENGINE = InnoDB CHARSET=utf32 COLLATE utf32_general_ci"
        print(sst)
        try:
            cr.execute(sst)
            connection.commit()
            print('table creation successfull', ' table name ', tablename)
        except:
            print('table creation failed')
            print(sst)
        return sst
        


            
            
            
            
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbotmain.py###
import pandas as pd
import cx_Oracle
import sys
import time
import os
import telepot
from telepot.loop import MessageLoop
import pyodbc
import subprocess
from pprint import pprint
import tbot.tbot_extend_1 as tex
import tbot.sitehistory as st
import tbot.tbot_single_site_status as stst
import omfn.xmssq as xmq
import requests

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
bot = telepot.Bot(TOKEN)

msq = xmq.mssq()

def custom_msg_sender(chatid,msg):
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)

def addme(uid,txt):
    if '$$' in txt:
        print(txt)
        st = txt
        nst = st.replace('$$', '')
        sst = nst.split(' ')
        print(sst)
        if len(sst) == 5:
            print(sst[2])
            msq.bot_usr_add(sst[1], str(uid), sst[3], str(sst[2]))
        else:
            print(len(sst))
        #bot_usr_add()
    else:
        fmt = "'Name 018XXXXXXXX Passcode'"
        st = "OK, Then" + '\n' + "send info like below format \n $$ Name 018XXXXXXXX Passcode $$ \n \n if u send me wrong format i did not reply"
        custom_msg_sender(uid,st)

def site_bio(txt,chat_id):
    cd = txt.upper()
    bot.sendMessage(chat_id, 'processing request for ' + cd + ' , please wait')
    getval = stst.query(cd)
    gethis = st.fnx(cd)
    txtx = getval + '\n' + '\n' + 'Site Details:' + '\n' + gethis
    bot.sendMessage(chat_id,txtx)
    return 'done'

def add_inc_notes(txt,chat_id):
    st = txt.split('-')
    print(st[1])
    x = msq.apend_into('incident_tracker_v2','sm_comment_tele', st[1], 'Incident_ID', st[0].strip())
    return x

def query_hanndler(code):
    return code

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if (content_type == 'text'):
        txt = msg['text']
        cht = msg['chat']
        frm = msg['from']
        fname = frm['first_name']
        uid = frm['id']
        cid = cht['id']
        ctype = cht['type']
        user_auth = msq.auth_check_db(str(uid), ctype)
        bot.sendMessage('671462535', user_auth)
        txupr = txt.upper()
        if user_auth == '1' or user_auth == 1:
            if 'hi' in txt:
                bot.sendMessage(chat_id, txt)
            elif ("ADD" in txupr or "RMV" in txupr or "LIST" in txupr):
                gtval = tex.M_handdler(txupr, msg)
                bot.sendMessage(chat_id, gtval)
            elif len(txt) == 7 and cid == uid:
                rs = site_bio(txt,chat_id)
                print(rs)
            elif ("INC0" in txupr or "RDTX" in txupr):
                print('add_inc_notes')
                rs = add_inc_notes(txupr,chat_id)
                bot.sendMessage(chat_id, rs)
        elif (user_auth == '0' or user_auth == 0) and ('ADDME' in txupr or '$' in txt):
                addme(uid, txt)
        else:
            bot.sendMessage(cid, 'You are not autorized')
            bot.sendMessage('671462535', fname + ', ID: ' + str(uid))

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_extend.py###
import pyodbc
import pandas as pd
#import MySQLdb

#def stname(code):
    #nm = 'NP'
    #conn= MySQLdb.connect("localhost","root","","ops_portal")
    #df = pd.read_sql("select * from stbase3 Where Site_Code='" + code + "'", conn)
   # rw = df.shape[0]
   # print("~~~~~")
   # print(rw)
   # print("~~~~~")
   # if rw != 0:
  ##      nm = df['Site_Name'].iloc[0] + '\n'
  #  return nm

def add_site(code,name,grp):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = '''INSERT INTO special_sites (SiteCode, Name, Gropu) VALUES (?,?,?)'''
    in_qry_1 = (code,name,grp)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()
    return "site added in list"
    
def rmv_site(code):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = "DELETE FROM special_sites WHERE SiteCode='" + code + "'"
    curs.execute(in_qry)
    conx.commit()
    conx.close()
    return "site removed from list"

def list_site():
    lst = ''
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from special_sites"
    df = pd.read_sql(qry, conx)
    for ind in df.index:
        lst = lst + '\n' + df['SiteCode'][ind] + "," + df['Name'][ind]
    return lst

def M_handdler(text):
    rval = 'please provide correct format'
    if 'ADD' in text:
        txt = text.strip()
        stsplit = txt.split(' ')
        ln = len(stsplit)
        if ln == 4:
            rval = add_site(stsplit[1],stsplit[2],stsplit[3])
        elif ln == 3:
            rval = add_site(stsplit[1], stsplit[2], "NA")
        elif ln == 2:
            rval = add_site(stsplit[1], stname(stsplit[1]), "NA")
        else:
            rval = 'format like:: ADD,DHGUL19,UDAY TOWER,VIP'
    elif 'RMV' in text:
        txt = text.strip()
        stsplit = txt.split(' ')
        ln = len(stsplit)
        if ln == 2:
            rval = rmv_site(stsplit[1])
    elif 'LIST' in text:
        rval = list_site()
    else:
        print('please provide correct format')
    return rval

tx = "ADD,PBSDR01,PABNA SADAR,NA"
tx2 = 'LIST'
#if ('add,' in text) or ('rmv,' in text) or ('list,' in text):
print(M_handdler(tx2))


    

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_extend_1.py###
import pyodbc
import pandas as pd
import MySQLdb

def stname(code):
    nm = 'NP'
    conn= MySQLdb.connect("localhost","root","","ops_portal")
    df = pd.read_sql("select * from stbase3 Where Site_Code='" + code + "'", conn)
    rw = df.shape[0]
    print("~~~~~")
    print(rw)
    print("~~~~~")
    if rw != 0:
        nm = df['Site_Name'].iloc[0] + '\n'
    return nm


def add_site(code, name, Mask, Tgrp, OwnerNm):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = '''INSERT INTO custom_sites (SiteCode, Name, MaskID, TeleGroup, OwnerName) VALUES (?,?,?,?,?)'''
    in_qry_1 = (code, name, Mask, Tgrp, OwnerNm)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()
    return "site added in list"


def rmv_site(code, Mask, Tgrp):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = "DELETE FROM custom_sites WHERE SiteCode='" + code + "'AND MaskID='" + Mask + "'"
    curs.execute(in_qry)
    conx.commit()
    conx.close()
    rval = 'Sites Removed From:' + '\n' + Tgrp
    return rval

def list_site(Mask, Tgrp):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where MaskID='" + str(Mask) + "'"
    df = pd.read_sql(qry, conx)
    lst1 = '\n'
    for ind in df.index:
        lst1 = lst1 + '\n' + df['SiteCode'][ind] + "," + df['Name'][ind]
    rval = Tgrp + ' Sites:' + '\n' + lst1
    return rval

def list_site_all(OwNm):
    lst = ''
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where OwnerName='" + OwNm + "'"
    df = pd.read_sql(qry, conx)
    for ind in df.index:
        lst = lst + '\n' + df['SiteCode'][ind] + "," + ' Group: ' + df['TeleGroup'][ind]
    rval = OwNm + ' Custom Sites List:' + '\n' + lst
    return rval

#txupr, str(uid), str(cid), msg
def M_handdler(text,msg):
    cht = msg['chat']
    frm = msg['from']
    ctype = cht['type']
    if ctype == 'group':
        GroupName = cht['title']
        GroupMask = cht['id']
        OwName = frm['first_name']
        rval = 'please provide correct format'
        GMask = GroupMask
        GN = GroupName
        if 'ADDBIG' in text:
            cd = text.split(",")
            i = 0
            for val in cd:
                rval = add_site(val, stname(val), GMask, GN, OwName)
                i = i + 1
                else:
                    rval = str(i) + " Sites Added Successfully"
        elif 'ADD' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 4:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 3:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 2:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            else:
                rval = 'format like:: ADD DHGUL19'
        elif 'RMV' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 2:
                rval = rmv_site(stsplit[1], str(GMask), GN)
        elif 'LIST' in text:
            rval = list_site(GMask, GN)
        else:
            print('please provide correct format')
        return rval
    else:
        return 'this feature only available in a group'


#tx = "ADD,PBSDR01,PABNA SADAR,NA"
#tx2 = 'LIST'
# if ('add,' in text) or ('rmv,' in text) or ('list,' in text):
#print(M_handdler(tx2))





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_prod1.py###
import time
import telepot
from telepot.loop import MessageLoop
from pprint import pprint


TechSOCBOT = '1228075595:AAGYj2ck_yErfmVQFfW1xb7pzpSjTfVpadE'
bot = telepot.Bot(TechSOCBOT)

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if (content_type == 'text'):
        print('ok')

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_Production.py###
import time
import telepot
from telepot.loop import MessageLoop
from pprint import pprint
import tbot.tbot_prod1 as techsoc

akomibot = "1054945336:AAGv-B9ojejhA0ohDwRltTs5mYnOX8lK55M" #akomibot
bot = telepot.Bot(akomibot)

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if (content_type == 'text'):
        bot.sendMessage(chat_id, "hello")

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_single_site_status.py###
import pandas as pd
import cx_Oracle

def query(code):
    conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn)
    qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
    Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,
    ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
    where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
    and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
    and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%"""
    qry2 = qry1 + code + "%'"""
    try:
        df = pd.read_sql(qry2, con=conn)
        print('try success')
    except:
        connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        df = pd.read_sql(qry2, con=connx)
        print('Except trigger')
    print(df)
    rows = df.shape[0]
    heap = code + ":"
    if rows != 0:
        for i in range(0, len(df)):
            tech = df.iloc[i]['TECHNOLOGY']
            tm = df.iloc[i]['STARTTIME']
            if '2G' in tech:
                heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
            if '3G' in tech:
                heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
            if '4G' in tech:
                heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
            # print(heap)
    else:
        return heap + '\nAll Tech are up'
    return heap
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_site_stat_old.py###
import pandas as pd
import cx_Oracle
import sys
import time
import os
import telepot
from telepot.loop import MessageLoop
import sitehistory as st
import subprocess

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
bot = telepot.Bot(TOKEN)
auth_file = os.getcwd() + "\\" + 'users.txt'
conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn)
def query(code):
    qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
    Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
    where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
    and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
    and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%""" 
    qry2 = qry1 + code + "%'"
    try:
        df = pd.read_sql(qry2, con=conn)
        print('try success')
    except:
        connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        df = pd.read_sql(qry2, con=connx)
        print('Except trigger')
    print(df)
    rows = df.shape[0]
    heap = code + ":"
    if rows != 0:
        for i in range(0,len(df)):
            tech = df.iloc[i]['TECHNOLOGY']
            tm = df.iloc[i]['STARTTIME']
            if '2G' in tech:
                heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
            if '3G' in tech:
                heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
            if '4G' in tech:
                heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
            #print(heap)
    else:
        return heap + '\nAll Tech are up'
    return heap

def auth_check(usrname,firstname):
    fo = open(auth_file,"r+")
    txt = fo.read()
    fo.close()
    if (usrname in txt) or (firstname in txt):
        print("auth chk send ok")
        return "OK"
    else:
        print("auth chk send not ok")
        return "NOT"

def rdpcls():
    subprocess.call(["E:\OmProject\Project20\Tele_BOT\rdp_cls.bat"])
    return "done"

def query_hanndler(code):
    return code

def handle(msg):
    content_type, chat_type, chat_id = telepot.glance(msg)
    if content_type == 'text':
        txt = msg['text']
        cid = chat_id
        frm = msg['from']
        #uname = msg['from']['last_name']
        uname = ""
        fname = msg['from']['first_name']
        print(uname)
        print(cid)
        apprv = auth_check(uname,fname)
        if apprv == "OK":
            if len(txt) == 7:
                cd = txt.upper()
                bot.sendMessage(chat_id, 'processing request for '+ cd + ' ,please wait')
                getval = query(cd)
                gethis = st.fnx(cd)
                txtx = getval + '\n' + '\n' + 'Site Details:' + '\n' + gethis
                bot.sendMessage(chat_id, txtx)
                bot.sendMessage('671462535', txtx)
            elif 'help' in txt:
                bot.sendMessage(chat_id, 'just provide sitecode to know status')
            elif 'rdp' in txt:
                gtval = rdpcls()
                bot.sendMessage(chat_id, 'Killed')
            else:
                bot.sendMessage(chat_id, 'Please Provide sitecode without space')
        else:
            bot.sendMessage(chat_id, 'You are not autorized')
            
MessageLoop(bot, handle).run_as_thread()
print ('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TD1.py###
import pandas as pd
from datetime import *
import os

def sec_to_dur(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def dfdiff(df, LO, CLR = False):
    df = df.astype (str)
    if CLR == False:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df = df.assign (DUR=df.apply (lambda x: pd.Timedelta (datetime.now() - x[LO]).seconds / 60, axis=1))
        return df
    else:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df[CLR] = df.apply (lambda x: pd.to_datetime (x[CLR]), axis=1)
        df = df.assign(DUR=df.apply (lambda x: pd.Timedelta (x[LO] - x[CLR]).seconds / 60 if (
                x[CLR].year >= 2019) else "ACT", axis=1))
        return df

def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def datetime_convert_format(df, col, fmt="%Y/%m/%d %H:%M:%S"):
    try:
        df[col] = df[col].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime(fmt))
        return df
    except:
        df[col] = df[col].apply(lambda x: pd.to_datetime (x, errors='coerce', yearfirst=True, cache=True).strftime(fmt))
        return df

def vL(df_Main, df_Ref, col='Code', pick_from_ref = ['Zone']):
    ls = df_Main.columns.to_list ()
    df1 = df_Main.merge (df_Ref, how='right', on=col)
    for i in pick_from_ref:
        ls.append(str(i))
    else:
        dfx = df1[ls]
        return dfx



#vlook = vL(df, db, col='Code', pick_from_ref=['Zone','Cluster'])
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\telebot.py###
import sys
import time
import telepot
from telepot.loop import MessageLoop
import json

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
bot = telepot.Bot(TOKEN)

def query_hanndler(code):
    return code

def handle(msg):
    content_type, chat_type, chat_id = telepot.glance(msg)
    print(content_type, chat_type, chat_id)
    if content_type == 'text':
        ctype = content_type
        txt = msg['text']
        if txt == "Clean and clear":
            bot.sendMessage(chat_id, "price 150TK")
        elif len(txt) == 7:
            getval = query_hanndler(txt)
            bot.sendMessage(chat_id, getval)
        else:
            bot.sendMessage(chat_id, 'what is name of facewash?')
            
        
MessageLoop(bot, handle).run_as_thread()
print ('Listening ...')

while 1:
    time.sleep(10)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\telethon_om.py###
from telethon.sync import TelegramClient

def omi():
    api_id = 628127
    api_hash = 'db7fa09d585d6eedddd0df5973f3239b'
    phone = '+8801817184338'
    client = TelegramClient(phone, api_id, api_hash)
    client.connect()
    if not client.is_user_authorized():
        client.send_code_request(phone)
        client.sign_in(phone, input('Enter the code: '))
        print(client.get_me().stringify())
    
def smpool():
    api_id = 1621549
    api_hash = '6b06c3cf6e7004803b11c79f80e1b8bf'
    phone = '+8801817183680'
    client = TelegramClient(phone, api_id, api_hash)

omi()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\test.py###
import MySQLdb
import pandas as pd
import os

conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "sem_raw.csv"

def dic_df_parse(dic,zn,zn_colname,parsecol_1,parsecol_2,parsecol_3):
    hp = ""
    #count = 0
    nd = pd.DataFrame(dic)
    ndf = nd[nd[zn_colname].str.contains(zn, na=False)]
    for ind in ndf.index:
        code = str(ndf[parsecol_1][ind])
        lo = str(ndf[parsecol_2][ind])
        resource = str(ndf[parsecol_3][ind])
        hp = hp + " \n"  + code + " || " + lo + " || " + resource
    z = zn + ': \n' + hp
    return z

dfc = pd.read_csv(file)
dic = dfc.to_dict()
gval = dic_df_parse(dic,'DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
print(gval)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\test3.py###

import socket
import Queue
import threading
import time
import os
import sys
from random import *
from struct import *





def getSocksVersion(self, proxy):
        host = proxy.split(":")[0]
        try:
            port = int(proxy.split(":")[1])
            if port < 0 or port > 65536:
                print "Invalid: " + proxy
                return 0
        except:
            print "Invalid: " + proxy
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(self.timeout)
        try:
            s.connect((host, port))
            if(self.isSocks4(host, port, s)):
                s.close()
                return 5
            elif(self.isSocks5(host, port, s)):
                s.close()
                return 4
            else:
                ("Not a SOCKS: " + proxy)
                s.close()
                return 0
        except socket.timeout:
            print "Timeout: " + proxy
            s.close()
            return 0
        except socket.error:
            print "Connection refused: " + proxy
            s.close()
            return 0

getSocksVersion('45.72.6.167:8000')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\testapi.py###
import json
import requests
import os
from pprint import pprint

def api_ip2asn(ip):
    url = "https://api.iptoasn.com/v1/as/ip/" + ip
    x = requests.get(url)
    y = x.json()
    return y["as_description"]    
api_ip2asn("38.114.23.4")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\textfl.py###
import os

fpth = os.getcwd() + "//txtfile"
grp = os.getcwd() + "//rpa_group"
grponlymask = grp + "//grpmask.txt"
grpmask_and_head = grp + "//grmask_head.txt"

def srctxt_exact(content,srcstr):
    ls = []
    for ln in content:
        lnx = ln.strip()
        if srcstr == lnx:
            ls.append(lnx)
    return ls
            
def srctxt_partial(content,srcstr):
    ls = []
    for ln in content:
        lnx = ln.strip()
        if srcstr in lnx:
            ls.append(lnx)
    return ls

def rdline(flname):
    fl  = open(flname, "r") 
    contents =fl.readlines()
    fl.close()
    return contents
        
def rdall(flname):
    fl  = open(flname, "r") 
    contents =fl.read()
    fl.close()
    return contents
    
def wrt(flname,content):
    fl  = open(flname, "w+", encoding="utf-8")
    fl.write(content)
    fl.close()
    
def apnd(flname,content):
    fl  = open(flname, "a+")
    fl.write(content)
    fl.close()
    
def get_list_txt_file(dirr):
    fl = os.listdir(dirr)
    ls = []
    for f in fl:
        if f.endswith('.txt'):
            ls.append(f)
    return ls

def pick_rpa_group():
    lst = get_list_txt_file(fpth)
    st = ""
    sthd = ""
    for i in range(len(lst)):
        pth = fpth + "//" + lst[i]
        contents = rdline(pth)
        n = 0
        for f in contents:
            fr = f.find('-R')
            fd = f.find('$')
            grpname = f[0:fr-1]
            grpmask = f[fd+1:len(f)-1]
            grpcon = grpmask + "," + grpname
            if grpmask not in st:
                st = st + "\n" + grpmask
            if grpmask not in sthd:
                n = n + 1
                sthd = sthd + "\n" + grpcon
        print(st)
        print(sthd)
        wrt(grponlymask,st)
        wrt(grpmask_and_head,sthd)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\top5.py###
import pandas as pd
import numpy as np
import os
import requests
import func.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import func.omdtfn as odt
import func.fnfn as fn
import db.db as sq
import prep as pr
from datetime import *


def custom_msg_sender_top5(chatid,msg):
    TOKEN = "961035316:AAGWIlt5GjIkBz1QI1s6WKbwVnfubmn0m6E"
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


TSS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else "other"
                ))

def map_customer(df):
    df4 = df
    df4 = df4.rename(columns={'CUSTOMATTR15':'CODE'})
    pt = os.getcwd() + "\\db\\T70.csv"
    df5 = pd.read_csv(pt)
    df6 = flk.vlookup(df4,df5,'CODE','NA')
    return df6

def mod_techwise(df14):
    try:
        df15 = df14.groupby(df14['CODE']).MTTR.sum().to_frame(name = 'SMX').reset_index()
        df17 = df14.merge(df15, on='CODE')
        df17 = df17.drop_duplicates(subset='CODE',keep='last', inplace = False)
        df17['SMX'] = df17['SMX'].round(decimals=2)
        df18 = df17.sort_values('CODE')
        df19 = df18[['CODE','CName','CNT','SMX']]
        arr = df19.to_numpy()
        rw, col = arr.shape
        stx = ""
        for i in range(rw):
            if arr[i][3] > 2:
                if stx == "":
                    stx = arr[i][1] + chr(10) + arr[i][0] + ': ' + str(arr[i][2]) + '/' + str(arr[i][3]) + ' min'
                else:
                    stx = stx + chr(10) + chr(10) + arr[i][1] + chr(10) + arr[i][0] + ': ' + str(arr[i][2]) + '/' + str(arr[i][3]) + 'min'
        return stx
    except:
        return "NA"

def top5_outage_report(df0):
    df1 = df0
    df = fst.add_col_df(df1,'cat')
    df['cat'] = df.apply(lambda row: TSS(row.SUMMARY) , axis = 1)
    df2 = df[~df['cat'].isin(['other'])]
    df4 = fst.add_col_df(df2,'DT')
    df4['DT'] = df4.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%b-%Y"), axis = 1)
    df6 = fst.add_col_df(df4,'CLRYR')
    df6['CLRYR'] = df6.apply(lambda x : pd.to_datetime(x.CLEARTIMESTAMP).strftime("%Y"), axis = 1)
    dd = odt.day_minus_dy(1)
    df7 = df6[df6.DT.str.contains(dd) & df6.CLRYR.str.contains('2020')]
    df11 = map_customer(df7)
    df12 = flk.countif(df11,'CName','CName','CNT')
    df13 = df12[['CODE','LASTOCCURRENCE','CLEARTIMESTAMP','cat','CName','GName', 'CNT']]
    df14 = fdt.datedif(df13,'MTTR','LASTOCCURRENCE','CLEARTIMESTAMP')
    df2G = df14[df14.cat.str.contains('2G')]
    df3G = df14[df14.cat.str.contains('3G')]
    df4G = df14[df14.cat.str.contains('4G')]
    G2 = "2G: " + chr(10) + mod_techwise(df2G)
    G3 = "3G: " + chr(10) + mod_techwise(df3G)
    G4 = "4G: " + chr(10) + mod_techwise(df4G)
    GG = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4
    fstx = "VIP TOP 5 Sites" + chr(10) +"Outage Count and Durtaion " + chr(10) + "on " + odt.day_minus(1) + chr(10) + chr(10) + "code: count/sum of duration" + chr(10) + chr(10) + GG
    fmsg1 = fstx.replace("&","and")
    fmsg = fmsg1.replace(chr(10),"%0a")
    custom_msg_sender_top5("-352454352",fmsg)
    print('top5 done')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TS.py###
import pandas as pd
import numpy as np
import os
import datetime
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\'")
        s2 = s1.replace(":","\:")
        return s2

def col_space_rmv(ndf, space = '_'):
    df = ndf.replace (np.nan, '')
    dfcol = df.columns.to_list()
    for i in range(len(dfcol)):
        try:
            df = df.rename(columns={dfcol[i]:dfcol[i].replace(' ', space)})
        except:
            pass
    return df
        
        
def dtype_match_mysql(db, table, conn, ndf):
    df = ndf.replace (np.nan, '')
    dfcol = df.columns.to_list()
    for i in range(len(dfcol)):
        df = df.rename(columns={dfcol[i]:dfcol[i].replace(' ', '_')})
    dic = mysql_table_colinfo(db, table)
    try:
        colunmatch = []
        q = 0
        Y = 1
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            q = q + 1
            try:
                xdf = df[st]
            except:
                Y = 0
                notmat = 'column not matched: - ' + st
                print(notmat)
            if Y == 1:
                print('dtype_match: ', dbty)
                try:
                    if dbty == 'int':
                        df[st] = df[st].astype(int)
                    elif dbty == 'float':
                        df[st] = df[st].astype(float)
                    elif dbty == 'datetime':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                    elif dbty == 'date':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                    else:
                        df = df.apply(lambda x: x.replace("'","\'"))
                except:
                    pass
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)
         
def insert_into_mysql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            if lsval[i] != '' and lsval[i] is not None:
                dtype = get_key(dic,lscol[i])
                if dtype == 'text' or dtype == 'varchar':
                    valmod = modstr(lsval[i])
                else:
                    valmod = str(lsval[i])
                if val == '':
                    col = lscol[i]
                    val = "'" + valmod + "'"
                else:
                    col = col + ',' + lscol[i]
                    val = val + ',' + "'" + valmod + "'"
            else:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""
                
def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn    



def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                df[cname] = df[cname].fillna('NA')
                df[cname] = df.apply(lambda x: x[cname].replace("'","\'"))
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
                df[cname] = df[cname].replace(np.nan, 0)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
                df[cname] = df[cname].replace(np.nan, 0)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df[cname].replace(np.nan, '')
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df[cname].replace(np.nan, '')
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df[cname].replace(np.nan, '')
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def main():
    pt = os.getcwd() + "\\sclick.csv"
    ndf = pd.read_csv(pt)
    xdf = ndf.convert_dtypes()
    conn = MySql('root','admin','127.0.0.1:3306','om1')
    dc = mysql_table_colinfo('om1', 'TAXW3', conn)
    dfn = dtype_match_dbdf(xdf, dc)
    df = col_space_rmv(dfn, "_")
    q = 0
    rwval = []
    colval = df.columns.to_list()
    for (indx, rwseries) in df.iterrows():
        q = q + 1
        if q == 5:
            break
        rwval = rwseries.values.tolist()
        x = insert_into_mysql('TAXW3', dc, colval, rwval)
        print(x)
#main()      
pt = os.getcwd() + "\\sclick.csv"
ndf = pd.read_csv(pt)
xdf = ndf.convert_dtypes()


#conn = MySql('root','admin','127.0.0.1:3306','om1')
#dc = mysql_table_colinfo('om1', 'TAXW3', conn)
#df = dtype_match_dbdf(xdf, dc)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TS2.py###
import pandas as pd
import numpy as np
import os
import datetime
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import upin as upd

def get_server_name(db, table, conn):
    try:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con = conn)
        return "MYSQL"
    except:
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= conn)
            return "MSSQL"
        except:
            return "only MYSQL and MSSQL is Supported"

def mssql_table_colname(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    return dbcols

def mssql_table_colinfo(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    dbcolType = dfx['DATA_TYPE'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key
            
def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                pass
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def fuzzymatch(str1,str2, uplow = True):
    if uplow == True:
        s1 = str1.lower()
        s2 = str2.lower()
        ls1 = []
        ls2 = []
        for i in s1:
            ls1.append(i)
        for n in s2:
            ls2.append(n)
        q = 0
        succ = 0
        fail = 0
        if len(ls1) <= len(ls2):
            for j in range(len(ls1)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        else:
             for j in range(len(ls2)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        try:
            spercent = round((succ/q)*100,2)
        except:
            spercent = 0
        return spercent

def colchk_dbdf(coldb = [], coldf = []):
    if isinstance(coldb, list) and isinstance(coldf, list):
        cdb = coldb
        cdf = coldf
        cdb.sort
        coldf.sort
        nonmat = []
        for i in range(len(cdb)):
            d1 = cdb[i]
            mat = 0
            for j in range(len(cdf)):
                if d1 == cdf[j]:
                    mat = 1
                    break
            if mat == 0:
                nonmat.append(d1)
        return nonmat

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""



def df_to_sql(dataframe, dbname, tablename, conn, oncolumn = "ALL", bycolumn = None, how = 'append'):
    srv = get_server_name(dbname, tablename, conn)
    print(srv)
    if srv == 'other':
        exit()
    cr = conn.cursor()
    try:
        cr.execute('select 1 from '+ tablename)
    except:
        print('table does not exits')
        exit()
    if oncolumn != 'ALL' and bycolumn == None:
        dataframe = dataframe[oncolumn]
    ndf = dataframe.replace(r'^\s*$', np.nan, regex=True)
    xdf = ndf.convert_dtypes()
    dfcol = xdf.columns.to_list()
    if srv == "MYSQL":
        dbcol = mysql_table_colname(dbname, tablename, conn) #function call
    elif srv == "MSSQL":
        dbcol = mssql_table_colname(dbname, tablename, conn) #function call
    nonmat = colchk_dbdf(dbcol,dfcol)
    dfc = []
    rnmcol = {}
    if len(nonmat) != 0:
        for n in range(len(nonmat)):
            dbc = nonmat[n]
            y = 0
            for i in range(len(dfcol)):
                x = fuzzymatch(dbc, dfcol[i])
                #print(dbc,' - ',  dfcol[i], ' p- ', x, ' max ', y)
                if x >= y:
                    y = x
                    dfcl = dfcol[i]
            else:
                dfc.append(dfcl)
                rnmcol[dfcl] = dbc
    xdf = xdf.rename(columns = rnmcol)
    if srv == "MYSQL":
        dc = mysql_table_colinfo(dbname, tablename, conn)  #mysql function call
    elif srv == "MSSQL":
        dc = mssql_table_colinfo(dbname, tablename, conn)  #mysql function call
    df = dtype_match_dbdf(xdf, dc) #function call
    if bycolumn == None:
        q = 0
        rwval = []
        colval = df.columns.to_list()
        er = []
        for (indx, rwseries) in df.iterrows():
            q = q + 1
            rwval = rwseries.values.tolist()
            x = insert_into_sql(tablename, dc, colval, rwval)
            try:
                cr.execute(x)
            except:
                er.append(x)
                qq = "dfrow: " + str(q)
                er.insert(0, qq)
        print('row inserted: ', q - len(er), ' error found for rows: ', len(er), ", get error in return")
        return er
    else:
        tableprop = dc
        upd.UPIN(df, tablename, tableprop, conn, bycols = bycolumn)

    

pt = os.getcwd() + "\\sclick.csv"
ndf = pd.read_csv(pt)
conn = MySql('root','admin','127.0.0.1:3306','om1')
lser = df_to_sql(ndf, 'om1', 'TAXW3', conn, oncolumn = 'ALL', bycolumn = ['CustomAttr15'], how = 'replace')



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TST.py###
import os
import time


print("i am omi")
time.sleep(5)
print("exit")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tstststs.py###
import pandas as pd

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

# way of calling - print(countif(df['Colname'],"value_to_check"))
# we call above countif function using loop on dataframe and can store the result into a new column as following.
def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"


df = pd.DataFrame({
    'column_1': ['g', 't', 'n', 'w', 'n', 'g']
})

print(match('n',df['column_1'],"Last"))

df = df.assign(new_column = "NA")
list_as_range = df['column_1'].values.tolist()   #column_1 is the column name (can be any column)
for i in range(len(df)):
    cell_value = df.loc[i,'column_1']   #column_1 is the column name (can be any column)
    df.loc[i,'new_column'] = countif(list_as_range, cell_value)   #calling above functions
#print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TT.py###
import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\DevMeterials\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (minutes=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d


def parse_date_fuzzy(string, first='day'):
    try:
        if first == 'day':
            x = parse(string, fuzzy=True, dayfirst=True)
        elif first == 'year':
            x = parse(string, fuzzy=True, yearfirst=True)
        else:
            x = parse(string, fuzzy=True)
        return x.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return ""

    
def timebetween(t1,t2):
    d1 = parse_date_fuzzy(t1)
    d2 = parse_date_fuzzy(t2)
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1 + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + d2 + "','DD-MM-YYYY HH24:MI:SS')"
    print(dd)

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
flname = os.getcwd() + "\\" + dtst + "csv"

def qry(qq, savefile=dtst):
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    qry = q1 + qq
    print(qry)
    #df = pd.read_sql(qry, con = conn)
    #print(df)
    #df.to_csv(os.getcwd() + "\\dw.csv", index = False)
    #print("success")
    
qry("SEVERITY>0")
    
    
def customize():
    print (conn.version)
    allactive = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    print(allactive)
    df = pd.read_sql(allactive, con = conn)
    print(df)
    df.to_csv(os.getcwd() + "\\dw.csv", index = False)
    
#timebetween("22-12-2020 01:00","22-12-2020 02:00")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TXX.py###


import pandas as pd
import numpy as np
from datetime import *
import os


dfdb = pd.read_csv(db)
df = pd.read_sql('select * from big5', con = conn)
df0 = df.rename(columns=str.upper)
    ls = text2list(semcol)
    df1 = df0[ls]
    dc = text2dic(cat)
    df1['cat'] = df1.apply(lambda x: getkey(dc, x.SUMMARY) , axis = 1)
    df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
    df2 = df1.merge(dfdb, on='Code')
x = datetime.now()
y = datetime.strftime(x, "%m-%d-%Y %H:%M:%S")
svpt = os.getcwd() + "\\OMDW.csv"
df = pd.read_csv(svpt)
df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'])
df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
df = df.assign(NW = y)
df['DUR'] = df.apply(lambda x : pd.to_datetime(x.NW) - pd.to_datetime(x.LASTOCCURRENCE) ,axis=1)
df['DUR'] = df['DUR'].astype('timedelta64[m]')
print(df)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\upin.py###
import pandas as pd
import numpy as np
import os
from df_to_sql.write2text import *


def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operations = "and"):
    cr = conn.cursor()
    er = 0
    lser = []
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                lser.append(qry)
                er = er + 1
                print('error sql: ', qry)
                if er > 500:
                    wrt2txt(excmd, 'exe_error')
                    print('exiting as error greater than 500 rows')
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbafn.py###
#import MySQLdb
import pandas as pd
import os
import numpy

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "RobiLive.csv"

class pyvb:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
    def PrintDf(self):
        print(self.df)
    def print_all_row_comm_seperated(self):
        lrw = (self.arr).shape[0]
        lcol = (self.arr).shape[1]
        i = 0
        hp = ''
        heap = ''
        while i < lrw:
            hp = ''
            j = 0
            while j < lcol:
                if hp == '':
                    hp = str(self.arr[i][j])
                else:
                    hp = hp + ', ' + str(self.arr[i][j])
                j = j + 1
            heap = heap + '\n' + str(hp)
            i = i + 1
        return heap
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
    def make_qry_str_sitecode(self,colname):
        lst = self.df[colname].to_list()
        hp = 0
        n = 0
        for i in lst:
            n = n + 1
            if n == 1:
                hp = "'" + i + "'"
            else:
                hp = hp + ',' + "'" + i + "'"
        return hp
    def vbprint_row_after_row(self, colinlist):
        hd = ''
        for x in colinlist:
            if hd == '':
                hd = x
            else:
                hd = hd + ', ' + x
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                count = count + 1
            if cnt == 0:
                heap = hd + '\n' + hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
        return heap
    def vbprint_col_comma(self, colinlist):
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                    count = count + 1
            if cnt == 0:
                heap = hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
            hp = ''
        print(heap)
        #dfc = pd.read_csv(file)
#dic = dfc.to_dict()

#mli = ['LastOccurrence', 'Tally','CustomAttr11']
#pv.Row_Item_From_List(9,mli)

#pv2 = pyvb(dic,mli)
#pv.PrintDf()
#pv2.PrintDf_ByList()
#gval = pv.MatchParse('DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
#print(gval)
#print(pv.VbMatch_Col('DHKTL04',3))
#print(pv.VbMatch_Row('CustomAttr15',0))
#pv.PrintLst()
#df = pd.read_csv(file)
#print(df)
#dic = df.to_dict()
#lst = ['Site Code','LTE Status','Priority']
#pv2 = pyvb(dic)
#print(pv2.print_all_row_comm_seperated())
#print(pv2.vbprint_row_after_row(lst))
#print(pv.make_qry_str('INTERNALLAST'))
#pv.make_qry_str(lst)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbcls1.py###
import pandas as pd
import numpy as np


class omdf:
    def __init__(self,dff):
        self.df = dff
        self.arr = self.df.to_numpy()
    def df_add_col_instr(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_add_col_dic(self,colname,newcol,dic):
        self.df[newcol] = self.df['scode'].map(dic)
        return self.df.to_dict()
    def df_add_col_slice_str(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_rmv_column(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()
    def df_countif(self,column_name,newcolumn_name):
        code = pd.Series(self.df[column_name])
        lst = code.values.tolist()
        dic = {}
        for i in lst:
            dic[i] = lst.count(i)
        df_occ = pd.DataFrame(dic.items(),columns=[column_name, newcolumn_name])
        mdf = self.df.merge(df_occ, on=column_name)
        return mdf
    def df_instr(self,colname,srcstr):
        self.df[srcstr] = list(map(lambda x: x.count(srcstr), self.df[colname]))
        return self.df
    def df_vlookup(self,df2,common_colname):
        mdf = self.df.merge(df2, on=common_colname)
        return mdf




class pyvb:
    def __init__(self, dic, li=[]):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = self.df[li]
    def PrintDf(self):
        print(self.df)
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbcntifs.py###
import pandas as pd
df = pd.DataFrame({
    'name_code': ['c001','c002','c022', 'c2002', 'c2222'],
    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],
    'age': [18.5, 21.2, 22.5, 22, 23]
})
print("Original DataFrame:")
print(df)
print("\nCount occurrence of 2 in date_of_birth column:")
df['count'] = list(map(lambda x: x.count("2"), df['name_code']))
print(df)


products = {'Product': ['Tablet','iPhone','Laptop','Monitor'],
            'Price': [250,800,1200,300]
            }

df = pd.DataFrame(products, columns= ['Product', 'Price'])

products_list = df.values.tolist()
print (products_list)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbdf.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def duration(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = duration(abs(d1 - d2).total_seconds())
            return x
    except:
        return ""
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbfn.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = "E:\\GIT\\OmProject\\OmPY\\omfn4\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]



def df_add_list_col(dfx,nc,nwlst):
    dfx[nc] = np.nan
    dfx[nwcol] = np.array(nwlst)
    return dfx

def vlookup(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        lst = df[dt_col1]
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        lst = df[dt_col1]
        clr = df[dt_col2]
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    df[nwcol] = np.nan
    df[nwcol] = np.array(ls)
    print('In Minutes')
    return df

def process_sem_raw(df):
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CUSTOMATTR15']
    LL2 = df1['LASTOCCURRENCE']
    LL3 = df1['CLEARTIMESTAMP']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    print(ndf3)

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , Ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(df, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(df,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs(df,refcol,numeric_col):
    df['agsum'] = df.groupby(refcol)[numeric_col].sum()
    return df
    #df['agsum'] = df.groupby('pet').treats.transform('sum')

def match(df,indx,typ):
    pass

df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
#print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
#print(asq)

sm = sumifs(asq,'CUSTOMATTR15','AG')
print(sm)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbfn1.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = "E:\\GIT\\OmProject\\OmPY\\omfn4\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]



def df_add_list_col(dfx,nc,nwlst):
    dfx[nc] = np.nan
    dfx[nwcol] = np.array(nwlst)
    return dfx

def vlookup(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        lst = df[dt_col1]
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        lst = df[dt_col1]
        clr = df[dt_col2]
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    df[nwcol] = np.nan
    df[nwcol] = np.array(ls)
    print('In Minutes')
    return df

def process_sem_raw(df):
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CUSTOMATTR15']
    LL2 = df1['LASTOCCURRENCE']
    LL3 = df1['CLEARTIMESTAMP']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    print(ndf3)

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , Ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(df, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(df,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs(df,refcol,numeric_col):
    df['agsum'] = df.groupby(refcol)[numeric_col].sum()
    return df
    #df['agsum'] = df.groupby('pet').treats.transform('sum')

def match(df,indx,typ):
    pass

df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
#print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
#print(asq)

sm = sumifs(asq,'CUSTOMATTR15','AG')
print(sm)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbfn2.py###
import pandas as pd
import numpy as np

def join_list(ls1, ls2, ls3):
    ToDf = pd.DataFrame(zip(ls1, ls2, ls3))
    return ToDf

def add_col_df(df, colname, indx=False):
    if indx == False:
        ndf = df.assign(coln = 'NWC')
        ndf.rename(columns = {'coln': colname}, inplace = True)
        return ndf
    else:
        df.insert(indx, colname, 'NWC', allow_duplicates=False)
        return df

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
    except:
        print('err')
    return dc

def add_list_as_column(df,nlst):
    #ls = df.values.tolist()
    df = df.append(pd.DataFrame(nlst,columns=['col1','col2']),ignore_index=True)
    print(df)

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def vlookup(df0,refdic,refcol,nwcol):
    try:
        df = add_col_df(df0, nwcol)
        df[nwcol] = df.reset_index()[refcol].map(refdic).values
        return df
    except:
        df = map_df_dic(df0,refdic,refcol,nwcol)
        return df

def countif(df0,refcolumn,datacol,newcolname = False):
    if isinstance(refcolumn,str):
        df = add_col_df(df0, newcolname)
        rdf = df[refcolumn]
        reflst = rdf.values.tolist()
        vdf = df[datacol]
        nwlst = []
        for i in vdf:
            try:
                count = reflst.count(i)
                nwlst.append(count)
            except:
                nwlst.append('0')
    df[newcolname] = nwlst
    return df


l0 = ["0", "1", "2", "3", "4"]
l1 = ["Amar", "Barsha", "Barsha", "Tanmay", "Misbah"]
l2 = ["Alpha", "Bravo", "Charlie", "Tango", "Mike"]
l4 = [["Amar", "Barsha", "Carlos", "Tanmay", "Misbah"],["Alpha", "Bravo", "Charlie", "Tango", "Mike"]]
l5 = ['A','B','C','D','E']
l6 = ['DHK', 'RAJ', 'CTG', 'SYL', 'MYN']
l7 = [['DHK, P1'], ['DHK, P2'] , ['DHK, P3'] , ['DHK, P4'] , ['DHK, P5']]

df1 = join_list(l0, l1, l2)
df1.columns = ['1','2','3']
dc1 = conv_lst_dic(l0,l6)
#print(dc1)
dc2 = conv_lst_dic(l0,l7)
#print(dc2)
l8 = df1['1']
l9 = df1 [['2','3']]
l10 = l9.values.tolist()
dc3 = conv_lst_dic(l0,l7)
#print(dc3)
#print(df1)
df2 = pd.DataFrame(dc3)
#print(df2)

x = vlookup(df1,dc3,'1','TOTO')

#print(x)
ts = x['2']
lx = ts.values.tolist()
cnt = lx.count('Barsha')
#print(cnt)
x = countif(x,'2','2',"ONCOL2")
#p = add_col_df(df,'Test',1)
#add_list_as_column(df,l4)
#datatype_conversion = df['Customer Number'].astype('int')


def conct(a1,a2):
    ls = []
    strn = ""
    for i in range(len(a1)):
        strn = strn + str(a1[i]) + str(a2[i])
    return strn

def conct1(arg1,arg2):
    if isinstance(arg1, list) and isinstance(arg2, list):
        ls = []
        for i in range(arg1):
            ls.append(str([i]) + str(arg2[i]))
        return ls
    else:
        ag1 = arg1.values.tolist()
        ag2 = arg2.values.tolist()
        ls = []
        for i in range(ag1):
            ls.append(str([i]) + str(ag2[i]))
        return ls

def countifz(df,*argv):
    if isinstance(df,pd.DataFrame):
        if len(argv) % 2 != 0:
            print('need conditions for every ref range have')
        else:
            rng = len(argv) / 2
            i = 0
            j = 2
            A1 = ""
            B1 = ""
            X1 = []
            X2 = []
            while i < rng:
                if j > rng:
                    A1 = A1 + (df[argv[i]])
                    B1 = B1 + (df[argv[i+1]])
                    i = i + 2
                else:
                    A1 = A1 + (conct(df[argv[i]],df[argv[j]]))
                    B1 = B1 + (conct(df[argv[i+1]],df[argv[j+1]]))
                    i = i + 2
                    j = j + 2
                X1.append(A1)
                X2.append(B1)
            print(X1,X2)
    else:
        print('first parameter must be dataframe (full data range)')


countifz(x, '1', '1', '3', '3')




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbt.py###
import pandas as pd
import numpy as np
import os
import func.fnfn as fn

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

df = pd.read_csv(pt2)
#print(df.columns)
#df = df.assign(new_column = "NA") # column inserted at last, here new_column = column name and "NA" = rows value of new column

def concat(df, column_1, column_2, new_column_name):
    df = df.assign(new_column = "NA")
    df.rename(columns = {'new_column': new_column_name}, inplace = True)
    for i in range(len(df)):
        data_1 = df.loc[i,column_1]
        data_2 = df.loc[i,column_2]
        df.loc[i,new_column_name] = str(data_1) + str(data_2)
    return df

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"


print(countif(df['CUSTOMATTR15'],"FNCGL06"))



def countif_apply_on_col(df0,ref_col_as_range,ref_col_for_Cells):
    if isinstance(ref_col_as_range,str):
        df = df0.assign(coln = 'NA')
        rdf = df[ref_col_as_range]
        reflst = rdf.values.tolist()
        vdf = df[ref_col_for_Cells]
        nwlst = []
        for i in vdf:
            try:
                count = reflst.count(i)
                nwlst.append(count)
            except:
                nwlst.append('0')
    df['coln'] = nwlst
    return df

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            return abs(d1 - d2)
        elif len(unit)>3:
            x = abs(d1 - d2)
            print(x)
            try:
                return datetime.strftime(x,"%Y%M%d")
            except:
                return "format not appropriate"
    except:
        return "NA"


xx = countif_apply_on_col(df,'CUSTOMATTR15','CUSTOMATTR15')
print(xx)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\wait_handdle.py###
import time as tm
from datetime import *

ts= tm.time()
n = datetime.now()
td = date.today()

def wait_handdle(ex_time):
    Mn = int(n.strftime("%M"))
    if ex_time==55:
        if Mn>=55:
            wt = (60-Mn)*60
            print('Waiting for second: ', str(wt))
            tm.sleep(wt)
            return "EX"
        elif Mn >= 0 and Mn <= 15:
            return "EX"
        elif Mn >= 16 and Mn < 25:
            return "STOP"
        else:
            return "STOP"
    elif ex_time==25:
        if Mn>=25 and Mn<30:
            tm.sleep((30-Mn)*60)
            return "EX"
        elif Mn >= 30 and Mn <= 45:
            return "EX"
        elif Mn >= 45 and Mn < 55:
            return "STOP"
        else:
            return "STOP"
    else:
        return "EX"






$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinMain.py###
import sys
import os
import wmi
import subprocess

def ex(cmd):
    command = os.popen(cmd).read()
    return command
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinNetsh.py###
import subprocess

def ex(cmd):
    command = subprocess.popen(cmd).read()
    return command


def set_proxy(proxy_ip):
   print('x')







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinReg.py###
import subprocess
import os
import wmi



def addkey():


def editkey():
    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinWmi.py###
import os
import wmi
import winreg

ip = '173.0.54.190'
username = 'OMI'
password = '1q2w3eaz$'
from socket import *
#connection = wmi.WMI(ip, user=username, password=password)

r = wmi.WMI(ip, user=username, password=password).Registry()
result, names = r.EnumKey (hDefKey=0x80000001,sSubKeyName=r"Software")
for ky in names:
    print(ky)


def netsh_proxy(ip,port):
    x = "netsh winhttp set proxy " + ip + ':' + port
    os.system(x)

def addkey(ip,prt):
    x1 = "reg add 'HKCU\Software\Microsoft\Windows\CurrentVersion\Internet Settings / v ProxyEnable / t REG_DWORD / d 1'"
    x2 = "reg add 'HKCU\Software\Microsoft\Windows\CurrentVersion\Internet Settings /v ProxyServer /t REG_SZ /d '" + ip + ':' + prt

addkey('23.160.192.180','2016')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WMI_T.py###

#http://timgolden.me.uk/python/wmi/tutorial.html

import wmi
import os
import subprocess

def ex(cmd):
    command = os.popen(cmd).read()
    return command

def os_version():
    c = wmi.WMI()
    for os in c.Win32_OperatingSystem():
        print(os.Caption)
  
#x = os.system('ipconfig')
#os.system("netsh interface show interface")
#x = subprocess.call('netsh interface ipv4 show interface')
#y = ex('powershell "get-wmiobject win32_networkadapter | select netconnectionid, name, InterfaceIndex, netconnectionstatus"')
y = ex('powershell "Get-NetConnectionProfile"')


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\write2text.py###


import time, os
import datetime
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xdbfn_sem.py###
import pandas as pd
import cx_Oracle
import time as tmm
import os
from datetime import date
import win32com.client
import xdttm as odt

class omdb:
    def __init__(self):
        self.orc_con_str = "'SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'"
        self.mssq_con_str = "'Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&'"
        self.cdir = os.getcwd() + '\\'
        self.today = date.today()
    def orc_all_active(self,tbl,selcol):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        tim1 = tmm.localtime()
        dy_p = odt.day_minus(7)
        dy_f = odt.day_plus(1)
        Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
        Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
        QF = "SELECT" + selcol + Q1 + Q2
        print(tmm.strftime("%H%M", tim1))
        print('----------------')
        print(QF)
        df = pd.read_sql(QF, con=conn)
        print('----------------')
        tim2 = tmm.localtime()
        print(df.shape[0])
        print(tmm.strftime("%H%M", tim2))
        df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
        df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
        df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
        dfmf = df[df['SUMMARY'].str.contains('MAIN')]
        dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
        dftmp = df[df['SUMMARY'].str.contains('TEMP')]
        dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
        dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
        df_cnct = [df2g, df3g, df4g, dfmf, dfdl, dftmp, dfcell, dfth]
        df_all = pd.concat(df_cnct)
        df_final = df_all.rename(columns={'EQUIPMENTKEY': 'Resource', 'CUSTOMATTR26': 'AssociatedCR',
                                          'CUSTOMATTR24': 'BCCH',
                                          'OWNERGID': 'Incident Owner',
                                          'EVENTID': 'Frequency',
                                          'TTREQUESTTIME': 'TT Creation Time'})
        dic = df_final.to_dict()
        conn.close()
        return dic
    def orc_qry_on_cond(self, tbl, cond, fdt, tdt):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        Q2 = "(LASTOCCURRENCE BETWEEN TO_DATE('" + fdt + "','DD-MM-RRRR') AND TO_DATE('" + tdt + "','DD-MM-RRRR'))"
        QF = "SELECT * from " + tbl + " WHERE " + cond + ' AND ' + Q2
        print(QF)
        tim1 = tmm.localtime()
        print(tmm.strftime("%H%M", tim1))
        print('----------------')
        df = pd.read_sql(QF, con=conn)
        tim2 = tmm.localtime()
        print(tmm.strftime("%H%M", tim2))
        print('----------------')
        dic = df.to_dict()
        conn.close()
        return dic
    def orc_qry_all_active(self, tbl, cond):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        qry1 = "Select * from " + tbl + " WHERE " + cond
        print(qry1)
        tim1 = tmm.localtime()
        print(tmm.strftime("%H%M", tim1))
        df = pd.read_sql(qry1, con=conn)
        tim2 = tmm.localtime()
        print(tmm.strftime("%H%M", tim2))
        print('----------------')
        dic = df.to_dict()
        conn.close()
        return dic

    def orc_qry_by_code(self,code):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
        Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
        where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
        and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
        and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%"""
        qry2 = qry1 + code + "%'"
        try:
            df = pd.read_sql(qry2, con=conn)
            print('try success')
        except:
            connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
            df = pd.read_sql(qry2, con=connx)
            print('Except trigger')
        print(df)
        rows = df.shape[0]
        heap = code + ":"
        if rows != 0:
            for i in range(0, len(df)):
                tech = df.iloc[i]['TECHNOLOGY']
                tm = df.iloc[i]['STARTTIME']
                if '2G' in tech:
                    heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
                if '3G' in tech:
                    heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
                if '4G' in tech:
                    heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
                # print(heap)
        else:
            return heap + '\nAll Tech are up'
        return heap


dy_from = odt.day_minus(3)
dy_to = odt.day_plus(1)
pth = os.getcwd() + '\\' + 'stcode.csv'
x = omdb()
#dc = x.orc_all_active('SEMHEDB.ALERTS_STATUS_V_FULL',' * ')
#dc = x.orc_all_active('SEMHEDB.ALERTS_STATUS',' * ')
cond1 = 'SEVERITY BETWEEN 1 AND 5 AND ALERTGROUP IN'
alrt_grp = """'SyntheticSiteDownAlarm','Processing Error Alarm:Cell Unavailable','Processing Error Alarm:NodeB Unavailable',
'Quality of Service Alarm:UMTS Cell Unavailable','Quality of Service Alarm:Local Cell Unusable','Processing Error Alarm:CSL Fault',
'Communication Alarm:OML Fault','Processing Error Alarm:GSM Cell out of Service','ET_PROCESSING_ERROR_ALARM','ET_QUALITY_OF_SERVICE_ALARM',
'ET_COMMUNICATIONS_ALARM','ET_EQUIPMENT_ALARM','Processing Error Alarm'"""
condition = cond1 + ' (' + alrt_grp + ')'
#dc = x.orc_qry_on_cond('SEMHEDB.ALERTS_STATUS',condition,dy_from,dy_to)
#df = pd.DataFrame(dc)
#df.to_csv(pth)

cond2 = "Summary IN ('2G SITE DOWN','3G SITE DOWN','4G SITE DOWN','MAINS FAIL','VOLTAGE','CELL DOWN') and Summary not like 'Synthetic_Fluc' and (Severity between 1 and 5) and Type=1"
cond3 = "Severity between 1 and 5 AND Summary IN ('2G SITE DOWN','3G SITE DOWN','4G SITE DOWN','HUW-MAINS FAILURE','HUW-DC VOLTAGE LOW','ERI-DC LOW VOLTAGE','ERI-AC MAINS FAILURE','ERI-AC MIANS FILT') and Summary not like 'Synthetic_Fluc'"
dc = x.orc_qry_all_active('SEMHEDB.ALERTS_STATUS',cond3)
#cd = "'DHSVRJ4','CGDMG39','NOSBC23'"
df = pd.DataFrame(dc)
print(df)
df.to_csv(pth)
#print(x.orc_qry_by_code('JPISL15'))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xdttm.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()

def Now():
    return n

def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str

def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d

def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d

def curr_day():
    return td.strftime('%d')

def curr_month():
    return td.strftime('%m')

def curr_year():
    return td.strftime('%Y')

def curr_date():
    return td.strftime('%Y-%m-%d')

def date_between(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2 - d1).days


def aging(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2= datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2 - d1)
    return mn


def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx + relativedelta(months=diff)
    return delt


def day_minus(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d


def day_plus(diff):
    d = td + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

# def date_str(dt):
# def fmt_to_datetime():
# def fmt_to_str():
# delta_month(nw(),-4)
# def month_delta(dt,diff):
# d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
# def day_delta(dt,diff):
# def date_minus(dt, diff):
# def month_minus(dt, diff):
# def year_minus(dt, diff):
# print(aging(nw(),'2020-06-13 00:00:00'))
# print(min_plus(500))
# print(min_minus(500))
# print(hr_plus(2))







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xlread.py###
import pandas as pd
from pandas import ExcelWriter
from pandas import ExcelFile
import os, sys
import argparse

parser = argparse.ArgumentParser(description='Script so useful.')

def read_csv_xls(pth, sht = None):
    df = ''
    if sht == None:
        df = pd.read_csv(pt)
    else:
        df = pd.read_excel(pt, sheet_name = sht)
    print(df)
    
args = parser.parse_args()
print(args)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xmssq.py###
import pandas as pd
import pyodbc
import omfn.xdttm as odt
import omfn.vbafn as vbf
import requests

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'

def custom_msg_sender(chatid, msg):
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


class mssq:
    def __init__(self):
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)

    def check_existance_by_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        rw = df.shape[0]
        return rw

    def query_full_tbl(self, tbl):
        qry = "select * from " + tbl
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def insert_new_entry(self, tbl, colnames, values):
        qry = "insert into " + tbl + " (" + colnames + ") values (" + values + ")"
        print(qry)
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        print(rs)

    def apend_into(self, tbl, colname, value, refcolname, refvalue):
        qry1 = "select " + colname + " from " + tbl + " where " + refcolname + "='" + refvalue + "'"
        print(qry1)
        curs = self.conx.cursor()
        rsl = curs.execute(qry1)
        rs = rsl.fetchall()
        print(rs)
        vl = value
        qry = "UPDATE " + tbl + " SET " + colname + "='" + vl + "' WHERE " + refcolname + "='" + refvalue + "'"
        print(qry)
        rs2 = curs.execute(qry)
        print(rs2)

    def query_by_single_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_by_double_ref(self, tbl, colname1, value1, colname2, value2):
        qry = "select * from " + tbl + " where " + colname1 + "='" + value1 + "' AND " + colname2 + "='" + value2 + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_string(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + " like " + value
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def upd_by_ref(self, tbl, colnames, values, ref, refvalue):
        qry = "UPDATE " + tbl + " SET " + colnames + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'updated'
    def del_by_ref(self, tbl, colname, value):
        qry = "DELETE FROM " + tbl + " WHERE " + colname + "='" + value + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'deleted'
    def bot_usr_add(self, nam, uid, pas, msisdn):
        td = odt.Now()
        tday = td.strftime('%Y-%m-%d')
        print(tday)
        dt = td.strftime('%d')
        mn = td.strftime("%m")
        wkdy = td.strftime('%a')
        valu = ""
        ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
        print('psscode=', ps)
        if pas == ps or pas == '07085122':
            colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
            valu = "'" + nam + "','" + uid + "','" + tday + "','" + msisdn + "','Y','N','N'"
            qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            print(rs)
            custom_msg_sender(uid, 'congrats, write help to the secrat to use me')
        else:
            custom_msg_sender(uid, 'you send wrong passcode')
        self.conx.close()
    def bot_usr_list(self, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = 'select * from om_socbot_access'
            df = pd.read_sql(qry, self.conx)
            dic = df.to_dict()
            x = vbf.pyvb(dic)
            return x.print_all_row_comm_seperated()

    def bot_usr_delete(self, sl, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = "DELETE FROM om_socbot_access WHERE SL ='" + sl + "'"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            return 'user deleted success'

    def bot_today_pass(self, secrat):
        if secrat == '07085122' or secrat == 'jahid1998':
            td = odt.Now()
            tday = td.strftime('%Y-%m-%d')
            print(tday)
            dt = td.strftime('%d')
            mn = td.strftime("%m")
            wkdy = td.strftime('%a')
            valu = ""
            ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
            return ps
        else:
            return 'unauthorized attempt'
    def auth_check_db(self, uid, qryfrom):
        df1 = pd.read_sql("select * from om_socbot_access", self.conx)
        df = df1[df1['UID'].str.contains(uid)]
        x = df.shape[0]
        if x == 0:
            return str(x)
        else:
            Status = df['Status'].iloc[0]
            special = df['Special'].iloc[0]
            if qryfrom != 'private' and special != 'Y':
                return 0
            elif qryfrom == 'private' and Status == 'Y':
                return '1'
            elif special == 'Y':
                return '1'


x = mssq()
# print(x.check_existance_by_ref('incident_tracker_v2','Incident_ID','INY00001138080'))
# df = pd.DataFrame(x.query_full_tbl('incident_tracker_v2'))
# x.bot_usr_delete('4','07085122')
print(x.bot_usr_list('07085122'))
#
# vl = ""
# x.insert_new_entry('om_socbot_access',colnm,vl)
# print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xxtest.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import OmSQ.omsqlfn as fn
import OmSQ.InsUpd as fni
from datetime import *
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\zFluc.py###
import pandas as pd
import numpy as np
from datetime import *
import cx_Oracle

def cols():
    ls = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP',
          'CUSTOMATTR3','EventId','X733CorrNotif','X733EventType','X733ProbableCause','X733SpecificProb',
          'CorrelateTopologyKey','TTSequence','TTStatus','TTUpdate','TTUser','CustomAttr10','CustomAttr11',
          'CustomAttr12','CustomAttr13','CustomAttr5','CustomAttr26']
    hp = ''
    for i in range(len(ls)):
        if hp == '':
            hp = ls[i].upper()
        else:
            hp = hp + ',' + ls[i].upper()
    return hp


def last24hr():
    conn = cx_Oracle.connect('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    d1 = datetime.now() + timedelta(hours=-23)
    dtfrom = d1.strftime("%d-%m-%Y %H:00:00")
    d2 = datetime.now() + timedelta(hours=1)
    dtto = d2.strftime("%d-%m-%Y %H:00:00")
    st = cols()
    print(st)
    q0 = "SELECT " + cols() + " FROM SEMHEDB.ALERTS_STATUS WHERE SERIAL IN"
    q1 = "SELECT SERIAL FROM SEMHEDB.ALERTS_STATUS WHERE LASTOCCURRENCE BETWEEN TO_DATE('" + str(dtfrom) + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + str(dtto) + "','DD-MM-YYYY HH24:MI:SS')"
    q2 = "AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')"
    qry = q0 + '(' + q1 + " AND " + q2 + ')'
    print(qry)
    df = pd.read_sql(qry, con = conn)
    df.to_csv(os.getcwd() + "\\OMDW.csv")
    print(os.getcwd() + "\\OMDW.csv")

last24hr()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\zFluc0.py###


###d:\omEngin\Z_ALL_FILE\Py1\10102020-1833-XAQ-vbfn1.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = "E:\\GIT\\OmProject\\OmPY\\omfn4\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]




df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
#print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
#print(asq)

sm = sumifs(asq,'CUSTOMATTR15','AG')
print(sm)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10102020-253-XAQ-ipmap.py###
import pandas as pd
import numpy as np
import os
import csv
import requests
import io
import datetime as dt
import geoip2.database

#shift-ctrl-b

pt = os.getcwd()
dbmx = "/root/OmProject/OmSocks/ippro/GeoLite2-City.mmdb"
dbas2ip = "/root/OmProject/OmSocks/ippro/ip2asn.csv"

def mxdb(ip):
    with geoip2.database.Reader(dbmx) as reader:
        try:
            response = reader.city(ip)
            lst = response.city.name + ' -' + response.country.iso_code
            return lst
        except:
            lst = 'NA'
            return lst

def filename_maker():
    y = dt.datetime.now()
    x = y.strftime("%d%m%Y-%H%M")
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww

def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]


def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

def maincall(dpx1):
    df = pd.read_csv(dbas2ip)
    ls = []
    for r in range(dpx1.shape[0]):
        lst = []
        ip = dpx1.iloc[r,0]
        prt = dpx1.iloc[r,1]
        ipx = ip.split('.')
        ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
        aa = find_owner(ddf.to_numpy(),ip)
        lst.insert(0,ip)
        lst.insert(1,prt)
        lst.insert(2,mxdb(ip))
        lst.insert(3,aa)
        ls.append(lst)
    fdf = pd.DataFrame(ls,columns = ['ip','port','CityCountry','SL'])
    ffd = pd.merge(fdf,df,on ='SL',how ='left')
    fd = ffd[['ip','port','CityCountry','ISP','ASN','Country']]
    fd.to_csv(filename_maker())
    return fd

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10102020-253-XAQ-jsonrw.py###
#ref:https://pynative.com/python-json-dumps-and-dump-for-json-encoding/
import json
import os

def jsonMod(jsn,ip,port):
    with open(jsn, "r") as jsonFile:
        x = json.load(jsonFile)
        x['configs'][0]['server'] = ip
        x['configs'][0]['server_port'] = port
        print(x)
    with open(jsn, "w") as jsonFile:
        json.dump(x, jsonFile)

jp = os.getcwd() + "\\proxylist.json"
jsonMod(jp,'8.8.8.8','01010')

#demjson.decode(prot)
#(prot)
#print(usr)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10102020-253-XAQ-omprox.py###
import os
import geoip2.database
import pandas as pd
import api.omapi as oap
import api.lvblk as lv
import api.ipapi as iap
import ippro.ipmap as ipm
import csv
pd.options.mode.chained_assignment = None  # default='warn'

#shift-ctrl-b

def runner(df1,filename):
    df = df1[df1['Country'].str.contains('US')]
    rw = df.shape[0]
    n = 0
    for i in range(len(df)):
        try:
            df.loc[i,"status"] = lv.islive(str(df.loc[i,"ip"]), str(df.loc[i,"port"]))
        except:
            print('err')
        finally:
            break
        n = n + 1
        print('checking done: ' + str(n) + '/' + str(rw))
    df.to_csv('A.csv')
    return df

hme = oap.dailyproxy()
print(hme)
hme.columns = ['ip','port']
GT = ipm.maincall(hme)
df = GT[ (GT.ASN != 13335) & (GT.Country == 'US') ]
#df['ip']= df['ip'].astype(str)
df['port']= df['port'].astype(str)
ndf = df[['ip','port','ISP']]
print(ndf)
nr = ndf.to_numpy()
zz = ""
rw, col = nr.shape
ls = []
for r in range(rw):
    lst = []
    IP = nr[r][0]
    PORT = nr[r][1]
    lst.insert(0, str(IP) + ':' + str(PORT))
    lst.insert(1, nr[r][2])
    lst.insert(2, lv.islive(IP,PORT))
    ls.append(lst)
dfx = pd.DataFrame(ls, columns = ['ip_port','isp','status'])
dfx.to_csv('/root/OmProject/azsa.csv')
    
    


#dfop = oap.openproxy()
#dfdl = dailyproxy()
#dfprm = api_premproxy()



#prem.columns = ['ip','port']


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10112020-1432-XAQ-omapi.py###
import csv
import pandas as pd
import io
import requests
import nmap
import pydnsbl
import urllib
import socket
import json
import requests
socket.setdefaulttimeout(180)
import os

def api_hideme():
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + "730480402242392"
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

def api_premproxy():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    urlData = requests.get(z).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def dailyproxy():
    url = "https://proxy-daily.com/api/getproxylist?apikey=MHAvkX-UOWjz6vbT-t9cpK1&format=ipport&country=US&type=socks5&lastchecked=60"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def openproxy():
    url = "https://api.openproxy.space/premium/plain?amount=34999&apiKey=i9414-d994p4Pa29118LW-yfIl5-eBY64dMT5N16uDv-Vw10n&checksMore=354&countries=US&protocols=3&status=1&streak=1"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def auth0(ip):
    try:
        url = "https://signals.api.auth0.com/badip/" + ip
        headers = {
            'accept': "application/json",
            'x-auth-token': "51fac7a1-04c8-4c2f-8143-76c5fa498ff9"
            }
        response = r.request("GET", url, headers=headers)
        x = json.loads(response.text)
        return x['type']
    except:
        print('err')
    finally:
        return "NA"


def isblk(ip):
    ip_checker = pydnsbl.DNSBLIpChecker()
    x = str(ip_checker.check(ip))
    print(x)
    if 'BLACKLISTED' in x:
        a = x.rfind('(')
        b = x.rfind(')')
        ab = x[a+1:b]
        ap = auth0(ip)
        return 'black - ' + ab + ' - ' + str(ap)
    else:
        return 'fine'

def islive(ip,port):
    qry = 'nmap -p ' + str(port) + ' ' + str(ip)
    y = os.popen(qry).read()
    print(y)
    if 'open' in y:
        ab = isblk(ip)
        x = 'live' + '-' + str(ab)
    else:
        x = 'dead'
    return x

def ipdb_2(ip):
    url = "https://freegeoip.app/json/" + ip
    headers = {
        'accept': "application/json",
        'content-type': "application/json"
        }
    response = requests.request("GET", url, headers=headers)
    x = json.loads(response.text)
    y = x['city'] + ' -' + x['country_code']
    return y


islive('173.0.54.188','6888')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10142020-1240-XAQ-omdtfn.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()


def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str


def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def curr_day():
    return td.strftime('%d')


def curr_month():
    return td.strftime('%m')


def curr_year():
    return td.strftime('%Y')


def curr_date():
    return td.strftime('%Y-%m-%d')


def date_between(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2 - d1).days


def aging(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2 - d1)
    return mn


def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx + relativedelta(months=diff)
    return delt

def day_minus_dy(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d")
    return str_d

def day_minus(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def day_plus(diff):
    d = td + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def hrmin():
    str_d = n.strftime("%H:%M")
    return str_d

def dtmnyr():
    str_d = n.strftime("%Y-%m-%d")
    return str_d

# def date_str(dt):
# def fmt_to_datetime():
# def fmt_to_str():
# delta_month(nw(),-4)
# def month_delta(dt,diff):
# d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
# def day_delta(dt,diff):
# def date_minus(dt, diff):
# def month_minus(dt, diff):
# def year_minus(dt, diff):
# print(aging(nw(),'2020-06-13 00:00:00'))
# print(min_plus(500))
# print(min_minus(500))
# print(hr_plus(2))







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10162020-628-XAQ-vbfn2.py###
import pandas as pd
import numpy as np







def add_list_as_column(df,nlst):
    #ls = df.values.tolist()
    df = df.append(pd.DataFrame(nlst,columns=['col1','col2']),ignore_index=True)
    print(df)




l0 = ["0", "1", "2", "3", "4"]
l1 = ["Amar", "Barsha", "Barsha", "Tanmay", "Misbah"]
l2 = ["Alpha", "Bravo", "Charlie", "Tango", "Mike"]
l4 = [["Amar", "Barsha", "Carlos", "Tanmay", "Misbah"],["Alpha", "Bravo", "Charlie", "Tango", "Mike"]]
l5 = ['A','B','C','D','E']
l6 = ['DHK', 'RAJ', 'CTG', 'SYL', 'MYN']
l7 = [['DHK, P1'], ['DHK, P2'] , ['DHK, P3'] , ['DHK, P4'] , ['DHK, P5']]

df1 = join_list(l0, l1, l2)
df1.columns = ['1','2','3']
dc1 = conv_lst_dic(l0,l6)
#print(dc1)
dc2 = conv_lst_dic(l0,l7)
#print(dc2)
l8 = df1['1']
l9 = df1 [['2','3']]
l10 = l9.values.tolist()
dc3 = conv_lst_dic(l0,l7)
#print(dc3)
#print(df1)
df2 = pd.DataFrame(dc3)
#print(df2)

x = vlookup(df1,dc3,'1','TOTO')

#print(x)
ts = x['2']
lx = ts.values.tolist()
cnt = lx.count('Barsha')
#print(cnt)
x = countif(x,'2','2',"ONCOL2")
#p = add_col_df(df,'Test',1)
#add_list_as_column(df,l4)
#datatype_conversion = df['Customer Number'].astype('int')


def conct(a1,a2):
    ls = []
    strn = ""
    for i in range(len(a1)):
        strn = strn + str(a1[i]) + str(a2[i])
    return strn

def conct1(arg1,arg2):
    if isinstance(arg1, list) and isinstance(arg2, list):
        ls = []
        for i in range(arg1):
            ls.append(str([i]) + str(arg2[i]))
        return ls
    else:
        ag1 = arg1.values.tolist()
        ag2 = arg2.values.tolist()
        ls = []
        for i in range(ag1):
            ls.append(str([i]) + str(ag2[i]))
        return ls

def countifz(df,*argv):
    if isinstance(df,pd.DataFrame):
        if len(argv) % 2 != 0:
            print('need conditions for every ref range have')
        else:
            rng = len(argv) / 2
            i = 0
            j = 2
            A1 = ""
            B1 = ""
            X1 = []
            X2 = []
            while i < rng:
                if j > rng:
                    A1 = A1 + (df[argv[i]])
                    B1 = B1 + (df[argv[i+1]])
                    i = i + 2
                else:
                    A1 = A1 + (conct(df[argv[i]],df[argv[j]]))
                    B1 = B1 + (conct(df[argv[i+1]],df[argv[j+1]]))
                    i = i + 2
                    j = j + 2
                X1.append(A1)
                X2.append(B1)
            print(X1,X2)
    else:
        print('first parameter must be dataframe (full data range)')


countifz(x, '1', '1', '3', '3')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10182020-49-XAQ-omfn.py###
import pandas as pd
import numpy as np
import .db.db as sq

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('C2G' if ('2G CELL DOWN' in x) \
                else ('C3G' if ('3G CELL DOWN' in x) \
                else ('C4G' if ('4G CELL DOWN' in x) \
                else "NA"))))))))))))

def Lcut(mstr,cut_to):
    try:
        if len(mstr) >= cut_to:
            x = mstr[0:cut_to]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def Rcut(mstr,cut_to):
    try:
        if len(mstr) - cut_to >= 0:
            a = len(mstr) - cut_to
            b = len(mstr)
            x = mstr[a:b]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def src_in_str(mstr,lkstr):
    if lkstr in mstr:
        return mstr.find(lkstr)
    else:
        return 0

def code_corr(df0):
    df = df0
    for i in range(len(df)):
       Eky = df.loc[i,'EQUIPMENTKEY']
       A15 = df.loc[i,'CUSTOMATTR15']
       if A15 == 'UNKNOWN' and Eky != 'UNKNOWN' and len(Eky)<15:
           if len(Eky) == 7:
               df.loc[i,'CUSTOMATTR15'] = Eky
           elif '_' in Eky:
               x = Eky.find('_')
               if x > 4:
                   df.loc[i,'CUSTOMATTR15'] = Lcut(Eky,7)
               else:
                   df.loc[i,'CUSTOMATTR15'] = Rcut(Eky,7)
    return df

def catsemrw(df0):
    df = add_col_df(df0,'cat')
    df['cat'] = df.apply(lambda row: TS(row.SUMMARY), axis = 1)
    return df

def get_region(df):
    df4 = df
    df5 = flk.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df6.drop('ShortCode', axis='columns', inplace=True)
    return df6

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10242020-055-XAQ-vbdf.py###
import pandas as pd
import numpy as np
import os
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnstr as fst
import db.db as sq
from datetime import *


pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

df1 = pd.read_csv(pt1)
df0 = pd.read_csv(pt2)

def get_region(df):
    df4 = df
    df5 = flk.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df6.drop('ShortCode', axis='columns', inplace=True)
    return df6

def conv_to_datetime(df1,col):
    df1[col] = pd.to_datetime(df1[col], errors='coerce')
    return df1

def pick_by_day(df1,day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1,yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def datediff(df1,newcolname,col1,col2=False):
    if col2 != False:
        df1 = conv_to_datetime(df1,col1)
        df1 = conv_to_datetime(df1,col2)
        df1 = pick_except_year(df1,1970)
        df2 = fdt.add_col_df(df1,newcolname)
        df2[newcolname] = df2[col2] - df2[col1]
        df2[newcolname] = df2[newcolname].astype('timedelta64[m]')
        return df2
    else:
        df1 = conv_to_datetime(df1,col1)
        df2 = fdt.add_col_df(df1,'now',datetime.now())
        df2 = conv_to_datetime(df2,'now')
        df3 = fdt.add_col_df(df2,newcolname)
        df3[newcolname] = df3['now'] - df3[col1]
        df3[newcolname] = df3[newcolname].astype('timedelta64[m]')
        df3.drop('now', axis='columns', inplace=True)
        return df3

#print(df0)
#print(df0.columns)



def cntif(df,*argv):
    rngmod = len(argv) % 2
    n = 0
    if rngmod == 0:
        ls = []
        while n<=len(argv):
            col = 'c' + str(n) + str(n+1)
            if isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], pd.core.series.Series):
                ls1 = argv[n].to_list()
                ls2 = argv[n+1].to_list()
                #ls = [i + j for i, j in zip(ls1, ls2)]
                print(ls2)
            elif isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], str):
                print('x')
            elif isinstance(argv[n+1], str) and isinstance(argv[n], pd.core.series.Series):
                print('x')
                n = n + 2
        print(ls)
    else:
        print('no of reference and no of criteria must be equal')


dfy = fst.catsemrw(df0)
dfz = get_region(dfy)
print('OK')
cntif(dfz,dfz['Region'],dfz['cat'])


def cifz(df,*argv):
    rng = len(argv) / 2
    if rng>=1:
        n = 0
        ls = []
        lss = []
        while n<=rng:
            if isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], pd.core.series.Series):
                ls1 =  argv[n].to_list()
                ls2 =  argv[n+1].to_list()
                if len(lss)<1:
                    lss = ls1
                    ls = ls2
                else:
                    l1 = []
                    l2 = []
                    l1 = [i + j for i, j in zip(lss, ls1)]
                    l2 = [i + j for i, j in zip(ls, ls2)]
                    lss = l1
                    ls = l2
            elif isinstance(argv[n], pd.core.series.Series) and isinstance(argv[n+1], str):
                ls1 =  argv[n].to_list()
                ar = np.repeat(argv[n+1], len(ls1))
                ls2 = ar.tolist()
                ls3 = [i + j for i, j in zip(ls1, ls2)]
                if len(lss)<1:
                    lss = ls1
                    ls = ls2
                else:
                    l1 = []
                    l2 = []
                    l1 = [i + j for i, j in zip(lss, ls1)]
                    l2 = [i + j for i, j in zip(ls, ls2)]
                    lss = l1
                    ls = l2
            n = n + 2
        df1 = pd.DataFrame(list(zip(lss, ls)),columns =['refrng','criteria'])
        dff = pd.concat([df, df1], axis=1, sort=False)
        print(dff)
        dfx = df1.groupby(['refrng','criteria']).count().to_frame(name = 'cnt').reset_index()
        #dd = df1.value_counts(['refrng','criteria'])).counts()
        print(dfx)
        #dfy = dff.merge(dfx, on='refrng')
        #df2.drop(st, axis='columns', inplace=True)
        #print(dfx)

#cifz(dfz,dfz['Region'],dfz['cat'])

#dfx = datediff(df0,'datedff','LASTOCCURRENCE')

#print(dfz)
#cat Region

#dfz['rgcat'] = dfz['Region'] + dfz['cat']
#d1 = dfz.groupby(['rgcat'])['rgcat'].count().to_frame(name = 'counts').reset_index()
#ls = ['Region','cat']
#dx = countifs(dfz,ls,'count')
#print(dx)
#print(dfz['concat'])


#df3 = df2.groupby(['CUSTOMATTR15','diff'])['CUSTOMATTR15'].count()
#print(df3)
#dfx = df2.groupby(['CUSTOMATTR15']).CUSTOMATTR15.count().to_frame(name = 'SMX').reset_index()
#df3 = df2.groupby('CUSTOMATTR15')['diff'].sum().to_frame(name = 'SMX').reset_index()
#df3['SMX'] = df3['SMX'].astype(int)
#df3['SMX'] = df3['SMX'].astype(str).astype(int)
#df3['SMX'] = df3['SMX'].astype('int64').dtypes
#df3["SMX"] = df3["SMX"].astype(int)
#df3 = df2.groupby(df2['CUSTOMATTR15']).diff.sum().to_frame(name = 'SMX').reset_index()
#print(df3#)



#ds = df3.dtypes
#print(ds)
#print(type(df1['LASTOCCURRENCE']))
#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)














#print(pt)
#df0 = pd.read_csv(pt)
#cols = ['Serial','EquipmentKey','LastOccurrence','Summary','AssociatedCR','TTSequence','TTStatus','CustomAttr15','BCCH','AlertKey','CustomAttr3','ClearTimestamp']
#df1 = df0[cols]
#df2 = look.catsemrw(df1)
#print(df2.head(5))
#df3 = look.process_sem_raw(df2)
#df4 = look.code_corr(df3)
#print(df4['CustomAttr15'])
#df.astype({'col1': 'int32'}).dtypes


#df1 = look.add_col_df(df,'cnt')
#
#df2 = df0.value_counts(dropna=False)
#print(df2)
#print(df2.shape[0])
#ls = df2.values.tolist()
#print(df2)
#print(df2.shape[1])

#df4 = pd.DataFrame(df3, columns=['1','2'])
#print(df4)
#df3 = df.merge(df2,)
#df1 = look.timediff(df,'LASTOCCURRENCE','CLEARTIMESTAMP',"MTTR")
#print(df1)dropna=False
#print(df1)
#print(df)

#df0 = look.countif(df,'Summary','Summary',"CAT")
#print(df0)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10252020-194-XAQ-main.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs

tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=1)
tmnw = datetime.now() - timedelta(minutes=1)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
conx = pyodbc.connect(UserEx)

def sendsms(msisdn,txt):
    sURL1 = "http://10.101.11.164:10144/cgi-bin/sendsms?user=tester&pass=foobar&to="
    sURL2 = "&from=10144&text="
    sURL_pgon = sURL1 + msisdn + sURL2 + txt
    resp = rs.get(sURL_pgon)
    print(resp)

def smscheck():
    smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
    dfsms = pd.read_sql(smsinbox, conx)
    return dfsms


def main():
    df = smscheck()
    if df.shape[0] != 0:
        for i in range(len(df)):
            print(df.iloc[i,1])
    else:
        print('no sms')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10262020-221-XAQ-main.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs
import sqltdb as sqdb
import sitecount as st
import omfn as fn
import urllib3
import urllib.parse


tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=1)
tmnw = datetime.now() - timedelta(minutes=1)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')


def handdler(ussd,msg,msisdn):
    nw = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    rval = ""
    if msg !="":
        ms = msisdn[-10:len(msisdn)]
        ms4sms = msisdn[-11:len(msisdn)]
        code = fn.sitecode_pick(msg)
        if "ALL" in msg  or '2G' in msg or  "3G" in msg or "SC" in msg or  "4G" in msg:
            xx = st.siteinfo(msg)
            print(nw, xx)
            yy = st.sms(ms4sms,xx)
            rval = "S"
        elif "PGSTART" in msg and code != 'NA':
            xx = st.roc(ussd,code,ms,'PGSTART')
            print(nw,xx)
            if 'PGON_DONE' in xx:
                rval = "S"
            else:
                rval = "F"
        elif "PGSTOP" in msg and code != 'NA':
            xx = st.roc(ussd,code,ms,'PGSTOP')
            print(nw,xx)
            if 'PGOFF_DONE' in xx:
                rval = "S"
            else:
                rval = "F"
        else:
            rval = "Not Related Query"
    return rval

def main():
    nww = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    df = st.smscheck()
    if df.shape[0] != 0:
        for i in range(len(df)):
            msg1 = df.loc[i,"MESSAGE"]
            if isinstance(msg1, str):
                ussd = df.loc[i,"USDLogId"]
                msg = msg1.upper()
                msisdn = df.loc[i,"DESTADDR"]
                sqret = sqdb.queryussd(ussd)
                if sqret == 0:
                    st.general_qry()
                    rval = handdler(ussd,msg,msisdn)
                    st.general_qry()
                    if rval == 'S':
                        rv2 = sqdb.insertussd(ussd)
                        if rv2 == "S":
                            print('Cycle Complete for::::: ', nww, ussd, msg, msisdn)
                        else:
                            print("Cycle failed:::", nww, ussd, msg, msisdn)
                    else:
                        print(rval)
                else:
                    print('already served::', nww, ussd, msg, msisdn)
    else:
        print('no sms')
    return "done at " + nww
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10262020-356-XAQ-runner.py###
import asyncio
import main as m
from datetime import *

async def periodic():
    while True:
        nww = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print("start at ", nww)
        xx = m.main()
        print("ends at " , xx)
        await asyncio.sleep(30)

def stop():
    task.cancel()

loop = asyncio.get_event_loop()
task = loop.create_task(periodic())

try:
    loop.run_until_complete(task)
except asyncio.CancelledError:
    pass
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\10302020-2358-XAQ-sitecount.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
import requests as rs
import db121 as d121
import sqltdb as sq

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
conn = pyodbc.connect(UserEx)

tday = date.today()

def smscheck():
    tmdlta = datetime.now() + timedelta(minutes=1)
    tmnw = datetime.now() - timedelta(minutes=2)
    qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
    qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')
    smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
    print(smsinbox)
    dfsms = pd.read_sql(smsinbox, conn)
    return dfsms

def sms(ms,text):
    url = "https://web1.robi.com.bd/apiresponse.php?user=robircouser&pass=Gqras@3789291&from=10144&to=" + str(ms) + "&text=" + text
    rs = requests.get(url)
    print(rs)


def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "ALL2G") or (txtwht == "2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "ALL3G") or (txtwht == "3G"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "4G") or (txtwht == "ALL4G"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "ALL") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        allnode = df2G.shape[0]
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "Radio Node: " + str(allnode) + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"
    

tmnw = datetime.now()
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')

def general_qry():
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    qry = "SELECT * from [dbo].[pglog4]"
    df = pd.read_sql(qry, conn)
    print(df)

def db_insert_pgon(ussd,code,msisdn):
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    in_qry = '''INSERT INTO dbo.pglog4 (SMSID, SITECODE, MSISDN) VALUES (?,?,?)'''
    in_qry_1 = (ussd, code, msisdn)
    curs.execute(in_qry, in_qry_1)
    conn.commit()
    sms(str(msisdn),"PGSTART ACK AT " + qryst + " CODE:" + code)

def db_query_duplicate(code):
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    select_qry = "SELECT * FROM pglog4 WHERE SITECODE = '"+ code +"' AND STATUS_ACTIVE= 'TRUE'"
    curs.execute(select_qry)
    rows = curs.fetchone()
    bol = bool(rows)
    if bol == True:
        return "ACT_CASE_FOUND"
    else:
        return "NO_ACT_CASE"

def db_update_pgoff(code,msisdn):
    #conn = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conn.cursor()
    qry_1 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND STATUS_ACTIVE= 'TRUE')"
    qry1 = "UPDATE dbo.pglog4 SET END_DATETIME = CURRENT_TIMESTAMP WHERE " + qry_1
    qry2 = "UPDATE dbo.pglog4 SET CASE_STATUS = 'Closed' WHERE " + qry_1
    curs.execute(qry1)
    conn.commit()
    curs.execute(qry2)
    conn.commit()
    qry_2 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND CASE_STATUS= 'Closed')"
    qry3 = "UPDATE dbo.pglog4 SET STATUS_ACTIVE = '0' WHERE " + qry_2
    curs.execute(qry3)
    conn.commit()
    sms(msisdn,"PGSTOP ACK AT " + qryst + ' Code: '+ code)

def roc(ussd,code,msisdn,job):
    x = 0
    if job == "PGSTART":
        ans = db_query_duplicate(code)
        print("~~~~ ", ans, " ~~~~",code)
        if ans == "NO_ACT_CASE":
            try:
                db_insert_pgon(str(ussd),code,str(msisdn))
                print('DBUPDATE ROC SUCC')
                x = 1
            except:
                print('DBUPDATE ROC FAIL')
            try:
                d121.insert_pgon(str(ussd),code,str(msisdn))
                print('DBUPDATE 121 SUCC')
            except:
                print('DBUPDATE 121 FAIL')
            if x == 1:
                return 'PGON_DONE' + code
            else:
                return 'DBUPDATE FAIL ' + code
        else:
            sms(msisdn,"PGSTART ALREADY LOGGED (Duplicate Entry)")
            sq.insertussd(ussd)
            return "Duplicate Entry: " + code
    elif job == "PGSTOP":
        ans = db_query_duplicate(code)
        if ans == "ACT_CASE_FOUND":
            db_update_pgoff(code,str(msisdn))
            d121.update_pgoff(code,str(msisdn))
            return 'PGOFF_DONE'
        else:
            sms(msisdn,"NO PGON Found, Invalid PG OFF Request")
            sq.insertussd(ussd)
            return ""


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1042020-2217-XAQ-ipmap.py###
import pandas as pd
import numpy as np
import os
import MySQLdb
import csv
import requests
import io
import datetime as dt


def filename_maker():
    y = dt.datetime.now()
    x = y.strftime('%d%m%Y-%H%M')
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww

def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]

def api_hideme():
    hideme_access = "730480402242392"
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + hideme_access
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

def maincall(df_port_ip):
    df = pd.read_csv(path_ip2as)
    dpx1 = df_port_ip[['ip','port']]
    dpip = df_port_ip[['ip']]
    ls = []
    for r in range(dpx1.shape[0]):
        lst = []
        ip = dpx1.iloc[r,0]
        prt = dpx1.iloc[r,1]
        ipx = ip.split('.')
        ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
        aa = find_owner(ddf.to_numpy(),ip)
        lst.insert(0,ip)
        lst.insert(1,prt)
        lst.insert(2,aa)
        ls.append(lst)
        print(ls)
    fdf = pd.DataFrame(ls,columns = ['ip','port','SL'])
    ffd = pd.merge(fdf,df,on ='SL',how ='left')
    fd = ffd[['ip','port','ISP','ASN','Country']]
    print(fd)
    fd.to_csv(filename_maker())
    return fd

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1082020-121-XAQ-test.py###
import socket
import Queue
import threading
import time
import os
import sys
from random import *
from struct import *


class ThreadChecker(threading.Thread):
    def __init__(self, queue, timeout):
        self.timeout = timeout
        self.q = queue
        threading.Thread.__init__(self)
    def isSocks4(self, host, port, soc):
        ipaddr = socket.inet_aton(host)
        packet4 = "\x04\x01" + pack(">H",port) + ipaddr + "\x00"
        soc.sendall(packet4)
        data = soc.recv(8)
        if(len(data)<2):
            # Null response
            return False
        if data[0] != "\x00":
            # Bad data
            return False
        if data[1] != "\x5A":
            # Server returned an error
            return False
        return True
    def isSocks5(self, host, port, soc):
        soc.sendall("\x05\x01\x00")
        data = soc.recv(2)
        if(len(data)<2):
            # Null response
            return False
        if data[0] != "\x05":
            # Not socks5
            return False
        if data[1] != "\x00":
            # Requires authentication
            return False
        return True
    def getSocksVersion(self, proxy):
        host = proxy.split(":")[0]
        try:
            port = int(proxy.split(":")[1])
            if port < 0 or port > 65536:
                print "Invalid: " + proxy
                return 0
        except:
            print "Invalid: " + proxy
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(self.timeout)
        try:
            s.connect((host, port))
            if(self.isSocks4(host, port, s)):
                s.close()
                return 5
            elif(self.isSocks5(host, port, s)):
                s.close()
                return 4
            else:
                ("Not a SOCKS: " + proxy)
                s.close()
                return 0
        except socket.timeout:
            print "Timeout: " + proxy
            s.close()
            return 0
        except socket.error:
            print "Connection refused: " + proxy
            s.close()
            return 0
    def run(self):
        while True:
            proxy = self.q.get()
            version = self.getSocksVersion(proxy)
            if version == 5 or version == 4:
                print "Working: " + proxy
                socksProxies.put(proxy)
            self.q.task_done()


class ThreadWriter(threading.Thread):
    def __init__(self, queue, outputPath):
        self.q = queue
        self.outputPath = outputPath
        threading.Thread.__init__(self)
    def run(self):
        while True:
            toWrite = self.q.qsize()
            outputFile = open(self.outputPath, 'a+')
            for i in xrange(toWrite):
                proxy = self.q.get()
                outputFile.write(proxy + "\n")
                self.q.task_done()
            outputFile.close()
            time.sleep(10)



def info():
    os.system("clear")
    os.system("chmod +x .start")
    os.system("./.start")

def Exit():
    os.system("clear")
    numc=randint(30,37)
    os.system("echo -e \"\\e[1;"+str(numc)+"m\"")
    os.system("cat .end")
    os.system("echo -e \"\\e[0m\"")
    exit()

flag=True
while flag:
    info()
    checkQueue = Queue.Queue()
    socksProxies = Queue.Queue()
    if len(sys.argv)==2:
        print "    Help "
        print "To run the SOCKER: python2 socker.py"
        print "1. Give the SOCKS List Path"
        print "2. Give the FileName To which working Proxy Would be written"
        print "3. Give Number of threads between 10-15 in phone and 30-50 in PC\n\tNote The Number of threads depends on your processor if u have a high end phone or pc You can use more threads"
        print "4. Give Timeout between 1-2\n\tNote Faster Your net speed , put your timeout less"
        print "\n\n Command Line Usage:"
        print "\t\tpython2 socker.py <socks_file_list> <file_to_write> <threads> <timeout>"
        print "\nAll parameters are optional...\nBut if used all must be used..."
        print "Don't use < or > while giving parameters..."
        print "Remember File Names are case-sensitive...."
            print "\n\n\nPress Enter To Continue..."
        raw_input()
        Exit()
    
    if not (len(sys.argv) == 1 or len(sys.argv) == 5):
            print "This Script Was Created By SpeedX!!"
            print "Invalid Parameters used..."
            print "\n\nUsage:"
        print "python2 socker.py <socks_file_list> <file_to_write> <threads> <timeout>"
        print "\n\nAll parameters are optional...\nBut if used all must be used..."
        print "Don't use < or > while giving parameters..."
        print "Remember File Names are case-sensitive....\n\nFor More Information Type python2 socker.py help "
            print "\n\n\nPress Enter To Continue..."
        raw_input()
        Exit()
    if not (sys.argv[0] == "socker.py" or  sys.argv[0] == "socker"):
            print "This Script Was Created By SpeedX!!"
            print "Don't Be OVERSMART by changing script file name or its contents!!"
            print "Get Your Hands off you chessy ass !!!"
            print "\n\n\nPress Enter To Continue..."
        raw_input()
        Exit()
    if len(sys.argv)==5:
        ifile=sys.argv[1]
        outputPath=sys.argv[2]
        threads = int(sys.argv[3])
        timeout = int(sys.argv[4])
    else:
        ifile = raw_input("Proxy list: ")
        outputPath = raw_input("Output file: ")
        threads = int(raw_input("Number of threads: "))
        timeout = int(raw_input("Timeout(seconds): "))
    exists = os.path.isfile(ifile)
    if not exists:
        print "The File "+ifile+" Doesn't exists !!!"
        print "Try Again !!!"
        print "Press Enter To Continue..."
        raw_input()
        continue
    else:
        inputFile=open(ifile,'r')
    for line in inputFile.readlines():
        checkQueue.put(line.strip('\n'))
    print str(len(line.strip('\n')))+" Proxies Loaded !!!"
    inputFile.close()
    for i in xrange(threads):
        t = ThreadChecker(checkQueue, timeout)
        t.setDaemon(True)
        t.start()
        time.sleep(.25)
    wT = ThreadWriter(socksProxies, outputPath)
    wT.setDaemon(True)
    wT.start()
    checkQueue.join()
    socksProxies.join()
    Exit()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1092020-139-XAQ-vbcls1.py###
import pandas as pd
import numpy as np


class pyvb:
    def __init__(self, dic, li=[]):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = self.df[li]
    def PrintDf(self):
        print(self.df)
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11122020-628-XAQ-main.py###
import pandas as pd
import numpy as np
import os
import requests
import lookup.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import db.db as sq
import db.semqry as semq
import func.fnfn as fn
import prep as pr
import func.omdtfn as odt
import rruocc as rru
import top5 as t5
from datetime import *


df0 = semq.qry_all_last_day('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * '," AND AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')")
df1 = df0.rename(columns=str.upper)
rru.theft_occ(df1)
t5.top5_outage_report(df1)
#df20 = df17[['CODE','CName','CNT','SMX']]
#df19 = df20.applymap(str)
#for i in range(len(df19)):
    #print(df19.loc[i,'CName'] + chr(10) + df19.loc[i,'CODE'] + ': ' + str(df19.loc[i,'CNT']) + '/' + str(df19.loc[i,'SMX']))
    #print(chr(10))
#df04 = pd.DataFrame(df03)
#print(df04)
#print(df3)
#df = pd.DataFrame(fruit_list, columns = ['Name' , 'Price', 'In_Stock'])
#x = df.groupby(df.Name == 'banana').Price.sum()
#print(x)
#def rru_occ(df):
#df = df0.rename(columns=str.upper)
#df = process_sem_data(df0)
#df1 = df[['CUSTOMATTR15','AGING','cat', 'ShortCode', 'Region']]
#df2 = fst.add_col_df(df1,'NEW_AG')
#df2['NEW_AG'] = df2.apply(lambda x : x.AGING/(60*24), axis = 1)
#df3 = df2.groupby(df2['ShortCode']).NEW_AG.sum()
#print(df2)
#df3 = df2.groupby(['Region','cat']).cat.count()
#print(df3)
#print(df3.first())
#df4 = pd.DataFrame(df3)
#print(df3)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11122020-850-XAQ-xmssq.py###
import pandas as pd
import pyodbc
import omfn.xdttm as odt
import omfn.vbafn as vbf
import requests

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'

def custom_msg_sender(chatid, msg):
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


class mssq:
    def __init__(self):
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)

    def check_existance_by_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        rw = df.shape[0]
        return rw

    def query_full_tbl(self, tbl):
        qry = "select * from " + tbl
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def insert_new_entry(self, tbl, colnames, values):
        qry = "insert into " + tbl + " (" + colnames + ") values (" + values + ")"
        print(qry)
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        print(rs)

    def apend_into(self, tbl, colname, value, refcolname, refvalue):
        qry1 = "select " + colname + " from " + tbl + " where " + refcolname + "='" + refvalue + "'"
        print(qry1)
        curs = self.conx.cursor()
        rsl = curs.execute(qry1)
        rs = rsl.fetchall()
        print(rs)
        vl = value
        qry = "UPDATE " + tbl + " SET " + colname + "='" + vl + "' WHERE " + refcolname + "='" + refvalue + "'"
        print(qry)
        rs2 = curs.execute(qry)
        print(rs2)

    def query_by_single_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_by_double_ref(self, tbl, colname1, value1, colname2, value2):
        qry = "select * from " + tbl + " where " + colname1 + "='" + value1 + "' AND " + colname2 + "='" + value2 + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_string(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + " like " + value
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def upd_by_ref(self, tbl, colnames, values, ref, refvalue):
        qry = "UPDATE " + tbl + " SET " + colnames + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'updated'
    def del_by_ref(self, tbl, colname, value):
        qry = "DELETE FROM " + tbl + " WHERE " + colname + "='" + value + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'deleted'
    def bot_usr_add(self, nam, uid, pas, msisdn):
        td = odt.Now()
        tday = td.strftime('%Y-%m-%d')
        print(tday)
        dt = td.strftime('%d')
        mn = td.strftime("%m")
        wkdy = td.strftime('%a')
        valu = ""
        ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
        print('psscode=', ps)
        if pas == ps or pas == '07085122':
            colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
            valu = "'" + nam + "','" + uid + "','" + tday + "','" + msisdn + "','Y','Y','Y'"
            qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            print(rs)
            custom_msg_sender(uid, 'congrats, write help to the secrat to use me')
        else:
            custom_msg_sender(uid, 'you send wrong passcode')
        self.conx.close()
    def bot_usr_list(self, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = 'select * from om_socbot_access'
            df = pd.read_sql(qry, self.conx)
            dic = df.to_dict()
            x = vbf.pyvb(dic)
            return x.print_all_row_comm_seperated()

    def bot_usr_delete(self, sl, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = "DELETE FROM om_socbot_access WHERE SL ='" + sl + "'"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            return 'user deleted success'

    def bot_today_pass(self, secrat):
        if secrat == '07085122' or secrat == 'jahid1998':
            td = odt.Now()
            tday = td.strftime('%Y-%m-%d')
            print(tday)
            dt = td.strftime('%d')
            mn = td.strftime("%m")
            wkdy = td.strftime('%a')
            valu = ""
            ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
            return ps
        else:
            return 'unauthorized attempt'
    def auth_check_db(self, uid, qryfrom):
        df1 = pd.read_sql("select * from om_socbot_access", self.conx)
        df = df1[df1['UID'].str.contains(uid)]
        x = df.shape[0]
        if x == 0:
            return str(x)
        else:
            Status = df['Status'].iloc[0]
            special = df['Special'].iloc[0]
            if qryfrom != 'private' and special != 'Y':
                return 0
            elif qryfrom == 'private' and Status == 'Y':
                return '1'
            elif special == 'Y':
                return '1'


#x = mssq()
#bot_usr_add(self, nam, uid, pas, msisdn)
#x.bot_usr_add('s_sohel','178798745','07085122','1819210176')
# print(x.check_existance_by_ref('incident_tracker_v2','Incident_ID','INY00001138080'))
# df = pd.DataFrame(x.query_full_tbl('incident_tracker_v2'))
# x.bot_usr_delete('4','07085122')
#print(x.bot_usr_list('07085122'))
#
# vl = ""
# x.insert_new_entry('om_socbot_access',colnm,vl)
# print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11202020-30-XAQ-omsqlfn.py###

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            print('OK', 'listCols', 'listvalue')
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11222020-1528-XAQ-InsUpd.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os
from mysql import *
#from sqlalchemy import create_engine
import omsqlfn as fn
import os
from datetime import *
import datetime
import time

#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def get_key(my_dict, val): 
    for value, key in my_dict.items(): 
        if value == val:
            return key
        
def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)
            
#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)


def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + fn.prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def InsertUpdate(db, tbl, con, df, bycol = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            dfx = ndf.drop(bycol, 1)
            colsname = dfx.columns.to_list()
            colscond = ndf[bycol].to_list()
            q = 0
            for i in range(len(colscond)):
                vl = colscond[i]
                chk = CheckExist(con, tbl, bycol, vl)
                ls = []
                qry = ''
                if chk != 0:
                    for c1 in dfx:
                        ls.append(dfx.loc[i,c1])
                    qry = "update " + tbl + ' set ' + fn.prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                else:
                    for c1 in ndf:
                        ls.append(ndf.loc[i,c1])
                    qry = "insert into " + tbl + ' ' + fn.prep_insert(allcols,ls)
                cr.execute(qry)
                q = q + 1
                if q <3:
                    print(qry)
                con.commit()
                



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11232020-234-XAQ-InsUpd.py###
import pandas as pd
import os, datetime, time
from datetime import *
#import cx_Oracle, pyodbc, requests, os
#from mysql import *
#from sqlalchemy import create_engine


#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)

#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)

def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df

def qrybuilt(tbl, ndf, bycol):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            a1 = str(ncols[n])
            a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
            if y == '':
                y = a1 + '=' + a2
            else:
                y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry


def InsertUpdate(db, tbl, con, df, bycol = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, list):
                lsqry = qrybuilt(tbl, ndf, bycol)
                for i in range(len(lsqry)):
                    qry = lsqry[i]
                    try:
                        cr.execute(qry)
                    except:
                        print("failed lsqry get from 'def qrybuilt' ", qry)
                con.commit()
            elif isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()

def InsertUpdate_mod(db, tbl, con, df, bycol = False, oncols = False):
    allcols = []
    if oncols:
        allcols = oncols
    else:
        allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()
            elif isinstance(bycol, list): # ndf, bycol
                dfx = drop_cols(ndf, bycol)
                ncols = dfx.columns.to_list()
                lsqry = []
                for i in range(len(ndf)):
                    x = ''
                    y = ''
                    for j in range(len(bycol)):
                        x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
                        if x == '':
                            x = x1
                        else:
                            x = x + " and " + x1
                    for n in range(len(ncols)):
                        a1 = str(ncols[n])
                        a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                        if y == '':
                            y = a1 + '=' + a2
                        else:
                            y = y + "," + a1 + '=' + a2
                    qry = "update " + tbl + ' set ' + y + ' Where ' + x
                    lsqry.append(qry)
                    print('InsertUpdate_mod qry: ', qry)
                return lsqry

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11232020-310-XAQ-omsq.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        dbcols = []
        dbcolType = []
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['COLUMN_NAME'].to_list()
            dbcolType = dfx['DATA_TYPE'].to_list()
        except:
            qry = 'EXPLAIN ' + self.db + '.' + table
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['Field'].to_list()
            dbcolType = dfx['Type'].to_list()
        dc= zip(dbcols, dbcolType)
        self.tabledetails = dict(dc)
        return dbcols

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0

    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df

    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False, oncol = False):
        if bycols != False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols, oncol)
        if bycols == False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, oncols = oncol)
        if bycols != False and oncol == False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = [], condcols = []):
        if len(cols) == 0 and len(condcols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        elif len(cols) == 0 and len(condcols) !=0:
            self.Upd_or_Insert(tbl, dataframe, condcols)
        elif len(cols) != 0 and len(condcols) !=0:
            print(' built required')
            self.Upd_or_Insert(tbl, dataframe, condcols, cols)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()

    #def df_to_sql(df, tbl = None, cols = ['all_cols_of_df'], how = 'append', replaceby = []):
    def UpdateBulk(self, ndf, tbl, bycond_colname, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)

    def df_tosql(self, df, tblname, oncols = False, bycols = False):
        if self.is_table_exist(tblname) == 1:
            self.Upd_or_Insert(self, df, tblname, oncols, bycols)

    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11232020-66-XAQ-call_omsql.py###
import pandas as pd
import csv, os, time
from omsql.omsq import *
import omsql.omsqlite3 as sq3


def sqllite3():
    svpt = os.getcwd() + '\\VIP.csv'
    df = pd.read_csv(svpt)
    col = df.columns.to_list()
    mydb = os.getcwd() + '\\omsql\\' + 'oSqltdb.db'
    obj = sq3.sqlt3('oSqltdb.db', mydb)
    obj.createtable('VIP', col)
    obj.Export(df, 'VIP')
    print(obj.Read('select * from VIP'))


def for_contacts(svpt, tblname, colhead, srv = None):
    fl = open(svpt, 'r+')
    ls = []
    lns = 0
    for i in fl.readlines():
        x1= i.replace(',','')
        x2 = x1.replace('\n','')
        ls.append(x2)
        lns = lns + 1
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    print(df)
    print('waiting 10 sec to check....')
    col = df.columns.to_list()
    if srv == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
        print(x.col_and_type(tblname))
        x.df2sql(tblname,df)
        print(lns, df.shape[0], x.Getdf().shape[0])
    else:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        print(x.col_and_type(tblname))
        try:
            x.df2sql(tblname,df)
            print(lns, df.shape[0], x.Getdf().shape[0])
        except:
            print('fail')
    


def periodic_contacts(contact_With_cmd):
    x = ''
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is \n periodic,01817183XXX,add"
    tbl = 'PeriCon'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    try:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
    except:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        rs = x.Ex('select * from ' + tbl + " where Number = '" + fcn + "'")
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if cmd == None:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                x.InsertSingle(tbl, 'Number', fcn)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                x.DeleteByCond(tbl, 'Number', fcn)
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'
            

#print('bot send: ', periodic_contacts('periodic,717015682,remove'))

def for_csv2sql(csv_file_path, tblname):
    df = pd.read_csv(csv_file_path)
    x = ''
    #try:
        #x = omsql('root','admin','127.0.0.1:3306','omdb')
        #x.MySql()
    #except:
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    print(df)
    x.df2sql(tblname,df)
    qry = 'select * from ' + tblname
    print(x.Ex(qry))
    print(tblname)


svpt = os.getcwd() + '\\Contacts.txt' 
#for_contacts(svpt, 'PeriCon1', 'Number')   
    
pt2 = os.getcwd() + '\\VIP.csv'
#for_csv2sql(pt2,'VIP')

pt3 = os.getcwd() + '\\TOP5.csv'
#for_csv2sql(pt3,'TOP5')

pt4 = os.getcwd() + '\\IBS.csv'
#for_csv2sql(pt4,'IBS')

pt5 = os.getcwd() + '\\AB.csv'
#for_csv2sql(pt5,'ABHI')

pt5 = os.getcwd() + '\\RMT.csv'
#for_csv2sql(pt5,'RMT')

#ob = omsql('root','admin','127.0.0.1:3306','omdb')
#ob.MySql()
#csvfile = os.getcwd() + '\\AB.csv'
#df = pd.read_csv(csvfile)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11242020-02-XAQ-omsq.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class osql:
    def __init__(self, conn, table, db = None):
        



    

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0

    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        cmd = qry
        TS()
        try:
            df = pd.read_sql(qry, conn)
            rw = df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return df

    def setdf(self, ndf):
        df = ndf
        print('dataframe set to df')

    
    
    def InsertSingle(self, tbl, colname, values):
        cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', cmd)
        try:
            cur.execute(cmd)
            conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = [], condcols = []):
        if len(cols) == 0 and len(condcols) == 0:
            Upd_or_Insert(tbl, dataframe)
        elif len(cols) == 0 and len(condcols) !=0:
            Upd_or_Insert(tbl, dataframe, condcols)
        elif len(cols) != 0 and len(condcols) !=0:
            print(' built required')
            Upd_or_Insert(tbl, dataframe, condcols, cols)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        cmd = ''
        x = CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', cmd)
        else:
            cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', cmd)
        cur.execute(cmd)
        conn.commit()

    #def df_to_sql(df, tbl = None, cols = ['all_cols_of_df'], how = 'append', replaceby = []):
    def UpdateBulk(self, ndf, tbl, bycond_colname, oncols = False):
        if ndf == False:
            ndf = df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= engine)
        except:
            cur.execute(qry)
            dfx = pd.DataFrame(cur.fetchall())
        df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        cur.execute(xx)
        conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        cur.execute(qry)
        conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(df)
            df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(tabledetails)
        if by_cond_cols:
            Upd_or_Insert(tblname,df, by_cond_cols)
        else:
            Upd_or_Insert(tblname,df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            csv2sql(ndf, tblname, table_cols, table_dtype)

    def df_tosql(self, df, tblname, oncols = False, bycols = False):
        if is_table_exist(tblname) == 1:
            Upd_or_Insert(self, df, tblname, oncols, bycols)
        

    
def MySql(user, password, host):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    cur = conn.cursor()
    server = 'mysql'
    print('mysql conn successful')

def MsSql(user, password, host):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    TS(cstr)
    conn = pyodbc.connect(cstr)
    cur = conn.cursor()
    server = 'mssql'
    print('mssql conn success')

def Oracle(user, password):
    oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
    db = 'SEMDB'
    conn = cx_Oracle.connect(user, password, oHost)
    server = 'oracle'
    print(conn.version)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11252020-456-XAQ-omsqlfn.py###

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '' and len(lsval[i]) > 0 :
                    hp = x
                else:
                    if len(lsval[i]) > 0:
                        hp = hp + ',' + x
                    else:
                        pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11262020-1848-XAQ-InsUpd.py###
import pandas as pd
import os, datetime, time
from datetime import *

#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)

#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)

def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df

def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry


def InsertUpdate(db, tbl, con, df, bycol = False, oncols = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, list):
                if oncols != False:
                    lsqry = qrybuilt(tbl, ndf, bycol, oncols)
                else:
                    lsqry = qrybuilt(tbl, ndf, bycol)
                for i in range(len(lsqry)):
                    qry = lsqry[i]
                    try:
                        cr.execute(qry)
                    except:
                        print("failed lsqry get from 'def qrybuilt' ", qry)
                con.commit()
            elif isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()

def InsertUpdate_mod(db, tbl, con, df, bycol = False, oncols = False):
    allcols = []
    if oncols:
        allcols = oncols
    else:
        allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            if isinstance(bycol, str):
                dfx = ndf.drop(bycol, 1)
                colsname = dfx.columns.to_list()
                colscond = ndf[bycol].to_list()
                q = 0
                for i in range(len(colscond)):
                    vl = colscond[i]
                    chk = CheckExist(con, tbl, bycol, vl)
                    ls = []
                    qry = ''
                    if chk != 0:
                        for c1 in dfx:
                            ls.append(dfx.loc[i,c1])
                        qry = "update " + tbl + ' set ' + prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                    else:
                        for c1 in ndf:
                            ls.append(ndf.loc[i,c1])
                        qry = "insert into " + tbl + ' ' + prep_insert(allcols,ls)
                    cr.execute(qry)
                    q = q + 1
                    if q <3:
                        print(qry)
                    con.commit()
            elif isinstance(bycol, list): # ndf, bycol
                dfx = drop_cols(ndf, bycol)
                ncols = dfx.columns.to_list()
                lsqry = []
                for i in range(len(ndf)):
                    x = ''
                    y = ''
                    for j in range(len(bycol)):
                        x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
                        if x == '':
                            x = x1
                        else:
                            x = x + " and " + x1
                    for n in range(len(ncols)):
                        a1 = str(ncols[n])
                        a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                        if y == '':
                            y = a1 + '=' + a2
                        else:
                            y = y + "," + a1 + '=' + a2
                    qry = "update " + tbl + ' set ' + y + ' Where ' + x
                    lsqry.append(qry)
                    print('InsertUpdate_mod qry: ', qry)
                return lsqry

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11262020-648-XAQ-upin.py###
import pandas as pd
import numpy as np
import os

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    er = 0
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                er = er + 1
                print('error sql: ', qry)
                if er > 5:
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11272020-327-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11272020-44-XAQ-semqry.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
from datetime import timedelta
from datetime import datetime
pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
pntxt = pt + '\\' + 'pntxt.txt'
savedirr = pt + '\\' + 'OMTX.csv'


print(ExTime)

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def day_diff(diff):
    d = datetime.now() + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def qry_all_active(tbl,usr, pas, selcol,Q3=False):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = day_diff(-7)
    dy_f = day_diff(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]
    df1.to_csv(savedirr)
    print(savedirr)
    return df1

def qry_all_last_day(tbl,usr, pas, selcol,Q3):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    d1 = datetime.now() + timedelta(days=-1)
    dy_p = d1.strftime("%d-%b-%Y")
    d2 = datetime.now() + timedelta(days=1)
    dy_f = d2.strftime("%d-%b-%Y")
    Q1 = "FROM " + tbl + " WHERE TYPE=1 " #AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2 + Q3
    print(QF)
    print('----------------')
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    print('start at ', curr_tm)
    df = pd.read_sql(QF, con=conn)
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    print('start at ', curr_tm)
    df1 = df[['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','EventId','X733CorrNotif','X733EventType','X733ProbableCause','X733SpecificProb','CorrelateTopologyKey','TTSequence','TTStatus','TTUpdate','TTUser','CustomAttr10','CustomAttr11','CustomAttr12','CustomAttr13','CustomAttr5','CustomAttr26']]
    df1.to_csv(savedirr)
    print(savedirr)
    return df1

def qry_all():
    df = qry_all_last_day('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * '," AND AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')")
    return df

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11282020-1949-XAQ-omdf_call.py###
import pandas as pd
import numpy as np
import os
from mysql import *
from sqlalchemy import create_engine

def myFun(arg1, *argv, **kwargs): 
    print ("First argument :", arg1) 
    for arg in argv: 
        print("Next argument through *argv :", arg)

def oFn1(df, *argv, **kwargs):
    #*argv = df column names
    #**kwargs = df columns values
    print(df.columns)
    ls = []
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
            print(ls)
        print(ls)
    #for i in range(len(colname)):
    #print(colname[i])
def AA():
    db = os.getcwd() + "\\OMDB.csv"
    livedb = os.getcwd() + "\\robi_live.csv"
    xa = os.getcwd() + "\\xa.csv"
    sclick = os.getcwd() + "\\sclick.csv"
    df = pd.read_csv(sclick)
    ls_sclick = ['Severity','Node','Resource']
    dc_sclick = {'Severity': 'Severity','Node':'Node','Resource':'Resource'}
    oFn1(df, ls_sclick, one = '1', two = '2', )





def MySql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "om2"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine


pth = os.getcwd() + "\\OMTX.csv"
pth2 = os.getcwd() + "\\OMT.csv"
df = pd.read_csv(pth, low_memory=False)
ndf = df[['SERIAL','IDENTIFIER','NODE','AGENT','ALERTGROUP','SEVERITY','LOCALSECOBJ','X733EVENTTYPE','X733SPECIFICPROB','MANAGEDOBJCLASS','GEOINFO','CUSTOMATTR3','CUSTOMATTR5','CUSTOMATTR25','TTSEQUENCE','TTSTATUS','SRCDOMAIN','CUSTOMATTR26','OUTAGEDURATION','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']]
ndf.to_csv(pth2)
conn = MySql()
#= ndf.convert_dtypes()
ndf.to_sql("big5", con = conn,  if_exists = 'append', index= False, chunksize=5000)






$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\11282020-2218-XAQ-fnfn.py###
import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1


def conct(df, col1, col2, newcolname, seperator=False):
    if seperator == False:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2])
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2], sep=seperator)
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')


def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')


def map_df_dic(df0, dc, onkey_col, newcolname):
    df = add_col_df (df0, newcolname)
    df[newcolname] = df[onkey_col].map (dc)
    return df


def df_add_list_col(df, nc, nwlst):
    dfx = add_col_df (df, nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array (nwlst)
    return dfx


def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.drop_duplicates (subset=list_of_columns)
    return df


def sort_dsc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.sort_values (by=oncol, ascending=False)


def sort_asc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df = df.sort_values (by=oncol, ascending=True)
    return df


def left(df, sdf, i):
    df1 = add_col_df (df, 'left_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[0:i])
    return df1


def right(df, sdf, i):
    df1 = add_col_df (df, 'right_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[-i:len (x)])
    return df1


def vlookup(df0, refdic, refcol, nwcol):
    if isinstance (refdic, dict):
        try:
            df = add_col_df (df0, nwcol)
            df[nwcol] = df.reset_index ()[refcol].map (refdic).values
            return df
        except:
            df = map_df_dic (df0, refdic, refcol, nwcol)
            return df
    else:
        ndf = df0.merge (refdic, on=refcol)
        return ndf


def countifz(df, list_of_cols_as_ref, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[st].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[col].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def datediff(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")


def aplist(L1, L2):
    #L1 = List/df series
    #l2 = List/String
    ls = []
    if isinstance (L1, pd.core.series.Series) and isinstance (L2, pd.core.series.Series):
        ls1 = L1.to_list ()
        ls2 = L2.to_list ()
        ls = [i + j for i, j in zip (ls1, ls2)]
    elif isinstance (L1, list) and isinstance (L2, list):
        ls = [i + j for i, j in zip (L1, L2)]
    elif isinstance (L1, pd.core.series.Series) and isinstance (L2, str):
        ls1 = L1.to_list ()
        for i in range (len (ls1)):
            ni = str (ls1[i]) + L2
            ls.append (ni)
    elif isinstance (L1, list) and isinstance (L2, str):
        for i in range (len (L1)):
            ni = str (L1[i]) + L2
            ls.append (ni)
    else:
        print ('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls


def countifs(df0, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            df2 = df1.groupby (['NC1']).NC1.count ().to_frame (name='cnt').reset_index ()
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt


def match(df, *argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len (argv) > 0 and len (argv) <= 3:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str) or isinstance (argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list ()
            for i in range (len (colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance (argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len (idx)
                    if manner == 'last':
                        return idx[ln - 1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx


def sumifz(df, list_of_cols_as_ref, numeric_col, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def instr(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.find (srcvalue)
        return f
    else:
        f = strtext.find (srcvalue)
        return f

def instrrev(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.rfind (srcvalue)
        return f
    else:
        f = strtext.rfind (srcvalue)
        return f


def sumifs(df0, numeric_col, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            print (ls)
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            print (df1)
            df2 = df1.groupby (['NC1'])[numeric_col].sum ().to_frame (name='sumifs').reset_index ()
            print (df2)
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1172020-137-XAQ-conn_brocker.py###

import socket
import threading
import sys


def handle(buffer):
    return buffer


def transfer(src, dst, direction):
    src_name = src.getsockname()
    src_address = src_name[0]
    src_port = src_name[1]
    dst_name = dst.getsockname()
    dst_address = dst_name[0]
    dst_port = dst_name[1]
    while True:
        buffer = src.recv(0x400)
        if len(buffer) == 0:
            print("[-] No data received! Breaking...")
            break
        if direction:
            print(f"[+] {src_address}:{src_port} >>> {dst_address}:{dst_port} [{len(buffer)}]")
        else:
            print(f"[+] {dst_address}:{dst_port} <<< {src_address}:{src_port} [{len(buffer)}]")
        dst.send(handle(buffer))
    print(f"[+] Closing connections! [{src_address}:{src_port}]")
    src.shutdown(socket.SHUT_RDWR)
    src.close()
    print(f"[+] Closing connections! [{dst_address}:{dst_port}]")
    dst.shutdown(socket.SHUT_RDWR)
    dst.close()


def server(local_host, local_port, remote_host, remote_port, max_connection):
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    server_socket.bind((local_host, local_port))
    server_socket.listen(max_connection)
    print(f"[+] Server started [{local_host}:{local_port}]")
    print(f"[+] Connected to [{local_host}:{local_port}] to get the content of [{remote_host}:{remote_port}]")
    while True:
        local_socket, local_address = server_socket.accept()
        print(f"[+] Detect connection from [{local_address[0]}:{local_address[1]}]")
        print(f"[+] Connecting to the REMOTE server [{remote_host}:{remote_port}]")
        remote_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        remote_socket.connect((remote_host, remote_port))
        print("[+] Tunnel connected! Transferring data...")
        # threads = []
        s = threading.Thread(target=transfer, args=(
            remote_socket, local_socket, False))
        r = threading.Thread(target=transfer, args=(
            local_socket, remote_socket, True))
        # threads.append(s)
        # threads.append(r)
        s.start()
        r.start()
    print("[+] Releasing resources...")
    remote_socket.shutdown(socket.SHUT_RDWR)
    remote_socket.close()
    local_socket.shutdown(socket.SHUT_RDWR)
    local_socket.close()
    print("[+] Closing the server...")
    server_socket.shutdown(socket.SHUT_RDWR)
    server_socket.close()
    print("[+] Shutting down the server!")


def main(*argv):
    if len(argv) == 4:
        print("Usage : ")
        print(f"\tpython {sys.argv[0]} [L_HOST] [L_PORT] [R_HOST] [R_PORT]")
        print("Example : ")
        print(f"\tpython {sys.argv[0]} 127.0.0.1 8888 127.0.0.1 22")
        print("Author : ")
        print("\tWangYihang <wangyihanger@gmail.com>")
        print("\nNB! Requires Python 3.6 or above.")
        exit(1)
    LOCAL_HOST = sys.argv[1]
    LOCAL_PORT = int(sys.argv[2])
    REMOTE_HOST = sys.argv[3]
    REMOTE_PORT = int(sys.argv[4])
    MAX_CONNECTION = 0x10
    server(LOCAL_HOST, LOCAL_PORT, REMOTE_HOST, REMOTE_PORT, MAX_CONNECTION)


#if __name__ == "__main__":
    #main()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1172020-1847-XAQ-Test.py###
from datetime import *
from dateutil.relativedelta import *
from dateutil.easter import *
from dateutil.rrule import *
from dateutil.parser import *


def PTM(d,fmt):
    if isinstance(d,str):
        tm = parse(d)
        #print(type(tm),tm)
        str_d = tm.strftime(fmt)
        print(str_d)
    else:
        d1 = d
        d = str(d1)
        tm = parse(d1)
        #print(type(tm),tm)
        str_d = tm.strftime(fmt)
        print(str_d)

D1 = "2020-11-07 04:05:00"
D2 = "07-11-2020 05:12:00"
PTM(D1,"%Y-%m-%d %H:%M:%S")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1636-XAQ-tbot_single_site_status.py###
import pandas as pd
import cx_Oracle

def query(code):
    conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn)
    qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
    Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,
    ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
    where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
    and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
    and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%"""
    qry2 = qry1 + code + "%'"
    try:
        df = pd.read_sql(qry2, con=conn)
        print('try success')
        conn.close()
    except:
        connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        df = pd.read_sql(qry2, con=connx)
        print('Except trigger')
        connx.close()
    print(df)
    rows = df.shape[0]
    heap = code + ":"
    if rows != 0:
        for i in range(0, len(df)):
            tech = df.iloc[i]['TECHNOLOGY']
            tm = df.iloc[i]['STARTTIME']
            if '2G' in tech:
                heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
            if '3G' in tech:
                heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
            if '4G' in tech:
                heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
            # print(heap)
    else:
        return heap + '\nAll Tech are up'
    return heap
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1755-XAQ-upin.py###
import pandas as pd
import numpy as np
import os
from write2text import *


def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operations = "and"):
    cr = conn.cursor()
    er = 0
    lser = []
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                lser.append(qry)
                er = er + 1
                print('error sql: ', qry)
                if er > 500:
                    wrt2txt(excmd, 'exe_error')
                    print('exiting as error greater than 500 rows')
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1820-XAQ-single_sql.py###
import pandas as pd
import requests, os, time

def prep_updatex(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '' and len(lsval[i]) > 0 :
                    hp = x
                else:
                    if len(lsval[i]) > 0:
                        hp = hp + ',' + x
                    else:
                        pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insertx(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))


def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def Update_insert_single(conn, tbl, listcols, listvalue, bycol, bycolv):
    cur = conn.cursor()
    cmd = ''
    x = CheckExist(conn, tbl, bycol, bycolv)
    if x != 0:
        cmd = "update " + tbl + ' set ' + prep_updatex(listcols, listvalue) + ' where ' + bycol + "='" + bycolv + "'"
        print('Existing rows found, proceed for update', cmd)
    else:
        cmd = "insert into " + tbl + ' ' + prep_insertx(listcols, listvalue)
        print('no existing value found, proceed for insert \n', cmd)
    cur.execute(cmd)
    conn.commit()

def Query(conn, tbl, Ex = False, colname = False, condition = False):
    cur = conn.cursor()
    if Ex:
        if isinstance(Ex, str):
            df = pd.read_sql(Ex, conn)
            return df
            exit()
    if colname != False and tbl != None:
        x = ''
        qry = ''
        if isinstance(colname, list):
            for i in range(len(colname)):
                if x == '':
                    x = colname[i]
                else:
                    x = x + "," + colname[i]
        else:
            x = str(colname)
        if condition != False:
            y = ''
            if isinstance(condition, list):
                for i in range(len(condition)):
                    if y == '':
                        x = condition[i]
                    else:
                        y = y + " and " + condition[i]
                qry = "select " + x + " from " + tbl + " where " + y
            else:
                y = str(condition)
                qry = "select " + x + " from " + tbl + " where " + y
    print('query: ', qry)
    dfx = pd.read_sql(qry, con= conn)
    return dfx

def DeleteByCond(conn, tbl, col, cond):
    xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
    cur = conn.cursor()
    cur.execute(xx)
    conn.commit()

def DeleteDuplicate(conn, tbl, cond_col):
    qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
    cur = conn.cursor()
    cur.execute(qry)
    conn.commit()

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#conn = MySql('root','admin','127.0.0.1:3306','omdb')
#print(Query(conn, tbl = 'mytable', Ex = "select * from eve"))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']), condition = " Zone Like 'BAR'")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1212020-1916-XAQ-df_to_sql.py###
import pandas as pd
import numpy as np
import os
import datetime
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    try:
        qry = "select * from " + tbl + " where " + colname + " LIKE '" + values + "'"
        dfx = pd.read_sql(qry, conn)
        rw = dfx.shape[0]
        return rw
    except:
        qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        dfx = pd.read_sql(qry, conn)
        rw = dfx.shape[0]
        return rw
        

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operations = "and"):
    cr = conn.cursor()
    er = 0
    lser = []
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            try:
                dfx = pd.read_sql(qr, conn)
            except:
                x = qr.find('where ')
                qr0 = qr[0:x]
                qr1 = qr[x:len(qr)]
                qr2 = qr1.replace("=", " LIKE ")
                qrf = qr0 + qr2
                dfx = pd.read_sql(qrf, conn)
                
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                lser.append(qry)
                er = er + 1
                print('error sql: ', qry)
                if er > 500:
                    wrt2txt(excmd, 'exe_error')
                    print('exiting as error greater than 500 rows')
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + " Like '" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry

def get_server_name(db, table, conn):
    try:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con = conn)
        return "MYSQL"
    except:
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= conn)
            return "MSSQL"
        except:
            return "only MYSQL and MSSQL is Supported"

def mssql_table_colname(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    return dbcols

def mssql_table_colinfo(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    dbcolType = dfx['DATA_TYPE'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic


def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key
            
def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                pass
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def fuzzymatch(str1,str2, uplow = True):
    if uplow == True:
        s1 = str1.lower()
        s2 = str2.lower()
        ls1 = []
        ls2 = []
        for i in s1:
            ls1.append(i)
        for n in s2:
            ls2.append(n)
        q = 0
        succ = 0
        fail = 0
        if len(ls1) <= len(ls2):
            for j in range(len(ls1)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        else:
             for j in range(len(ls2)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        try:
            spercent = round((succ/q)*100,2)
        except:
            spercent = 0
        return spercent

def colchk_dbdf(coldb = [], coldf = []):
    if isinstance(coldb, list) and isinstance(coldf, list):
        cdb = coldb
        cdf = coldf
        cdb.sort
        coldf.sort
        nonmat = []
        for i in range(len(cdb)):
            d1 = cdb[i]
            mat = 0
            for j in range(len(cdf)):
                if d1 == cdf[j]:
                    mat = 1
                    break
            if mat == 0:
                nonmat.append(d1)
        return nonmat

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""


def df_to_sql(dataframe, dbname, tablename, conn, oncolumn = "ALL", bycolumn = None, opeation = 'and'):
    srv = get_server_name(dbname, tablename, conn)
    print(srv)
    if srv == 'other':
        exit()
    cr = conn.cursor()
    try:
        cr.execute('select 1 from '+ tablename)
    except:
        print('table does not exits')
        exit()
    if isinstance(oncolumn, list) or oncolumn != 'ALL' and bycolumn == None:
        dataframe = dataframe[oncolumn]
    ndf = dataframe.replace(r'^\s*$', np.nan, regex=True)
    xdf = ndf.convert_dtypes()
    dfcol = xdf.columns.to_list()
    if srv == "MYSQL":
        dbcol = mysql_table_colname(dbname, tablename, conn) #function call
    elif srv == "MSSQL":
        dbcol = mssql_table_colname(dbname, tablename, conn) #function call
    nonmat = colchk_dbdf(dbcol,dfcol)
    dfc = []
    rnmcol = {}
    if len(nonmat) != 0:
        for n in range(len(nonmat)):
            dbc = nonmat[n]
            y = 0
            for i in range(len(dfcol)):
                x = fuzzymatch(dbc, dfcol[i])
                #print(dbc,' - ',  dfcol[i], ' p- ', x, ' max ', y)
                if x >= y:
                    y = x
                    dfcl = dfcol[i]
            else:
                dfc.append(dfcl)
                rnmcol[dfcl] = dbc
    xdf = xdf.rename(columns = rnmcol)
    if srv == "MYSQL":
        dc = mysql_table_colinfo(dbname, tablename, conn)  #mysql function call
    elif srv == "MSSQL":
        dc = mssql_table_colinfo(dbname, tablename, conn)  #mysql function call
    df = dtype_match_dbdf(xdf, dc) #function call
    if bycolumn == None:
        excmd = []
        q = 0
        rwval = []
        colval = df.columns.to_list()
        er = []
        for (indx, rwseries) in df.iterrows():
            q = q + 1
            rwval = rwseries.values.tolist()
            x = insert_into_sql(tablename, dc, colval, rwval)
            try:
                cr.execute(x)
                excmd.append(x)
            except:
                er.append(x)
                qq = "dfrow: " + str(q)
                er.insert(0, qq)
        print('row inserted: ', q - len(er), ' error found for rows: ', len(er), ", get error in return")
        wrt2txt(excmd, 'exe_succ')
        wrt2txt(excmd, 'exe_fail')
        return er
    else:
        tableprop = dc
        excmd = UPIN(df, tablename, tableprop, conn, bycols = bycolumn, operations = 'and')
        wrt2txt(excmd, 'exe_succ')





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\12192020-1922-XAQ-fluc.py###
import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *
import malsem as sem

#print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
#df = pd.read_csv(os.getcwd() + "\\B1.csv")
#nw = datetime.now()



TS1 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('2' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('3' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('4' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))

TS2 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('22' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('33' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('44' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))


DCAT = lambda x: 'H2' if (x < 300) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    df2.to_csv(os.getcwd() + "\\P3.csv", index = False)
    df3 = df2.drop_duplicates(subset=['CD_TM_CT2'], inplace=False, ignore_index=True)
    df3 = df3.reset_index()
    df4 = df3.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    df4 = df4.reset_index()
    df4.to_csv(os.getcwd() + "\\P5.csv", index = False)
    return df4

def Part2(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    #df.to_csv(os.getcwd() + "\\P6.csv", index = False)
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\"IAMPY".csv", index = False)
    #df['H12'] = df['H12'].fillna(0, inplace=True)
    #df['H2'] = df['H2'].fillna(0, inplace=True)
    print(df)
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    

#pvt = fdf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt', aggfunc='sum').reset_index()
df = sem.semqry()
fdf = extrafeat(df)
Part2(fdf)
#pvt(fdf)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1222020-182-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1222020-342-XAQ-write2text.py###
import os
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', fpath = None):
    if filename is None:
        filename = "X"
    if fpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    else:
        flpath = fpath + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
        return flpath
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
            return flpath
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))
            return "failed"
    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1222020-910-XAQ-mssql.py###
import pandas as pd
import pyodbc
from datetime import *

soc = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#soc = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"

def chk_exist(qry):
    conn = pyodbc.connect(soc)
    df = pd.read_sql(qry, con=conn)
    return df.shape[0]

def exqry(qr):
    conn = pyodbc.connect(soc)
    cr = conn.cursor()
    print(qr)
    st = 'does not exist'
    if 'select' in qr:
        cr.execute(qr)
        rs = cr.fetchone()
        try:
            for i in rs:
                if st == 'does not exist':
                    st = i
                else:
                    st = st + ' | ' + i
            return st
        except:
            return st
    else:
        if isinstance(qr, str):
            try:
                cr.execute(qr)
                conn.commit()
                return 'successfully'
            except:
                print(qr, 'failed')
                return ''
        elif isinstance(qr, list):
            cnt = 0
            for i in range(len(qr)):
                try:
                    cr.execute(qr)
                    cnt = cnt + 1
                except:
                    pass
            else:
                st = cnt + ' rows modified successfully'
                return st
        
def execute_qry(qq, colname=[]):
    conn = pyodbc.connect(soc)
    print('query execute- ', qq)
    if "select" in qq:
        df = pd.read_sql(qq, con=conn)
        heap = ''
        ls = []
        if len(colname) != 0:
            dfx = df[colname]
            df = dfx
        print(df)
        if df.shape[0] > 1:
            for i in range(len(df)):
                hp = ''
                for j in df:
                    if hp == '':
                        hp = df.loc[i, j]
                    else:
                        hp = hp + ',' + df.loc[i, j]
                if heap == '':
                    heap = hp
                elif len(heap) < 3500:
                    heap = heap + chr(10) + hp
                else:
                    ls.append(heap)
                    heap = ''
            else:
                ls.append(heap)
                return ls
        elif df.shape[0] == 1:
            hp = ''
            for i in df:
                if hp == '':
                    hp = df.loc[0, i]
                else:
                    hp = hp + chr(10) + df.loc[0, i]
            return hp
        else:
            return 'not exist'
    elif "update" in qq or "delete" in qq:
        cr = conn.cursor()
        try:
            cr.execute(qq)
            conn.commit()
            return "successful"
        except:
            return "failed"
    else:
        cr = conn.cursor()
        cr.execute(qq)

def qry_code_name(code, cols = []):
    qry = "select Site_Name from sitebase where Site_Code LIKE '%" + code + "%'"
    conn = pyodbc.connect(soc)
    cr = conn.cursor()
    st = ''
    try:
        cr.execute(qry)
        rs = cr.fetchone()
        for i in rs:
            if st == '':
                st = i
            else:
                st = st + ", " + i
            return st
    except:
        return ""

def qry_select(tx2, omv):
    qry = ''
    qy = ''
    tbl = ''
    if 'CONTACT' in tx2 or 'CONTACTS' in tx2:
        qry = "select Number from PeriCon where Number LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' periodic contacts'
    elif "ABH" in tx2 or 'ABHIGHTECH' in tx2:
        qry = "select Code from ABHI where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' AB hi-tech'
    elif "RMT" in tx2 or 'ROBIMT' in tx2:
        qry = "select Code,Name from RMT where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' robi mt'
    elif "VIP" in tx2:
        qry = "select Code,Name from VIP where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' vip'
    elif "TOP5" in tx2:
        qry = "select Code,Name from TOP5 where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = ' vip top5'
    elif "EXCEPTION" in tx2:
        qry = "select code from EXCEPTION where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
        tbl = 'EXCEPTION '
    else:
        txx = tx2.split(',')
        qry = "select * from " + txx[1] + "where Code LIKE '%" + omv + "%'"
        qy = exqry(qry)
    if str(omv) in str(qy):
        return omv + ' already exist in' + tbl
    else:
        return omv + ' does not exist in' + tbl

def qry_add(tx2, omv):
    qry = ''
    sitename = ''
    result = qry_select(tx2, omv)
    if 'does not exist' in result:
        if 'CONTACT' in tx2:
            qry = "insert into PeriCon (Number) values ('" + omv + "')"
            tbl = " in periodic contacts "
        elif "ABH" in tx2:
            qry = "insert into ABHI (Code) values ('" + omv + "')"
            tbl = " in ab-hitech  "
        elif "RMT" in tx2:
            sitename = qry_code_name(omv)
            qry = "insert into RMT (Code,Name) values ('" + omv + "','" + sitename + "')"
            tbl = " in RMT  "
        elif "VIP" in tx2:
            sitename = qry_code_name(omv)
            qry = "insert into VIP (Code,Name) values ('" + omv + "','" + sitename + "')"
            tbl = " in VIP  "
        elif "VIPTOP5" in tx2:
            sitename = qry_code_name(omv)
            qry = "insert into TOP5 (Code,Name) values ('" + omv + "','" + sitename + "')"
            tbl = " in VIPTO5  "
        elif "EXCEPTION" in tx2:
            qry = "insert into EXCEPTION (code,reason) values ('" + omv + "','" + "" + "')"
            tbl = " in EXCEPTION "
        if qry != '':
            rs = exqry(qry)
            if 'failed' not in rs:
                return 'added ' + omv + tbl + rs
            else:
                return 'adding failed - ' + omv + tbl + rs
    else:
        return result

def qry_delete(tx2, omv):
    qry = ''
    result = qry_select(tx2, omv)
    print('chk result', result)
    if 'does not exist' not in result:
        if 'CONTACT' in tx2:
            qry = "DELETE FROM PeriCon WHERE Number Like '" + omv + "'"
            tbl = " from periodic contacts "
        elif "ABH" in tx2:
            qry = "DELETE FROM ABHI WHERE Code Like '" + omv + "'"
            tbl = " from ABHI-TECH "
        elif "RMT" in tx2:
            qry = "DELETE FROM RMT WHERE Code Like '" + omv + "'"
            tbl = " from Robi top MGT "
        elif "VIP" in tx2:
            qry = "DELETE FROM VIP WHERE Code Like '" + omv + "'"
            tbl = " from VIP "
        elif "VIPTOP5" in tx2:
            qry = "DELETE FROM TOP5 WHERE Code Like '" + omv + "'"
            tbl = " from VIP-TOP5 "
        elif "EXCEPTION" in tx2:
            qry = "DELETE FROM EXCEPTION WHERE code Like '" + omv + "'"
            tbl = " from EXCEPTION "
        if qry != '':
            rs = exqry(qry)
            return 'removed ' + omv + tbl + rs
        else:
            return 'failed'
    else:
        return result



def auth_check_db(uid):
    conn = pyodbc.connect(soc)
    qry = "select * from om_socbot_access"
    df1 = pd.read_sql(qry, con=conn)
    df = df1[df1['UID'].str.contains(uid)]
    x = df.shape[0]
    conn.close()
    if x == 0:
        return 0
    else:
        return 1


def query_code_or_ms(tx):
    try:
        if ',' in tx:
            txx = tx.split(',')
            xx = str(txx[2])
            xxy = xx.strip(' ')
            print('xx - ', xxy)
            return xxy
        else:
            txx = tx.split(' ')
            xx = str(txx[2])
            if len(xx) == 10 or len(xx) == 11:
                return xx
            else:
                return ""
    except:
        return ""

def private_add_rmv_upd(txt, ty='text'):
    print('private_add_rmv_upd')
    if ty == 'text':
        tx1 = txt.upper()
        rs = query_code_or_ms(tx1)
        print(rs)
        qx = ''
        qy = ''
        if rs != '':
            if 'CHK' in tx1:
                qx = qry_select(tx1, rs)
                return qx
            elif 'RMV' in tx1:
                qx = qry_delete(tx1, rs)
                return qx
            elif 'ADD' in tx1:
                qx = qry_add(tx1, rs)
                return qx
        else:
            return "NA"
    else:
        print('x')



def rpa_help():
    rpachk = ["chk, VIP, PBSDR01", "chk, ABHITECH, KHSDR56", "chk, TOP5, DHGUL19", "chk, contact, 01817183680", "chk, RMT, DHGULF2", "chk, exception, DHGULF2"]
    rpaadd = ["add, VIP, PBSDR01", "add, ABHITECH, PBSDR01", "add, TOP5, PBSDR01", "add, contact, 01717015682", "add, RMT, DHGULF0", "add, exception, DHGULF2"]
    rparmv = ["rmv, VIP, PBSDR01", "rmv, ABHITECH, PBSDR01", "rmv, TOP5, PBSDR01", "rmv, contact, 01717015682", "rmv, RMT, DHGULF0", "rmv, exception, DHGULF2"]
    st = ''
    for i in range(len(rpachk)):
        st1 = rpachk[i]
        st2 = rpaadd[i]
        st3 = rparmv[i]
        if st =='':
            st = st1 + chr(10) + st2 + chr(10) + st3
        else:
            st = st + chr(10) + st1 + chr(10) + st2 + chr(10) + st3
    else:
        return st
    

def priority(txt):
    tx2 = txt.upper()
    qq = ''
    if tx2 == "RWS":
        qq = "select TOP 1 msgtext from rpa_msg where msghead ='update s' ORDER BY SL DESC"
    elif tx2 == "P1":
        qq = "select TOP 1 msgtext from rpa_msg where msghead ='update p1' ORDER BY SL DESC"
    elif tx2 == "P2":
        qq = "select TOP 1 msgtext from rpa_msg where msghead ='update p2' ORDER BY SL DESC"
    if qq != '':
        rs = exqry(qq)
        if rs != '':
            return rs
        else:
            return "database update on going, please try later"
        

def auser(msg1):
    td = datetime.now()
    tday = td.strftime('%Y-%m-%d')
    msgspl = msg1.split(',')
    colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
    valu = "'" + msgspl[1] + "','" + str(msgspl[2]) + "','" + str(tday) + "','" + str(msgspl[3]) + "','Y','N','N'"
    qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
    return qry

def duser(msg1):
    tx1  = msg1.lower()
    tx = tx1.split(",")
    qr = "delete from om_socbot_access where "
    qr1 = ''
    if 'msisdn' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('msisdn=','')
        qr1 = qr + "MSISDN LIKE '%" + str(txx) + "%'"
    elif 'name' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('name=','')
        qr1 = qr + "NAME LIKE '%" + str(txx) + "%'"
    elif 'id' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('id=','')
        qr1 = qr + "UID LIKE '%" + str(txx) + "%'"
    return qr1

def qryusers(txt):
    qr1 = ''
    qr = "select NAME,UID,MSISDN from om_socbot_access where "
    tx = txt.split(",")
    if 'msisdn' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('msisdn=','')
        qr1 = qr + "MSISDN LIKE '%" + str(txx) + "%'"
    elif 'name' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('name=','')
        qr1 = qr + "NAME LIKE '%" + str(txx) + "%'"
    elif 'id' in tx[1]:
        txx1 = tx[1].replace(' ','')
        txx  = txx1.replace('id=','')
        qr1 = qr + "UID LIKE '%" + str(txx) + "%'"
    print(qr1)
    return qr1
    
def usrctrl(tx):
    print(tx)
    txt = tx.lower()
    st = "qry reply"
    if 'rmvu' in txt or 'RMVU' in txt:
        qry = duser(txt)
        z = execute_qry(qry)
        return z
    if 'addu' in txt or 'ADDU' in txt:
        qry = auser(txt)
        z = execute_qry(qry)
        return z
    if 'qryu' in txt or 'QRYU' in txt:
        qry = qryusers(txt)
        rs = execute_qry(qry)
        if isinstance(rs, list):
            x = wrt2txt(rs, filename = 'usrctrl')
            print('path--', x)
            return x
        else:
            return rs
        

#usrctrl("adduser,Ashiq,782541759,01833181485")
#usrctrl("adduser,Shahriar,611926049,01833181818")
#usrctrl("adduser,mamun,584678769,01817183461")
#usrctrl("adduser,Halim,667675107,01819210773")
#usrctrl("adduser,Alauddin,682665140,01819550506")
#usrctrl("adduser,Antu,773107608,01833182291")
#usrctrl("adduser,Tamanna,680694380,8801817184334")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\12232020-1839-XAQ-oDT.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M:%S")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
        df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\12242020-417-XAQ-oDT.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import oFn.fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            df1 = fnx.add_col_df(df, 'newcol')
            df1[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df1 = fnx.add_col_df(df, 'newcol')
        df1[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-102-XAQ-fluc.py###
import sys, os
import pandas as pd
import MySQLdb
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
from oDT import *
import fnfn as fx

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
conn = MySQLdb.connect ("localhost", "root", "admin", "om2")


def hr_minus(diff):
    n = datetime.now ()
    d = n - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d


def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list ()
    for n in range (len (argv)):
        TempLs = df[argv[n]].values.tolist ()
        if len (ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip (ls, TempLs)]
            ls = tls
    ld = []
    for key, value in kwargs.items ():
        if col.count (value) != 0:
            TmpLd = df[value].to_list ()
            if len (ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip (ld, TmpLd)]
                ld = tld
        else:
            ar = np.full (df.shape[0], value)
            TmpLd = ar.tolist ()
            if len (ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip (ld, TmpLd)]
                ld = tld
    fls = []
    for i in range (len (ld)):
        x = ls.count (ld[i])
        fls.append (x)
    colx = 'C' + str (df.shape[1])
    df[colx] = np.array (fls)
    return df


def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines ():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: '2H' if (x < 120) \
    else ('4H' if (x < 240)\
    else ('6H' if (x < 360)\
    else ('12H' if (x < 720)\
    else ('24H' if (x < 1440)\
    else ('48H' if (x < 2880)\
    else ('72H'))))))

TS = lambda x: '2G' if ('2G' in x) \
    else ('3G' if ('3G' in x) \
    else ('4G' if ('4G' in x) \
    else ('OML' if ('2G' in x) \
    else "other")))

def duration(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def catmap_mod(df):
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    ndf = countifs (xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs (ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    

def catmap(df):
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        xdf = df2[df2['CAT'].isin (['2', '3', '4','22', '33', '44'])]
    except:
        try:
            xdf = df2[df2['CATX'].isin (['2', '3', '4','22', '33', '44'])]
        except:
            xdf = df2[df2['CATX'].isin (['2G', '3G', '4G'])]
    xdf.to_csv(os.getcwd () + "\\C7.csv")
    xdf = xdf.convert_dtypes()
    return xdf

def fluc(df):
    dfx = catmap(df)
    print('1')
    try:
        xdy = DateDiff(dfx, "DUR", "LASTOCCURRENCE")
    except:
        xdy = datediff_ondf(dfx, "DUR", 'LASTOCCURRENCE')
    xdf = duration(xdy)
    xdf.to_csv (os.getcwd () + "\\A2.csv", index=False)
    xdf = xdf.replace (np.nan, 0)
    ndf = countifs (xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    ndf.to_csv (os.getcwd () + "\\FINAL0.csv", index=False)
    ndf = ndf.sort_values (by='CAT', inplace=True, ascending=True)
    dfz = ndf.drop_duplicates (subset=['CATX', 'CDLO'], keep='first', inplace=True)
    dfz.to_csv (os.getcwd () + "\\A3.csv", index=False)
    dfy = pd.read_csv (os.getcwd () + "\\A3.csv")
    dfy.to_csv (os.getcwd () + "\\FINAL1.csv", index=False)
    return ndf



svpt = os.getcwd () + "\\OMTX.csv"
df = pd.read_csv (svpt, low_memory=False)
df1 = catmap_mod(df)
print('done')
#print(xdf)
#PP(xdf)
#print(df1['LASTOCCURRENCE'])
#print('df1 get')
#df2 = duration(df1)
#xy = duration(ddf)
#ddfx = pd.read_csv (svpt2)
#df = xx (ddfx)
# print(df)
#df = ndf.convert_dtypes ()

# df4['NW'] = df4.apply(lambda x: x.DURCAT + x.AB, axis = 1)
# df5 = df4[df4['NW'].isin(['<12H10','<2H2'])]
# print(df4, df4.columns, df4.shape[0])
# for i in range(len(df4)):
# print(df4.loc[i, 'EQUIPMENTKEY'])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-2339-XAQ-fluctuation.py###
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120) \
    else ('H12' if (x < 720)\
    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    return odf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    return xdf
    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    q = tmsg(msk, "SITE " + GG2)
    q = tmsg (msk, "CELL " + GG2C)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    q = tmsg (msk, "SITE " + GG3)
    q = tmsg (msk, "CELL " + GG3C)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    q = tmsg (msk, "SITE " + GG4)
    q = tmsg (msk, "CELL " + GG4C)
    print('done')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
df = semqry()
y = main(df)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-315-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-37-XAQ-fnfn.py###
import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1


def conct(df, col1, col2, newcolname, seperator=False):
    if seperator == False:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2])
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2], sep=seperator)
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')


def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')


def map_df_dic(df0, dc, onkey_col, newcolname):
    df = add_col_df (df0, newcolname)
    df[newcolname] = df[onkey_col].map (dc)
    return df


def df_add_list_col(df, nc, nwlst):
    dfx = add_col_df (df, nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array (nwlst)
    return dfx


def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.drop_duplicates (subset=list_of_columns)
    return df


def sort_dsc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.sort_values (by=oncol, ascending=False)


def sort_asc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df = df.sort_values (by=oncol, ascending=True)
    return df


def left(df, sdf, i):
    df1 = add_col_df (df, 'left_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[0:i])
    return df1


def right(df, sdf, i):
    df1 = add_col_df (df, 'right_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[-i:len (x)])
    return df1


def vlookup(df0, refdic, refcol, nwcol):
    if isinstance (refdic, dict):
        try:
            df = add_col_df (df0, nwcol)
            df[nwcol] = df.reset_index ()[refcol].map (refdic).values
            return df
        except:
            df = map_df_dic (df0, refdic, refcol, nwcol)
            return df
    else:
        ndf = df0.merge (refdic, on=refcol)
        return ndf


def countifz(df, list_of_cols_as_ref, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[st].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[col].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def datediff(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")


def aplist(L1, L2):
    ls = []
    if isinstance (L1, pd.core.series.Series) and isinstance (L2, pd.core.series.Series):
        ls1 = L1.to_list ()
        ls2 = L2.to_list ()
        ls = [i + j for i, j in zip (ls1, ls2)]
    elif isinstance (L1, list) and isinstance (L2, list):
        ls = [i + j for i, j in zip (L1, L2)]
    elif isinstance (L1, pd.core.series.Series) and isinstance (L2, str):
        ls1 = L1.to_list ()
        for i in range (len (ls1)):
            ni = str (ls1[i]) + L2
            ls.append (ni)
    elif isinstance (L1, list) and isinstance (L2, str):
        for i in range (len (L1)):
            ni = str (L1[i]) + L2
            ls.append (ni)
    else:
        print ('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls


def countifs(df0, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            df2 = df1.groupby (['NC1']).NC1.count ().to_frame (name='cnt').reset_index ()
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt


def match(df, *argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len (argv) > 0 and len (argv) <= 3:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str) or isinstance (argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list ()
            for i in range (len (colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance (argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len (idx)
                    if manner == 'last':
                        return idx[ln - 1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx


def sumifz(df, list_of_cols_as_ref, numeric_col, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def instr(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.find (srcvalue)
        return f
    else:
        f = strtext.find (srcvalue)
        return f

def instrrev(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.rfind (srcvalue)
        return f
    else:
        f = strtext.rfind (srcvalue)
        return f


def sumifs(df0, numeric_col, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            print (ls)
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            print (df1)
            df2 = df1.groupby (['NC1'])[numeric_col].sum ().to_frame (name='sumifs').reset_index ()
            print (df2)
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1232020-39-XAQ-oDT.py###
import pandas as pd
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M:%S")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1242020-1944-XAQ-fnfn.py###

import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df


def conv_to_datetime(df1,col):
    df1[col] = pd.to_datetime(df1[col], errors='coerce')
    return df1

def pick_by_day(df1,day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1,yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df,oncol,lst,byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin(lst)]
        return df1
    else:
        df1 = df[df[oncol].isin(lst)]
        return df1

def conct(df,col1,col2,newcolname,seperator = False):
    if seperator == False:
        try:
            df1 = add_col_df(df,newcolname)
            df1[newcolname] = df1[col1].str.cat(df1[col2])
            return df1
        except:
            print('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df(df,newcolname)
            df1[newcolname] = df1[col1].str.cat(df1[col2],sep=seperator)
            return df1
        except:
            print('conct: column name not found in dataframe or dataframe is not valid dataframe')

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
        return dc
    except:
        print('err')

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def df_add_list_col(df,nc,nwlst):
    dfx = add_col_df(df,nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array(nwlst)
    return dfx

def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sort_dsc(ndf,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sort_asc(ndf,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=True)

def vlookup(df0,refdic,refcol,nwcol):
    if isinstance(refdic,dict):
        try:
            df = add_col_df(df0, nwcol)
            df[nwcol] = df.reset_index()[refcol].map(refdic).values
            return df
        except:
            df = map_df_dic(df0,refdic,refcol,nwcol)
            return df
    else:
        ndf = df0.merge(refdic, on=refcol)
        return ndf

def sumifs(df,list_of_cols_as_ref,numeric_col,newcol):
    if len(list_of_cols_as_ref) > 1:
        st = ""
        for i in range(len(list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)
        df1 = df.groupby(st)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=st)
        df2.drop(st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby(col)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=col)
        return df2

def countifz(df,list_of_cols_as_ref,newcol):
    if len(list_of_cols_as_ref) > 1:
        st = ""
        for i in range(len(list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)
        df1 = df.groupby(st)[st].count().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=st)
        df2.drop(st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby(col)[col].count().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=col)
        return df2

def datediff(df1,newcolname,col1,col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime(df1,col1)
            df1 = conv_to_datetime(df1,col2)
            df1 = pick_except_year(df1,1970)
            df2 = add_col_df(df1,newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime(df1,col1)
            df2 = add_col_df(df1,'now',datetime.now())
            df2 = conv_to_datetime(df2,'now')
            df3 = add_col_df(df2,newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype('timedelta64[m]')
            df3.drop('now', axis='columns', inplace=True)
            return df3
    except:
        print("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")



def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            print(ls)
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(df,*argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len(argv) > 0 and len(argv) <= 3:
        while n < len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str) or isinstance(argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list()
            for i in range(len(colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance(argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len(idx)
                    if manner == 'last':
                        return idx[ln-1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-1757-XAQ-conn_brocker.py###
import pyodbc
from mysql import *
from sqlalchemy import create_engine


def mssql_121():
    cstr = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(cstr)
    return conn

def mssql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-1757-XAQ-omsql.py###
import pandas as pd
import os, datetime, time, pyodbc
import omsql.df_to_sql as insupd
import omsql.create_table.tbl_mysql as myq
import omsql.create_table.tbl_mssql as msq
from omsql.singlebuilt.single_sql import *
from omsql.write2text import *
from omsql.conn_brocker import *

def MsSql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn

def mysql_dell(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

def insert_data():
    pt = os.getcwd() + "\\csv\\sclick.csv"
    ndf = pd.read_csv(pt)
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    lser = insupd.df_to_sql(ndf, 'omdb', 'TAX1', conn, oncolumn = 'ALL')
    conn.close()

def update_by_condition():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    lser = insupd.df_to_sql(df, 'omdb', 'TAX1', conn, bycolumn=['CustomAttr15'])
    conn.close()

def createtable():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')    
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    x = myq.CreateTable_MYSQL(connection = conn, tablename = 'TAX2', df = df, table_col = False, table_col_datatype = False, space = '_')
    conn.close()

def sql2df(tbl):
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    qry = 'select * from '+ tbl
    df = pd.read_sql(qry, con = conn)
    return df

#createtable()
#conn = MySql('root','admin','127.0.0.1:3306','omdb')
#pt = os.getcwd() + "\\OMTX.csv"
#df = pd.read_csv(pt)
#df.to_sql('omtx2', con= conn, if_exists='replace', chunksize= 10000)
#dfx = pd.read_sql('select * from omtx2', con = conn)
#print(dfx.columns, dfx.dtypes, df.shape[0])
#CreateTable_MSSQL(df, tablename, conn) #import create_table.tbl_mssql as msq
#x = myq.CreateTable_MYSQL(connection = conn, tablename = 'TAX2', df = df, table_col = False, table_col_datatype = False, space = '_')
#lser = insupd.df_to_sql(dataframe=df, dbname='omdb', tablename='TAX1', conn = conn, oncolumn = "ALL", bycolumn=['CustomAttr15'], opeation = 'and')

def update_table(dataframe, db, tbl, con, bycolumn_list):
    lser = insupd.df_to_sql(dataframe, db, tbl, con, oncolumn = 'ALL' , bycolumn=bycolumn_list)
    return lser

def create_table(df, tablename, con, server = 'mssql'):
    xx = ''
    if server == 'mssql':
        xx = msq.CreateTable_MSSQL(df, tablename, con)
    elif server == 'mysql':
        xx = myq.CreateTable_MYSQL(con, tablename, df, table_col = False, table_col_datatype = False, space = '_')
    else:
        print('currently only mysql and mssql')
    return xx

def create_table_custom(tbl, conn, list_col, list_type = False, server = "mssql"):
    if server == 'mssql':
        msq.CT_MSSQL(conn, tbl, list_col, list_type)
    elif server =='mysql':
        myq.CreateTable_MYSQL(conn, tbl, list_col, list_type , space = '_')
        
def upload_bulkdata(df, tablename, conn, dbname):
    try:
        df.to_sql(name=tablename, con=conn, if_exists='append', chunksize=10000)
        ls = df.columns.to_list()
        DeleteDuplicate(conn, tablename, ls[0])
    except:
        try:
            lser = insupd.df_to_sql(df, dbname, tablename, conn, oncolumn = 'ALL')
            print(lser)
        except:
            print('failed')
    
def update_single(con, tbl, listcols = [], listvalue = [], bycol = '', bycolv='' ):
    xx = Update_insert_single(con, tbl, listcols, listvalue, bycol, bycolv)
    return xx

#DeleteDuplicate(conn, tbl, cond_col)

def HELP():
    c1 = """update_single(con, tbl, listcols = [], listvalue = [], bycol = '', bycolv='' )"\n,
"return connection -> mssql_121(), mysql_dell()\n"
"upload_bulkdata(df, tablename, conn, dbname)"\n,
"create_table_custom(tbl, conn, list_col, list_type = False, server = "mssql")"\n,
"create_table(df, tablename, con, server = 'mssql')"\n,
"update_table(dataframe, db, tbl, con, bycolumn_list)","Sample:\n,
"obj.df_to_sql(dataframe=df, dbname='omdb', tablename='TAX1', conn = conn, oncolumn = "ALL", bycolumn=['CustomAttr15'], opeation = 'and')"""
    print(c1)          
    



    
    
    
    

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-1757-XAQ-TS.py###
from omsql.omsql import *

HELP()
x = mysql_dell()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1252020-956-XAQ-A.py###
import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(max(lss).strftime("%Y/%m/%d %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

print(find_lastest_date(mydf)) #change mydf to yours






'102','4/12/2020 4:52','3/12/2020 16:46','1/12/2020 16:46','4/12/2020 1:08','3/12/2020 12:40'
'501','3/12/2020 16:43','3/12/2020 16:44','3/12/2020 16:39','3/12/2020 16:43','4/12/2020 1:24','4/12/2020 4:46'
'603',3/12/2020 12:27				4/12/2020 1:51	4/12/2020 5:11
501	3/12/2020 12:29	3/12/2020 16:34	3/12/2020 23:53	4/12/2020 0:07	4/12/2020 2:18	4/12/2020 5:42





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-07-XAQ-fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            xyz = "cnt-" + str(df0.shape[1]) 
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = xyz).reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-1335-XAQ-otime.py###
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
import pandas as pd
import os
import numpy as np



#x = relativedelta(datetime(2003, 10, 24, 10, 0), datetime.now()).__format__
#print(x)


def parse_date_fuzzy(string, first='day'):
    x = ""
    try:
        if first == 'day':
            x = parse(string, fuzzy=True, dayfirst=True)
        elif first == 'year':
            x = parse(string, fuzzy=True, yearfirst=True)
        else:
            x = parse(string, fuzzy=True)
        return x.strftime("%Y-%m-%d")
    except:
        return ""

print(parse_date_fuzzy("INC 7/12/20"))

def conv_to_datetime(df1,col):
    df1[col] = pd.to_datetime(df1[col], errors='coerce')
    return df1

def pick_by_day(df1,day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == day]

def pick_except_year(df1,yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2


def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls

def ddiff(DT1, DT2):
    #serialize and convert using dateutil.parser and datetime.strftime
    ls1 = formatchk(DT1)
    ls2 = formatchk(DT2)
    if len(ls1) == len(ls2):
        lss = []
        for i in range(len(ls1)):
            dt1 = parse(str(ls1[i]))
            dt2 = parse(str(ls2[i]))
            if '1970' not in ls2[i]:
                diff = abs(dt2 - dt1)
                lss.append(diff.total_seconds()/60)
            else:
                diff = (datetime.now() - dt1)
                diff = abs(dt2 - dt1)
                lss.append(diff.total_seconds()/60)
        else:
            return lss

#diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
#diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60





def help_otime():
    a = """#df = pd.read_csv(os.getcwd() + "\\sclick.csv")
#print(df.columns)
#df = df.assign(dur = 0)
#x = ddiff(df['FO'],df['LO'])
#print(x)
#print(df[['LO','CLR','Diff']])"""
    print(a)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-2031-XAQ-tbot_extend_1.py###
import pyodbc
import pandas as pd
#import MySQLdb

socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#socdb = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"


def stname_mysql(code):
    nm = 'NP'
    conn= MySQLdb.connect("localhost","root","","ops_portal")
    df = pd.read_sql("select * from stbase3 Where Site_Code='" + code + "'", conn)
    rw = df.shape[0]
    print("~~~~~")
    print(rw)
    print("~~~~~")
    if rw != 0:
        nm = df['Site_Name'].iloc[0] + '\n'
    return nm

def stname(code):
    qry = "select Site_Name from sitebase where Site_Code LIKE '%" + code + "%'"
    conn = pyodbc.connect(socdb)
    cr = conn.cursor()
    st = ''
    try:
        cr.execute(qry)
        rs = cr.fetchone()
        for i in rs:
            if st == '':
                st = i
            else:
                st = st + ", " + i
            return st
    except:
        return ""

def add_site(code, name, Mask, Tgrp, OwnerNm):
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = '''INSERT INTO custom_sites (SiteCode, Name, MaskID, TeleGroup, OwnerName) VALUES (?,?,?,?,?)'''
    in_qry_1 = (code, name, Mask, Tgrp, OwnerNm)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()
    return "site added in list"


def rmv_site(code, Mask, Tgrp):
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = "DELETE FROM custom_sites WHERE SiteCode='" + code + "'AND MaskID='" + Mask + "'"
    curs.execute(in_qry)
    conx.commit()
    conx.close()
    rval = 'Sites Removed From:' + '\n' + Tgrp
    return rval

def list_site(Mask, Tgrp):
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where MaskID='" + str(Mask) + "'"
    df = pd.read_sql(qry, conx)
    lst1 = '\n'
    for ind in df.index:
        lst1 = lst1 + '\n' + df['SiteCode'][ind] + "," + df['Name'][ind]
    rval = Tgrp + ' Sites:' + '\n' + lst1
    conx.close()
    return rval

def list_site_all(OwNm):
    lst = ''
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where OwnerName='" + OwNm + "'"
    df = pd.read_sql(qry, conx)
    for ind in df.index:
        lst = lst + '\n' + df['SiteCode'][ind] + "," + ' Group: ' + df['TeleGroup'][ind]
    rval = OwNm + ' Custom Sites List:' + '\n' + lst
    conx.close()
    return rval

#txupr, str(uid), str(cid), msg
def M_handdler(text,msg):
    cht = msg['chat']
    frm = msg['from']
    ctype = cht['type']
    if ctype == 'group':
        GroupName = cht['title']
        GroupMask = cht['id']
        OwName = frm['first_name']
        rval = 'please provide correct format'
        GMask = GroupMask
        GN = GroupName
        if 'BULK' in text:
            tx = text[7:]
            text = tx
            cd = text.split(",")
            i = 0
            for val in cd:
                print(val)
                rval = add_site(val, stname(val), GMask, GN, OwName)
                i = i + 1
            else:
                rval = str(i) + " Sites Added Successfully"
        elif 'ADD' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 4:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 3:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 2:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            else:
                rval = 'format like:: ADD DHGUL19'
        elif 'RMV' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 2:
                rval = rmv_site(stsplit[1], str(GMask), GN)
        elif 'LIST' in text:
            rval = list_site(GMask, GN)
        else:
            print('please provide correct format')
        return rval
    else:
        return 'this feature only available in a group'


#tx = "ADD,PBSDR01,PABNA SADAR,NA"
#tx2 = 'LIST'
# if ('add,' in text) or ('rmv,' in text) or ('list,' in text):
#print(M_handdler(tx2))





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-2032-XAQ-sitehistory.py###
import pandas as pd
#import MySQLdb
import pyodbc

socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#socdb = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"


def fnx(code):
    conn = pyodbc.connect(socdb)
    df1 = pd.read_sql("select * from sitebase", conn)
    df = df1[df1['Site_Code'].str.contains(code)]
    a1 =  'Site Owner: ' + df['Mergeco__Robi'].iloc[0]  + '\n'
    a2 =  'AT Code/Relocation Code :' + df['AT_Code'].iloc[0]  + '\n'
    a3 =  'Site Name: ' + df['Site_Name'].iloc[0]  + '\n'
    a4 =  'Lat-Long: ' + df['Lat'].iloc[0] + ' - ' + df['Lon'].iloc[0]  + '\n'
    a5 =  'Site Address :' + df['Site_Physical_Address'].iloc[0]  + '\n'
    a6 =  'Site Type:' + df['Site_Type'].iloc[0]  + '\n'
    a7 =  'Site Build: ' + df['Build'].iloc[0]  + '\n'
    a8 =  'Share Operator: ' + df['Share_Operator'].iloc[0]  + '\n'
    a9 =  'Operator Code: ' + df['Operator_Code'].iloc[0]  + '\n'
    a10 =  'Region: ' + df['Region_(15)'].iloc[0]  + '\n'
    a11 =  'Zone: ' + df['Zone'].iloc[0]  + '\n'
    a12 =  'Cluster Type:' + df['Clutter_Type'].iloc[0]  + '\n'
    a13 =  'Tech: ' + df['All_Tech'].iloc[0]  + '\n'
    a14 =  'Tech Band: ' + df['Tech_Band'].iloc[0]  + '\n'
    a15 =  'Vendor: ' + df['Vendor'].iloc[0]  + '\n'
    a16 =  'Site Priority: ' + df['Priority'].iloc[0]  + '\n'
    vchk = df['PG_Allowed_Not_'].iloc[0]
    if "Run allowed" in vchk:
        a17 =  'PG Restricted : ' + "No" + '\n'
    else:
        a17 =  'PG Restricted : ' + "Yes" + '\n'
    a18 =  'DG: ' + df['DG_Status'].iloc[0]  + '\n'
    a19 =  'Revenue(k): ' + df['Revenue_(in_K_BDT)'].iloc[0]  + '\n'
    aa = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8 + a9 + a10 + a11 + a12 + a13 + a14 + a15 + a16 + a17 + a18 + a19
    conn.close()
    return aa

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-222-XAQ-main.py###
import pandas as pd
import time as tm
import telepot
from telepot.loop import MessageLoop
from pprint import pprint
import mssql as msq
import tbot.tbot_extend_1 as tex
import tbot.sitehistory as st
import tbot.tbot_single_site_status as stst
import incident as inc
import handover as ho

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
#TOKEN = '1055749951:AAG9J4nV8thnnSPSKNkvf-G1lcWmH5QMyjA' #jolelallubot
bot = telepot.Bot(TOKEN)


def hlp(tx2, chat_id):
    print('printing from help -', tx2)
    if tx2 == 'HELP' or tx2 == 'help' or tx2 == "//start" or tx2 == "/START":
        msg = "101. RPA-HELP" + chr(10) + "102. INC-HELP" + chr(10) + "103. COMMON-TRACKER-HELP" + chr(10) + "104 . CONFIG-MSG" + chr(10) + "105. OTHER-HELP"
        bot.sendMessage(chat_id, msg)
        return 'done'
    elif "RPA-HELP" in str(tx2) or str(tx2) == '101':
        rs = "Command Samples" + chr(10) + chr(10) + msq.rpa_help()
        bot.sendMessage(chat_id, rs)
        return 'done'
    elif "INC-HELP" in str(tx2) or str(tx2) == '102':
        txx0 = "COMMAND - [COMMENT]" + chr(10) + chr(10)
        txx = "INC  [onging incident]" + chr(10) + chr(10) + "INCID, INC00X87  [impacted code by inc id]" + chr(10) + chr(10) + "INC 2020/11/25  [by date]" + chr(10) + chr(10) + "INC DHGULM1 [get lastest 3 incident associated with sitecode]"
        b1 = "you can write date by 4 format" + chr(10) + "12-sept or 12/09/20 or 12092019 or 12-09-19"
        txx11 = txx0 + txx + chr(10) + chr(10) + b1
        bot.sendMessage(chat_id, txx11)
        return 'done'
    elif "COMMON-TRACKER-HELP" in tx2 or str(tx2) == '103':
        txx = ho.trcking_format()
        bot.sendMessage(chat_id, txx)
        return 'done'
    elif "CONFIG-MSG" in str(tx2) or str(tx2) == '104':
        a1 = """1.create a telegram group\n2. add two bot, 1.tech_socbot and 2.SocRbot \n3.add, DHGUL19 - to add site \n4.rmv,DHGUL19 - to add site \n5.list - to check site \n"""
        bot.sendMessage(chat_id, a1)
        return 'done'
    elif "Other-Help" in str(tx2) or str(tx2) == '105':
        a1 = "DHGUL19 - to get site current status\n"
        a2 = "RWS - Priority Update summary \nP1 - for p1 sites current down list \nP2 = for p2 sites current down list"
        aaa = a1 + a2
        bot.sendMessage(chat_id, aaa)
        return 'done'
    else:
        return "NA"

def incident_checker(txt, cht_id):
    ls = inc.inc_chk(txt)
    st = ''
    try:
        if ls is not None:
            for i in range(len(ls)):
                if st == "":
                    st = ls[i]
                else:
                    st = st + chr(10) + chr(10) + ls[i]
                    if len(st) > 3500:
                        bot.sendMessage(cht_id, st)
                        st = ""
            else:
                bot.sendMessage(cht_id, st)
        else:
            print('get none')
        return 'incident checker returned'
    except:
        return "error at main-incident_checker"
            
        

def text_handdler(chat_id, txt):
    tx0 = ''
    try:
        tx0 = txt.strip('/', "")
    except:
        tx0 = txt
    tx2 = tx0.upper()
    if "RPA HELP" in tx2.upper() or "RPA-HELP" in tx2.upper():
        rs = "Command Samples" + chr(10) + chr(10) + msq.rpa_help()
        bot.sendMessage(chat_id, rs)
        return 'done'
    elif "CHK" in tx2 or "ADD" in tx2 or "RMV" in tx2:
        rs = msq.private_add_rmv_upd(tx2)
        if isinstance(rs, str):
            if rs != 'NA':
                bot.sendMessage(chat_id, rs)
            else:
                print('text_handdle ', 'failed')
        elif isinstance(rs, list):
            for i in range(len(rs)):
                st = rs[i]
                bot.sendMessage(chat_id, st)
        return "done"
    else:
        return "NA"

def site_bio(txt,chat_id):
    cd = txt.upper()
    bot.sendMessage(chat_id, 'processing request for ' + cd + ' , please wait')
    try:
        getval = stst.query(cd)
        gethis = st.fnx(cd)
        txtx = getval + '\n' + '\n' + 'Site Details:' + '\n' + gethis
        bot.sendMessage(chat_id,txtx)
        return 'done'
    except:
        bot.sendMessage(chat_id,'sem server busy, try later')
        return 'error'

def inform_om(msg,uauth):
    try:
        xx = ''
        if uauth == 0:
            txt = msg['text']
            frm = msg['from']['first_name']
            uid = msg['from']['id']
            if str(uid) != '671462535':
                xx = str(frm) + ", " + str(uid) + ', ' + str(txt)
                bot.sendMessage('671462535', xx)
                return ""
            else:
                xx = str(frm) + ", " + str(uid) + ', ' + str(txt)
                if str(uid) != '671462535':
                    bot.sendMessage('671462535', xx)
                return ""
    except:
        return ""

def handle(msg):
    #pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    val = msq.auth_check_db(str(chat_id))
    uid = msg['from']['id']
    uid_auth = 0
    if uid != chat_id:
        uid_auth = msq.auth_check_db(str(uid))
    inform_om(msg, uid_auth)
    if val == 1 and content_type == 'text':
        print('1')
        txt = msg['text']
        tx = ''
        try:
            tx = txt.upper()
        except:
            tx = str(txt)
        
        try:
            zz = int(tx)
            zz1 = hlp(tx, chat_id)
        except:
            zz1 = ''
            print('not int type')
        if zz1 == "" and "HELP" in tx or "/START" in tx:
            xz = hlp(tx, chat_id)
            print(xz)
        if len(tx) == 7 and tx.find(',') == -1 and chat_id == uid:
            print('11', tx)
            x = site_bio(tx, chat_id)
            print(x)
        elif 'RWS' in tx or 'P1' in tx or 'P2' in tx:
            print('rws p1 p2')
            res = msq.priority(tx)
            bot.sendMessage(chat_id, res)
        elif chat_id == uid and 'ADD' in tx.upper() or 'RMV' in tx.upper() or 'CHK' in tx.upper() or 'HELP' in tx.upper():
            print('12', tx)
            res = text_handdler(chat_id, txt)
            print(res)
        elif chat_id == uid and 'INCIDENT' in tx.upper() or "INCID" in tx.upper() or 'INC' in tx.upper():
            x = incident_checker(tx, chat_id)
            print(x)
        else:
            print('escape')
    elif uid_auth == 1:
        txt = msg['text']
        if chat_id != uid and 'add' in txt or 'list' in txt or 'rmv' in txt or 'bulk' in txt:
            tx = ''
            try:
                tx = txt.upper()
            except:
                tx = txt
            rval = tex.M_handdler(tx, msg)
            bot.sendMessage(chat_id, rval)
            print('done', " uid_auth is 1")
    else:
        print('unauth user')

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    tm.sleep(10)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-414-XAQ-osq.py###
import pandas as pd
import os
from tbl_mssql import *

def attempt_dt(df):
    ls = df.columns.to_list()
    for i in range(len(ls)):
        cname = ls[i]
        try:
            df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
        except:
            pass
    return df

def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x

def dtype_match(db, table, conn, ndf):
    df = ndf.apply(lambda x: x.str.replace("'",''))
    dbcols = []
    dbcolType = []
    try:
        dfy = pd.read_sql("select 1 from " + table, con=conn)
    except:
        x = CreateTable_MSSQL(ndf, table, conn)
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'float' in dbty:
                    df[st] = df[st].astype(float)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)

def inser_or_update(db, conn, tbl, df, bycol, oncols=False, operator=False):
    ddf = dtype_match(db, tbl, conn, df)
    exe = False
    ndf = attempt_dt(ddf)
    #cr = conn.cursor ()
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    k = 0
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
        if exe == True:
            try:
                cr.execute (qry)
            except:
                try:
                    cr.execute (qryinsert)
                except:
                    qq.append (q)
                    pass
        else:
            print(qry, chr(10), chr(10))
            print(qryinsert, chr(10))
            k = k + 1
            if k == 10:
                exit()
        q = q + 1
    print ("failed rows: ", qq)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf

def df2sq(df, table, conn, bycol=False, oncol=False, operator='Like'):
    if bycol == False and oncol == False:
        df.to_sql(table, con=conn, if_exists="append", chunksize=10000)
        print('success')
    else:
        cr = conn.cursor ()
        try:
            cr.execute ("select 1 from " + table)
            dfx = inser_or_update (conn, table, df, bycol, oncol, operator)
            return dfx
        except:
            df.to_sql (table, con=conn, if_exists="replace", chunksize=10000)
            print('success')


df = pd.read_csv(os.getcwd() + "\\ss2.csv")
conn = ""
print(df)
inser_or_update(conn, 'tblx', df, ['Serial'])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-415-XAQ-buildqry.py###
import pandas as pd
import os
import omsqlfn as ofn
import InsUpd as InUp
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, ndf):
    df = ndf.apply(lambda x: x.str.replace("'",''))
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'float' in dbty:
                    df[st] = df[st].astype(float)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)


def Insert_bydf(tbl, df, cols = False):
    q = 0
    if cols:
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                match = 0
                for c in range(len(cols)):
                    if cols[c] == j:
                        match = 1
                        break
                if match == 1:
                    lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(cols,lsval)
            ls.append(qry)
        return ls
    else:
        colname = df.columns.to_list()
        q = 0
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(colname,lsval)
            ls.append(qry)
        return ls

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry

def UpdInsert(ndf, tbl, conn, bycols = False, oncol = False):
    qry = ''
    cr = conn.cursor()
    if bycols != False and oncol != False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)        
    elif bycols != False and oncol == False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)
    elif bycols == False and oncol != False:
        qry = Insert_bydf(tbl, ndf, oncol)
    else:
        qry = Insert_bydf(tbl, ndf)
    cnt = 0
    for i in range(len(qry)):
        cnt = cnt + 1
        q = qry[i]
        cr.execute(q)
    conn.commit()
    print(cnt, ' rows of data instered into ', tbl)
    return qry


def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#df1 = pd.read_sql('select * from omdb3',conn)
#print('before row: ', df1.shape[0])
#pt = os.getcwd() + '\\omsql\\OM2.csv'
#df = pd.read_csv(pt)
#oncol = ['Zone', 'Commercial_Zone', 'PFM_ZONE']
#bycol = ['Code','Authority']
#ls = UPIN(df, 'omdb3', conn, "Code", oncol)
#ls = UPIN(df, 'omdb3', conn, bycol, oncol)
#print('after row: ', df1.shape[0])

# df = dataframe
# db_connection  = database connection object
# how = 'append' or 'replace' or 'tuncate'
# bycols (list/str) = conditional columns for insert and update [if how = 'replace']
# oncols (list) = columns on that update and insert perfromed on table [False = all dataframe column]
# datatype_map = special feat, before insert or update datatype mapping beteen table columns and dataframe columns
def df_to_sql(df, db_name, db_table, db_connection, how = 'replace', bycols = False, oncols = False, datatype_map = True):
    ndf = dtype_match(db_name, db_table, db_connection, df)
    if bycols != False and how == 'replace':
        ls = UPIN(ndf, db_table, db_connection, bycols, oncols)
    elif bycols == False:
        ls = UpdInsert(ndf, db_table, db_connection, bycols = bycols, oncol = oncols)

def pattern1():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMDB.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn)
    conn.close()

def pattern2():
    print('pattern2')
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OM.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn, bycols = ['Code'], oncols = ['Zone','Commercial_Zone','PFM_ZONE'])





#x1 = UpdInsert('TB1',df)
#x2 = UpdInsert('TB1',df, bycol, oncol)
#x3 = UpdInsert('TB1',df, bycol)
#x4 = UpdInsert('TB1',df, oncol = oncol)
#print('X1', '~~', x1)
#print('X2', '~~', x2)
#print('X3', '~~', x3)
#print('X4', '~~', x4)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\1262020-618-XAQ-osq.py###
import pandas as pd
import numpy as np
import os


def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x


def query_built(ndf, tbl, bycol, oncols=False, operator=False):
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf


def df2sq(df, table, conn, bycol=False, oncol=False, operator='Like'):
    if bycol == False and oncol == False:
        df.to_sql(table, con=conn, if_exists="append", chunksize=10000)
        print('success')
    else:
        cr = conn.cursor ()
        try:
            cr.execute ("select 1 from " + table)
            dfx = inser_or_update (conn, table, df, bycol, oncol, operator)
            return dfx
        except:
            df.to_sql (table, con=conn, if_exists="replace", chunksize=10000)
            print('success')
            
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\8242020-1333-XAQ-tst.py###
import xlrd
import os
pt = os.getcwd()
excelpath = pt + '\\xlsF\\A_SEMRW.xlsm'
filepath= pt + '\\download\\0730200157.csv'
excel_app = xlwings.App(visible=False)
excel_book = excel_app.books.open(excelpath)
# into brackets, the path of the macro
x = excel_book.macro('init')
x(filepath)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\9252020-1939-XAQ-test.py###
def format_sentence(val, b=False):
    poststring = ''
    if b:
        for char in val:
            ascval = ord(char)
            #if ascval <= 65 and ascval <= 90:
               #poststring = poststring + char
            if ascval >= 97 and ascval <= 122:
                poststring = poststring + chr(ascval-32)
            else:
                poststring = poststring + char
        else:
            print(poststring)
    else:
        for char in val:
            ascval = ord(char)
            if ascval >= 65 and ascval <= 92:
                poststring = poststring + chr(ascval+32)
            else:
                poststring = poststring + char
        else:
            print(poststring)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\932020-60-XAQ-vbafn.py###
#import MySQLdb
import pandas as pd
import os
import numpy

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "RobiLive.csv"

class pyvb:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
    def PrintDf(self):
        print(self.df)
    def print_all_row_comm_seperated(self):
        lrw = (self.arr).shape[0]
        lcol = (self.arr).shape[1]
        i = 0
        hp = ''
        heap = ''
        while i < lrw:
            hp = ''
            j = 0
            while j < lcol:
                if hp == '':
                    hp = str(self.arr[i][j])
                else:
                    hp = hp + ', ' + str(self.arr[i][j])
                j = j + 1
            heap = heap + '\n' + str(hp)
            i = i + 1
        return heap
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
    def make_qry_str_sitecode(self,colname):
        lst = self.df[colname].to_list()
        hp = 0
        n = 0
        for i in lst:
            n = n + 1
            if n == 1:
                hp = "'" + i + "'"
            else:
                hp = hp + ',' + "'" + i + "'"
        return hp
    def vbprint_row_after_row(self, colinlist):
        hd = ''
        for x in colinlist:
            if hd == '':
                hd = x
            else:
                hd = hd + ', ' + x
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                count = count + 1
            if cnt == 0:
                heap = hd + '\n' + hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
        return heap
    def vbprint_col_comma(self, colinlist):
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                    count = count + 1
            if cnt == 0:
                heap = hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
            hp = ''
        print(heap)
    def vbrht(self):
        print('x')
    def vblft(self):
        print('x')
    def vbinstr(self):
        print('x')
    def vbmid(self):
        print('x')
    def vbdatediff(self):
        print('x')
    def vbreplace(self):
        print('x')




#dfc = pd.read_csv(file)
#dic = dfc.to_dict()

#mli = ['LastOccurrence', 'Tally','CustomAttr11']
#pv.Row_Item_From_List(9,mli)

#pv2 = pyvb(dic,mli)
#pv.PrintDf()
#pv2.PrintDf_ByList()
#gval = pv.MatchParse('DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
#print(gval)
#print(pv.VbMatch_Col('DHKTL04',3))
#print(pv.VbMatch_Row('CustomAttr15',0))
#pv.PrintLst()
#df = pd.read_csv(file)
#print(df)
#dic = df.to_dict()
#lst = ['Site Code','LTE Status','Priority']
#pv2 = pyvb(dic)
#print(pv2.print_all_row_comm_seperated())
#print(pv2.vbprint_row_after_row(lst))
#print(pv.make_qry_str('INTERNALLAST'))
#pv.make_qry_str(lst)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\A.py###
import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(max(lss).strftime("%Y/%m/%d %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

print(find_lastest_date(df1)) #change df1 to your
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\a1.py###
import pandas as pd
import numpy as np
import os


pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

df1= pd.read_csv(pt2)
print(df1)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\a1_vbdf.py###
import pandas as pd
import numpy as np
import os
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnstr as fst
import db.db as sq
from datetime import *

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\alive.py###
#from proxy_checker import ProxyChecker
import nmap


#checker = ProxyChecker()
#checker.check_proxy('45.72.6.167:8000')
       

#checkProxy('45.72.6.167:8000')
#--proxy 45.72.6.167:8000
#nmap 45.72.6.167 -p8000
#nmap -p T:8000 45.72.6.167
nm = nmap.PortScanner()
x = nm.scan('45.72.6.167', '8000')
print(x)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_csv.py###
import requests
import pandas as pd
import os
import csv
import io

pth = os.getcwd() + '\\DW\\'
cf = pth + 'hideme.csv'
hideme_access = "730480402242392"
hideme = "http://incloak.com/api/proxylist.php?country=US&Speed<=1000&ports=&type=socks5&out=csv&code=" + hideme_access
lnFF = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"

def csv_read(cf):
    with open(cf, newline='') as csvfile:
        reader = csv.DictReader(csvfile,delimiter=';')
        for row in reader:
            print(row['ip'],row['port'],row['city'])

def csv_2df(path,delim):
    df = pd.read_csv(path,delimiter=delim)
    return df

def csv_2dict(path,lst_fieldname):
    with open(path, newline='') as csvfile:
        fieldnames = lst_fieldname
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        return writer

def api_csv_read(lnk,delim):
    download = requests.get(lnk)
    decoded_content = download.content.decode('utf-8')
    cr = csv.reader(decoded_content.splitlines(), delimiter=delim)
    lst = list(cr)
    for row in lst:
        print(row)

def api_csv_df(lnk,delim):
    urlData = requests.get(lnk).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=delim)
    return df

#x = api2df(hideme,";")
x = csv_2df(cf,";")
print(x)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_json.py###
import requests
import pandas as pd
import os
import json
import io
from pprint import pprint
import pandas as pd
from pandas.io.json import json_normalize


pth = os.getcwd()
print(pth)
s1 = pth + '\\sample1.json'
s2 = pth + '\\sample2.json'
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"

def json_read(pth):
    with open(pth, "r") as jsonFile:
        x = json.load(jsonFile)
        pprint(x)

def api_json_read(url):
    response = requests.get(url)
    json_rs = response.json()
    print(json_rs.keys())
    


#json_read(s1)
api_json_read(tele_sender)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_json_1.py###
import requests
import pandas as pd
import os
import json
import io
from pprint import pprint
import pandas as pd
from pandas.io.json import json_normalize


pth = os.getcwd()
print(pth)
s1 = pth + '\\sample1.json'
s2 = pth + '\\sample2.json'
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"

def json_read(pth):
    with open(pth, "r") as jsonFile:
        x = json.load(jsonFile)
        pprint(x)

def api_json_read(url):
    response = requests.get(url)
    json_rs = response.json()
    print(json_rs.keys())
    


#json_read(s1)
api_json_read(tele_sender)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\api_json_2.py###
import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result


def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)

        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)

        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)

def printField(ele, prefix):
    print (prefix, ":" , ele)


tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
print(type(data))

def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

pth = os.getcwd()
print(pth)
s1 = pth + '\\sample2.json'
with open(s1, "r") as jsonFile:
        x = json.load(jsonFile)
        get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            print('~~dict~~')
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            print('~~list~~')
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            print('~~str~~')
            printField(data[element], element)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\as.py###
import asyncio
import aiosocks

reader, writer = await aiosocks.open_connection(proxy= '24.249.199.14' , proxy_auth='', dst= '57335', remote_resolve=True)
data = await reader.read(10)
writer.write('data')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\async1.py###
import asyncio
import time

async def run(cmd):
    proc = await asyncio.create_subprocess_shell(
        cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE)

    stdout, stderr = await proc.communicate()

    print(f'[{cmd!r} exited with {proc.returncode}]')
    if stdout:
        print(f'[stdout]\n{stdout.decode()}')
        print('1')
    if stderr:
        print(f'[stderr]\n{stderr.decode()}')
        print('1')

asyncio.run(run('r.bat'))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\asy_1.py###
import asyncio, pproxy


def handle_echo(reader, writer):
    data = yield from reader.read(100)
    message = data.decode()
    addr = writer.get_extra_info('peername')
    print("Received %r from %r" % (message, addr))

    print("Send: %r" % message)
    writer.write(data)
    yield from writer.drain()

    print("Close the client socket")
    writer.close()


server = pproxy.Server('socks5://0.0.0.0:6888')
remote = pproxy.Connection('socks5://185.183.98.136:8080')
args = dict( rserver = [remote],
             verbose = print )

loop = asyncio.get_event_loop()
server = loop.run_until_complete(server.start_server(args))

#loop = asyncio.get_event_loop()
#coro = asyncio.start_server(handle_echo, '127.0.0.1', 8888, loop=loop)
#server = loop.run_until_complete(coro)

# Serve requests until Ctrl+C is pressed
print('Serving on {}'.format(server.sockets[0].getsockname()))
try:
    loop.run_forever()
except KeyboardInterrupt:
    pass

# Close the server
server.close()
loop.run_until_complete(server.wait_closed())
loop.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\az.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import OmSQ.omsqlfn as fn
import OmSQ.InsUpd as fni
from datetime import *



def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''
    
    
def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        qry = 'EXPLAIN ' + self.db + '.' + table
        try:
            dfx = pd.read_sql(qry, con= self.engine)
            cols = dfx['Field'].to_list()
            typ = dfx['Type'].to_list()
            zips = zip(cols, typ)
            self.tabledetails = dict(zips)
            return self.tabledetails
        except:
            return "table not exist"

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0
    
    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df
    
    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False):
        if bycols:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = []):
        if len(cols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        else:
            if isinstance(cols, list):
                xdf = dataframe[cols]
                self.Upd_or_Insert(tbl, xdf)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()
      
    def UpdateBulk(self, tbl, bycond_colname, ndf = False, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\blk.py###
import socks


s = socks.socksocket()
s.set_proxy(socks.SOCKS5, "134.122.36.167", 1080)
x = s.connect(("www.google.com", 80))
print(x)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\buildqry.py###
import pandas as pd
import os
import omsqlfn as ofn
import InsUpd as InUp
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, ndf):
    df = ndf.apply(lambda x: x.str.replace("'",''))
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)


def Insert_bydf(tbl, df, cols = False):
    q = 0
    if cols:
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                match = 0
                for c in range(len(cols)):
                    if cols[c] == j:
                        match = 1
                        break
                if match == 1:
                    lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(cols,lsval)
            ls.append(qry)
        return ls
    else:
        colname = df.columns.to_list()
        q = 0
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(colname,lsval)
            ls.append(qry)
        return ls

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry

def UpdInsert(ndf, tbl, conn, bycols = False, oncol = False):
    qry = ''
    cr = conn.cursor()
    if bycols != False and oncol != False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)        
    elif bycols != False and oncol == False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)
    elif bycols == False and oncol != False:
        qry = Insert_bydf(tbl, ndf, oncol)
    else:
        qry = Insert_bydf(tbl, ndf)
    cnt = 0
    for i in range(len(qry)):
        cnt = cnt + 1
        q = qry[i]
        cr.execute(q)
    conn.commit()
    print(cnt, ' rows of data instered into ', tbl)
    return qry


def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#df1 = pd.read_sql('select * from omdb3',conn)
#print('before row: ', df1.shape[0])
#pt = os.getcwd() + '\\omsql\\OM2.csv'
#df = pd.read_csv(pt)
#oncol = ['Zone', 'Commercial_Zone', 'PFM_ZONE']
#bycol = ['Code','Authority']
#ls = UPIN(df, 'omdb3', conn, "Code", oncol)
#ls = UPIN(df, 'omdb3', conn, bycol, oncol)
#print('after row: ', df1.shape[0])

# df = dataframe
# db_connection  = database connection object
# how = 'append' or 'replace' or 'tuncate'
# bycols (list/str) = conditional columns for insert and update [if how = 'replace']
# oncols (list) = columns on that update and insert perfromed on table [False = all dataframe column]
# datatype_map = special feat, before insert or update datatype mapping beteen table columns and dataframe columns
def df_to_sql(df, db_name, db_table, db_connection, how = 'replace', bycols = False, oncols = False, datatype_map = True):
    ndf = dtype_match(db_name, db_table, db_connection, df)
    if bycols != False and how == 'replace':
        ls = UPIN(ndf, db_table, db_connection, bycols, oncols)
    elif bycols == False:
        ls = UpdInsert(ndf, db_table, db_connection, bycols = bycols, oncol = oncols)

def pattern1():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMDB.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn)
    conn.close()

def pattern2():
    print('pattern2')
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OM.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn, bycols = ['Code'], oncols = ['Zone','Commercial_Zone','PFM_ZONE'])





#x1 = UpdInsert('TB1',df)
#x2 = UpdInsert('TB1',df, bycol, oncol)
#x3 = UpdInsert('TB1',df, bycol)
#x4 = UpdInsert('TB1',df, oncol = oncol)
#print('X1', '~~', x1)
#print('X2', '~~', x2)
#print('X3', '~~', x3)
#print('X4', '~~', x4)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\bycols_inupd.py###
import pandas as pd
import numpy as np
import os

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(lscol,lsval):
    hp = ''
    stval = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                if lsval[i] is not None:
                    if isinstance(lsval[i],str):
                        xxx1 = lsval[i].replace("'","\\'")
                        stval = xxx1.replace(":","\\:")
                    else:
                        stval = str(lsval[i])
                    x = str(lscol[i]) + "='" + stval + "'"
                    if hp == '' and len(stval) > 0 :
                        hp = x
                    else:
                        if len(stval) > 0:
                            hp = hp + ',' + x
                        else:
                            pass
                else:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + insert_into_sql(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + insert_into_sql(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\call_omsql.py###
import pandas as pd
import csv, os, time
from omsql.omsq import *
import omsql.omsqlite3 as sq3
import telepot
from telepot.loop import MessageLoop
from pprint import pprint


def sqllite3():
    svpt = os.getcwd() + '\\VIP.csv'
    df = pd.read_csv(svpt)
    col = df.columns.to_list()
    mydb = os.getcwd() + '\\omsql\\' + 'oSqltdb.db'
    obj = sq3.sqlt3('oSqltdb.db', mydb)
    obj.createtable('VIP', col)
    obj.Export(df, 'VIP')
    print(obj.Read('select * from VIP'))


def for_contacts(svpt, tblname, colhead, srv = None):
    fl = open(svpt, 'r+')
    ls = []
    lns = 0
    for i in fl.readlines():
        x1= i.replace(',','')
        x2 = x1.replace('\n','')
        ls.append(x2)
        lns = lns + 1
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    print(df)
    print('waiting 10 sec to check....')
    col = df.columns.to_list()
    if srv == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
        print(x.col_and_type(tblname))
        x.df2sql(tblname,df)
        print(lns, df.shape[0], x.Getdf().shape[0])
    else:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        print(x.col_and_type(tblname))
        try:
            x.df2sql(tblname,df)
            print(lns, df.shape[0], x.Getdf().shape[0])
        except:
            print('fail')
    






def periodic_contacts(conn, contact_With_cmd):
    x = ''
    cur = conn.cursor()
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is \n periodic,01817183XXX,add"
    tbl = 'PeriCon'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    cr = conn.cursor()        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        qry = 'select * from ' + tbl + " where Number = '" + fcn + "' or  Number like '" + fcn + "'"
        rs = pd.read_sql(qry, con = conn)
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if 'check' in cmd or 'check' in contact_With_cmd:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                qry = "insert into " + tbl + " (Number) values ('" + fcn + "')"
                cur.execute(qry)
                conn.commit
                print(qry)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                xx = "DELETE FROM " + tbl + " WHERE Number Like '" + fcn + "'"
                cur.execute(xx)
                conn.commit
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'
            

#print('bot send: ', periodic_contacts('periodic,717015682,remove'))

def for_csv2sql(csv_file_path, tblname):
    df = pd.read_csv(csv_file_path)
    x = ''
    #try:
        #x = omsql('root','admin','127.0.0.1:3306','omdb')
        #x.MySql()
    #except:
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    print(df)
    x.df2sql(tblname,df)
    qry = 'select * from ' + tblname
    time.sleep(2)
    print(x.Ex(qry))
    print(tblname)


svpt = os.getcwd() + '\\Contacts.txt' 
#for_contacts(svpt, 'PeriCon1', 'Number')   
    
pt2 = os.getcwd() + '\\VIP.csv'
#for_csv2sql(pt2,'VIP')

pt3 = os.getcwd() + '\\TOP5.csv'
#for_csv2sql(pt3,'TOP5')

pt4 = os.getcwd() + '\\IBS.csv'
#for_csv2sql(pt4,'IBS')

pt5 = os.getcwd() + '\\AB.csv'
#for_csv2sql(pt5,'ABHI')

pt5 = os.getcwd() + '\\RMT.csv'
#for_csv2sql(pt5,'RMT')

#ob = omsql('root','admin','127.0.0.1:3306','omdb')
#ob.MySql()
#csvfile = os.getcwd() + '\\AB.csv'
#df = pd.read_csv(csvfile)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\call_omsql_bottest.py###
import csv, os
import telepot
from telepot.loop import MessageLoop
from pprint import pprint
from call_omsql import *
import time as tm
from datetime import *


TOKEN = '1055749951:AAG9J4nV8thnnSPSKNkvf-G1lcWmH5QMyjA'
bot = telepot.Bot(TOKEN)

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if content_type == 'text':
        txt = msg['text']
        chtid = msg['chat']['id']
        if 'periodic' in txt.lower():
            x = periodic_contacts(txt.lower())
            if len(x) < 1:
                bot.sendMessage(chat_id, 'please send correctly')
            else:
                bot.sendMessage(chat_id, x)
        else:
            bot.sendMessage(chat_id, txt + ' ' + str(chtid))
    else:
        try:
            x = msg['document']['file_id']
            bot.sendMessage(chat_id, x.replace('%0a','/n'))
        except:
            bot.sendMessage(chat_id, 'can not read file id')

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    tm.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\checktest.py###
zn = "ABC"
p1p2 ="P1"
pg = "ACT"
owner = "ulka"
smsid = "123"
thn ="TH"
pwaut="REB"
qryupd = "UPDATE [dbo].[omidb] SET (REGION=" + zn + ", P1P2=" + p1p2 + ", PG=" + pg + ", OWNER=" + owner + ") WHERE SMSID=" + smsid
print(qryupd)

qryupd2 = "UPDATE [dbo].[pglog4] SET REGION='" + zn +"', PRIORITY='" + p1p2 + "',SITETYPE_PG='" + pg + \
          "', POWER_AUTH='" + pwaut + "', THANA='" + thn + "', OWNER='" + owner + "' WHERE SMSID='" + smsid +"'"
print(qryupd2)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\checktest2.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
from datetime import datetime
from datetime import timedelta
import win32com.client
from dateutil.relativedelta import *

today = date.today()
td1 = today.strftime('%Y%m')
lastmnth = datetime.now() - relativedelta(months=1)
td2 = lastmnth.strftime('%Y%m')

def filename():
    pt = os.getcwd() + "\\" + "csv_download\\"
    t = time.localtime()
    folderName1 = today.strftime('%m%d%y')
    folderName2 = time.strftime("%H%M", t)
    pth = os.path.join(pt + folderName1 + folderName2 + '.csv')
    return pth

def qry_delta(from_min,to_min): 
    tday = date.today()
    tmdlta_from_now = datetime.now() - timedelta('minutes='+ int(from_min))
    tmdlta_to_now = datetime.now() - timedelta('minutes='+ int(to_min))
    qry_from = tmdlta_from_now.strftime('%Y-%m-%d %H:%M:%S')
    qry_to = tmdlta_to_now.strftime('%Y-%m-%d %H:%M:%S')
    dyn_date = "TO_DATE('" + qry_from + "','dd/mm/yyyy hh:mi:ss') AND TO_DATE('" + qry_to + "','dd/mm/yyyy hh:mi:ss')"
    return dyn_date


col = '*'
smry = "'2G SITE DOWN'"
query_p1 = 'SELECT ' + col + ' FROM ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + td1 + ') WHERE '
query_p2 = "(TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970') AND (SUMMARY=" + smry + ')'
query_p3 = 'IN (SELECT ' + col + 'FROM ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + td2 + ') WHERE '
query_p4 = 'SUMMARY=' + smry + " AND (TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970')) AND CUSTOMATTR15!='UNKNOWN')"

qry_type1 = query_p1 + query_p2
print(qry_type1)




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\check_test.py###
import os
scrpt_name = "ErrorHanddle_VBS.vbs"
fpth_0 = os.getcwd() + "\\" + scrpt_name
os.system(fpth_0)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\class_call_test.py###
import pandas as pd
import csv, os, time
from omsql.omsq import *
import omsql.omsqlite3 as sq3

def sqllite3():
    svpt = os.getcwd() + '\\VIP.csv'
    df = pd.read_csv(svpt)
    col = df.columns.to_list()
    mydb = os.getcwd() + '\\omsql\\' + 'oSqltdb.db'
    obj = sq3.sqlt3('oSqltdb.db', mydb)
    obj.createtable('VIP', col)
    obj.Export(df, 'VIP')
    print(obj.Read('select * from VIP'))

sqllite3()

def for_contacts(svpt, tblname, colhead, srv = None):
    fl = open(svpt, 'r+')
    ls = []
    lns = 0
    for i in fl.readlines():
        x1= i.replace(',','')
        x2 = x1.replace('\n','')
        ls.append(x2)
        lns = lns + 1
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    print(df)
    print('waiting 10 sec to check....')
    col = df.columns.to_list()
    if srv == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
        print(x.col_and_type(tblname))
        x.df2sql(tblname,df)
        print(lns, df.shape[0], x.Getdf().shape[0])
    else:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        print(x.col_and_type(tblname))
        try:
            x.df2sql(tblname,df)
            print(lns, df.shape[0], x.Getdf().shape[0])
        except:
            print('fail')
    


def periodic_contacts(contact_With_cmd):
    x = ''
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is %0a-periodic,01817183XXX,add"
    tbl = 'Periodic_Contacts'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    try:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
        x.MySql()
    except:
        x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
        x.MsSql()
        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        rs = x.Ex('select * from ' + tbl + " where Number = '" + fcn + "'")
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if cmd == None:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                x.InsertSingle(tbl, 'Number', fcn)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                x.DeleteByCond(tbl, 'Number', fcn)
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'
            

#print('bot send: ', periodic_contacts('periodic,717015682,remove'))

def for_csv2sql(csv_file_path, tblname):
    df = pd.read_csv(csv_file_path)
    x = ''
    #try:
        #x = omsql('root','admin','127.0.0.1:3306','omdb')
        #x.MySql()
    #except:
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    print(df)
    x.df2sql(tblname,df)
    qry = 'select * from ' + tblname
    time.sleep(2)
    print(x.Ex(qry))
    print(tblname)


svpt = os.getcwd() + '\\Contacts.txt' 
#for_contacts(svpt, 'PeriCon', 'Number', 'mssql')   
    
pt2 = os.getcwd() + '\\VIP.csv'
#for_csv2sql(pt2,'VIP')

pt3 = os.getcwd() + '\\TOP5.csv'
#for_csv2sql(pt3,'TOP5')

pt4 = os.getcwd() + '\\IBS.csv'
#for_csv2sql(pt4,'IBS')

pt5 = os.getcwd() + '\\AB.csv'
#for_csv2sql(pt5,'ABHI')

pt5 = os.getcwd() + '\\RMT.csv'
#for_csv2sql(pt5,'RMT')

ob = omsql('root','admin','127.0.0.1:3306','omdb')
ob.MySql()
csvfile = os.getcwd() + '\\AB.csv'
df = pd.read_csv(csvfile)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\code_qry.py###
import pandas as pd
import os



#opt = itertools.islice(ls, len(ls))
#st = map(lambda x : )

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    code = []
    q = 0
    for i in range(len(ls)):
        text = txt
        if ls[i] in text:
            n = text.find(ls[i])
            st = text[n:n+7]
            code.append(st)
            txt = txt.replace(ls[i],'')
            q = q + 1
    else:
        if q == 0:
            return ''
        else:
            return code
        
def qry_by_code(code, tbl = None, col = None):
    if tbl is None and col is None:
        a1 = "select Incident_Notification,Down_Time,Up_Time,Major_Cause,Action_Taken,Link_ID_Site_ID,Incident_ID from incident_tracker_v2 where ("
        a2 = " No_of_2G_Impacted_sites Like '%" + code + "%' or No_of_3G_Impacted_sites like '%" + code + "%' or No_of_4G_Impacted_Sites like '%" + code + "%' or Incident_Notification Like '%" + code 
        a3 = "%') order by Down_Time desc"
        aa = a1 + a2 + a3
        return aa
    else:
        return ""

def codechk(txt):          
    rs = parsecode(txt.upper())
    st = 0
    print('ret val', rs)
    if len(rs) == 1:
        code = rs[0]
        rn = 0
        try:
            cd = int(code[6:7])
            qry = qry_by_code(code)
            conn = pyodbc.connect(soc)
            df = pd.read(qry, con = conn)
            if df.shape[0] != 0:
                if df.shape[0] > 3:
                    st = "last 3 incident out of " + df.shape[0]
                    rn = 3
                else:
                    st = "incident found " + df.shape[0] + chr(10)
                    rn = df.shape[0]
                for i in range(rn):
                    tmp = chr(10)
                    for j in df:
                        tmp = tmp + chr(10) + df.loc[i,j]
                    else:
                        st = st + chr(10) + str(i) + tmp
        except:
            print('not code')
        return st
    else:
        return st



    

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\conn_brocker.py###
import pyodbc
from mysql import *
from sqlalchemy import create_engine


def mssql_121():
    cstr = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(cstr)
    return conn

def mssql_115():
    cstr = "Driver={SQL Server};SERVER=192.168.0.115;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"
    conn = pyodbc.connect(cstr)
    return conn

def mssql_host(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn

def mysql(user = 'root', password = 'root', host = '127.0.0.1:3306', db = "omdb"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


con = mssql_115()
con2 = mysql()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\create_table.py###
import pandas as pd
import os
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

def CreateTable_MSSQL(tablename, list_col, list_type=None):
    st = ""
    finalstr = ''
    x = ""
    for i in range(len(list_col)):
        if list_type != None:
            x = list_col[i] + "' " + list_type[i]
        else:
            x = list_col[i] + "' TEXT NULL"
        if st == "":
            addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
            st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
            # st = "CREATE TABLE '" + tablename + "' ( '" + x
        else:
            st = st + ', ' + "'" + x
    else:
        finalstr = st + ' )'
        return finalstr

def CreateTable_MYSQL(tablename, list_col, list_type =None):
    st = ""
    finalstr = ''
    x = ""
    for i in range(len(list_col)):
        if list_type != None:
            x = list_col[i] + "` " + list_type[i]
        else:
            x = list_col[i] + "` text NULL DEFAULT NULL"
        if st == "":
            addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
            st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
        else:
            st = st + ', ' + "`" + x
    else:
        finalstr = st + ' )'
        print(finalstr)
        return finalstr

def is_table_exist(tbl, conn):
    qry = "SELECT 1 FROM " + tbl
    print(qry)
    try:
        cr = conn.cursor()
        rs = cr.execute(qry)
        return 1
    except:
        return 0

def create_table_mysql(csv_or_df, new_table_name, db_conn, columns_remane = True):
    exist = is_table_exist(new_table_name, db_conn)
    if exist == 0:
        df = ''
        if isinstance(csv_or_df, str):
            df = pd.read_csv(csv_or_df)
        else:
            df = csv_or_df
        if columns_remane:
            ndf = mod_cols_name(df)
            cols = ndf.columns.to_list()
            try:
                qry = CreateTable_MYSQL(new_table_name,cols)
                cr = db_conn.cursor()
                cr.execute(qry)
                db_conn.commit()
                print('table creation successful')
            except:
                print('table creation failed')
        else:
            cols = ndf.columns.to_list()
            CreateTable_MYSQL(new_table_name,cols)
    else:
        print('table already exist')

def create_table_mssql(csv_or_df, new_table_name, db_conn, columns_remane = True, infer_datatype = True):
    if is_table_exist(new_table_name, db_conn) == 0:
        df = ''
        if isinstance(csv_or_df, str):
            df = pd.read_csv(csv_or_df)
        else:
            df = csv_or_df
        if columns_remane:
            ndf = mod_cols_name(df)
            cols = ndf.columns.to_list()
            try:
                qry = CreateTable_MSSQL(new_table_name,cols)
                cr = db_conn.cursor()
                cr.execute(qry)
                db_conn.commit()
                print('table creation successful')
            except:
                print('table creation failed')
        else:
            cols = ndf.columns.to_list()
            CreateTable_MYSQL(new_table_name,cols)
    else:
        print('table already exist')

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn

def change_dtype(df, colnm, to_type):
    ndf = pd.DataFrame([])
    if to_type == "dt":
        try:
            df[colnm] = df.apply(lambda x : pd.to_datetime(x[colnm]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            return df
        except:
            return ndf
    if to_type == "integer":
        try:
            df[colnm] = df[colnm].astype(str)
            return df
        except:
            return ndf
    if to_type == "string":
        try:
            df[colnm] = df[colnm].apply(lambda _: str(_))
            return df
        except:
            return ndf


#create_table_mysql(df, 'mytable1', conn)
#qry = "select * from mytable"
#print(pd.read_sql(qry ,con = conn))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\db - Copy.py###
import pandas as pd
import os
import sqlite3

pt = os.getcwd()
csvpt = ""
sqdb = ""

if "db" in pt:
    csvpt = os.getcwd() + "\\omdb.csv"
    sqdb = os.getcwd() + "\\omdb.db"
else:
    csvpt = os.getcwd() + "\\db\\omdb.csv"
    sqdb = os.getcwd() + "\\db\\omdb.db"

conn = sqlite3.connect(sqdb)
c = conn.cursor()

def comm_create(sql):
    c.execute(sql)
    conn.commit()
    print('successful commit')

def comm_read(sql):
    c.execute(sql)
    rw = []
    for row in c.fetchall():
        rw.append(row)
    df = pd.DataFrame(rw)
    return df
#df.to_sql('SITEDB', conn, if_exists='replace', index = False)

def sitedb_col():
    col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
    return col

def omdb(col = False, tbl = False):
    if col == False:
        col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
        c.execute('''SELECT * FROM SITEDB''')
        df = pd.DataFrame(c.fetchall(), columns=[col])
        return df
    else:
        if tbl == False:
            tbl = 'SITEDB'
        sql = "SELECT " + col + " FROM " + tbl
        c.execute(sql)
        lst = col.split(',')
        df = pd.DataFrame(c.fetchall())
        df.columns = lst
        return df

def replace_data(df,tbl):
    sql = "DELETE FROM " + tbl + ';'
    c.execute(sql)
    df.to_sql('SITEDB', conn, if_exists='replace', index = False)

#cols = "ECO,ULKA"
#sql = "SELECT " + cols + " FROM SITEDB"
#comm_read(sql)
#print(omdb(cols,'SITEDB'))


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\db.py###
import pandas as pd
import os
import sqlite3

pt = os.getcwd()
csvpt = ""
sqdb = ""

if "db" in pt:
    csvpt = os.getcwd() + "\\omdb.csv"
    sqdb = os.getcwd() + "\\omdb.db"
else:
    csvpt = os.getcwd() + "\\db\\omdb.csv"
    sqdb = os.getcwd() + "\\db\\omdb.db"

conn = sqlite3.connect(sqdb)
c = conn.cursor()

def comm_create(sql):
    c.execute(sql)
    conn.commit()
    print('successful commit')

def comm_read(sql):
    c.execute(sql)
    rw = []
    for row in c.fetchall():
        rw.append(row)
    df = pd.DataFrame(rw)
    return df
#df.to_sql('SITEDB', conn, if_exists='replace', index = False)

def sitedb_col():
    col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
    return col

def omdb(col = False, tbl = False):
    if col == False:
        col = ['ShortCode','Region','Region_long','ECO','ULKA','Dist','PowerAuthority','Cluster']
        c.execute('''SELECT * FROM SITEDB''')
        df = pd.DataFrame(c.fetchall(), columns=[col])
        return df
    else:
        if tbl == False:
            tbl = 'SITEDB'
        sql = "SELECT " + col + " FROM " + tbl
        c.execute(sql)
        lst = col.split(',')
        df = pd.DataFrame(c.fetchall())
        df.columns = lst
        return df

def replace_data(df,tbl):
    sql = "DELETE FROM " + tbl + ';'
    c.execute(sql)
    df.to_sql('SITEDB', conn, if_exists='replace', index = False)

#cols = "ECO,ULKA"
#sql = "SELECT " + cols + " FROM SITEDB"
#comm_read(sql)
#print(omdb(cols,'SITEDB'))


df = pd.DataFrame([['Iphone','DHDEM26',
'11-09-2020 12:14','11-20-2020 12:24',
'400'],['Iphone','CGHTZ09',
'11-09-2020 12:14','11-20-2020 12:24',
'400'],['dell','LXRGN32',
'11-09-2020 12:14','11-20-2020 12:24',
'300'],['dell','DHDEM39',
'11-09-2020 12:13','11-20-2020 12:24',
'300'],['Samsung ','SGSJP04',
'11-09-2020 12:12','11-20-2020 12:24',
'250'],['Samsung ','CXMHK36',
'11-09-2020 12:11','11-20-2020 12:24',
'250'],['Samsung ','CGFTK29',
'11-09-2020 12:10','11-20-2020 12:24',
'250'],['dell','CGKTLB6',
'11-09-2020 12:10','11-20-2020 12:24',
'300'],['dell','CMBRR57',
'11-09-2020 12:10','11-20-2020 12:24',
'300']],columns=('PRODUCT','ZIPCODE',
            'SHIPMENT','DELIVERY','PRICE'))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\db121.py###
import time
from datetime import date
from datetime import datetime
from datetime import timedelta
import pyodbc
import requests as rs
import pandas as pd

tmnw = datetime.now()
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')

def generalqry():
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    qry = "SELECT * from [dbo].[pglog4]"
    df = pd.read_sql(qry, conx)
    print(df)
    print(df.shape[0])

def insert_pgon(ussd,code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    in_qry = '''INSERT INTO dbo.pglog4 (SMSID, SITECODE, MSISDN) VALUES (?,?,?)'''
    in_qry_1 = (ussd, code, msisdn)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()

def update_pgoff(code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    qry_1 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND STATUS_ACTIVE= 'TRUE')"
    qry1 = "UPDATE dbo.pglog4 SET END_DATETIME = CURRENT_TIMESTAMP WHERE " + qry_1
    qry2 = "UPDATE dbo.pglog4 SET CASE_STATUS = 'Closed' WHERE " + qry_1
    curs.execute(qry1)
    conx.commit()
    curs.execute(qry2)
    conx.commit()
    qry_2 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND CASE_STATUS= 'Closed')"
    qry3 = "UPDATE dbo.pglog4 SET STATUS_ACTIVE = '0' WHERE " + qry_2
    curs.execute(qry3)
    conx.commit()
    conx.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dbpull.py###
from datetime import *
import time as tm
import pandas as pd
import numpy as np
import os
from mysql import *
from sqlalchemy import create_engine
from sqlalchemy import update
import subprocess
import conn_brocker

engine = create_engine('mysql+mysqlconnector://akomi:1q2w3eaz$@38.70.234.101:3306/omdb', echo=False)
conn = engine.raw_connection()
cursor = conn.cursor()

def dbup(df0):
    df1 = df0.applymap(str)
    ls = ['ip','port','ISP','ASN','country','prot','prot_status','blkchk','blk_status','priority']
    df2 = df1[ls]
    df2.to_sql(name='live', con=engine, if_exists = 'append', index=False)
    print('db update done')

def dbdw():
    qry = "select * from live where blk_status='fine'"
    df = pd.read_sql(qry, con=engine)
    return df
    
def dbupd(ip):
    live.update().where(ip==ip).values(name="some name")
    
    
def netcat(ip,port):
    qry = "timeout 5 nc -v -N  -w 5 " + ip + ' ' + str(port)
    process = subprocess.Popen(qry, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    err = str(process.stderr.read())
    if 'succeeded' in err:
        return 'success'
    else:
        return 'fail'

def getip_port():
    df = dbdw()
    print(df)
    df = df.fillna(0)
    df2 = df[df.blk_status.str.contains('fine')]
    df2 = df2.drop_duplicates(subset='ip',keep='last', inplace = False)
    dfp1 = df2[(df2.priority == "P1")]
    dfp2 = df2[(df2.priority != "P1")]
    ippr = ""
    for i in range(len(dfp1)):
        ip = dfp1.iloc[i][1]
        port = dfp1.iloc[i][2]
        status = netcat(ip,port)
        if status == 'success':
            nip = ip
            nport = port
            ippr = ip + "," + str(port)
            break
    return ippr

def connint():
    ipr = getip_port()
    ipx = ipr.split(',')
    nip = ipx[0]
    nport = ipx[1]
    conn_brocker.server('0.0.0.0', 12876, nip, int(nport), 2)



nip = '142.93.245.242'
nport = '30588'
conn_brocker.server('0.0.0.0', 12876, nip, int(nport), 2)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dbqry.py###
import sqlite3

con = sqlite3.connect('omdb.db')
cr = con.cursor()
def create_tbl():
    cr.execute("CREATE TABLE hs(SERIAL,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,CUSTOMATTR3)")
    con.commit()
def uoload_data(df1,dbname):
    df1.to_sql("'" + dbname + "'", con)
def delete_data(tblName):
    sql = "DELETE FROM " + tblName + ';'
    con.execute(sql)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\DBUP.py###
import os
import MySQLdb
import csv

pt = os.getcwd()
fl = pt + '\\A2S.csv'
conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
cr = conn.cursor()
try:
    csv_data = csv.reader(open(fl))
    print(csv_data.text)
    # execute and insert the csv into the database.
    for row in csv_data:
        cr.execute('INSERT INTO ipasn10 (IP1, IP2, ASN, Country, ISP, IPMOD)''VALUES(%s, %s, %s, %s, %s , %s)',row)
        print(row)
    cr.commit()
except:
    conn.rollback()
finally:
    conn.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dbup_test.py###
import pandas as pd
import numpy as np
import os
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnstr as fst
import db.db as sq
from datetime import *
from dateutil.relativedelta import *
from dateutil.easter import *
from dateutil.rrule import *
from dateutil.parser import *
import db.omdb as od

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"
df1 = pd.read_csv(pt1)
df0 = pd.read_csv(pt2)

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"

def get_date(d1):
    tm = parse(d1)
    dt = tm.date()
    return str(dt)

def PTM(d,fmt=False):
    if fmt == False:
        fmt = "%Y-%m-%d %H:%M:%S"
    if isinstance(d,str):
        tm = parse(d)
        str_d = tm.strftime(fmt)
        return str_d
    elif isinstance(d,datetime):
        d1 = d
        d = str(d1)
        tm = parse(d1)
        str_d = tm.strftime(fmt)
        return str_d
    else:
        return 0

def dateformat(d1):
    if isinstance(d1, str):
        d = datetime.strptime(d1)
        return d.strftime("%Y-%d-%m %H:%M:%S")
    if isinstance(d1, datetime):
        d = d1.strftime("%Y-%d-%m %H:%M:%S")
        return d

conn = od.MySql_3('127.0.0.1','root','admin','om1')
cr = conn.cursor()
x = od.prep_query("tm1")

def lp():
    for i in range(len(df0)):
        CL = df0.loc[i,"CLEARTIMESTAMP"]
        LO = PTM(df0.loc[i,"LASTOCCURRENCE"])
        CLR = PTM(df0.loc[i,"CLEARTIMESTAMP"])
        ls = []
        if '1970' not in CL:
            AG = datediff("",LO,CLR)
            DT = get_date(LO)
            st = "'" + DT + "','" + LO + "','" + CLR + "','" + AG + "','" + df0.loc[i,"CUSTOMATTR15"] + "'"
            print(st)
            x.q_insert("`TODAY`, `LO`, `CLR`, `AG`, `CODE`",st)
            ist = x.get()
            cr.execute(ist)
            conn.commit()
lp()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dfmtd.py###
import pandas as pd
import numpy as np
import os
import sys

def conv_datatype():
    print('x')

def dfmt1(arg):
    x = isinstance(arg, (str, float, int, str, list, dict, tuple, pd.DataFrame, np.ndarray))
    if type(x) == pd.DataFrame:
        df0 = arg
    elif type(x) ==np.ndarray:
        nar = arg
    elif type(x) == dict:
        df0 = pd.Dataframe(arg)
        print(df0)

def dfmt2(df, whatto):
    if whatto == 'col':
        print('df frame columns name')
        print('1 . df columns \n', df.columns)
        print('\n 2. columns into list \n' ,list(df.columns))
        print('\n No of Colummns', df.shape[1])
        print('\n slice columns ', df0)
    if whatto == 'row':
        print(df.shape[0])








FL1 = "E:\\GIT\\OmProject\\OmPY\\omfn\\sem_raw.csv"
dff = pd.read_csv(FL1)
dic = dff.to_dict()
nar = dff.to_numpy()
dk = dff.columns[['Severity','PG_Restricted']]
#df0 = dff.columns[['Serial','Summary']]
#dfmt2(dff,'col')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_dic.py###
import MySQLdb
import pandas as pd
try:
    conn= MySQLdb.connect("localhost","root","admin","omdb")
except:
    print("Can't connect to database")
#cursor = conn.cursor()








#filename = os.getcwd() + '//inc.csv'
#df = pd.read_csv(filename)
##dic = df.to_dict()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_dict.py###
#df to dic
import pandas as pd
filename = 'Book1.csv'
df = pd.read_csv(filename)
dic = df.to_dict()
#print(df)
#print(dic)
#for col in dic:  #print header
    #print(col)
#for rw in dic.values():  #print header
    #print(rw)
#for col in dic.items():
    #print(dic['Site_Code'])
j = 0
for i in dic.values():
    j = j + 1
    #print(j)
   # print(dic['Site_Code'][j])
    
#for i in dic:
    #print(i)
#for i in dic.values():
    #print(i)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_dict_list.py###
import pandas as pd
filename = 'Book1.csv'
dic = {0:'zero',1:'one',2:'two'}
print(dic)
def df_2_lst():
    lst = df.values.tolist()
    
def df_2_dic():
    dic = df.to_dict()

def df_2_series():
    dic = df.to_dict()
    
def df_2_numpy_arr():
    dic = df.to_dict()
    
dfrm = pd.read_csv(filename)
df = pd.DataFrame(list(dic.items()))
dic1 = df.to_dict()

print(df)
#print_from_lst()
#print_from_dic()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_insupd.py###
import pandas as pd
import numpy as np
import os
import omsqlfn as ofn
import InsUpd as InUp
import create_table as ct
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def dtype_match(db, table, conn, ndf):
    df = ndf.replace (np.nan, '')
    dfcol = df.columns.to_list()
    for i in range(len(dfcol)):
        df = df.rename(columns={dfcol[i]:dfcol[i].replace(' ', '_')})
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        colunmatch = []
        q = 0
        Y = 1
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            q = q + 1
            try:
                xdf = df[st]
            except:
                Y = 0
                notmat = 'column not matched: - ' + st
                print(notmat)
            if Y == 1:
                print('dtype_match: ', dbty)
                try:
                    if dbty == 'int':
                        df[st] = df[st].astype(int)
                    elif dbty == 'float':
                        df[st] = df[st].astype(float)
                    elif dbty == 'datetime':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                    elif dbty == 'date':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                    else:
                        df = df.apply(lambda x: x.replace("'","\'"))
                except:
                    pass
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)


def Insert_bydf(tbl, df, cols = False):
    print(df)
    colname = df.columns.to_list()
    q = 0
    if cols:
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                match = 0
                for c in range(len(cols)):
                    if cols[c] == j:
                        match = 1
                        break
                if match == 1:
                    lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(cols,lsval)
            ls.append(qry)
        return ls
    else:
        q = 0
        ls = []
        for i in range(len(df)):
            lsval = []
            q = q + 1
            for j in df:
                lsval.append(df.loc[i,j])
            qry = "insert into " + tbl + ' ' + ofn.prep_insert(colname,lsval)
            ls.append(qry)
        return ls

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def UPIN(df, tbl, conn, bycols, oncols = False, operation = "and"):
    cr = conn.cursor()
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + ofn.prep_update(fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = "insert into " + tbl + ' ' + ofn.prep_insert(fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry


def UpdInsert(ndf, tbl, conn, bycols = False, oncol = False):
    qry = ''
    cr = conn.cursor()
    if bycols != False and oncol != False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)        
    elif bycols != False and oncol == False:
        qry = qrybuilt(tbl,ndf, bycols, oncol)
    elif bycols == False and oncol != False:
        qry = Insert_bydf(tbl, ndf, oncol)
    else:
        qry = Insert_bydf(tbl, ndf)
    cnt = 0
    er = 0
    for i in range(len(qry)):
        cnt = cnt + 1
        q = qry[i]
        try:
            cr.execute(q)
        except:
            er = er + 1
            print("a error found for query - :" , q, " at row num ", cnt)
    conn.commit()
    print(cnt, ' rows of data instered into ', tbl)
    print('error found for rows ', er)
    return qry


def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


#df1 = pd.read_sql('select * from omdb3',conn)
#print('before row: ', df1.shape[0])
#pt = os.getcwd() + '\\omsql\\OM2.csv'
#df = pd.read_csv(pt)
#oncol = ['Zone', 'Commercial_Zone', 'PFM_ZONE']
#bycol = ['Code','Authority']
#ls = UPIN(df, 'omdb3', conn, "Code", oncol)
#ls = UPIN(df, 'omdb3', conn, bycol, oncol)
#print('after row: ', df1.shape[0])

# df = dataframe
# db_connection  = database connection object
# how = 'append' or 'replace' or 'tuncate'
# bycols (list/str) = conditional columns for insert and update [if how = 'replace']
# oncols (list) = columns on that update and insert perfromed on table [False = all dataframe column]
# datatype_map = special feat, before insert or update datatype mapping beteen table columns and dataframe columns
def df_to_sql(df, db_name, db_table, db_connection, how = 'replace', bycols = False, oncols = False, datatype_map = True):
    ndf = dtype_match(db_name, db_table, db_connection, df)
    print(ndf['LastOccurrence'])
    if isinstance(ndf, pd.DataFrame):
        if bycols != False and how == 'replace':
            ls = UPIN(ndf, db_table, db_connection, bycols, oncols)
        elif bycols == False:
            ls = UpdInsert(ndf, db_table, db_connection, oncol = oncols)
    else:
        print('check column name between db and dataframe')

def pattern1():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMDB.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn)
    conn.close()

def pattern2():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OM.csv'
    df = pd.read_csv(pt)
    df_to_sql(df, 'omdb', 'mytable', conn, bycols = ['Code'], oncols = ['Zone','Commercial_Zone','PFM_ZONE'])

def pattern3():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + '\\omsql\\OMTX.csv'
    df = pd.read_csv(pt)
    ct.create_table_mysql(df, 'eve', conn )
    df_to_sql(df, 'omdb', 'eve', conn)
    conn.close()


#x1 = UpdInsert('TB1',df)
#x2 = UpdInsert('TB1',df, bycol, oncol)
#x3 = UpdInsert('TB1',df, bycol)
#x4 = UpdInsert('TB1',df, oncol = oncol)
#print('X1', '~~', x1)
#print('X2', '~~', x2)
#print('X3', '~~', x3)
#print('X4', '~~', x4)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\df_to_sql.py###
import pandas as pd
import numpy as np
import os
import datetime
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import df_to_sql.upin as upd
import df_to_sql.write2text as wrt

def get_server_name(db, table, conn):
    try:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con = conn)
        return "MYSQL"
    except:
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= conn)
            return "MSSQL"
        except:
            return "only MYSQL and MSSQL is Supported"

def mssql_table_colname(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    return dbcols

def mssql_table_colinfo(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    dbcolType = dfx['DATA_TYPE'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic



def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key
            
def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                pass
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def fuzzymatch(str1,str2, uplow = True):
    if uplow == True:
        s1 = str1.lower()
        s2 = str2.lower()
        ls1 = []
        ls2 = []
        for i in s1:
            ls1.append(i)
        for n in s2:
            ls2.append(n)
        q = 0
        succ = 0
        fail = 0
        if len(ls1) <= len(ls2):
            for j in range(len(ls1)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        else:
             for j in range(len(ls2)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        try:
            spercent = round((succ/q)*100,2)
        except:
            spercent = 0
        return spercent

def colchk_dbdf(coldb = [], coldf = []):
    if isinstance(coldb, list) and isinstance(coldf, list):
        cdb = coldb
        cdf = coldf
        cdb.sort
        coldf.sort
        nonmat = []
        for i in range(len(cdb)):
            d1 = cdb[i]
            mat = 0
            for j in range(len(cdf)):
                if d1 == cdf[j]:
                    mat = 1
                    break
            if mat == 0:
                nonmat.append(d1)
        return nonmat

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""


def df_to_sql(dataframe, dbname, tablename, conn, oncolumn = "ALL", bycolumn = None, opeation = 'and'):
    srv = get_server_name(dbname, tablename, conn)
    print(srv)
    if srv == 'other':
        exit()
    cr = conn.cursor()
    try:
        cr.execute('select 1 from '+ tablename)
    except:
        print('table does not exits')
        exit()
    if oncolumn != 'ALL' and bycolumn == None:
        dataframe = dataframe[oncolumn]
    ndf = dataframe.replace(r'^\s*$', np.nan, regex=True)
    xdf = ndf.convert_dtypes()
    dfcol = xdf.columns.to_list()
    if srv == "MYSQL":
        dbcol = mysql_table_colname(dbname, tablename, conn) #function call
    elif srv == "MSSQL":
        dbcol = mssql_table_colname(dbname, tablename, conn) #function call
    nonmat = colchk_dbdf(dbcol,dfcol)
    dfc = []
    rnmcol = {}
    if len(nonmat) != 0:
        for n in range(len(nonmat)):
            dbc = nonmat[n]
            y = 0
            for i in range(len(dfcol)):
                x = fuzzymatch(dbc, dfcol[i])
                #print(dbc,' - ',  dfcol[i], ' p- ', x, ' max ', y)
                if x >= y:
                    y = x
                    dfcl = dfcol[i]
            else:
                dfc.append(dfcl)
                rnmcol[dfcl] = dbc
    xdf = xdf.rename(columns = rnmcol)
    if srv == "MYSQL":
        dc = mysql_table_colinfo(dbname, tablename, conn)  #mysql function call
    elif srv == "MSSQL":
        dc = mssql_table_colinfo(dbname, tablename, conn)  #mysql function call
    df = dtype_match_dbdf(xdf, dc) #function call
    if bycolumn == None:
        excmd = []
        q = 0
        rwval = []
        colval = df.columns.to_list()
        er = []
        for (indx, rwseries) in df.iterrows():
            q = q + 1
            rwval = rwseries.values.tolist()
            x = insert_into_sql(tablename, dc, colval, rwval)
            try:
                cr.execute(x)
                excmd.append(x)
            except:
                er.append(x)
                qq = "dfrow: " + str(q)
                er.insert(0, qq)
        print('row inserted: ', q - len(er), ' error found for rows: ', len(er), ", get error in return")
        wrt.wrt2txt(excmd, 'exe_succ')
        wrt.wrt2txt(excmd, 'exe_fail')
        return er
    else:
        tableprop = dc
        excmd = upd.UPIN(df, tablename, tableprop, conn, bycols = bycolumn, operations = 'and')
        wrt.wrt2txt(excmd, 'exe_succ')





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\dt.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from oFn.fn import *
import oFn.fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            df1 = fnx.add_col_df(df, 'newcol')
            df1[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df1 = fnx.add_col_df(df, 'newcol')
        df1[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fileprocess.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = pt + "\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]



def df_add_list_col(dfx,nc,nwlst):
    dfx[nc] = np.nan
    dfx[nwcol] = np.array(nwlst)
    return dfx

def vlookup(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values 
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df
            
        
def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx
    
def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        lst = df[dt_col1]
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        lst = df[dt_col1]
        clr = df[dt_col2]
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    df[nwcol] = np.nan
    df[nwcol] = np.array(ls)
    print('In Minutes')
    return df
        
def process_sem_raw(df):
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CUSTOMATTR15']
    LL2 = df1['LASTOCCURRENCE']
    LL3 = df1['CLEARTIMESTAMP']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    print(ndf3)

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , Ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(df, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(df,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs():
    pass
def match():
    pass

df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
print(asq)




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\finally.py###
import subprocess
import time
import threading
import urllib
import requests
import queue

#def output_reader(proc, outq):
    #for line in iter(proc.stdout.readline, b''):
        #print('got line: {0}'.format(line.decode('utf-8')), end='')

def output_reader(proc, outq):
    for line in iter(proc.stdout.readline, b''):
        outq.put(line.decode('utf-8'))
        try:
            ln = outq.get(block=False)
            print('got line from outq: {0}'.format(ln), end='')
        except queue.Empty:
            print('could not get line from queue')

def main():
    #['python3', '-u', '-m', 'http.server', '8070']
    proc = subprocess.Popen(["gost","-L","socks5://0.0.0.0:11126","-D"],
                            stdout=subprocess.PIPE,
                            stderr=subprocess.STDOUT)
    outq = queue.Queue()
    t = threading.Thread(target=output_reader, args=(proc,outq))
    t.start()

    try:
        proc.wait(timeout=0.2)
        print('== subprocess exited with rc =', proc.returncode)
    except subprocess.TimeoutExpired:
        print('subprocess did not terminate in time')
    t.join()
    
main()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluc.py###
import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *
import flucsem as sem
import requests

#print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
#df = pd.read_csv(os.getcwd() + "\\B1.csv")
#nw = datetime.now()

n = datetime.now ()
td = n.today()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

TS1 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('2' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('3' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('4' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))

TS2 = lambda x: 'G2' if ('2G SITE DOWN' in x) \
    else ('C2' if ('2G CELL DOWN' in x) \
    else ('G3' if ('3G SITE DOWN' in x) \
    else ('C3' if ('3G CELL DOWN' in x) \
    else ('G4' if ('4G SITE DOWN' in x) \
    else ('C4' if ('4G CELL DOWN' in x) \
    else ('C2' if ('OML' in x) \
    else "0"))))))


DCAT = lambda x: 'H2' if (x < 90) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    #df4 = df2.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    #df4 = df2.reset_index()
    df2.to_csv(os.getcwd() + "\\T1.csv")
    return df2

def pivt(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)
    return pv
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    
def techwise(df, colnm, catby, fld0, fld1, fld2):
    hp = chr(10)
    q = 0
    for i in range(len(df)):
        n1 = df.loc[i,colnm]
        if catby in n1:
            hp = hp + chr(10) + df.loc[i,fld0] + ": " + str(df.loc[i,fld1]) + " | "  + str(df.loc[i,fld2])
    else:
        return catby + ":" + hp
    

df = sem.semqry_dummy()
print(df)
#fdf = extrafeat(df)
#ndf = pivt(fdf)

df2 = datediff_ondf(df, "DUR", 'LASTOCCURRENCE')
df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
df3 = df2[df2['SUMMARY'].str.contains('SITE DOWN') | df2['SUMMARY'].str.contains('CELL DOWN')]
df4 = df3.assign(CT1 = np.where(df3['SUMMARY'].str.contains('SITE DOWN'), 'SITE', 'CELL'))
df4 = df4.sort_values(by=['CT1'], ascending=False)
df4['CT2'] = df4.apply (lambda x: TS1 (x.SUMMARY), axis=1)
df4 = df4.astype(str)
df4['UNQ'] = df4['CUSTOMATTR15'].map(str) + '_' + df4['LO'].map(str) + "_" + df4['CT2'].map(str)
df5 = df4.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
df6 = df5.reset_index()
df6 = df6[~df6['CUSTOMATTR15'].isin(['UNKNOWN'])]
df6 = df6[~df6['CUSTOMATTR15'].isnull()]
#df[~df['var2'].isnull()]
df6['CT3'] = df6.apply (lambda x: TS2 (x.SUMMARY), axis=1)
df6['CT4'] = df6['CUSTOMATTR15'].map(str) + '_' + df6['CT3'].map(str)
df6['CT5'] = df6['CT4'].map(str) + "_" + df6['DCT'].map(str)
ls1 = df6['CT5'].to_list()
print(ls1)
print(df6.columns)
df6.to_csv(os.getcwd() + "\\Tju1.csv")
df6 = df6.drop_duplicates(subset=['CT5'], inplace=False, ignore_index=True)
df6 = df6.reset_index()
st = chr(10)
lss = []
G2 = "2G:"
G3 = "3G:"
G4 = "4G:"
cnt = 0
for i in range(len(df6)):
    x = df6.loc[i,"CT4"]
    y1 = x + "_H12"
    y2 = x + "_H2"
    ab = df6.loc[i,"CUSTOMATTR15"] + ' - ' + df6.loc[i,"CT3"] + " - " + str(ls1.count(y2)) + "/" + str(ls1.count(y1))
    ac = df6.loc[i,"CUSTOMATTR15"] + ' - ' + str(ls1.count(y1)) + " | " + str(ls1.count(y2))
    st = st + chr(10) + ab
    if ls1.count(y1)>9 and ls1.count(y2)>0 and df6.loc[i,"CUSTOMATTR15"] is not None:
        cnt = 1
        if df6.loc[i,"CT3"] == "G2":
            G2 = G2 + chr(10) + ac
        elif df6.loc[i,"CT3"] == "G3":
            G3 = G3 + chr(10) + ac
        elif df6.loc[i,"CT3"] == "G4":
            G4 = G4 + chr(10) + ac
else:
    if len(G2)<5:
        G2 = "2G:" + chr(10) + "NA"
    if len(G3)<5:
        G3 = "3G:" + chr(10) + "NA"
    if len(G4)<5:
        G4 = "4G:" + chr(10) + "NA"
    FG = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4 + chr(10) + chr(10)
    th1 = "Site Fluctuation Status" + chr(10) + "at " + "20:01 on 12-18-2020" + chr(10)
    th2 = "Tech: fluctuations count 00hr to last hr|only last hr count" + chr(10)
    FM = th1 + chr(10) + th2 + chr(10) + FG
    print(FM)
    msk = '-475120904'
    q1 = tmsg (msk, FM)
    

#df8 = df8.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
#df8.to_csv(os.getcwd() + "\\AA5.csv", index = False)
#site = df6[df6['SUMMARY'].str.contains('SITE DOWN')]
#cell = df6[df6['SUMMARY'].str.contains('CELL DOWN')]
#dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
#pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
#df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
#pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)










$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\flucsem.py###
import os, cx_Oracle
import time as ti
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *
from datetime import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"

nw = datetime.now()
td = nw.strftime("%Y_%b_%d")
mylog = os.getcwd() + "\\log"
todaylog = os.getcwd() + "\\log\\" + td
print(todaylog)

try:
    os.makedirs(mylog)
    os.makedirs(todaylog)
    print("folder created successfully")
except:
    try:
        os.makedirs(todaylog)
    except:
        print(" todayslog folder exits + ")

n = datetime.now ()
td = n.today()
#print(str(td) + "00:00:00")
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")


def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def lasthr(diff = 1):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%H")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,X733EVENTTYPE,X733SPECIFICPROB,CLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR26,TTSEQUENCE,ALARMDETAILS,EQUIPMENTKEY,SITECODE,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    #cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    x = n
    hr = x.strftime('%H')
    STDT = timedelt(-int(hr))
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    lscol = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']
    ddf = df[lscol]
    ddf.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    return ddf

def semqry_dummy():
    df = pd.read_csv(os.getcwd () + "\\SEMQRY.csv")
    return df
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\flucSlave.py###
import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *
import flucsem as sem
import requests

#print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
#df = pd.read_csv(os.getcwd() + "\\B1.csv")
#nw = datetime.now()

n = datetime.now ()
td = n.today()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

TS1 = lambda x: '2' if ('2G SITE DOWN' in x) \
    else ('2' if ('2G CELL DOWN' in x) \
    else ('3' if ('3G SITE DOWN' in x) \
    else ('3' if ('3G CELL DOWN' in x) \
    else ('4' if ('4G SITE DOWN' in x) \
    else ('4' if ('4G CELL DOWN' in x) \
    else ('2' if ('OML' in x) \
    else "0"))))))

TS2 = lambda x: 'G2' if ('2G SITE DOWN' in x) \
    else ('C2' if ('2G CELL DOWN' in x) \
    else ('G3' if ('3G SITE DOWN' in x) \
    else ('C3' if ('3G CELL DOWN' in x) \
    else ('G4' if ('4G SITE DOWN' in x) \
    else ('C4' if ('4G CELL DOWN' in x) \
    else ('C2' if ('OML' in x) \
    else "0"))))))


DCAT = lambda x: 'H2' if (x < 90) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    #df4 = df2.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    #df4 = df2.reset_index()
    df2.to_csv(os.getcwd() + "\\T1.csv")
    return df2

def pivt(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)
    return pv
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    
def techwise(df, colnm, catby, fld0, fld1, fld2):
    hp = chr(10)
    q = 0
    for i in range(len(df)):
        n1 = df.loc[i,colnm]
        if catby in n1:
            hp = hp + chr(10) + df.loc[i,fld0] + ": " + str(df.loc[i,fld1]) + " | "  + str(df.loc[i,fld2])
    else:
        return catby + ":" + hp
    

#df = sem.semqry_dummy()
#print(df)
#fdf = extrafeat(df)
#ndf = pivt(fdf)
def flucslave(df0):
    lscol = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']
    df = df0[lscol]
    df2 = datediff_ondf(df, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df3 = df2[df2['SUMMARY'].str.contains('SITE DOWN') | df2['SUMMARY'].str.contains('CELL DOWN')]
    df4 = df3.assign(CT1 = np.where(df3['SUMMARY'].str.contains('SITE DOWN'), 'SITE', 'CELL'))
    df4 = df4.sort_values(by=['CT1'], ascending=False)
    df4['CT2'] = df4.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df4 = df4.astype(str)
    df4['UNQ'] = df4['CUSTOMATTR15'].map(str) + '_' + df4['LO'].map(str) + "_" + df4['CT2'].map(str)
    df5 = df4.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
    df6 = df5.reset_index()
    df6 = df6[~df6['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df6 = df6[~df6['CUSTOMATTR15'].isnull()]
    #df[~df['var2'].isnull()]
    df6['CT3'] = df6.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df6['CT4'] = df6['CUSTOMATTR15'].map(str) + '_' + df6['CT3'].map(str)
    df6['CT5'] = df6['CT4'].map(str) + "_" + df6['DCT'].map(str)
    ls1 = df6['CT5'].to_list()
    print(ls1)
    print(df6.columns)
    df6.to_csv(os.getcwd() + "\\Tju1.csv")
    df6 = df6.drop_duplicates(subset=['CT5'], inplace=False, ignore_index=True)
    df6 = df6.reset_index()
    st = chr(10)
    lss = []
    G2 = "2G:"
    G3 = "3G:"
    G4 = "4G:"
    cnt = 0
    for i in range(len(df6)):
        x = df6.loc[i,"CT4"]
        y1 = x + "_H12"
        y2 = x + "_H2"
        ab = df6.loc[i,"CUSTOMATTR15"] + ' - ' + df6.loc[i,"CT3"] + " - " + str(ls1.count(y2)) + "/" + str(ls1.count(y1))
        ac = df6.loc[i,"CUSTOMATTR15"] + ' - ' + str(ls1.count(y1)) + " | " + str(ls1.count(y2))
        st = st + chr(10) + ab
        if ls1.count(y1)>9 and ls1.count(y2)>0 and df6.loc[i,"CUSTOMATTR15"] is not None:
            cnt = 1
            if df6.loc[i,"CT3"] == "G2":
                G2 = G2 + chr(10) + ac
            elif df6.loc[i,"CT3"] == "G3":
                G3 = G3 + chr(10) + ac
            elif df6.loc[i,"CT3"] == "G4":
                G4 = G4 + chr(10) + ac
    else:
        if len(G2)<5:
            G2 = "2G:" + chr(10) + "NA"
        if len(G3)<5:
            G3 = "3G:" + chr(10) + "NA"
        if len(G4)<5:
            G4 = "4G:" + chr(10) + "NA"
        FG = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4 + chr(10) + chr(10)
        th1 = "Site Fluctuation Status" + chr(10) + "at " + "20:01 on 12-18-2020" + chr(10)
        th2 = "Tech: fluctuations count 00hr to last hr|only last hr count" + chr(10)
        FM = th1 + chr(10) + th2 + chr(10) + FG
        print(FM)
        msk = '-475120904'
        q1 = tmsg (msk, FM)
    

#df8 = df8.drop_duplicates(subset=['UNQ'], inplace=False, ignore_index=True)
#df8.to_csv(os.getcwd() + "\\AA5.csv", index = False)
#site = df6[df6['SUMMARY'].str.contains('SITE DOWN')]
#cell = df6[df6['SUMMARY'].str.contains('CELL DOWN')]
#dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
#pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
#df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
#pv.to_csv(os.getcwd() + "\\IAMPY.csv", index = False)










$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation - Copy.py###
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120) \
    else ('H12' if (x < 720)\
    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('extrafeat',df.shape[0])
    return df

def filter_rmvdup_cnt(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    xdf = xdf.reset_index()
    xdf = xdf.sort_values(by=['CAT','CDLO'], ascending=True)
    xdf = xdf.reset_index()
    df1 = xdf.drop_duplicates(subset=['CDLOTECH'], ignore_index=True)
    ndf = countifs(df1, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    return odf
    

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    df5 = filter_rmvdup_cnt(df4)
    

    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    q = tmsg(msk, "SITE " + GG2)
    q = tmsg (msk, "CELL " + GG2C)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    q = tmsg (msk, "SITE " + GG3)
    q = tmsg (msk, "CELL " + GG3C)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    q = tmsg (msk, "SITE " + GG4)
    q = tmsg (msk, "CELL " + GG4C)
    print('done')

def filter_rmvdup_cnt(df):
    print(df.columns)
    #xdf = df.reset_index()
    #xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    #xdf = xdf.reset_index()
    df2 = df[~df['CATX'].isin(['other'])]
    df = df2.reset_index()
    xdf = df.sort_values(by=['CAT','CDLO'], ascending=True)
    xdf = xdf.reset_index()
    df1 = xdf.drop_duplicates(subset=['CDLOTECH'], ignore_index=True)
    ndf = countifs(df1, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf)
    return odf

def catmap_md(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    df1 = df0
    #ls = text2list (semcol)
    #df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    df5 = filter_rmvdup_cnt(df4)
    return df5


print(os.getcwd())
svpt = os.getcwd () + "\\OMTX.csv"
df = pd.read_csv (svpt, low_memory=False)
catmap_md(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation.py###
import os, cx_Oracle
import time as ti
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *
from datetime import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"

nw = datetime.now()
td = nw.strftime("%Y_%b_%d")
mylog = os.getcwd() + "\\log"
todaylog = os.getcwd() + "\\log\\" + td
print(todaylog)

try:
    os.makedirs(mylog)
    os.makedirs(todaylog)
    print("folder created successfully")
except:
    try:
        os.makedirs(todaylog)
    except:
        print(" todayslog folder exits + ")

n = datetime.now ()
td = n.today()
#print(str(td) + "00:00:00")
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")


def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def lasthr(diff = 1):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%H")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,X733EVENTTYPE,X733SPECIFICPROB,CLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR26,TTSEQUENCE,ALARMDETAILS,EQUIPMENTKEY,SITECODE,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    #cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    x = n
    hr = x.strftime('%H')
    STDT = timedelt(-int(hr))
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    df.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    df2 = pd.read_csv(os.getcwd () + "\\SEMQRY.csv")
    print(df2)
    return df2

def wrt2txt(contents, filename = 'excmd', flpath = None):
    print('contets', contents)
    filename =  n.strftime("%Y%m%d%H%M%S")
    if flpath == None:
        flpath = tm + '.txt'
    else:
        flpath = flpath + "\\" + filename + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 60) else ('H12')

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('extrafeat')
    return df

def prob(df):
    df.to_csv (os.getcwd () + "\\FINAL15.csv", index=False)
    xdf = pd.read_csv(os.getcwd () + "\\FINAL15.csv")
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    
    print(odf.shape[0])
    try:
        fdf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        fdf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', fdf.shape[0])
    print(fdf.columns)
    pvt = fdf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt', aggfunc='sum').reset_index()
    pvt.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    pvt = pd.read_csv(os.getcwd () + "\\pvt.csv")
    ndf = pvt[(pvt['H2'] > 1) & (pvt['H12'] > 10)]
    return ndf

def append_dic_value(dict_obj, key, value):
    if key in dict_obj:
        if not isinstance(dict_obj[key], list):
            dict_obj[key] = [dict_obj[key]]
        dict_obj[key].append(value)
    else:
        dict_obj[key] = value

def dic_by_key(dc, ky):
    hp = ky + " : "
    for key in dc:
        if key == ky:
            ls = dc[key]
            if isinstance(ls, list):
                for i in range(len(ls)):
                    if ls[i] not in hp:
                        hp = hp + chr(10) + ls[i]
                    else:
                        pass
                else:
                    if len(hp) < 8:
                        return "3G - 0"
                    else:
                        return chr(10) + hp
                    exit()
            elif ls is None or ls == '':
                return hp + " 0" + chr(10)
                exit()
            else:
                try:
                    hp = chr(10) + hp + chr(10) + ls
                    return hp
                    exit()
                except:
                    return hp + " 0" + chr(10)
                    exit()


def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    df3 = pd.DataFrame([])
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    print(df3)
    xdf = filter_p(df3, ['2G', '3G', '4G'], 'CATX')
    xdf.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(xdf)
    return df4

def sort_rvmdup(df):
    print('sort_rvmdup')
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    df1 = pd.read_csv(os.getcwd () + "\\FINAL13.csv")
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    return df1


def nonechk(tech, x):
    try:
        y = len(x)
        print(y)
        return x
    except:
        return chr(10) + tech + ': NA'

def final_mod(xdf):
    shp = xdf.shape[0]
    print('fmod start- ', shp)
    df1 = xdf.sort_values(by=['LASTOCCURRENCE'], ascending=True)
    df1 = df1.reset_index()
    print('fmod after reset index at line 266 - ', df1.shape[0])
    df1 = df1.assign(hr = '0')
    df1['hr'] = df1.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%H"), axis=1)
    hr = lasthr(1)
    dfh = df1[df1['hr'].isin([hr])]
    print('pick for last hour line 171 and found shape ', dfh.shape[0], ' checking hour ', hr)
    dff = dfh.reset_index()
    print('save file asdff after reset index at line 273- found row length', dff.shape[0])
    df = dff[['EQUIPMENTKEY','CUSTOMATTR15','CAT','CATX']]  ##-------------------df1 = all------------df = this hour
    df.to_csv(os.getcwd () + "\\OKOK.csv", index = False)
    print("\n \n")
    site = {}
    cell = {}
    A = {}
    B = {}
    df = df.astype(str)   #this hour
    df1 =  df1.astype(str)
    hpp = []
    qn = 0
    for i in range(len(df)):
        cat = df.loc[i,'CAT']
        qn = qn + 1
        if int(cat) == 2 or int(cat) == 3 or int(cat) == 4:
            ctx = df.loc[i,'CATX']
            code = df.loc[i, 'CUSTOMATTR15']
            this_hr = countifs(df, df['CUSTOMATTR15'], code, df['CAT'], str(cat))
            all_hr = countifs(df1, df1['CUSTOMATTR15'], code, df1['CAT'], str(cat))
            rest_hr = int(all_hr) - int(this_hr)
            #print(this_hr, all_hr, rest_hr)
            heap1 = code + "-" + str(ctx) + " running for Hour: " + str(hr) + " ~count for thishour-"  + str(this_hr) + "- all hour-" + str(all_hr)
            #print(heap1)
            hpp.append(heap1)
            if rest_hr >= 10:
                st = code + " - " + str(all_hr)
                #print(ctx , st)
                append_dic_value(site, ctx, st)
            else:
                #print('~~~~~~~', ctx, code)
                pass
        elif int(cat) == 22 or int(cat) == 33 or int(cat) == 44:
            ctx = df.loc[i,'CATX'] + " Cell"
            code = df.loc[i, 'EQUIPMENTKEY']
            this_hr = countifs(df, df['EQUIPMENTKEY'], code, df['CAT'], str(cat))
            all_hr = countifs(df1, df1['EQUIPMENTKEY'], code, df1['CAT'], str(cat))
            heap1 = code + " (" + str(ctx) + ") - last Hour fluc: " + str(this_hr) + ", fluc from 00:" + str(all_hr)
            hpp.append(heap1)
            rest_hr = int(all_hr) - int(this_hr)
            #print(this_hr, all_hr, rest_hr)
            if rest_hr >= 10:
                st = code + " - " + str(all_hr)
                #print(ctx , st)
                append_dic_value(cell, ctx, st)
            else:
                #print('~~~~~~~', ctx ,code)
                pass
        else:
            print('else')
    wrt2txt(hpp, "fluc_process", todaylog)       
    G2 = nonechk("2G ", dic_by_key(site, "2G"))
    G3 =  nonechk("3G ", dic_by_key(site, "3G"))
    G4 =  nonechk("4G ",dic_by_key(site, "4G"))
    G22 = nonechk("2G Cell ", dic_by_key(cell, "2G Cell"))
    G33 = nonechk("3G Cell ", dic_by_key(cell, "3G Cell"))
    G44 = nonechk("4G Cell ", dic_by_key(site, "4G Cell"))
    sitewise = G2 + chr(10) + G3 + chr(10) + G4
    cellwise = G22 + chr(10) + G33 + chr(10) + G44
    HD1 = "Site Fluctuation Status" + chr (10) + "at " + tm + chr (10) + sitewise
    HD2 = "Cell Fluctuation Status" + chr (10) + "at " + tm + chr (10) + cellwise
    print(HD1)
    print(HD2)
    msk = '-1001199723504'
    q1 = tmsg (msk, HD1)
    q2 = tmsg (msk, HD2)
    wrt2txt(hpp)

    
def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        





def save2db(df):
    soc ="Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(soc)
    xx = df2sq(df, 'fluc1', conn, bycol='SERIAL')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
#conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
#print (conn.version)
#conn.close()
#import qrybuilt as qr
#from omsql.create_table.tbl_mssql import *

def main(df):
    #cols = ["SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"]
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    #try:
        #CreateTable_MSSQL(df1, 'fluc1', con)
        #dfqry = qr.qbuilt(df1,'fluc1',['SERIAL'])
        #dfqry.to_csv(os.getcwd () + "\\qry.csv", index=False)
    #except:
        #pass
    df2 = sort_rvmdup(df1)
    df4 = final_mod(df2)
    #con = qr.mssql_121()
    #cr= con.cursor()
    #for i in range(len(dfqry)):
        #a1 = dfqry.iloc[i,1]
        #a2 = dfqry.iloc[i,2]
        #try:
            #cr.execute(a1)
        #except:
            #cr.execute(a2)
    #else:
        #con.commit()
    
    #con = mssql_121()
    #print(updf.shape[0])
    #updf = updf.reset_index()
    #updf.to_csv(os.getcwd () + "\\updf.csv", index = False)
    #udf = pd.read_csv(os.getcwd () + "\\updf.csv")
    #ud = udf[['NODE','AGENT','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','EQUIPMENTKEY','CUSTOMATTR15','CAT','CATX','CODE','ZONE','DUR','DURCAT','LO','CDLO','CDLOTECH','SERIAL']]
    #sq.create_table(ud, 'fromfluc2', con)
    #try:
        #sq.update_table(ud, 'SOC_Roster', 'fromfluc2', con, ['SERIAL'])
    #except:
        #sq.upload_bulkdata(ud,'fromfluc2', con, 'SOC_Roster')
        

df = semqry()
y = main(df)
    
#xdf = pd.read_csv(os.getcwd () + "\\FINAL13.csv")
#print(xdf)
#df4 = final_mod(xdf)



#ls = ['NODE','AGENT','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','EQUIPMENTKEY','CUSTOMATTR15','CAT','CATX','CODE','ZONE','DUR','DURCAT','LO','CDLO','CDLOTECH','SERIAL']
#df1 = pd.read_csv(os.getcwd () + "\\updf.csv")
#dfx = df1[ls]
#conn = sq.mssql_121()
#sq.df_to_sql(dfx, 'SOC_Roster', 'fromfluc2', conn, bycolumn=['CDLOTECH'])
#a.to_csv(os.getcwd () + "\\aa.csv")
#df = pd.read_sql("select * from fromfluc2", con = conn)
#print(df)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation1.py###
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d


def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: '2H' if (x < 120) \
    else ('4H' if (x < 240)\
    else ('6H' if (x < 360)\
    else ('12H' if (x < 720)\
    else ('24H' if (x < 1440)\
    else ('48H' if (x < 2880)\
    else ('72H'))))))

TS = lambda x: '2G' if ('2G' in x) \
    else ('3G' if ('3G' in x) \
    else ('4G' if ('4G' in x) \
    else ('OML' if ('2G' in x) \
    else "other")))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    return odf

def sort_rvmdup(df):
    df1 = df[~df['CATX'].isin(['other']) & ~df['CAT'].isin(['other'])]
    df1 = df1.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['72H'] > 10) & (pvt['48H'] > 2)]
    return ndf

def fmtmsg_techwise(df, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    heap = ''
    hp = ""
    hpx = ""
    for n in range(len(df)):
        code = df.loc[n, name_thread_col]
        cat = df.loc[n, name_catcol]
        if str(cat) == str(cat_text):
            for i in range(len(ls_datacol)):
                if hp == "":
                    hp = df.loc[n, ls_datacol[i]]
                else:
                    hp = hp + " | " + df.loc[n, ls_datacol[i]]
            hpx = code + ": " + hp
            if heap == "":
                heap = hpx
                hp = ""
            else:
                heap = heap + chr(10) + hpx
                hp = ""
    return heap

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    df1.to_csv(os.getcwd () + "\\SEMQRY.csv")
    return df1

def main(df):
    ls = ['2H', '12H']
    df1 = catmap_mod(df)
    df2 = sort_rvmdup(df1)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ls, 'CAT', '2') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ls, 'CAT', '3') + chr (10) + chr (10)
    G4 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ls, 'CAT', '4') + chr (10) + chr (10)
    HD1 = "SITE FLUCTUATION COUNT" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | 12Hr" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates 2+ in last 2hr and 10+ in last 12hr"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    msk = '-407548960'
    q = tmsg(msk, GG2)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    q = tmsg (msk, GG3)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    q = tmsg (msk, GG4)
    print('done')

#svpt = os.getcwd () + "\\OMTX.csv"
df = semqry()
xxx = main(df)
#svpt = os.getcwd () + "\\pvt.csv"
#df = pd.read_csv (svpt, low_memory=False)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fluctuation2.py###
import os, cx_Oracle
import time as ti
from datetime import *
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *


livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    STDT = timedelt(-23)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    df.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    df2 = pd.read_csv(os.getcwd () + "\\SEMQRY.csv")
    print(df2)
    
    return df2

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120) \
    else ('H12' if (x < 720)\
    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('2G' if ('2G CELL DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('3G' if ('3G CELL DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('4G' if ('4G CELL DOWN' in x) \
    else ('2G' if ('OML' in x) \
    else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('extrafeat')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    xdf.to_csv (os.getcwd () + "\\FINAL15.csv", index=False)
    xdf = pd.read_csv(os.getcwd () + "\\FINAL15.csv")
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    pvt = odf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    pvt.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    pvt = pd.read_csv(os.getcwd () + "\\pvt.csv")
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    df3 = pd.DataFrame([])
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    print(df3)
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    return df4
    

def sort_rvmdup(df):
    print('sort_rvmdup')
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    df1 = pd.read_csv(os.getcwd () + "\\FINAL13.csv", index = False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    return df1

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df2 = sort_rvmdup(df0)
    df0 = prob(df1)
    
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    q = tmsg(msk, "SITE " + GG2)
    q = tmsg (msk, "CELL " + GG2C)
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    q = tmsg (msk, "SITE " + GG3)
    q = tmsg (msk, "CELL " + GG3C)
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    q = tmsg (msk, "SITE " + GG4)
    q = tmsg (msk, "CELL " + GG4C)
    print('done')

def save2db(df):
    soc ="Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(soc)
    xx = df2sq(df, 'fluc1', conn, bycol='SERIAL')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
#conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
#print (conn.version)
#conn.close()

df = semqry()
y = main(df)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fn.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def con_sec(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = con_sec(abs(d1 - d2).total_seconds())
            return x
    except:
        return "NA"
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,newcolname,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,newcolname)
            df1[newcolname] = pd.Series(ls)
            xyz = "cnt-" + str(df0.shape[1]) 
            df2 = df1.groupby([newcolname])[newcolname].count().to_frame(name = xyz).reset_index()
            df = df1.merge(df2, on=newcolname)
            df = df.drop(newcolname, axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fndatetime.py###
import pandas as pd
import numpy as np
from datetime import *


nw = datetime.now().strftime("%d/%m/%Y %H:%M:%S")

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def timediff(df,c1,c2,newcol):
    df[c1] = pd.to_datetime(df[c1])
    df[c2] = pd.to_datetime(df[c2])
    df1 = add_col_df(df,newcol)
    df1[newcol] = abs(df1[c2] - df1[c1])
    df1[newcol] = df1[newcol].astype("i8")/1e9
    df1[newcol] = df1[newcol] / 60
    return df1

def timediff_2(df,c1,c2,newcol):
    df[c1] = pd.to_datetime(df[c1])
    df[c2] = pd.to_datetime(df[c2])
    df1 = add_col_df(df,newcol)
    df1[newcol] = abs(df1[c2] - df1[c1])
    df1[newcol] = df1[newcol].astype('timedelta64[m]')
    return df1

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        df1 = add_col_df(df,'NOW',nw)
        df2 = timediff(df1,dt_col1,'NOW',nwcol)
        df3 = df2.drop(['NOW'], axis = 1)
        return df3
        #lst = df[dt_col1]
        #ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        df2 = timediff(df,dt_col1,dt_col2,nwcol)
        return df2
        #ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    #df[nwcol] = np.nan
    #df[nwcol] = np.array(ls)
    #print('In Minutes')


def datediff(unit,Time1,Time2):
    print(type(Time1))
    print(type(Time2))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnfn.py###
import pandas as pd
import numpy as np
from datetime import *

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def filtering(df, oncol, lst, byhow):
    if byhow == 'out':
        df1 = df[~df[oncol].isin (lst)]
        return df1
    else:
        df1 = df[df[oncol].isin (lst)]
        return df1


def conct(df, col1, col2, newcolname, seperator=False):
    if seperator == False:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2])
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')
    else:
        try:
            df1 = add_col_df (df, newcolname)
            df1[newcolname] = df1[col1].str.cat (df1[col2], sep=seperator)
            return df1
        except:
            print ('conct: column name not found in dataframe or dataframe is not valid dataframe')


def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')


def map_df_dic(df0, dc, onkey_col, newcolname):
    df = add_col_df (df0, newcolname)
    df[newcolname] = df[onkey_col].map (dc)
    return df

def df_add_list_col(df, nc, nwlst):
    dfx = add_col_df (df, nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array (nwlst)
    return dfx


def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.drop_duplicates (subset=list_of_columns)
    return df


def sort_dsc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df.sort_values (by=oncol, ascending=False)


def sort_asc(ndf, oncol):
    df = ndf.replace (r'^\s*$', np.nan, regex=True)
    df = df.sort_values (by=oncol, ascending=True)
    return df


def left(df, sdf, i):
    df1 = add_col_df (df, 'left_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[0:i])
    return df1


def right(df, sdf, i):
    df1 = add_col_df (df, 'right_apply')
    df1['left_apply'] = sdf.apply (lambda x: x[-i:len (x)])
    return df1


def vlookup(df0, refdic, refcol, nwcol):
    if isinstance (refdic, dict):
        try:
            df = add_col_df (df0, nwcol)
            df[nwcol] = df.reset_index ()[refcol].map (refdic).values
            return df
        except:
            df = map_df_dic (df0, refdic, refcol, nwcol)
            return df
    else:
        ndf = df0.merge (refdic, on=refcol)
        return ndf


def countifz(df, list_of_cols_as_ref, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[st].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[col].count ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def datediff(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")


def aplist(L1, L2):
    ls = []
    if isinstance (L1, pd.core.series.Series) and isinstance (L2, pd.core.series.Series):
        ls1 = L1.to_list ()
        ls2 = L2.to_list ()
        ls = [i + j for i, j in zip (ls1, ls2)]
    elif isinstance (L1, list) and isinstance (L2, list):
        ls = [i + j for i, j in zip (L1, L2)]
    elif isinstance (L1, pd.core.series.Series) and isinstance (L2, str):
        ls1 = L1.to_list ()
        for i in range (len (ls1)):
            ni = str (ls1[i]) + L2
            ls.append (ni)
    elif isinstance (L1, list) and isinstance (L2, str):
        for i in range (len (L1)):
            ni = str (L1[i]) + L2
            ls.append (ni)
    else:
        print ('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls


def countifs(df0, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            df2 = df1.groupby (['NC1']).NC1.count ().to_frame (name='cnt').reset_index ()
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt


def match(df, *argv):
    x = 0
    n = 0
    st_cnt = 0
    pds_cnt = 0
    if len (argv) > 0 and len (argv) <= 3:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str) or isinstance (argv[n], int):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "int" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        if pds_cnt == 0:
            colList = df.columns.to_list ()
            for i in range (len (colList)):
                if colList[i] == argv[0]:
                    x = i
                    break
            return x
        else:
            try:
                manner = argv[2]
            except:
                manner = 'none'
            if isinstance (argv[0], pd.core.series.Series):
                if manner == 'none' or manner == 'first':
                    idx = df[argv[0] == argv[1]].index[0]
                    return idx
                else:
                    idx = df[argv[0] == argv[1]].index
                    ln = len (idx)
                    if manner == 'last':
                        return idx[ln - 1]
                    elif manner == 'all':
                        return idx
                    else:
                        err = "command can be 'first' or 'last' or 'all'"
                        return err
    else:
        xx = "Match works only for a string or int on single col/series element"
        return xx


def sumifz(df, list_of_cols_as_ref, numeric_col, newcol):
    if len (list_of_cols_as_ref) > 1:
        st = ""
        for i in range (len (list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply (lambda x: ''.join (map (str, x)), axis=1)
        df1 = df.groupby (st)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=st)
        df2.drop (st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby (col)[numeric_col].sum ().to_frame (name=newcol).reset_index ()
        df2 = df.merge (df1, on=col)
        return df2


def instr(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.find (srcvalue)
        return f
    else:
        f = strtext.find (srcvalue)
        return f

def instrrev(strtext, srcvalue, start_pos=False):
    if start_pos:
        st = strtext[start_pos:]
        f = st.rfind (srcvalue)
        return f
    else:
        f = strtext.rfind (srcvalue)
        return f


def sumifs(df0, numeric_col, *argv):
    df = df0
    rngmod = len (argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len (argv) > 0:
        while n < len (argv):
            if isinstance (argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance (argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        print (pds_cnt, st_cnt)
        n = 0
        if st_cnt != 0:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                elif isinstance (argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count (stst)
            except:
                cnt = 0
        else:
            while n < len (argv):
                if isinstance (argv[n], pd.core.series.Series):
                    if len (ls) <= 1:
                        ls = argv[n].to_list ()
                    else:
                        ls0 = argv[n].to_list ()
                        ls1 = aplist (ls, ls0)
                        ls = ls1
                n = n + 1
            print (ls)
            df1 = add_col_df (df, 'NC1')
            df1['NC1'] = pd.Series (ls)
            print (df1)
            df2 = df1.groupby (['NC1'])[numeric_col].sum ().to_frame (name='sumifs').reset_index ()
            print (df2)
            df = df1.merge (df2, on='NC1')
            df = df.drop ('NC1', axis='columns')
        print (cnt)
        if cnt == -1:
            return df
        else:
            return cnt

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnlook.py###
import pandas as pd
import numpy as np
import os
from datetime import *


def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
        return dc
    except:
        print('err')

def vlookup(df0,refdic,refcol,nwcol):
    if isinstance(refdic,dict):
        try:
            df = add_col_df(df0, nwcol)
            df[nwcol] = df.reset_index()[refcol].map(refdic).values
            return df
        except:
            df = map_df_dic(df0,refdic,refcol,nwcol)
            return df
    else:
        ndf = df0.merge(refdic, on=refcol)
        return ndf

def sumif(df2,refcol,numeric_col,newcol):
    df3 = df2.groupby(refcol)[numeric_col].sum().to_frame(name = newcol).reset_index()
    dic = conv_lst_dic(df3[refcol],df3[newcol])
    df4 = map_df_dic(df2,dic,refcol,'sumif')
    return df4

def countif(df0,refcolumn,datacol,newcolname = False):
    if isinstance(refcolumn,str):
        df = add_col_df(df0, newcolname)
        rdf = df[refcolumn]
        reflst = rdf.values.tolist()
        vdf = df[datacol]
        nwlst = []
        for i in vdf:
            try:
                count = reflst.count(i)
                nwlst.append(count)
            except:
                nwlst.append('0')
    df[newcolname] = nwlst
    return df

df = pd.read_csv("C:\\Users\\kabir.omi\\Desktop\\B2.csv")
print(df.columns)
#df["N1"] = df.apply(lambda x : x.Cat + x.CustomAttr11, axis=1) #using 
#x = type(df)
##print(type(df['Cat']))
#print(type(df))
#print(df['Cat'])
print(df['Cat'].to_list().count('2G'))
print(df['Cat'].value_counts())

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnsem.py###
import pandas as pd
import numpy as np
from datetime import *
import os
import fnfn as fn

pt = os.getcwd()

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('C2G' if ('2G CELL DOWN' in x) \
                else ('C3G' if ('3G CELL DOWN' in x) \
                else ('C4G' if ('4G CELL DOWN' in x) \
                else "NA"))))))))))))

def vlookup(df0,refdic,refcol,nwcol):
    if isinstance(refdic,dict):
        try:
            df = add_col_df(df0, nwcol)
            df[nwcol] = df.reset_index()[refcol].map(refdic).values
            return df
        except:
            df = map_df_dic(df0,refdic,refcol,nwcol)
            return df
    else:
        ndf = df0.merge(refdic, on=refcol)
        return ndf

def catsemrw(df0):
    df = add_col_df(df0,'cat')
    df['cat'] = df.apply(lambda row: TS(row.SUMMARY), axis = 1)
    return df

def get_region(df,column_contains_code):
    codemap = ""
    if "\func" in pt:
        codemap = os.getcwd() + "\\scode_map.csv"
    else:
        codemap = os.getcwd() + "\\func\\scode_map.csv"
    dmap = pd.read_csv(codemap)
    df1 = add_col_df(df,'scode')
    df1['scode'] = df1[column_contains_code].apply(lambda x : x[0:5])
    df3 = vlookup(df1,dmap,'scode','NA')
    df3 = df3.drop('scode', axis='columns')
    return df3

def cat_region(df):
    df1 = catsemrw(df)
    df2 = get_region(df1)
    print(df2)

def code_corr(df):
    ndf = df
    for i in range(len(ndf)):
        Eky = str(ndf.loc[i,'EQUIPMENTKEY'])
        A15 = str(ndf.loc[i,'CUSTOMATTR15'])
        if A15 == 'UNKNOWN' and len(Eky) < 15:
            if len(Eky) == 7:
                df.loc[i,'CUSTOMATTR15'] = Eky
            elif len(Eky) == 10:
                df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
            elif '_' in str(Eky):
                fnd =  Eky.find('_')
                if fnd > 7:
                    df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
                else:
                    try:
                        df.loc[i,'CUSTOMATTR15'] = Eky[fnd:7]
                    except:
                        df.loc[i,'CUSTOMATTR15'] = "UNKNOWN"
    return df


def techwise(df0):
    G2 = ""
    G3 = ""
    G4 = ""
    df = df0.applymap(str)
    print(len(df))
    colcode = fn.match(df,'CUSTOMATTR15')
    colLo = fn.match(df,'LASTOCCURRENCE')
    colcat = fn.match(df,'cat')
    for i in range(len(df)):
        try:
            ct = df.iloc[i,colcat]
            if df.iloc[i,colcat] == "2G":
                if G2 == "":
                    ls = df.iloc[:,colcat].to_list()
                    cnt2 = ls.count("2G")
                    G2 = "2G: " + str(cnt2) + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
                else:
                    G2 = G2 + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
            elif df.iloc[i,colcat] == "3G":
                if G3 == "":
                    ls = df.iloc[:,colcat].to_list()
                    cnt3 = ls.count("3G")
                    G3 = "3G: " + str(cnt3) + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
                else:
                    G3 = G3 + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
            elif df.iloc[i,colcat] == "4G":
                if G4 == "":
                    ls = df.iloc[:,colcat].to_list()
                    cnt4 = ls.count("4G")
                    G4 = "4G: " + str(cnt4) + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
                else:
                    G4 = G4 + chr(10) + df.iloc[i,colcode] + ", " + df.iloc[i,colLo]
        except:
            print(i)
    G = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4
    print(G)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnstr.py###
import pandas as pd
import numpy as np

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('C2G' if ('2G CELL DOWN' in x) \
                else ('C3G' if ('3G CELL DOWN' in x) \
                else ('C4G' if ('4G CELL DOWN' in x) \
                else "NA"))))))))))))

def Lcut(mstr,cut_to):
    try:
        if len(mstr) >= cut_to:
            x = mstr[0:cut_to]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def Rcut(mstr,cut_to):
    try:
        if len(mstr) - cut_to >= 0:
            a = len(mstr) - cut_to
            b = len(mstr)
            x = mstr[a:b]
            return x
        else:
            print("length of string is less than 'cut_to'")
    except:
        return mstr

def src_in_str(mstr,lkstr):
    if lkstr in mstr:
        return mstr.find(lkstr)
    else:
        return 0

def code_corr(df0):
    df = df0
    for i in range(len(df)):
       Eky = df.loc[i,'EQUIPMENTKEY']
       A15 = df.loc[i,'CUSTOMATTR15']
       if A15 == 'UNKNOWN' and Eky != 'UNKNOWN' and len(Eky)<15:
           if len(Eky) == 7:
               df.loc[i,'CUSTOMATTR15'] = Eky
           elif '_' in Eky:
               x = Eky.find('_')
               if x > 4:
                   df.loc[i,'CUSTOMATTR15'] = Lcut(Eky,7)
               else:
                   df.loc[i,'CUSTOMATTR15'] = Rcut(Eky,7)
    return df

def catsemrw(df0):
    df = add_col_df(df0,'cat')
    df['cat'] = df.apply(lambda row: TS(row.SUMMARY), axis = 1)
    return df

def get_region(df):
    df4 = df
    df5 = flk.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df6.drop('ShortCode', axis='columns', inplace=True)
    return df6

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\fnx.py###
import pandas as pd
import numpy as np
from datetime import *


df0 = pd.DataFrame([['Iphone','DHDEM26','30-10-2020 12:14','25-11-2020 12:24','400'],['Iphone','CGHTZ09','11-09-2020 12:14','22-11-2020 12:24','400'],
['dell','LXRGN32','11-09-2020 12:14','19-11-2020 12:24','300'],['dell','LXRGN31', '11-09-2020 12:13','11-20-2020 12:24','300'],
['Samsung ','SGSJP04', '11-09-2020 12:12','11-20-2020 12:24','250'],['Samsung ','CXMHK36', '11-09-2020 12:11','11-20-2020 12:24','250'],
['Samsung ','CGFTK29', '11-09-2020 12:10','11-20-2020 12:24','250'],['dell','CGKTLB6','11-09-2020 12:10','11-20-2020 12:24','300'],
['dell','null', '11-09-2020 12:10','11-20-2020 12:24','300']],columns=('PRODUCT','ZIPCODE','SHIPMENT','DELIVERY','PRICE'))

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def sumifs(df,numeric_col,list_of_cols_as_ref):
    if len(list_of_cols_as_ref) > 1:
        st = ""
        for i in range(len(list_of_cols_as_ref)):
            if st == '':
                st = list_of_cols_as_ref[i]
            else:
                st = st + '-' + list_of_cols_as_ref[i]
        df[st] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)
        df1 = df.groupby(st)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=st)
        df2.drop(st, axis='columns', inplace=True)
        return df2
    else:
        col = list_of_cols_as_ref[0]
        df1 = df.groupby(col)[numeric_col].sum().to_frame(name = newcol).reset_index()
        df2 = df.merge(df1, on=col)
        return df2


def cntff(df, numeric_col, *argv):
    rngmod = len(argv) % 2
    if len(argv) > 0 and rngmod == 0:
        n = 0
        lscnt = 0
        stcnt = 0
        lsTmp = []
        ls = []
        st = ""
        while n < len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                if len(ls) < 1:
                    ls = argv[n]
                else:
                    lsTmp = aplist(ls,argv[n])
                    ls = lsTmp
                lscnt = lscnt + 1
            else:
                stcnt = stcnt + 1
                st = st + str(argv[n])
            n = n + 1
        df['NC1'] = pd.Series(ls)
        if stcnt == lscnt:
            df1 = df.groupby(st)[numeric_col].sum().to_frame(name = "X").reset_index()
        elif stcnt == 0:
            df1 = df.groupby([ls])[numeric_col].sum().to_frame(name = "X").reset_index()
        print(df1)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\Fomdf.py###
import pandas as pd
import numpy as np
import os
import sqlite3

pt = os.getcwd()
alarm = pt + "\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]


con = sqlite3.connect('omdb.db')
def create_tbl():
    cr = con.cursor()
    cr.execute("CREATE TABLE hs(SERIAL,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,CUSTOMATTR3)")
    con.commit()

def uoload_data(df1,dbname):
    df1.to_sql("'" + dbname + "'", con)

def delete_data(dbname):
    pass



def concat(v1,v2):
    z = str(v1) + '-' + str(v2)
    return z

CDCT = lambda x : x[:4] if (len(x) >= 6) else "NF"

def df_add_col(dff,nwcol,whichfn):
    df = dff.replace(r'^\s*$', np.NaN, regex=True)
    if whichfn == 'concat':
        for i in range(len(df)):
            df.loc[i,nwcol] = concat(df.loc[i,"CUSTOMATTR15"],df.loc[i,"SUMMARY"])
        return df
    elif whichfn == 'codecut':
        dfx = df.convert_dtypes()
        dfx = dfx.assign(scode = lambda x: CDCT(x.CUSTOMATTR15), axis=1)
        return dfx
    elif whichfn == 'datediff':
        df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].astype('datetime64[ns]')
        print(df)



x = df_add_col(df1,'scode','datediff')
print(x)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\get_groups_details_om.py###
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from pprint import pprint
import os

api_id = 628127
api_hash = 'db7fa09d585d6eedddd0df5973f3239b'
phone = '+8801817184338'
client = TelegramClient(phone, api_id, api_hash)
client.connect()

if not client.is_user_authorized():
    client.send_code_request(phone)
    client.sign_in(phone, input('Enter the code: '))
    print("success")



def group_participant(target_group):
    all_participants = client.get_participants(target_group, aggressive=True)
    print('GroupName: ', target_group, "total member: ", len(all_participants))
    print("serial | firstname | lastname | phone")
    n = 0
    for i in all_participants:
        n = n + 1
        x = 'adduser, halim, 23421435, 01817123123'
        x1 = 'adduser,' + str(i.first_name) + "," + str(i.id) + "," + str(i.phone)
        print(x1)
        #if i.last_name == 'none':
            #print(n, '. name: ' , i.first_name, ' | ' , "Phone: ", i.phone, i.id)
        #else:
            #print (n, '. name: ', i.first_name, i.last_name , ' | ', "Phone: ", i.phone, 'ID - ', i.id)
    #print(all_participants)

x = group_participant('VIP Sites Update')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\group_member_smpool.py###
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from pprint import pprint
import os


api_id = 1621549
api_hash = '6b06c3cf6e7004803b11c79f80e1b8bf'
phone = '+8801817183680'
client = TelegramClient(phone, api_id, api_hash)
client.connect()

if not client.is_user_authorized():
    client.send_code_request(phone)
    client.sign_in(phone, input('Enter the code: '))
    print("success")

def group_participant(target_group):
    all_participants = client.get_participants(target_group, aggressive=True)
    print('GroupName: ', target_group, "total member: ", len(all_participants))
    print("serial | firstname | lastname | phone")
    n = 0
    for i in all_participants:
        n = n + 1
        if i.last_name == 'none':
            print(n, '. name: ' , i.first_name, ' | ' , "Phone: ", i.phone)
        else:
            print (n, '. name: ', i.first_name, i.last_name , ' | ', "Phone: ", i.phone)

x = group_participant()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\handover.py###
import pandas as pd
import re

#SOCCOM = ["infoadd, 'subject'; 'body'; 'msgcat'; 'concern(optional)'; 'code (optional)'; 'tag (optional)'",
#"handover, No# 'subject'; 'body';'msgcat'; 'concern(optional)'; 'code (optional)'; 'tag (optional)",
#"query, 'text/code/category', date(optional)"]


#def insert_msg(dt, src, subject, body, concern = "", unit = "" code = "", tag = ""):
#    from =

def trcking_format():
    SOCCOM_HELP = """
@infoadd,
subject: mandatory;
body: mandatory;
concern: (optional);
unit: TNR (optional);
code: (optional);
tag: (optional);
date: (optional)
..
            
@infoadd,
subject: DHBDD32 Locked;
body: due to stolen issue, sites locked;
date: 2020-11-20
..
            
@hadover,
1#
subject: tx issue at DHGUL02;
body: due to TNR NCR Activity/other information;
concern: sudipta (optional);
unit: TNR (optional);
code: (optional);
tag: (optional)
..
            
2#
subject: fauction issue of DHGUL02;body: fls is checking, need followup;concern: TBA
.."""
    return SOCCOM_HELP


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\hidemy.py###
import requests
import pandas as pd
import os
import csv
import io

pth = os.getcwd() + '\\DW\\'
cf = pth + 'hideme.csv'
hideme_access = "730480402242392"
hideme = "http://incloak.com/api/proxylist.php?country=US&Speed<=1000&ports=&type=socks5&out=csv&code=" + hideme_access
hideme2 = "http://incloak.com/api/proxylist.php?out=csv&code=" + hideme_access
lnFF = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"

def csv_read(cf):
    with open(cf, newline='') as csvfile:
        reader = csv.DictReader(csvfile,delimiter=';')
        for row in reader:
            print(row['ip'],row['port'],row['city'])

def csv_2df(path,delim):
    df = pd.read_csv(path,delimiter=delim)
    return df

def csv_2dict(path,lst_fieldname):
    with open(path, newline='') as csvfile:
        fieldnames = lst_fieldname
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        return writer

def api_csv_read(lnk,delim):
    download = requests.get(lnk)
    decoded_content = download.content.decode('utf-8')
    cr = csv.reader(decoded_content.splitlines(), delimiter=delim)
    lst = list(cr)
    for row in lst:
        print(row)

def api_csv_df(lnk,delim):
    urlData = requests.get(lnk).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=delim)
    return df

#x = api2df(hideme,";")
x = api_csv_df(hideme2,";")
print(x)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\incident.py###
import pyodbc,os
import pandas as pd
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from dateutil.relativedelta import *
from dateutil.parser import parse

n = datetime.now()
td = date.today()

soc = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
#soc = "Driver={SQL Server};SERVER=localhost;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"


#opt = itertools.islice(ls, len(ls))
#st = map(lambda x : )

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    code = []
    q = 0
    #print(ls)
    for i in range(len(ls)):
        text = txt
        if ls[i] in text.upper():
            n = text.find(ls[i])
            st = text[n:n+7]
            code.append(st)
            txt = txt.replace(ls[i],'')
            q = q + 1
    else:
        if q == 0:
            return ''
        else:
            return code
        
def qry_by_code(code, tbl = None, col = None):
    if tbl is None and col is None:
        a1 = "select Incident_Notification,Down_Time,Up_Time,Major_Cause,Action_Taken,Link_ID_Site_ID,Incident_ID from incident_tracker_v2 where ("
        a2 = " No_of_2G_Impacted_sites Like '%" + code + "%' or No_of_3G_Impacted_sites like '%" + code + "%' or No_of_4G_Impacted_Sites like '%" + code + "%' or Incident_Notification Like '%" + code 
        a3 = "%') order by Down_Time desc"
        aa = a1 + a2 + a3
        return aa
    else:
        return ""

def colsmod(txt):
    if txt == 'Incident_Notification':
        return ''
    elif txt == 'Down_Time':
        return "FT: "
    elif txt == 'Up_Time':
        return "RT: "
    elif txt == 'Major_Cause':
        return "Cause:"
    elif txt == 'Incident_ID':
        return "ID: "
    elif txt == 'Link_ID_Site_ID':
        return "Link: "
        

def codechk(txt):
    print('code checking init')
    rs = parsecode(txt.upper())
    st = 0
    print('ret val', rs)
    if len(rs) == 1:
        code = rs[0]
        rn = 0
        qry = qry_by_code(code)
        conn = pyodbc.connect(soc)
        df = pd.read_sql(qry, con = conn)
        print(qry, df)
        cols = df.columns.to_list()
        conn.close()
        if df.shape[0] != 0:
            if df.shape[0] > 3:
                st = "last 3 incident out of " + str(df.shape[0])
                rn = 3
            else:
                st = "incident found " + df.shape[0] + chr(10)
                rn = df.shape[0]
            for i in range(rn):
                tmp = chr(10)
                for j in range(len(cols)):
                    x = df.loc[i, cols[j]]
                    if x is not None  and x !='':
                        try:
                            tmp = tmp + chr(10) + colsmod(cols[j]) + str(x)
                        except:
                            print(type(x),type(cols[j]), cols[j])
                else:
                    st = st + ". " + tmp
        print('single code check', len(st), st)
        return st
    else:
        print('single code ELSE', st)
        return st
    



def incident_q(dt = None, incid = None):
    conn = pyodbc.connect(soc)
    qry = ''
    if dt is None and incid is None :
        qry = "select Incident_Notification,Down_Time,Incident_ID from incident_tracker_v2 where Status='Pending'"
    elif dt is not None and incid is None:
        qry = "select Incident_Notification,Down_Time,Up_Time,Reason,Incident_ID from incident_tracker_v2 where Incident_Date = '" + str(dt) + "'"
    elif dt is None and incid is not None and incid != '':
        qry = "select Incident_Notification,Down_Time,Up_Time,impacted_site_list from incident_tracker_v2 where Incident_ID='" + incid + "'"
    else:
        return 'format is like: "incident" or "incident, 2020-11-25" or "incident, today" or "incident, yesterday" or "incid, INC000012310663'
    conn = pyodbc.connect(soc)
    df = pd.read_sql(qry, con=conn)
    conn.close()
    ls = []
    st = ''
    q = 0
    cols = df.columns.to_list()
    if df.shape[0] != 0:
        for i in range(df.shape[0]):
            q = q + 1
            for j in range(len(cols)):
                xx = df.loc[i, cols[j]]
                if xx == "":
                   xx = "No Data"
                if st == '':
                    st = str(q) + ". " + str(xx)
                else:
                    st = st + chr(10) + cols[j] + ":" + str(xx)
            ls.append(st)
            st = ''
        else:
            return ls
    else:
        ls = ['no incident found']
        return ls

def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str

def parse_dt(tx):
    approval = 0
    try:
        int(tx[3])
        approval = 1
    except:
        try:
            int(tx[4])
            approval = 1
        except:
            try:
                int(tx[5])
                approval = 1
            except:
                return 0
                exit()
    txt = tx.upper()
    n = datetime.now()
    yr = n.strftime("%y")
    succ = 0
    try:
        pdt = parse(txt, fuzzy=True)
        print('parse print', pdt)
        x = pdt.strftime("%Y-%m-%d")
        succ = 1
    except:
        succ = 0
    if succ == 1:
        pdtx = parse(txt, dayfirst=True, fuzzy=True)
        dts = pdtx.strftime("%Y-%m-%d")
        print('returning as succ=1', dts)
        return dts
    elif 'TODAY' in txt:
        str_d = n.strftime("%Y-%m-%d")
        return str_d
    else:
       return 0

def inc_chk(txt):
    tx = ''
    xx = []
    xyz = codechk(txt.upper())
    find_dt = parse_dt(txt)
    if 'incid ' in txt or 'INCID ' in txt:
        idd = txt.split(',')
        incid = idd[1]
        incids = incid.strip(' ')
        xx = incident_q(dt = None, incid = incids)
        msg = "info associated with \n" + incid + chr(10) + chr(10)
        xx.insert(0,msg)
    elif xyz != 0:
        xx.append(xyz)
    else:
        if find_dt == '0' or find_dt == 0 :
            xx = incident_q()
            xx.insert(0,"Please have the current incident \n")
        else:
            xx = incident_q(find_dt)
            sss = "Please have the incident on date \n" + str(find_dt) + "\n"
            xx.insert(0,sss)
    return xx
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\insert_db.py###
import MySQLdb
import pandas as pd
try:
    conn= MySQLdb.connect("localhost","root","root","ops1")
except:
    print("Can't connect to database")
#cursor = conn.cursor()

df = pd.read_csv("F:\\MYDB.csv",delimiter = ',')
df.to_sql('OMIDB2', conn, if_exists = 'append', index = False)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\InsUpd.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os
from mysql import *
#from sqlalchemy import create_engine
import omsqlfn as fn
import os
from datetime import *
import datetime
import time

#user = 'root'
#password = 'admin'
#host = '127.0.0.1:3306'
#db = 'omdb'
#constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
#engine = create_engine(constr, echo=False)
#conn = engine.raw_connection()
#cur = conn.cursor()

def get_key(my_dict, val): 
    for value, key in my_dict.items(): 
        if value == val:
            return key
        
def dtype_match(db, table, conn, df):
    dbcols = []
    dbcolType = []
    try:
        qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['COLUMN_NAME'].to_list()
        dbcolType = dfx['DATA_TYPE'].to_list()
    except:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con= conn)
        dbcols = dfx['Field'].to_list()
        dbcolType = dfx['Type'].to_list()
       
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    dfcol = df.columns.to_list()
    dbcols.sort()
    dfcol.sort()
    st = ""
    q = 0
    if dbcols == dfcol:
        comment1 = 'column counts matched exactly'
    else:
        comment1 = 'column counts are not same'
    try:
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            Y = 0
            try:
                xdf = df[st]
                Y = 1
            except:
                Y = 0
            if Y == 1:
                if 'int' in dbty:
                    df[st] = df[st].astype(int)
                elif 'datetime' in dbty or 'timestamp' in dbty:
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                elif dbty == 'date':
                    df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)
            
#df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'],format="%d/%m/%y, %H:%M:%S", errors='raise')
#df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)


def ExInsert(tbl, conn, df):
    colname = df.columns.to_list()
    q = 0
    cr = conn.cursor()
    for i in range(len(df)):
        lsval = []
        q = q + 1
        for j in df:
            lsval.append(df.loc[i,j])
        qry = "insert into " + tbl + ' ' + fn.prep_insert(colname,lsval)
        print(qry)
        cr.execute(qry)
    else:
        conn.commit()
        print('row inserted: ' +  str(q))
        return 'row inserted: ' +  str(q)

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def InsertUpdate(db, tbl, con, df, bycol = False):
    allcols = df.columns.to_list()
    ndf = dtype_match(db, tbl, con, df)
    if isinstance(ndf, pd.DataFrame):
        cr = con.cursor()
        if bycol == False:
            rv = ExInsert(tbl, con, ndf)
        else:
            dfx = ndf.drop(bycol, 1)
            colsname = dfx.columns.to_list()
            colscond = ndf[bycol].to_list()
            q = 0
            for i in range(len(colscond)):
                vl = colscond[i]
                chk = CheckExist(con, tbl, bycol, vl)
                ls = []
                qry = ''
                if chk != 0:
                    for c1 in dfx:
                        ls.append(dfx.loc[i,c1])
                    qry = "update " + tbl + ' set ' + fn.prep_update(colsname,ls) + ' where ' + bycol + "='" + vl + "'"
                else:
                    for c1 in ndf:
                        ls.append(ndf.loc[i,c1])
                    qry = "insert into " + tbl + ' ' + fn.prep_insert(allcols,ls)
                cr.execute(qry)
                q = q + 1
                if q <3:
                    print(qry)
                con.commit()
                



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\ipapi.py###
import requests as r
import json
from pprint import pprint
import os

def ipdb_1(ip):
    #https://app.ipgeolocation.io/
    ipgeolocation = "ec875907f0da48b3ac1859a1096c5971"
    apilink = 'https://api.ipgeolocation.io/ipgeo?apiKey=' + ipgeolocation + "&ip=" + ip
    G = r.get(apilink)
    print(G.text)
    return G.text


def ipdb_2(ip):
    url = "https://freegeoip.app/json/" + ip
    headers = {
        'accept': "application/json",
        'content-type': "application/json"
        }
    response = r.request("GET", url, headers=headers)
    print(type(response))
    print(response.text)

def ipdb_filefab():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    G = r.get(z)
    print(G)

def ip_geojs(ip):
    os.system("curl https://get.geojs.io/v1/ip/geo/{" + ip + "}.js")

def ip_db3(ip):
    rs = r.get('https://bgp.tools/ip?q=' + ip).text
    print(rs)


#x = ipdb_1('45.156.24.78')
#ipdb_2('45.156.24.78')
ipdb_2('45.156.24.78')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\ipmap.py###
import pandas as pd
import numpy as np
import os
import MySQLdb
import csv
import requests
import io
import datetime as dt
import geoip2.database

#shift-ctrl-b

pt = os.getcwd()
dbmx = "E:\\GIT\\OmProject\\OmSocks\\ippro\\GeoLite2-City.mmdb"
dbas2ip = "E:\\GIT\\OmProject\\OmSocks\\ippro\\ip2asn.csv"

def mxdb(ip):
    with geoip2.database.Reader(dbmx) as reader:
        try:
            response = reader.city(ip)
            lst = response.city.name + ' -' + response.country.iso_code
            return lst
        except:
            lst = 'NA'
            return lst

def filename_maker():
    y = dt.datetime.now()
    x = y.strftime("%d%m%Y-%H%M")
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww

def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]


def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

def maincall(df_port_ip):
    df = pd.read_csv(dbas2ip)
    dpx1 = df_port_ip[['ip','port']]
    ls = []
    for r in range(dpx1.shape[0]):
        lst = []
        ip = dpx1.iloc[r,0]
        prt = dpx1.iloc[r,1]
        ipx = ip.split('.')
        ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
        aa = find_owner(ddf.to_numpy(),ip)
        lst.insert(0,ip)
        lst.insert(1,prt)
        lst.insert(2,mxdb(ip))
        lst.insert(3,aa)
        ls.append(lst)
    fdf = pd.DataFrame(ls,columns = ['ip','port','CityCountry','SL'])
    ffd = pd.merge(fdf,df,on ='SL',how ='left')
    fd = ffd[['ip','port','CityCountry','ISP','ASN','Country']]
    fd.to_csv(filename_maker())
    return fd

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\jsonrw.py###
#ref:https://pynative.com/python-json-dumps-and-dump-for-json-encoding/
import json
import os

def jsonMod(jsn,ip,port):
    with open(jsn, "r") as jsonFile:
        x = json.load(jsonFile)
        x['configs'][0]['server'] = ip
        x['configs'][0]['server_port'] = port
        print(x)
    with open(jsn, "w") as jsonFile:
        json.dump(x, jsonFile)

jp = os.getcwd() + "\\proxylist.json"
jsonMod(jp,'8.8.8.8','01010')

#demjson.decode(prot)
#(prot)
#print(usr)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\json_rewt.py###
#ref:https://pynative.com/python-json-dumps-and-dump-for-json-encoding/
import json
import os

def jsonMod(jsn,ip,port):
    with open(jsn, "r") as jsonFile:
        x = json.load(jsonFile)
        x['configs'][0]['server'] = ip
        x['configs'][0]['server_port'] = port
        print(x)
    with open(jsn, "w") as jsonFile:
        json.dump(x, jsonFile)

jp = os.getcwd() + "\\proxylist.json"
jsonMod(jp,'8.8.8.8','01010')

#demjson.decode(prot)
#(prot)
#print(usr)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\lookup.py###
import pandas as pd
import numpy as np
import os
from datetime import *



def join_list(ls1, ls2, ls3):
    ToDf = pd.DataFrame(zip(ls1, ls2, ls3))
    return ToDf

def add_col_df(df, colname, colval = False, indx=False):
    if indx == False:
        if colval == False:
            ndf = df.assign(coln = 'NWC')
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
        else:
            ndf = df.assign(coln = colval)
            ndf.rename(columns = {'coln': colname}, inplace = True)
            return ndf
    else:
        if colval == False:
            df.insert(indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert(indx, colname, colval, allow_duplicates=False)
            return df

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
        return dc
    except:
        print('err')

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def df_add_list_col(df,nc,nwlst):
    dfx = add_col_df(df,nc)
    dfx[nc] = np.nan
    dfx[nc] = np.array(nwlst)
    return dfx

def vlookup1(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls



def process_sem_raw(df1):
    #df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CustomAttr15']
    LL2 = df1['LastOccurrence']
    #LL3 = df1['ClearTimestamp']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    #agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    #ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    ndf4 = catsemrw(ndf2)
    return ndf4

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(ndf, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(ndf,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs(df,refcol,numeric_col):
    df['agsum'] = df.groupby(refcol)[numeric_col].sum()
    return df
    #df['agsum'] = df.groupby('pet').treats.transform('sum')

def match(df,indx,typ):
    pass

#### Custom For SEM DATA Process ###

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\main.py###
import pandas as pd
import os, datetime, time, pyodbc
from mysql import *
from sqlalchemy import create_engine
import df_to_sql.df_to_sql as insupd
import create_table.tbl_mysql as myq
import create_table.tbl_mssql as msq
#from conn_brocker import *

def mssql_115():
    cstr = "Driver={SQL Server};SERVER=192.168.0.115;DATABASE=SOC_Roster;UID=sa;PWD=1q2w3eaz$"
    conn = pyodbc.connect(cstr)
    return conn

def MsSql(user = 'root', password = 'admin', host = '127.0.0.1:3306', db = "omdb"):
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn

def mysql_self(user = 'root', password = 'root', host = '127.0.0.1:3306', db = "omdb"):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

def insert_data():
    pt = os.getcwd() + "\\csv\\sclick.csv"
    ndf = pd.read_csv(pt)
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    lser = insupd.df_to_sql(ndf, 'omdb', 'TAX1', conn, oncolumn = 'ALL')
    conn.close()

def update_by_condition():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    lser = insupd.df_to_sql(df, 'omdb', 'TAX1', conn, bycolumn=['CustomAttr15'])
    conn.close()

def createtable():
    conn = MySql('root','admin','127.0.0.1:3306','omdb')    
    pt = os.getcwd() + "\\csv\\sclick.csv"
    df = pd.read_csv(pt)
    x = myq.CreateTable_MYSQL(connection = conn, tablename = 'TAX2', df = df, table_col = False, table_col_datatype = False, space = '_')
    conn.close()

def sql2df(tbl):
    conn = MySql('root','admin','127.0.0.1:3306','omdb')
    qry = 'select * from '+ tbl
    df = pd.read_sql(qry, con = conn)
    return df

#createtable()
#conn = MySql('root','admin','127.0.0.1:3306','omdb')
pt = os.getcwd() + "\\sclick2.csv"
df = pd.read_csv(pt)
conn = mssql_115()
#df.to_sql("t12", con = conn)
#msq.CreateTable_MSSQL(df, "t33", conn)
#lser = insupd.df_to_sql(df, 'SOC_Roster', 't22', conn, oncolumn = 'ALL')
#conn.commit()
#
#dfx = pd.read_sql('select * from omtx2', con = conn)
#print(dfx.columns, dfx.dtypes, df.shape[0])
dfx = pd.read_sql("select * from t22", con=conn)
print(dfx.columns, dfx)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\maintest.py###


def main():
    print("Hello World!")

def omi():
    print('balsal')

if __name__ == "__main__":
    main()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\main_caller.py###
import subprocess
import time
import runpy
#def prnt():
   # print("running.....")
   # runpy.run_module('F:\PG\PgOnOFF\PGMAIN1406.py')
   # return "waiting"
#call("F:\\PG\\PgOnOFF\\Scripts\\python.exe","F:\\PG\\PgOnOFF\\pgmain_2.py")
#os.system('‪F:\PG\PgOnOFF\Scripts\python.exe pgmain_2.py')

def mcall():
    print("running.....")
    subprocess.call([r"F:\Python\Proj1\runbat.bat"])
    return "waiting"

while True:
    print(mcall())
    time.sleep(45)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\malsem.py###
import os, cx_Oracle
import time as ti
import requests
import numpy as np
import pandas as pd
from fn import *
from oDT import *
from datetime import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"

nw = datetime.now()
td = nw.strftime("%Y_%b_%d")
mylog = os.getcwd() + "\\log"
todaylog = os.getcwd() + "\\log\\" + td
print(todaylog)

try:
    os.makedirs(mylog)
    os.makedirs(todaylog)
    print("folder created successfully")
except:
    try:
        os.makedirs(todaylog)
    except:
        print(" todayslog folder exits + ")

n = datetime.now ()
td = n.today()
#print(str(td) + "00:00:00")
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")


def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def lasthr(diff = 1):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%H")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,X733EVENTTYPE,X733SPECIFICPROB,CLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR26,TTSEQUENCE,ALARMDETAILS,EQUIPMENTKEY,SITECODE,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    #cols = "SERIAL,NODE,AGENT,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,EQUIPMENTKEY,SITECODE"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    x = n
    hr = x.strftime('%H')
    STDT = timedelt(-int(hr))
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    try:
        df = df.rename(columns = {'SITECODE':'CUSTOMATTR15'})
    except:
        pass
    #df1 = df[df['AGENT'].isin([agent])]
    #print (df.shape[0])
    lscol = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP']
    ddf = df[lscol]
    ddf.to_csv(os.getcwd () + "\\SEMQRY.csv", index=False)
    ti.sleep(2)
    return ddf
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mapper.py###
import os
import omt as om
import textfl as tx
from datetime import *

nw = datetime.now()
filename = nw.strftime("%d%m%Y-%h%m")

rpa_mask = os.getcwd() + "//rpa_group//grpmask.txt"
rpa_mask_head = os.getcwd() + "//rpa_group//grmask_head.txt"
omgrp = os.getcwd() + "//omgroup//omgrp.txt"
mask_grp = os.getcwd() + "//mask_group_map//"+ filename + "_rpa_mask_grp.txt"
rpa_mask_grp_name = os.getcwd() + "//mask_group_map//21102020-Oct10_rpa_mask_grp.txt"
rpagrpmap = os.getcwd() + "//rpa_group_map//maksmap.txt"
rpagrpnm = os.getcwd() + "//rpa_group_map//grpname.txt"

def update_files_rpa():
    tx.pick_rpa_group()

def update_file_omgrp():
    om.client_run()

def map_text_by_mask(f1,f2):
    st = ""
    file1 = tx.rdall(f1)
    file2 = tx.rdline(f2)
    for line in file2:
        if len(line)>5:
            msk = line[0:line.find(",")-1]
            if msk in file1:
                st = st + "\n" + line
    tx.wrt(mask_grp,st)
    
def map_by_groupname(f1):
    f2 = om.client_run()
    st = ""
    m = ""
    file1 = tx.rdline(f1)
    file2 = tx.rdline(f2)
    for line in file2:
        if len(line)>5:
            msk = line[0:line.find(",")-1]
            grpname = line[line.find(",")+1:len(line)-1]
            for ln in file1:
                gn = ln[ln.find(",")+1:len(ln)-1]
                old_msk = ln[0:ln.find(",")-1]
                print(gn)
                if gn == grpname:
                    print(gn,grpname)
                               

def src_in_file(content,srcstr):
    for ln in content:
        lnx = ln.replace("\n","")
        comma = lnx.find(',')
        msk = lnx[0:comma]
        gnm = lnx[comma+1:len(lnx)]
        if gnm == srcstr:
            return msk
            break

def old_new_mask_map():
    oldref = tx.rdline(rpa_mask_grp_name)
    f2 = om.client_run()
    fl2 = tx.rdline(f2)
    n = 0
    st = ""
    currgrp = ""
    for ln in oldref:
        if len(ln)>5:
            n = n + 1
            lnx = ln.replace("\n","")
            comma = lnx.find(',')
            msk = lnx[0:comma]
            gnm = lnx[comma+1:len(lnx)]
            ms = src_in_file(fl2,gnm)
            if type(ms) != 'NoneType':
                if st == "":
                    st = str(msk) + "," + str(ms)
                    currgrp = str(n) + ". " + gnm
                else:
                    st = st + chr(10) + str(msk) + "," + str(ms)
                    currgrp = currgrp + chr(10) + str(n) + ". " + gnm
    tx.wrt(rpagrpmap,st)
    tx.wrt(rpagrpnm,currgrp)
    
old_new_mask_map()








$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\minifn.py###
import time as tm
import pandas as pd
import numpy as np
from datetime import *
import os

# getkey(my_dict, ky)



def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "key not found"

def append_dic_value(dict_obj, key, value):
    if key in dict_obj:
        if not isinstance(dict_obj[key], list):
            dict_obj[key] = [dict_obj[key]]
        dict_obj[key].append(value)
    else:
        dict_obj[key] = value

def dic_by_key(dc, ky):
    hp = ky + " : "
    for key in dc:
        if key == ky:
            ls = dc[key]
            if isinstance(ls, list):
                for i in range(len(ls)):
                    if ls[i] not in hp:
                        hp = hp + chr(10) + ls[i]
                    else:
                        pass
                else:
                    if len(hp) < 8:
                        return "3G - 0"
                    else:
                        return chr(10) + hp
                    exit()
            elif ls is None or ls == '':
                return hp + " 0" + chr(10)
                exit()
            else:
                try:
                    hp = chr(10) + hp + chr(10) + ls
                    return hp
                    exit()
                except:
                    return hp + " 0" + chr(10)
                    exit()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mproxy.py###
import asyncio
import pproxy

ipport = "185.183.98.136:5030"

server = pproxy.Server('socks5://173.0.54.188:6888')
remote = pproxy.Connection('socks5://45.72.6.167:8000#HsQ1hf:jEcN8w')
args = dict( rserver = [remote],verbose = print )

loop = asyncio.get_event_loop()
handler = loop.run_until_complete(server.start_server(args))
try:
    loop.run_forever()
except KeyboardInterrupt:
    print('exit!')

handler.close()
loop.run_until_complete(handler.wait_closed())
loop.run_until_complete(loop.shutdown_asyncgens())
loop.close()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mrg.py###
import pandas as pd
import numpy as np
import os
import MySQLdb
import csv
import requests
import io
import datetime as dt


def api_hideme():
    hideme_access = "730480402242392"
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + hideme_access
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
cur = conn.cursor()
pt = os.getcwd()
proxy = pt + '\\hideme.csv'
db = pt + '\\kkk.csv'
db2 = pt + '\\i2a.csv'
qqq = pt + '\\QQQQAQA.csv'

def split_col(npary,splitby,colname):
    rw, col = npary.shape
    flist = []
    for i in range(rw):
        lst = []
        x = npary[i][0]
        lst = x.split(splitby)
        lst.insert(0,x)
        flist.append(lst)
    df = pd.DataFrame(flist,columns = colname)
    return df

def add_col(dA,c):
    rw, col = dA.shape
    lst = []
    for i in range(rw):
        x = dA[i][c]
        y = x.rfind('.')
        s = x[0:y]
        lst.append(s)
    dA = np.append(dA, np.array([lst]).transpose(), axis=1)
    return dA

def api_ip2asn(ip):
    url = "https://api.iptoasn.com/v1/as/ip/" + ip
    x = requests.get(url)
    y = x.json()
    as_owner = y["as_description"]
    return as_owner

def missing(z):
    rw, col = z.shape
    lst = []
    dic = {}
    cnt = 0
    for i in range(rw):
        lst2 = []
        lst.append([z[i][0],z[i][1],z[i][2]])
        for c in range(col):
            lst2.append(z[i][c])
        ipmd = z[i][2]
        ip = z[i][0]
        df = ddb[ddb['IPMOD'].str.contains(ipmd)]
        if df.shape[0] > 0:
            rs = api_ip2asn(ip)
            print(rs)
            cnt = cnt + 1
        else:
            print(df)
        dic.update( {i : lst2} )
        if cnt == 5:
            break
    print(dic)
    #for c in range(col):
        #print(z[i][c])
        
    #x = z[i][2]
    #print(x)
   
#df1 = pd.DataFrame(z,columns=['ip','port','IPMOD'])
#print(df1)

#cur = conn.cursor()
#for row in df1():

#dpx = api_hideme()
def nearest(lst, K): 
     lst = np.asarray(lst) 
     idx = (np.abs(lst - K)).argmin() 
     return lst[idx]
    
def df_filering(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    if df0.shape[0] == 0:
        df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
        if df0.shape[0] == 0:
            df0 = df.loc[(df[c1]==c1val)]
    return df0

x = 0
if x == 1:
    qq = pd.read_csv(qqq)
    dpx1 = qq[['ip']]
    listformat = ['ip','i1','i2','i3','i4']
    getlist = split_col(dpx1.to_numpy(),".",listformat)
    print(getlist)
    df = pd.DataFrame(getlist,columns = listformat)
    dff = pd.merge(qq,df,on ='ip',how ='left')


def find_owner(nr,ip):
    x = ip.split('.')
    xsum1 = int(x[0]) + int(x[1]) + int(x[2])
    xsum2 = xsum1 + int(x[3])
    rw, col = nr.shape
    rn = []
    mnpre = 10000
    indx = 0
    for r in range(rw):
        I1 = nr[r][14]
        I2 = nr[r][15]
        diff1 = abs(I1 - xsum1)
        #print(I1,xsum1)
        mn = min(diff1,mnpre)
        if mn < mnpre and xsum2<=I2:
            indx = r
            mnpre = mn
    return nr[indx][0]

def filename_maker():
    y = dt.datetime.now()
    x = y.strftime('%d%m%Y-%H%M')
    dww = os.getcwd() + '\\' + x + '.csv'
    return dww
    
proxy = pt + '\\hideme.csv'
db = pt + '\\kkk.csv'
df = pd.read_csv(db)
#qq = pd.read_csv(proxy,delimiter=';')
qq = api_hideme()
dpx1 = qq[['ip','port']]
ls = []
for r in range(dpx1.shape[0]):
    lst = []
    ip = dpx1.iloc[r,0]
    prt = dpx1.iloc[r,1]
    ipx = ip.split('.')
    ddf = df_filering(df,'IP1-B1',int(ipx[0]),'IP1-B2',int(ipx[1]),'IP1-B3',int(ipx[2]))
    aa = find_owner(ddf.to_numpy(),ip)
    lst.insert(0,ip)
    lst.insert(1,prt)
    lst.insert(2,aa)
    ls.append(lst)
    
fdf = pd.DataFrame(ls,columns = ['ip','port','SL'])
ffd = pd.merge(fdf,df,on ='SL',how ='left')
fd = ffd[['ip','port','ISP','ASN','Country']]
fd.to_csv(filename_maker())


p = 0
if p == 1:
    B12 = ddf.columns.get_loc("IP1-B2")
    B22 = ddf.columns.get_loc("IP2-B2")
    B13 = ddf.columns.get_loc("IP1-B3")
    B23 = ddf.columns.get_loc("IP2-B3")
    for r in range(ddf.shape[0]):
        iB12 = ddf.iloc[r,B12]
        iB22 = ddf.iloc[r,B22]
        iB13 = ddf.iloc[r,B13]
        iB23 = ddf.iloc[r,B23]
        B2 = matching_point(50,iB12,iB22)
     
    

#rw, col = npar1.shape
#for i in range(rw):
    #B2_1 = npar1[i]['IP1-B2']
    #B2_2 = npar1[i]['IP2-B2']

#for i,j in getlist:
    #lstt= j
    #lstt.insert(0, i)
    #print(lstt)
#ddb = pd.read_csv(db)
#narr = split_col(ddb.to_numpy(),0)


#ddb2 = pd.read_csv(db2)
#dA = dpx1.to_numpy()
#narr = add_col(dA,0)
#df1 = pd.DataFrame(narr,columns=['ip','port','IPMOD'])
#RJ = pd.merge(df1,ddb2,on ='IPMOD',how ='left')

#missing(narr)

#df = pd.read_sql("select * from ipasn10",conn)
#print(df)
#fdf = df1.merge(df, on='IPMOD')
#fdf.to_csv(pt + '\\merged.csv')
#print(fdf)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\msq.py###
import os
import csv
import mysql.connector

skipHeader = True
pt = os.getcwd()
fl = pt + '\\i.csv'
#conn= mysql.connector.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
conn = mysql.connector.connect(user='akomi', password='1q2w3eaz$', host='23.152.224.49', database='omdb')
cur = conn.cursor()
tbl = "ipasn10"
csv_data = csv.reader(fl)

for row in csv_data:
    if skipHeader:
        skipHeader = False
        continue
    cur.execute('INSERT INTO ipasn3 (IP1, IP2, ASN, Country, ISP, IPMOD) VALUES (%s, %s, %s, %s, %s, %s)', row)

#query = "LOAD DATA INFILE 'C:/python/python-insert-csv-data-into-mysql/students-header.csv' INTO TABLE student FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' IGNORE 1 LINES (student_id, student_name, student_dob, student_email, student_address)"

#query = "LOAD DATA INFILE 'C:/python/python-insert-csv-data-into-mysql/students.csv' INTO TABLE student FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' (student_id, student_name, student_dob, student_email, student_address)"

#cur.execute(query)

conn.commit()

conn.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\msq2.py###
import MySQLdb
import os
import string

db = MySQLdb.connect (host="23.152.224.49",
    user="akomi",
    passwd="1q2w3eaz$",
    db="omdb",
    local_infile = 1) #Grants permission to write to db from an input file. Without this you get sql Error: (1148, 'The used command is not allowed with this MySQL version')

print("Connection to DB established")

#The statement 'IGNORE 1 LINES' below makes the Python script ignore first line on csv file
#You can execute the sql below on the mysql bash to test if it works
sqlLoadData = """load data local infile 'i.csv' into table ipasn FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n' IGNORE 1 LINES;"""

curs = db.cursor()   
curs.execute(sqlLoadData)
db.commit()   
print("SQL execution complete")
resultSet = curs.fetchall()

print("Data loading complete")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mssql.py###
import pyodbc
import pandas as pd

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
UserRd = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=rocuser;Pwd=Roc@072$123"
UserSMS = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"

conn = pyodbc.connect(socdb)
df = pd.read_csv("F:\\MYDB.csv",delimiter = ',')
cursor = conn.cursor()
for index, row in df.iterrows():
	#print(row)
	cursor.execute("INSERT INTO 'omidb' ([SITECODE],[THANA],[DISTRICT],[REGION],[LON],[LAT],[P1P2],[OWNER],[LINK],[PG],[PWR_AUT]) values (?,?,?,?,?,?,?,?,?,?,?)",
    (row['SITECODE'], row['THANA'], row['DISTRICT'], row['REGION'], row['LON'], row['LAT'], row['P1P2'], row['OWNER'], row['LINK'], row['PG'], row['PWR_AUT']))
conn.commit()

cursor.close()
conn.close()



#df.to_sql(name = "omidb",con = conn, if_exists = 'append', chunksize = 100000)
#cursor.execute(sql)  # table created
#conn.close()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\myq3.py###

import os
import csv
import mysql.connector

skipHeader = True
pt = os.getcwd()
fl = pt + '\\i.csv'
#conn= mysql.connector.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")
conn = mysql.connector.connect(user='akomi', password='1q2w3eaz$', host='23.152.224.49', database='omdb')
cur = conn.cursor()


with open(fl, newline='') as csvfile:
    customer_data = csv.reader(csvfile)
    for row in customer_data:
        sql = """INSERT INTO ipasn3 (IP1, IP2, ASN, Country, ISP, IPMOD) VALUES (%s, %s, %s, %s, %s, %s)"""
        cur.execute(sql, tuple(row))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mysq.py###
import pandas as pd
import pyodbc
import requests
from sqlalchemy import *

class mssq:
    def __init__(self):
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)


def telegram_send(chatid, msg):
    TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    try:
        requests.get(url)
    except:
        print('can not initiate first msg to a user')


class orsq:
    

class mysq:
    def __init__(self):
        


class mssq:
    def __init__(self):
        
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)

    def check_existance_by_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        rw = df.shape[0]
        return rw

    def query_full_tbl(self, tbl):
        qry = "select * from " + tbl
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def insert_new_entry(self, tbl, colnames, values):
        qry = "insert into " + tbl + " (" + colnames + ") values (" + values + ")"
        print(qry)
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        print(rs)

    def apend_into(self, tbl, colname, value, refcolname, refvalue):
        qry1 = "select " + colname + " from " + tbl + " where " + refcolname + "='" + refvalue + "'"
        print(qry1)
        curs = self.conx.cursor()
        rsl = curs.execute(qry1)
        rs = rsl.fetchall()
        print(rs)
        vl = value
        qry = "UPDATE " + tbl + " SET " + colname + "='" + vl + "' WHERE " + refcolname + "='" + refvalue + "'"
        print(qry)
        rs2 = curs.execute(qry)
        print(rs2)

    def query_by_single_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_by_double_ref(self, tbl, colname1, value1, colname2, value2):
        qry = "select * from " + tbl + " where " + colname1 + "='" + value1 + "' AND " + colname2 + "='" + value2 + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_string(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + " like " + value
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def upd_by_ref(self, tbl, colnames, values, ref, refvalue):
        qry = "UPDATE " + tbl + " SET " + colnames + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'updated'
    def del_by_ref(self, tbl, colname, value):
        qry = "DELETE FROM " + tbl + " WHERE " + colname + "='" + value + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'deleted'
    def bot_usr_add(self, nam, uid, pas, msisdn):
        td = odt.Now()
        tday = td.strftime('%Y-%m-%d')
        print(tday)
        dt = td.strftime('%d')
        mn = td.strftime("%m")
        wkdy = td.strftime('%a')
        valu = ""
        ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
        print('psscode=', ps)
        if pas == ps or pas == '07085122':
            colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
            valu = "'" + nam + "','" + uid + "','" + tday + "','" + msisdn + "','Y','Y','Y'"
            qry = 'insert into om_socbot_access (' + colnm + ") values ('" + valu + "')"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            print(rs)
            custom_msg_sender(uid, 'congrats, write help to the secrat to use me')
        else:
            custom_msg_sender(uid, 'you send wrong passcode')
        self.conx.close()
    def bot_usr_list(self, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = 'select * from om_socbot_access'
            df = pd.read_sql(qry, self.conx)
            dic = df.to_dict()
            x = vbf.pyvb(dic)
            return x.print_all_row_comm_seperated()

    def bot_usr_delete(self, sl, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = "DELETE FROM om_socbot_access WHERE SL ='" + sl + "'"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            return 'user deleted success'

    def bot_today_pass(self, secrat):
        if secrat == '07085122' or secrat == 'jahid1998':
            td = odt.Now()
            tday = td.strftime('%Y-%m-%d')
            print(tday)
            dt = td.strftime('%d')
            mn = td.strftime("%m")
            wkdy = td.strftime('%a')
            valu = ""
            ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
            return ps
        else:
            return 'unauthorized attempt'
    def auth_check_db(self, uid, qryfrom):
        df1 = pd.read_sql("select * from om_socbot_access", self.conx)
        df = df1[df1['UID'].str.contains(uid)]
        x = df.shape[0]
        if x == 0:
            return str(x)
        else:
            Status = df['Status'].iloc[0]
            special = df['Special'].iloc[0]
            if qryfrom != 'private' and special != 'Y':
                return 0
            elif qryfrom == 'private' and Status == 'Y':
                return '1'
            elif special == 'Y':
                return '1'


#x = mssq()
#bot_usr_add(self, nam, uid, pas, msisdn)
#x.bot_usr_add('s_sohel','178798745','07085122','1819210176')
# print(x.check_existance_by_ref('incident_tracker_v2','Incident_ID','INY00001138080'))
# df = pd.DataFrame(x.query_full_tbl('incident_tracker_v2'))
# x.bot_usr_delete('4','07085122')
#print(x.bot_usr_list('07085122'))
#
# vl = ""
# x.insert_new_entry('om_socbot_access',colnm,vl)
# print(df)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\mysql.py###
#ref: https://www.geeksforgeeks.org/mysqldb-connection-python/
import MySQLdb
import os
import pymysql
import pandas as pd
from sqlalchemy import create_engine

engin = create_engine('pymysql+mysqlconnector://' + 'root' + ':' + 'root' + '@' + '127.0.0.1' + ':' + '3306', echo=False)

#try:
    #conn= MySQLdb.connect("localhost","root","root","ops1")
#except:
    #print("Can't connect to database")
#cursor = conn.cursor()

sql = """CREATE TABLE `ops1`.`OMIDB2` ( `SITECODE` VARCHAR(255) NOT NULL , 
`THANA` VARCHAR(255) NULL DEFAULT NULL , `DISTRICT` VARCHAR(255) NULL DEFAULT NULL , 
`REGION` VARCHAR(255) NULL DEFAULT NULL , `LON` DOUBLE NULL DEFAULT NULL , 
`LAT` DOUBLE NULL DEFAULT NULL , `P1P2` VARCHAR(255) NULL DEFAULT NULL , 
`OWNER` VARCHAR(255) NULL DEFAULT NULL , `LINK` VARCHAR(255) NULL DEFAULT NULL , 
`PG` VARCHAR(255) NULL DEFAULT NULL , `PWR_AUT` VARCHAR(255) NULL DEFAULT NULL , 
UNIQUE (`SITECODE`(255))) ENGINE = InnoDB;"""

df = pd.read_csv("F:\\MYDB.csv")
df.to_sql(name='OMIDB2', con=engin, if_exists = 'append', index=False)
#df.to_sql('OMIDB2', con = conn, if_exists = 'append', chunksize = 1000)
#cols = "`,`".join([str(i) for i in df.columns.tolist()])
# Insert DataFrame recrds one by one.
#for i,row in df.iterrows():
    #sql = "INSERT INTO `OMIDB2` (`" + cols + "`) VALUES (" + "%s,"*(len(row)-1) + "%s)"
    #cursor.execute(sql, tuple(row))
    #conn.commit()
conn.close()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\N1.py###

import itertools
import operator
import itertools as it
from itertools import *

def pntx(op):
    q = 0
    try:
        print(type(op), "--", op, chr(10))
    except:
        pass
    if op is not None:
        q = q + 1
        try:
            for i in op:
                print(type(i), " output: ", i)
        except:
            try:
                print("loop not worked but direct -" , op)
                try:
                    for i in range(len(op)):
                        print('loop with range worked: ' , op[i])
                except:
                    print("anther loop attempt - ")
            except:
                print("failed for: ", q)
    else:
        print('input stored None -', type(op))

class p1:
    def __init__(self, *argv):
        if argv is not None:
            for i in range(len(argv)):
                print(type(argv[i]))
            self.arg = argv
        self.opt = ''
        print("-----------------------------------")
    def printx(self):
        q = 0
        if self.opt is not None:
            q = q + 1
            try:
                for i in self.opt:
                    print(type(i), " output: ", i)
            except:
                print("failed for: ", q)
    def f2(self, ls = None):
        if ls is None:
            self.opt = itertools.accumulate(self.arg[0], operator.mul)
        else:
            self.opt = itertools.accumulate(ls4, operator.mul)
        self.printx()
    def f3(self, ls = None):
        if ls is None:
            self.opt = map(lambda x: "$" + str(x) + "$", self.arg[0])
        else:
            self.opt = map(lambda x: "$" + str(x) + "$", ls)
        self.printx()
    def f4(self, ls = None):
        self.opt = itertools.islice(ls, len(ls))
        self.printx()

ls1 = ['CXTKN80','CXTKN80','CPMTB03','NGSNG49','RPPBT09','CMDBD56','NGRPG18','NGSNG49','CPMTB21','MDSDR02']
ls2 = ['6404','6406','6542','6691','6763','7088','7105','6406','8386','7268']
ls3 = ['5/12/2020  11:54:00 AM','5/12/2020  1:07:00 PM','2020/12/5  1:43:00 PM','5/12/2020  1:46:00 PM',
        '6763','7088','7105','RPPBT09','CMDBD56','NGRPG18']
ls4 = [4,7,9]
dc1 = dict(zip(ls1,ls2))
dc2 = dict(zip(ls2,ls3))

#x = p1(ls1,ls2)
#x.f3()

OM = lambda x : map(lambda y : "'" + y + "'", ls)

def mapper(ls1,ls2):
    ls = list(map(lambda x, y: x + "='" + str(y) + "'", ls1, ls2))
    return ls

def xmapper(ls1,ls2):
    ls = list(map(lambda x, y: x + "='" + str(y) + "'", ls1, ls2))
    return ls

def f3(ls):
    op = map(lambda x: "$" + str(x) + "$", ls)



TS = lambda x : itertools.islice(x, len(x))

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    for i in range(len(ls)):
        if ls[i] in txt:
            txt.find(ls[i])


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\odf.py###
import pandas as pd
import os
from datetime import *
import numpy as np
from fn import *
from mysql import *
from sqlalchemy import create_engine

def MySql(user='root',password='admin',host='127.0.0.1:3306',db='om2'):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return engine

pt = os.getcwd () + "\\"
def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines ():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DURCAT = lambda x : '<2H' if (x < 120) \
                else ('<12H' if (x < 240) \
                else ('<6H' if (x < 360) \
                else ('<12H' if (x < 720) \
                else ('<24H' if (x < 1440) \
                else ('48H+')))))

class fluc:
    def __init__(self, mdf):
        self.df = mdf
        self.col = mdf.columns.to_list()
        self.tdf = pd.DataFrame([])
    def initial(self, df):
        db = os.getcwd () + "\\OMDB.csv"
        dfdb = pd.read_csv(db)
        semcol = os.getcwd () + "\\semcols.txt"
        cat = os.getcwd () + "\\catdef.txt"
        df0 = df.rename(columns=str.upper)
        ls = text2list(semcol)
        df1 = df0[ls]
        dc = text2dic(cat)
        df1 = df1.assign(cat = "0")
        df1 = df1.assign(Code = "0")
        df1['cat'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
        df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
        df2 = df1.merge(dfdb, on='Code')
        df2['LASTOCCURRENCE'] = pd.to_datetime (df2['LASTOCCURRENCE'], errors='coerce')
        #df2['CLEARTIMESTAMP'] = pd.to_datetime(df2['CLEARTIMESTAMP'], errors='coerce')
        df2['DUR'] = df2.apply (lambda x: abs (datetime.now () - x['LASTOCCURRENCE']), axis=1)
        #df2['DUR'] = df2['DUR'].astype ('timedelta64[m]')
        #df2['DURCAT'] = df2.apply (lambda x: DURCAT (x.DUR), axis=1)
        #df2['LO'] = df2.apply(lambda x : pd.to_datetime(x['LASTOCCURRENCE']).strftime("%y%m%d%H%M"), axis = 1)
        #df2['CDLO'] = df2['LO'].str.cat(df2['CUSTOMATTR15'])
        #df3 = df2[~df2['cat'].isin(['other'])]
        #df4 = df3[['SERIAL','CUSTOMATTR3','CUSTOMATTR5','OUTAGEDURATION','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','cat','Code','Zone','DUR','DURCAT','CDLO']]
        #print(df4[['LASTOCCURRENCE']])
        df2.to_csv(pt + "\\A10.csv")


df1 = pd.read_csv(pt + 'OMT1.csv')
x = fluc(df1)
x.initial(df1)
#conn = MySql()
#df = pd.read_csv (pt + 'A10.csv')
#df.to_sql('adb10', con = conn, if_exists='replace', chunksize= 10000)

#dfx = df.groupby(['CUSTOMATTR15','DURCAT'])['DURCAT'].count()
#print(df[['DURCAT']])
#df1 = countifs(df,df['CUSTOMATTR15'],df['CUSTOMATTR15'],df['DURCAT'],'48H+')
#print(df1)
#df1.to_csv(pt + "\\A6.csv")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\oDT.py###
import pandas as pd
#from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fnfn as fnx

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def fmtconv(ls):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M:%S")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Sr2Tstamp(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    return df

def DateTime(df, nwcol, col1, col2 = False):
    df[col1] = df[col1].apply(lambda x : pd.to_datetime(x, errors='coerce', yearfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    dfx = df.convert_dtypes ()
    dfx.assign(nwcol = 0)
    if col2 == False:
        n = datetime.now ()
        xx = n.strftime("%Y/%m/%d %H:%M:%S")
        dfx.assign(TEMPCOL= xx)
        fnx.datediff()
        try:
            dfx[nwcol] = dfx.apply(lambda x : n.strftime("%Y/%m/%d %H:%M:%S") - x[col1], axis = 1)
        except:
            
            dfx[nwcol] = dfx['NW'] - dfx[col1]
    else:
        print('x')

    

#pt = os.getcwd() + "\\"
#df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
#print(xa)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\ofn1.py###
from datetime import *
import os
import pandas as pd
import numpy as np

def help_ofn1():
    ls =["write_into_text(contents, operation='write', filename = 'excmd', fpath = None) content can be list/string\n"]
    print(ls)

#df = df2.reset_index()

def append_into_textfile(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
            print(file2)
        except:
            f = open(file1, 'a+')
            print(file1)
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    return ""


def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def write_into_text(contents, operation="write", filename = 'excmd', fpath = None):
    f = ''
    if filename is None:
        filename = "X"
    if fpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    else:
        flpath = fpath + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    
    try:
        if operation == "write":
            f = open(flpath, 'w+')
        else:
            f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
        return flpath
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        try:
            if operation == "write":
                f = open(flpath, 'w+')
            else:
                f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
            return flpath
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))
            return "failed"


    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omapi.py###
import csv
import pandas as pd
import io
import requests

def api_hideme():
    hideme = "http://incloak.com/api/proxylist.php?out=csv&code=" + "730480402242392"
    urlData = requests.get(hideme).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')),delimiter=";")
    return df

def api_premproxy():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    urlData = requests.get(z).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def dailyproxy():
    url = "https://proxy-daily.com/api/getproxylist?apikey=MHAvkX-UOWjz6vbT-t9cpK1&format=ipport&country=US&type=socks5&lastchecked=60"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

def openproxy():
    url = "https://api.openproxy.space/premium/plain?amount=34999&apiKey=i9414-d994p4Pa29118LW-yfIl5-eBY64dMT5N16uDv-Vw10n&checksMore=354&countries=US&protocols=3&status=1&streak=1"
    urlData = requests.get(url).content
    df = pd.read_csv(io.StringIO(urlData.decode('utf-8')), delimiter=":")
    return df

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omapi_ip.py###
import requests as r
import json
from pprint import pprint
import os

def ipdb_1(ip):
    #https://app.ipgeolocation.io/
    ipgeolocation = "ec875907f0da48b3ac1859a1096c5971"
    apilink = 'https://api.ipgeolocation.io/ipgeo?apiKey=' + ipgeolocation + "&ip=" + ip
    G = r.get(apilink)
    print(G.text)
    return G.text


def ipdb_2(ip):
    url = "https://freegeoip.app/json/" + ip
    headers = {
        'accept': "application/json",
        'content-type': "application/json"
        }
    response = r.request("GET", url, headers=headers)
    print(response.text)

def ipdb_filefab():
    z = "http://filefab.com/api.php?l=90Ft8r4B9ejHAmXjfUKDcoNTZIZrCPGyqv-0E2JAx_Q"
    G = r.get(z)
    print(G)

def ip_geojs(ip):
    os.system("curl https://get.geojs.io/v1/ip/geo/{" + ip + "}.js")

def ip_db3(ip):
    rs = r.get('https://bgp.tools/ip?q=' + ip).text
    print(rs)


#x = ipdb_1('45.156.24.78')
#ipdb_2('45.156.24.78')
ip_geojs('58.212.41.124')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdb.py###
import pandas as pd
import os
import sqlite3
import pyodbc
import mysql.connector #pip install mysql-connector-python
import MySQLdb
from mysql import *
from sqlalchemy import create_engine
from sqlalchemy import update
from pypika import Query, Table, Field

def MySql_1(hPort,user,pas,db):
    conn_str = 'mysql+mysqlconnector://' + user + ':' + pas + '@' + hPort + '/' + db
    engine = create_engine(conn_str, echo=False)
    conn = engine.raw_connection()
    return conn

def MySql_3(host_name, user_name, user_password,db):
    conn = MySQLdb.connect(host_name,user_name,user_password,db)
    return conn


class prep_query:
    def __init__(self, tablename):
        self.cols = "*"
        self.tbl = tablename
        self.qry = ""
    def q_select(self, cond = False, cols=False):
        if cols == False and cond != False:
            self.qry = "select " + self.cols + " from " + self.tbl + " where " + cond
        elif cols != False and cond != False:
            self.qry = "select " + cols + " from " + self.tbl + " where " + cond
        elif cols != False and cond == False:
            self.qry = "select " + cols + " from " + self.tbl
        elif cols == False and cond == False:
            self.qry = "select " + self.cols + " from " + self.tbl
    def q_delete(self, cols , value):
        self.qry = "DELETE FROM " + self.tbl + " WHERE " + cols + "='" + value + "'"
    def q_insert(self, cols, values):
        self.qry = "insert into " + self.tbl + " (" + cols + ") values (" + values + ")"
    def q_update(self, cols, values, ref, refvalue):
        self.qry = "UPDATE " + self.tbl + " SET " + cols + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
    def get(self):
        return self.qry


#x = prep_query("omtb")
##x.q_select()
#print(x.get())
#print(x.q_sel("asn = '123' and gsn = '5'", "col1, col2"))



def prep_qry(tbl, cond, column = False, vals = False):
    if column == False:
        cols = "*"
    else:
        cols = column
    #s_select = 'select ' + col + ' from ' + tbl + ' where ' + cond
    #s_update = 'update from ' + tbl + ' from ' + tbl + ' where ' cond
    #s_insert = "insert into " + tbl + " (" + col + ") values (" + values + ")"
    #qry = "UPDATE " + tbl + " SET " + col + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"


class oMySql:
    def __init__(self, connection, tablename):
        self.conn = connection
        self.cr = connection.cursor()
        self.tbl = tablename
    def q_row_count(self):
        sql = "select * from " + self.tbl
        df = pd.read_sql(sql, self.conn)
        print(sql,'-' , df.shape[0])
    def q_fetch_all_row(self):
        sql = 'select * from ' + self.tbl
        self.cr.execute(sql)
        rs = self.cr.fetchall()
        ls = []
        for r in rs:
            ls1 = list(r)
            ls.append(ls1)
        print(ls)


#q = Query.from_('asdb').select('id', 'fname', 'lname', 'phone')
#Query.from_('asdb').select('id', 'fname', 'lname', 'phone').orderby('id', order=Order.desc)


#cn = MySql_1('38.70.234.101','akomi','1q2w3eaz$','omdb')
#x = oMySql(cn,'live')
#x.q_fetch_all_row()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdf5.py###
import pandas as pd

dates=['April-10', 'April-11', 'April-12', 'April-13','April-14','April-16']
income1=[10,20,10,15,10,12]
income2=[20,30,10,5,40,13]

df=pd.DataFrame({"Date":dates,
                "Income_1":income1,
                "Income_2":income2})



print(df.apply(lambda row: "Total income in "+ row["Date"]+ " is:"+str(row["Income_1"]+row["Income_2"]),axis=1))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdf_call.py###
import pandas as pd

def oFun(df = None, *colname, **col_criteria):
    print('colnam', colname)
    print('col_criteria', col_criteria)

def myFun(arg1, *argv, **kwargs): 
    print ("First argument :", arg1) 
    for arg in argv: 
        print("Next argument through *argv :", arg)

myFun('Hello', 'Welcome', 'to', 'GeeksforGeeks') 
a = ['1','2','3']
b = {'one':'1','two':'2','three':'3'}
c = ('x','y')
s1 = "omi"
s2 = "ona"
s3 = "himi"
s4 = "babu"

oFun(s1, a, x = '1', y = '2' )
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdt.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()

def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str
def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d
def curr_day():
    return td.strftime('%d')
def curr_month():
    return td.strftime('%m')
def curr_year():
    return td.strftime('%Y')
def curr_date():
    return td.strftime('%Y-%m-%d')
def date_between(date1,date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2-d1).days
def aging(date1,date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2- d1)
    return mn
def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx+relativedelta(months=diff)
    return delt


#def date_str(dt):
#def fmt_to_datetime():
#def fmt_to_str():
#delta_month(nw(),-4)
#def month_delta(dt,diff):
#d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
#def day_delta(dt,diff):
#def date_minus(dt, diff):
#def month_minus(dt, diff):
#def year_minus(dt, diff):
#print(aging(nw(),'2020-06-13 00:00:00'))
#print(min_plus(500))
#print(min_minus(500))
#print(hr_plus(2))





    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omdtfn.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()


def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str


def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def curr_day():
    return td.strftime('%d')


def curr_month():
    return td.strftime('%m')


def curr_year():
    return td.strftime('%Y')


def curr_date():
    return td.strftime('%Y-%m-%d')


def date_between(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2 - d1).days


def aging(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2 - d1)
    return mn


def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx + relativedelta(months=diff)
    return delt


def day_minus(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def day_plus(diff):
    d = td + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

def hrmin():
    str_d = n.strftime("%H:%M")
    return str_d

def dtmnyr():
    str_d = n.strftime("%Y-%m-%d")
    return str_d

# def date_str(dt):
# def fmt_to_datetime():
# def fmt_to_str():
# delta_month(nw(),-4)
# def month_delta(dt,diff):
# d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
# def day_delta(dt,diff):
# def date_minus(dt, diff):
# def month_minus(dt, diff):
# def year_minus(dt, diff):
# print(aging(nw(),'2020-06-13 00:00:00'))
# print(min_plus(500))
# print(min_minus(500))
# print(hr_plus(2))







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omfn.py###

def sitecode_pick(txt):
    stcnt = 0
    numcnt = 0
    lp = 1
    prelp = 0
    indx = 0
    for i in txt:
        try:
            ix = int(i)
        except:
            ix = i
        if isinstance(ix,str):
            stcnt = stcnt + 1
        elif isinstance(ix,int):
            numcnt = numcnt + 1
            if lp - prelp == 1 and indx ==0:
                indx = lp
            else:
                prelp = lp
        lp = lp + 1
    if indx != 0:
        code = txt[indx-7:indx]
        return code
    else:
        return "NA"
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omishadowbot.py###


TK = "1196095594:AAGjCMyqdc-62Yabj9Bdyn3_s5H5MkBmDC"
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omprox.py###
import os
import geoip2.database
import pandas as pd
import api.omapi as oap
import ippro.ipmap as ipm
import csv

#shift-ctrl-b
pt = os.getcwd()
hme = oap.api_hideme()
GT = ipm.maincall(hme)
#hme = oap.openproxy(
GT.to_csv(pt + "//ONA3.csv")
#hme.columns = ['ip','port']
print(hme)
#df = hme.loc[(hme['country_code']=='US') & (hme['socks5']==1)]
#GT = ipm.maincall(prem)
#print(GT)
#print(GT)
#GT1 = GT[ (GT.ASN != 13335) & (GT.Country == 'US') ]

#getas.to_csv(pt + '\\KJ1.csv')
#print(prem)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsc.py###
import socket

sock_obj = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print ('Socket Initialized')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsq.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''
    
def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        qry = 'EXPLAIN ' + self.db + '.' + table
        try:
            dfx = pd.read_sql(qry, con= self.engine)
            cols = dfx['Field'].to_list()
            typ = dfx['Type'].to_list()
            zips = zip(cols, typ)
            self.tabledetails = dict(zips)
            return self.tabledetails
        except:
            return "table not exist"

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0
    
    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df
    
    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False):
        if bycols:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = []):
        if len(cols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        else:
            if isinstance(cols, list):
                xdf = dataframe[cols]
                self.Upd_or_Insert(tbl, xdf)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()
      
    def UpdateBulk(self, tbl, bycond_colname, ndf = False, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsq3.py###
import pandas as pd
import os
import sqlite3
import omsqlfn as fn

dbname = os.getcwd() + '\\SQL\\omsq.db'
try:
    conn = sqlite3.connect(dbname)
    cursor = conn.cursor()
    print("Database created and Successfully Connected to SQLite")
except sqlite3.Error as error:
    print("Error while connecting to sqlite", error)

def replace_data(df,tbl):
    sql = "DELETE FROM " + tbl + ';'
    cursor.execute(sql)
    df.to_sql('SITEDB', conn, if_exists='replace', index = False)

def Export(df, tbl):
    df.to_sql(tbl, conn, if_exists='replace', index = False)

def Read(sql):
    cursor.execute(sql)
    rw = []
    for row in cursor.fetchall():
        rw.append(row)
    df = pd.DataFrame(rw)
    return df

def createtable(tblname, cols):
    sql = "CREATE TABLE " + tblname
    hp = ""
    fsql = ''
    for i in range(len(cols)):
        x = str(cols[i]) + ' TEXT NULL'
        if hp =='':
            hp = sql + ' (' + x
        else:
            hp = hp + ', ' + x
    else:
        fsql = hp + ' )'
        print(fsql)
    try:
        cursor.execute(fsql)
        conn.commit()
        print('success')
    except:
        print('table already exist')
    


svpt = os.getcwd() + '\\robi_live_oct_20.csv'
df = pd.read_csv(svpt)
col = df.columns.to_list()
createtable('test', col)
Export(df, 'test')
print(Read('select * from test'))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsql.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os
from mysql import *
from sqlalchemy import create_engine
import OmSQ.omsqlfn as fn
import OmSQ.InsUpd as fni
import os

def about():
        print('initiate class: ', "x = omsql('root','admin','127.0.0.1:3306','omdb')")
        print('Class method : connection ', "MySql(self), MsSql(Self), def Oracle(self)")
        print('class method* : col_and_type(self, table)', 'Return dictionary key as colname and type as value')
        print('class method : Query(self, tbl, colname = False, condition = False)')
        print('class method : Update(self, tbl, listcols, listvalue, bycol, bycolv):')
        print('class method : Insert(self, tbl, colname, values):')
        print('class method : GetResult(self)',' returns dataframe')
        print('class method : SaveToCsv(self, path_with_filename):')
        print('class method : SaveToCsv(self, path_with_filename):')
        print('class method* : Ex(self, arg = False, ret_type = False)', ' for any custom type execution')
        print('every will save at self.df every time and get with GetResult')
        print('few calling example are below in source file')
        print("class Method: CreateTable(self, tablename, list_col, list_type = None, servername = 'mysql')")


def for_contacts(svpt, tblname, colhead):
    fl = open(svpt, 'r+')
    ls = []
    for i in fl.readlines():
        x = i.strip('\n')
        ls.append(x)
    df = pd.DataFrame(ls, columns=[colhead])
    df = df.astype(str)
    col = df.columns.to_list()
    #x = omsql('root','admin','127.0.0.1:3306','omdb')
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    x.CreateTable(tblname,col, None,'mssql')
    print(x.col_and_type(tblname))
    x.Export(tblname,df)

def corp_db(csvpt, tblname, colhead):
    df = pd.read_csv(csvpt)
    df = df.astype(str)
    col = df.columns.to_list()
    #x = omsql('root','admin','127.0.0.1:3306','omdb')
    x = omsql('sa','Robi456&', '192.168.88.121', 'SOC_Roster')
    x.MsSql()
    x.CreateTable(tblname, col, None,'mssql')
    print(x.col_and_type(tblname))
    x.Export(tblname,df)

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.engin = ''
        self.conn = ''
        self.cur = ''
        self.rw = 0
        self.qry = ''
        self.colv_coltyp = {}
        self.df = pd.DataFrame([''])
        self.dftemp = pd.DataFrame([''])
    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        print('mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db)
        try:
            self.engine = create_engine(constr, echo=False)
            self.conn = self.engine.raw_connection()
            self.cur = self.conn.cursor()
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        print(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        print(self.conn.version)
    
    def Ex(self, arg = False, ret_type = False):
        print('ret_type = dataframe/(fetchone/row), so get data as object')
        if arg != False:
            if ret_type == 'dataframe' or ret_type == 'df':
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            elif ret_type == 'fetchone' or ret_type == 'row':
                self.cur.execute(arg)
                rs = self.cur.fetchall()
                return rs
            elif ret_type == False:
                cr = self.conn.cursor()
                cr.execute(arg)
                cr.commit()
        else:
            if self.qry != '':
                try:
                    self.cur.execute(self.qry)
                    self.conn.commit()
                    print('qry executed')
                except:
                    print('error')
    
    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx
    
    def CheckExist(self, tbl, colname, values):
        qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        print(qry)
        dfx = pd.read_sql(qry, self.conn)
        rw = dfx.shape[0]
        return rw
    
    def Update(self, tbl, listcols, listvalue, bycol, bycolv):
        self.qry = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.qry = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "=" + bycolv
            print('Existing rows found, proceed for insert', self.qry)
        else:
            self.qry = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.qry)
        self.cur.execute(self.qry)
        self.conn.commit()
    
    def Insert(self, tbl, colname, values):
        self.qry = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.qry)
        try:
            self.cur.execute(self.qry)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def col_and_type(self, table):
        qry = 'EXPLAIN ' + self.db + '.' + table
        dfx = pd.read_sql(qry, con= self.engine)
        cols = dfx['Field'].to_list()
        typ = dfx['Type'].to_list()
        zips = zip(cols, typ)
        self.colv_coltyp = dict(zips)
        return self.colv_coltyp

    def SaveToCsv(self, path_with_filename):
        try:
            self.df.to_csv(path_with_filename, index = False)
            print('save successfully: ', path_with_filename)
        except:
            print('could not saved to path : ', path_with_filename)

    def GetResult(self):
        dfx = self.df
        return dfx

    def Export(self, tbl, dfx, delim = False):
        try:
            dfx.to_sql(name = tbl, con = self.conn, if_exists='replace', index = False)      
        except:
            cols = list(self.colv_coltyp.keys())
            cnt = 0
            insertrow = 0
            for i in range(len(dfx)):
                ls = []
                x = ""
                cnt = cnt + 1
                for j in dfx:
                    x = dfx.loc[i,j]
                    if x == '':
                        ls.append('NA')
                    else:
                        ls.append(dfx.loc[i,j])
                qry = "insert into " + tbl + ' ' + fn.prep_insert(cols,ls)
                print(qry)
                self.cur.execute(qry)
                insertrow = insertrow + 1
            self.conn.commit()
            print('row inserted: ' + str(insertrow))

    def CreateTable(self, tablename, list_col, list_type = None, servername = 'mysql'):
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    st = "CREATE TABLE `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
    def Upd_or_Insert(self, tbl, ndf, bycols = False):
        if bycols:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)
    def Close(self):
        self.conn.close()

def csv2sql(csvfile, tblname, by_cond_cols = False , table_cols = 'csvhead', table_dtype = 'TEXT' , dbname = None, host = None, user = None, password = None, dbserver = 'mysql'):
    x = ''
    df = pd.read_csv(csvfile)
    if dbname == None:
        x = omsql('root','admin','127.0.0.1:3306','omdb')
    else:
        x = omsql(user, password, host, dbname)
    if dbserver == 'mysql':
        x.MySql()
    else:
        x = dbserver
    if table_cols == 'csvhead':
        cols = df.columns.to_list()
    else:
        cols = table_cols
    try:
        if isinstance(table_dtype, str):
            x.CreateTable(tblname,cols,None,'mysql')
        elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
            x.CreateTable(tblname,cols,table_dtype,'mysql')
        else:
            print('table cols and table_dtype field not same')
            exit()
    except:
        print('table already exist')
    print(x.col_and_type(tblname))
    if by_cond_cols:
        x.Upd_or_Insert(tblname,df, by_cond_cols)
    else:
        x.Upd_or_Insert(tblname,df)
    return x

S2 = os.getcwd() + '\\SQL\\OmSQ\\bk1.csv'
ob = csv2sql(S2,'test_time')
S0 = os.getcwd() + '\\SQL\\s0.csv'
S1 = os.getcwd() + '\\SQL\\s1.csv' 
#ob = csv2sql(S0,'ONA_2')
#ob = csv2sql(S1,'ONA_2', 'CustomAttr11')

#x.upin('ARABI_2',df, "CustomAttr15")
#SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&
#print(x.Ex("selct * from omdb.ARABI_2", 'df'))

#print(x.CheckExist('sitedb','Site_Code','sfsdgsdfgdfgdsg'))
#x.CreateTable('oTest1',col,coltype,'mysql')
#x = omsql('SOC_READ', 'soc_read')
#x.Oracle()
#x.Query('sitedb')
#print(x.GetResult())
#rs = x.Ex('select * from sitedb', 'row')
#fn.fetchone_read(rs)
#df = x.Ex('select * from sitedb', 'df')
#print(df)


#x = omsql('root','admin','127.0.0.1:3306','omdb')
#x.MySql()
#x.Ex('select * from sitedb')
#print(x.col_and_type('ABC'))
#C1 = ['A1','A2','A3']
#V1 = ['X1','X2','X3']
#C2 = ['A1','A3']
#V2 = ['OMI','ARABI']
#x.Insert('ABC',C1,V1)
#x = omsql('root','admin','127.0.0.1:3306','omdb')
#x.MySql()
#x.Update('ABC',C2,V2,"A2","'ONA'")
#x.Ex('select * from ABC')
#x.column_details('sitedb')
#x.Query('sitedb','LTE_Status', "LTE_Status = 'NA'")
###x.SaveToCsv(svpt)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsqlfn.py###

def prep_update(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                x = str(lscol[i]) + "='" + str(lsval[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
            
        return hp

def prep_insert(lscol,lsval):
    hp = ''
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            ls = []
            for i in range(len(lsval)):
                ls.append("'" + str(lsval[i]) + "'")
                hp = '(' + str.join(',', lscol) + ') values (' + str.join(',', ls) + ')'
        else:
            hp = "check list values for double color"
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp1 = ""
        hp2 = ""
        hp = ""
        cnt = 0
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = str(x2[i])
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + str(x2[i])
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp
        elif invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                if hp1 == '':
                    hp1 = str(x1[i])
                    hp2 = "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                else:
                    hp1 = hp1 + "," + str(x1[i])
                    hp2 = hp2 + "," + "'" + str(x2[i]) + "'"
                    cnt = cnt + 1
                hp = '(' + hp1 + ') values (' + hp2 + ')'
            return hp

def fetchone_read(rs):
    if isinstance(rs, list):
        print('fetchone readed called \n ')
        ls = []
        cnt = 0
        for r in rs:
            ls1 = list(r)
            cnt = cnt + 1
            print(cnt , '.', ls1)
            ls.append(ls1)
    else:
        print('list type data required but passed data type is ', type(rs))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omsqlite3.py###
import pandas as pd
import os
import sqlite3
import omsql.omsqlfn as fn


class sqlt3:
    def __init__(self, dbname, bdpath):
        self.db = dbname
        self.conn = sqlite3.connect(bdpath)
        self.cur = self.conn.cursor()
        print("Successfully Connected to SQLite with database name: ", self.db)

    def replace_data(self, df, tbl):
        sql = "DELETE FROM " + tbl + ';'
        self.cur.execute(sql)
        df.to_sql('SITEDB', self.conn, if_exists='replace', index = False)

    def Export(self, df, tbl):
        df.to_sql(tbl, self.conn, if_exists='replace', index = False)

    def Read(self, sql):
        self.cur.execute(sql)
        rw = []
        for row in self.cur.fetchall():
            rw.append(row)
        df = pd.DataFrame(rw)
        return df

    def createtable(self, tblname, cols):
        sql = "CREATE TABLE " + tblname
        hp = ""
        fsql = ''
        for i in range(len(cols)):
            x = str(cols[i]) + ' TEXT NULL'
            if hp =='':
                hp = sql + ' (' + x
            else:
                hp = hp + ', ' + x
        else:
            fsql = hp + ' )'
            print(fsql)
        try:
            self.cursor.execute(fsql)
            self.conn.commit()
            print('success')
        except:
            print('table already exist')
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omt.py###
from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from pprint import pprint
import os

api_id = 628127
api_hash = 'db7fa09d585d6eedddd0df5973f3239b'
phone = '+8801817184338'
client = TelegramClient(phone, api_id, api_hash)
client.connect()
if not client.is_user_authorized():
    client.send_code_request(phone)
    client.sign_in(phone, input('Enter the code: '))


async def main():
    st = ""
    async for dialog in client.iter_dialogs():
        try:
            st1 = str(dialog.id)
            st2 = st1[0]
            if st2 == chr(45):
                st = st + "\n" + str(dialog.id) + ',' + str(dialog.name)
        except:
            pass
    return st

def wrt_content(st):
    try:
        file = os.getcwd() + "//omgroup//omgrp.txt"
        fl = open(file, "w+", encoding="utf-8")
        fl.write(st)
        fl.close()
    except:
        file = os.getcwd() + "//omgrp.txt"
        fl = open(file, "w+", encoding="utf-8")
        fl.write(st)
        fl.close()
    return file

def client_run():
    with client:
        sx = client.loop.run_until_complete(main())
        fl = wrt_content(sx)
        return fl

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\omtime.py###
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
import os
import pandas as pd
import numpy as np

def datetime_re_format(ls, fmt='%Y/%m/%d %H:%M'):
    #serialize and convert using dateutil.parser and datetime.strftime
    if ls is not None and isinstance(ls, list):
        lss = []
        for i in range(len(ls)):
            try:
                dt = parse(str(ls[i])).strftime(fmt)
                lss.append(dt)
            except:
                lss.append(ls[i])
        else:
            return lss

#diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diffdate = lambda T1, T2 : datetime(T2-T1).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def makelist_dttm_now(ln):
    nw = datetime.now()
    st = nw.strftime("%d/%m/%Y %H:%M")
    ls = []
    for i in range(ln):
        ls.append(st)
    return ls

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls
        

def DateDif(DT1, DT2 = None):
    TM1 = formatchk(DT1)
    if DT2 is None:
        TM2 = makelist_dttm_now(len(DT1))
    else:
        TM2 = formatchk(DT2)
    try:
        TM11 = datetime_re_format(TM1)
        TM22 = datetime_re_format(TM2)
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM11, TM22))
        return dur
    except:
        print("except")
        return []



def help_omtime():
    a1 = """#------------dataframe calclate datetime difference ---------------------\n#
# main function -> DateDif(DT1, DT2 = None) DT1 & DT2 can 'pandas series/list', return 'list'
    - if DT2 = None, it will find difference from 'now - DT1'
    - if DT3 provided but value contains '1970' then, calculate diff as 'now - DT1'
    - any datetime format can be handdled, even DT1 and DT2 format is different as using dateut
#----------- Example -------------------#
# df.assign(dur = 'x')
# df['dur'] = np.array(DateDif(df['LASTOCCURRENCE'],df['CLEARTIMESTAMP']))
# lst = DateDif(df['LASTOCCURRENCE']) 
# df['DUR'] = np.array(lst)
#--------------------------------------#"""
    print(a1)

#help_omtime()


def parse_dt(txt):
    n = datetime.now()
    yr = n.strftime("%y")
    print(yr)
    if 'TODAY' in txt:
        str_d = n.strftime("%Y-%m-%d")
        return str_d
    else:
        try:
            x = parse(txt, fuzzy=True, dayfirst = True)
            yx = x.strftime("%Y-%m-%d")
            return yx
        except:
            return 0

b1 = "you can write date by 4 format" + chr(10) + "12-sept or 12/09/20 or 12092019 or 12-09-19"
b2 = "12-sept"
print(parse_dt(b2))



#df = pd.read_csv(os.getcwd() + "\\FINAL15.csv")
#df['Diff'] = np.array(DateDif(df['LO'],df['CLR']))
#print(df[['LO','CLR','Diff']])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\OmWmi.py###
import os
import wmi
import winreg
import subprocess

ip = '173.0.54.190'
username = 'OMI'
password = '1q2w3eaz$'
from socket import *
#connection = wmi.WMI(ip, user=username, password=password)

r = wmi.Registry()
result, names = r.EnumKey (hDefKey=0x80000001,sSubKeyName=r"Software")
#for ky in names:
    #print(ky)

def netsh_proxy(ip,port):
    x = 'netsh winhttp set proxy ' + ip + ':' + port
    print(x)
    os.system(x)

def addkey(ip,prt):
    x1 = "reg add 'HKLM\Software\Microsoft\Windows\CurrentVersion\Internet Settings / v ProxyEnable / t REG_DWORD / d 1'"
    x2 = "reg add 'HKLM\Software\Microsoft\Windows\CurrentVersion\Internet Settings /v ProxyServer /t REG_SZ /d '" + ip + ':' + prt
    os.system(x1)
    os.system(x2)

#addkey('23.160.192.180','2016')


def read_reg(arg1,arg2):
    command = os.popen('cscript regrd.vbs "' +  arg1 + '"' + ' "' + arg2 + '"').read()
    print(command)

def addky(kpath,kname,ktype,kvalue):
    x = 'reg add' + ' "' + kpath + '" /v "' +  kname + '" /t "' + ktype + '" /d "' + kvalue + '"'
    print(x)
    os.system(x)

def editky(kpath,kname,ktype,kvalue):
    x = 'reg add' + ' "' + kpath + '" /v "' +  kname + '" /t "' + ktype + '" /d "' + kvalue + '" /F'
    print(x)
    os.system(x)

kp = "HKCU\Software\Microsoft\Windows\CurrentVersion\Internet Settings"
#knm = "ProxyEnable"
#kty = "REG_DWORD"
#kvl ="1"

knm = "ProxyServer"
kty = "REG_SZ"
kvl = "23.160.192.180:2016"


read_reg("Software\Microsoft\Windows\CurrentVersion\Internet Settings","HKCU")
#netsh_proxy('23.160.192.180','2016')
#addky(kp, knm, kty, kvl)
editky(kp, knm, kty, kvl)


def qryky(pth,keyname):
    x = 'reg query \HKLU\Software\"  /ve'


#REG QUERY HKLM\SOFTWARE /ve
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\om_dfloop.py###
import pandas as pd
import numpy as np
import os

##https://www.delftstack.com/howto/python-pandas/how-to-iterate-through-rows-of-a-dataframe-in-pandas/

pt = os.getcwd()
FL1 = "E:\\GIT\\OmProject\\OmSocks\\T3.csv"
dff = pd.read_csv(FL1)

#Procedure 1: index
def dflp_rw_using_index(df):
    for i in df.index:
        print(df['ip'][i], df['port'][i])

#Procedure 2: loc
def dflp_rw_using_loc(df):
    for i in range(len(df)):
        print(df.loc[i,"ip"])

#Procedure 3: iloc
def dflp_rw_using_iloc(df):
    for i in range(len(df)):
        print(df.iloc[i,0])

#Procedure 4: iterrows
def dflp_rw_using_iterrows(df):
    for indx, row in df.iterrows():
        print(row['ip'],row['port'])

#addcol type 1
def df_add_col_1(df):
    for i in range(len(df)):
        df.loc[i,"NWcol"] = df.loc[i,"port"] + 4
    return df

def addtest(x,y):
    z = x + ":" + str(y)
    return z

#addcol type 2
def df_add_col_2(df):
    for i in range(len(df)):
        df.loc[i,"ip_port"] = addtest(df.loc[i,"ip"], df.loc[i,"port"])
    return df

#addcol type 3
def df_add_col_3(df,colname):
    df = df.assign(colname = lambda row: row['port'] + 4 , axis=1)
    return df

def df_add_row_1(df,content_lst):
    df.loc[df.shape[0]+1] = content_lst
    return df

def df_del_row_cond_1(df,colname,ontxt):
    df.replace('', np.nan)
    indx = df[ df[colname] != ontxt ].index
    df.drop(indx , inplace=True)
    return df

#dff['NWcol'] = np.nan
#derive_col_with_cond(dff)
#df_add_row_1
#lst = ['0.0.0.0','1111','Kiskunlachaza -HU','1111','0.0','188.6','29582','us']
#print(df_add_row_1(dff,lst))
#print(df)
dx = df_del_row_cond_1(dff,"ip",'41.76.157.202')
print(dx.columns.to_list())
print(dx.columns.values.tolist())

#xd.to_csv("E:\\GIT\\OmProject\\OmSocks\\T4.csv")
#print(dff)
# dff.columns = ['ip','port'] #(set columns names)
# dff.iloc[0,0] = "New Val" #(change values in df cells using iloc)
# dff.loc[1,"ip"] = "XXXXX" #(change values in df cells using loc)
# print(dff)

#dff['NWcol'] = np.nan #(add empty column)
#print(dflp_add_col_2(dff))
def df_col_2_list_1(df):
    xx = df.apply(lambda row: row['port'] + 4 , axis=1)
    print(xx.to_list())

def df_2_list(df):
    df0 = df['ip']  #serialization
    df1 = df['port']  #serialization
    lst1 = df0.to_list()  #Convert into list
    lst2 = df1.to_list()  #Convert into list
    lst1.append(lst2)

df_2_list(dff)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\om_notes.py###

TSS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else "other"
                ))

df['cat'] = df.apply(lambda row: TSS(row.SUMMARY) , axis = 1)
df['Status'] = np.where(df['Name'].str.contains('Hisil'), 'HH', 'KK')
df2 = df[~df['cat'].isin(['other','NA'])]
df7 = df6[df6.DT.str.contains(dd) & df6.CLRYR.str.contains('2020')]
df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
df0 = df.drop_duplicates(subset=list_of_columns)
df1 = df1.sort_values(by=['CAT','CDLO'], ascending=True)
df4 = df4.rename(columns={'CUSTOMATTR15':'CODE'})
lst = list(df.columns.values)
dic = {'PBSDR': 'KHU', 'DHGUl': 'DHK_M'}
df[newcolname] = df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
df = pd.DataFrame(nparry,columns = ['ip','port','con','prot'])
dfx[nc] = np.nan
dfx[nwcol] = np.array(nwlst)
df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, ['1/12/2020  3:04:51','1/12/2020  8:34:04']))
df2 = df1[df1['LASTOCCURRENCE'].dt.day == 15 & df1['LASTOCCURRENCE'].dt.day == 16]
df["AB"] = df["A"] + df["B"]
df = ndf.replace(r'^\s*$', np.nan, regex=True)
df2['diff'] = df2['diff'].dt.components['minutes'] #hour
df['diff'] = df['diff'].round(decimals=3)
ndf = df1.append([df2, df3],ignore_index=True, sort=False)  #adding rows
ndf = pd.concat([s3, s4, s5], axis=1)  #Adding columns
ndf = pd.concat([s3, s4, s5])
df[newcol] = df[newcol].astype(float).round(2)


#df datatypes
ds = df6.dtypes
print(ds)
df1['LASTOCCURRENCE'] = pd.to_datetime(df1['LASTOCCURRENCE'], errors='coerce')
df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'], format="%m/%d/%Y, %H:%M:%S")
df1['LASTOCCURRENCE'] = df1.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%m-%Y h:M"), axis = 1)
df1[newcol] = df1[newcol].astype('timedelta64[m]')
df3['SMX'] = df3['SMX'].astype(int)
df1[newcol] = df1[newcol].astype("i8")/1e9
df = df.applymap(str)

#df big functions
df['nwcol'] = df.reset_index()['refcol'].map(refdic).values
df.insert(indx, colname, colval, allow_duplicates=False)
ndf = df.assign(coln = 'NWC')
df[newcolname] = df['scode'].map(dic)
df17 = df7.merge(df15, on='CODE')
df4['DT'] = df4.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%b-%Y"), axis = 1)
dataframe1 = dataframe.where((dataframe==80)|(dataframe<50), other= 0)
df['ipport'] = df['ip'].str.cat(df['port'],sep=":")
df['col1col2'] = df['col1','col2'].apply(lambda x: ''.join(map(str,x)),axis=1)

#df special groupby
https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html
https://wesmckinney.com/blog/groupby-fu-improvements-in-grouping-and-aggregating-data-in-pandas/
dfx = df2.groupby(['CUSTOMATTR15']).CUSTOMATTR15.count().to_frame(name = 'SMX').reset_index()
df3 = df2.groupby('CUSTOMATTR15')['diff'].sum().to_frame(name = 'SMX').reset_index()
df15 = df14.groupby(df14['CODE']).MTTR.sum().to_frame(name = 'SMX').reset_index()
pvt = df1.pivot_table(index='CUSTOMATTR15', columns='DURCAT', values='cnt', aggfunc='sum')

https://wellsr.com/python/python-group-data-with-pandas-groupby/
dfx = grades.groupby("Type", as_index=False).mean()
df.groupby(‘species’).apply(lambda gr: gr.sum())

#NumPy:
arr = df.to_numpy()
rw, col = arr.shape
lst3 = []
for i in range(rw):
    lst3.append(arr[i][0], arr[i][1])
ar = np.append(arr, np.array([lst3]).transpose(), axis=1)
df['new_col'] = np.array(mylist)


#List:
dff = pd.Series(df['CustomAttr15'])
lst1 = dff.to_list()
lst2 = df.values.tolist()
lst3 = df.columns.values.tolist()
lst4 = df['Summary'].values.tolist()
lst5 = df[['Summary','LastOccurrence']].values.tolist()
fruits = ['apple', 'banana', 'cherry','banana']
fruits.append("orange")
fruits.insert(0,'guava')
print(fruits.count("banana"))
print(fruits.index("cherry"))
cars = ['bmw','porshe']
fruits.extend(cars)


#Dictionary:
dic1 = {}
dic2 = {1: 'apple', 2: 'ball'}
dic4 = dict({1:'apple', 2:'ball'})
df = pd.DataFrame(list(dic4.items()),columns = ['key','val'])


#LIST 2 DF
df = pd.DataFrame(zip(ls1, ls2, ls3))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\oracle.py###
import cx_Oracle
conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\osq.py###
import pandas as pd
import os

def attempt_dt(df):
    ls = df.columns.to_list()
    for i in range(len(ls)):
        cname = ls[i]
        try:
            df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
        except:
            pass
    return df

def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x


def inser_or_update(conn, tbl, df, bycol, oncols=False, operator=False):
    ndf = attempt_dt(df)
    cr = conn.cursor ()
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
        if ccr == 1:
            try:
                cr.execute (qry)
            except:
                try:
                    cr.execute (qryinsert)
                except:
                    qq.append (q)
                    pass
        q = q + 1
    print ("failed rows: ", qq)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf

def df2sq(df, table, conn, bycol=False, oncol=False, operator='Like'):
    if bycol == False and oncol == False:
        df.to_sql(table, con=conn, if_exists="append", chunksize=10000)
        print('success')
    else:
        cr = conn.cursor ()
        try:
            cr.execute ("select 1 from " + table)
            dfx = inser_or_update (conn, table, df, bycol, oncol, operator)
            return dfx
        except:
            df.to_sql (table, con=conn, if_exists="replace", chunksize=10000)
            print('success')
            
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\osql.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import omsql.omsqlfn as fn
import omsql.InsUpd as fni
from datetime import *

def sql_between_days(d1 = None, d2 = None):
    print("d1 set to today and d2 set to yesterday")
    nw = datetime.now()
    thisdy = ''
    sincedy = ''
    if d1 == None:
        thisdy = nw.strftime("%Y%m%d")
    else:
        thisdy = d1
    if d2 == None:
        sincedy = ''
    else:
        sincedy = ''

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(flpath, content):
    try:
        f = open(flpath, 'a+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'a+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def save_cmd(content):
    nw = datetime.now()
    thisdy = nw.strftime("%Y%m%d")
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    fl = os.getcwd() + '\\' + thisdy + '.txt'
    cont = ''
    try:
        if content == None:
            cont = "class initiated - " + thistm + chr(10)
            wrt2txt(fl, cont)
        elif content == '':
            pass
        else:
            cont = content + ' - ' + thistm + chr(10)
            wrt2txt(fl, cont)
    except:
        print('failed to def save_cmd')

def SaveToCsv(df, content = None, path_with_filename = None):
    pth = ''
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.csv'
    else:
        pth = path_with_filename
    if content == None:
        try:
            df.to_csv(pth, index = False)
            print("save 'df' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)
    else:
        try:
            content.to_csv(pth, index = False)
            print("save 'content' successfully: ", pth)
        except:
            print('could not saved to path : ', pth)

def SaveToText(self, content, path_with_filename = None):
    if path_with_filename == None:
        pth = os.getcwd() + '\\' + tm() + '.txt'
    else:
        pth = path_with_filename
    try:
        wrt2txt(pth, content)
    except:
        print('failed to write in text')

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

##### Class Starts #########

class omsql:
    def __init__(self, User, Password, Host = False, Db = False):
        self.db = Db
        self.user = User
        self.password = Password
        self.host = Host
        self.conn = ''
        self.cur = ''
        self.tabledetails = {}
        self.df = pd.DataFrame([''])
        self.server = ''
        self.cmd = None
        self.TS()

    def TS(self, arg = False):
        if arg:
            self.cmd = arg
            save_cmd(self.cmd)
        else:
            save_cmd(self.cmd)
            self.cmd = ''

    def col_and_type(self, table):
        dbcols = []
        dbcolType = []
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['COLUMN_NAME'].to_list()
            dbcolType = dfx['DATA_TYPE'].to_list()
        except:
            qry = 'EXPLAIN ' + self.db + '.' + table
            dfx = pd.read_sql(qry, con= self.conn)
            dbcols = dfx['Field'].to_list()
            dbcolType = dfx['Type'].to_list()
        dc= zip(dbcols, dbcolType)
        self.tabledetails = dict(dc)
        return dbcols

    def MySql(self):
        constr = 'mysql+mysqlconnector://' + self.user + ':' + self.password + '@' + self.host + '/' + self.db
        self.TS(constr)
        try:
            engine = create_engine(constr, echo=False)
            self.conn = engine.raw_connection()
            self.cur = self.conn.cursor()
            self.server = 'mysql'
            print('mysql conn successful')
        except:
            print('mysql conn failed')
    def MsSql(self):
        cstr = "Driver={SQL Server};SERVER=" + self.host + ";DATABASE=" + self.db + ";UID=" + self.user + ";PWD=" + self.password
        self.TS(cstr)
        try:
            self.conn = pyodbc.connect(cstr)
            self.cur = self.conn.cursor()
            self.server = 'mssql'
            print('mssql conn success')
        except:
            print('mssql conn failed')
    def Oracle(self):
        oHost = 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'
        self.db = 'SEMDB'
        self.conn = cx_Oracle.connect(self.user, self.password, oHost)
        self.server = 'oracle'
        print(self.conn.version)

    def is_table_exist(self, tbl):
        qry = "SELECT TOP 3 * FROM " + tbl
        try:
            rs = self.cur.execute(qry)
            print('table exist')
            return 1
        except:
            print('table does not exist')
            return 0

    def CheckExist(self, tbl, colname, values, args_qry = None):
        qry = ''
        msg = ''
        rw = 0
        if args_qry == None:
            qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
        else:
            qry = "select * from " + tbl + " where " + args_qry + ' and ' + colname + "='" + values + "'"
        self.cmd = qry
        self.TS()
        try:
            self.df = pd.read_sql(qry, self.conn)
            rw = self.df.shape[0]
            msg = 'execution success'
        except:
            rw = 'NA'
            msg = 'execution Failed'
        print(qry,' ',  msg,' ', rw)
        return rw

    def Ex(self, arg, return_type = 'dataframe'):
        self.TS(arg)
        if return_type == 'dataframe':
            print('return datatype will be dataframe')
            try:
                rs = pd.read_sql(arg, con = self.conn)
                return rs
            except:
                print('execution failed, need to check query string')
        elif return_type == 'fetchone' or return_type == 'row':
            print('return datatype will be rows object')
            try:
                rs = self.cur.execute(arg)
                return rs
            except:
                print('execution failed, need to check query string')

    def Getdf(self):
        return self.df

    def setdf(self, ndf):
        self.df = ndf
        print('dataframe set to self.df')

    def CreateTable(self, tablename, list_col, list_type = None):
        servername = self.server
        print('list_col = list of columns, servername can be = mysql/mssql')
        st = ""
        finalstr = ''
        x = ""
        if servername.lower() == 'mssql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "' " + list_type[i]
                else:
                    x = list_col[i] + "' TEXT NULL"
                if st == "":
                    addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                    st = "CREATE TABLE '" + tablename + "'(" + addsl + "'" + x
                    #st = "CREATE TABLE '" + tablename + "' ( '" + x
                else:
                    st = st + ', ' +  "'" + x
            else:
                finalstr = st + ' )'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                print('table created succssfully with cmd', finalstr)
                x = self.col_and_type(tablename)
        elif servername.lower() == 'mysql':
            for i in range(len(list_col)):
                if list_type != None:
                    x = list_col[i] + "` " + list_type[i]
                else:
                    x = list_col[i] + "` TEXT NULL"
                if st == "":
                    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + "`" + x
                    #st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( `" + x
                else:
                    st = st + ', ' +  "`" + x
            else:
                finalstr = st + ' ) ENGINE=InnoDB'
                print(finalstr)
                self.cur.execute(finalstr)
                self.conn.commit()
                time.sleep(1)
                x = self.col_and_type(tablename)
                print('table created succssfully with cmd', finalstr)

    def Upd_or_Insert(self, tbl, ndf, bycols = False, oncol = False):
        if bycols != False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols, oncol)
        if bycols == False and oncol != False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, oncols = oncol)
        if bycols != False and oncol == False:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf, bycols)
        else:
            fni.InsertUpdate(self.db, tbl, self.conn, ndf)

    def InsertSingle(self, tbl, colname, values):
        self.cmd = "insert into " + tbl + ' ' + fn.prep_insert(colname,values)
        print('qry string from insert: ', self.cmd)
        try:
            self.cur.execute(self.cmd)
            self.conn.commit()
            print('insert success')
        except:
            print('error')

    def InsertBulk(self, tbl, dataframe , cols = [], condcols = []):
        if len(cols) == 0 and len(condcols) == 0:
            self.Upd_or_Insert(tbl, dataframe)
        elif len(cols) == 0 and len(condcols) !=0:
            self.Upd_or_Insert(tbl, dataframe, condcols)
        elif len(cols) != 0 and len(condcols) !=0:
            print(' built required')
            self.Upd_or_Insert(tbl, dataframe, condcols, cols)

    def UpdateSingle(self, tbl, listcols, listvalue, bycol, bycolv):
        self.cmd = ''
        x = self.CheckExist(tbl, bycol, bycolv)
        if x != 0 :
            self.cmd = "update " + tbl + ' set ' + fn.prep_update(listcols,listvalue) + ' where ' + bycol + "='" + bycolv + "'"
            TS()
            print('Existing rows found, proceed for insert', self.cmd)
        else:
            self.cmd = "update " + tbl + ' set ' + fn.prep_insert(listcols,listvalue)
            print('no existing value found, proceed for inserting \n', self.cmd)
        self.cur.execute(self.cmd)
        self.conn.commit()

    #def df_to_sql(df, tbl = None, cols = ['all_cols_of_df'], how = 'append', replaceby = []):
    def UpdateBulk(self, ndf, tbl, bycond_colname, oncols = False):
        if ndf == False:
            ndf = self.df
        if oncols:
            try:
                xdf = ndf[oncols]
                ndf = xdf
                self.Upd_or_Insert(tbl, ndf, bycond_colname)
            except:
                print('def UpdateBulk- oncols mustbe list by u provide ', type(oncols))
                print('update execution halted')

    def Query(self, tbl, colname = False, condition = False):
        qry = "select * from " + tbl
        if colname != False:
            cname = str(colname)
            if condition == False:
                qry = "select " + cname + " from " + tbl
            else:
                cond = str(condition)
                qry = "select " + cname + " from " + tbl + " where " + cond
        print('query: ', qry)
        try:
            dfx = pd.read_sql(qry, con= self.engine)
        except:
            self.cur.execute(qry)
            dfx = pd.DataFrame(self.cur.fetchall())
        self.df = dfx

    def DeleteByCond(self, tbl, col, cond):
        xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
        print(xx)
        self.cur.execute(xx)
        self.conn.commit()

    def DeleteDuplicate(self, tbl, cond_col):
        qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
        print(qry)
        self.cur.execute(qry)
        self.conn.commit()

    def csv2sql(self, csvfile, tblname, table_cols = 'csvhead', table_dtype = 'TEXT', by_cond_cols = False):
        if isinstance(csvfile, str):
            ndf = pd.read_csv(csvfile)
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        else:
            ndf = csvfile
            self.df = ndf.apply(lambda x: x.str.replace("'",''))
        xx = self.is_table_exist(tblname)
        if xx == 0:
            xdf = mod_cols_name(self.df)
            self.df = xdf
            if table_cols == 'csvhead' or table_cols == 'dataframe_head':
                cols = self.df.columns.to_list()
            else:
                cols = table_cols
            try:
                if isinstance(table_dtype, str):
                    self.CreateTable(tblname,cols,None)
                elif isinstance(table_dtype, list) and len(table_dtype) == len(cols):
                    self.CreateTable(tblname,cols,table_dtype)
                else:
                    print('table cols and table_dtype field not same')
                    exit()
            except:
                print(self.tabledetails)
        if by_cond_cols:
            self.Upd_or_Insert(tblname,self.df, by_cond_cols)
        else:
            self.Upd_or_Insert(tblname,self.df)

    def df2sql(self, tblname, ndf, table_cols = 'dataframe_head', table_dtype = 'TEXT', by_cond_cols = False):
        if by_cond_cols:
            self.csv2sql(ndf, tblname, table_cols, table_dtype, by_cond_cols)
        else:
            self.csv2sql(ndf, tblname, table_cols, table_dtype)

    def df_tosql(self, df, tblname, oncols = False, bycols = False):
        if self.is_table_exist(tblname) == 1:
            self.Upd_or_Insert(self, df, tblname, oncols, bycols)
        

    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\oTime.py###
import pandas as pd
from datetime import *
import os

def sec_to_dur(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def dfdiff(df, LO, CLR = False):
    df = df.astype (str)
    if CLR == False:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df = df.assign (DUR=df.apply (lambda x: pd.Timedelta (datetime.now() - x[LO]).seconds / 60, axis=1))
        return df
    else:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df[CLR] = df.apply (lambda x: pd.to_datetime (x[CLR]), axis=1)
        df = df.assign(DUR=df.apply (lambda x: pd.Timedelta (x[LO] - x[CLR]).seconds / 60 if (
                x[CLR].year >= 2019) else "ACT", axis=1))
        return df

def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def datetime_convert_format(df, col, fmt="%Y/%m/%d %H:%M:%S"):
    try:
        df[col] = df[col].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime(fmt))
        return df
    except:
        df[col] = df[col].apply(lambda x: pd.to_datetime (x, errors='coerce', yearfirst=True, cache=True).strftime(fmt))
        return df

def vL(df_Main, df_Ref, col='Code', pick_from_ref = ['Zone']):
    ls = df_Main.columns.to_list ()
    df1 = df_Main.merge (df_Ref, how='right', on=col)
    for i in pick_from_ref:
        ls.append(str(i))
    else:
        dfx = df1[ls]
        return dfx

def ofn():
    print("func")
    print("dfdiff(df, LO, CLR = False) #if CRL=False, calcute from now, return minutes")
    print("sec_to_dur(sec), convert second into hh:mm:ss")
    print("""datetime_convert_format(df, col, fmt="%Y/%m/%d %H:%M:%S")""")
    print("vL(df, db, col='Code', pick_from_ref=['Zone','Cluster'])")
    
print("moduel 'oTime': on datetime, call ofn() to see function")
#vlook = vL(df, db, col='Code', pick_from_ref=['Zone','Cluster'])
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\otree.py###
import os
import shutil

def w2tx(dirName,xx):
    fp = open(dirName, "w")
    fp.write(xx)
    fp.close()

def w2t(text):
    nx = datetime.now ()
    file1 = os.getcwd() + "\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    file2 = os.getcwd() + "\\dump\\" + nx.strftime("%m%d%H%M%S") + ".txt"
    try:
        try:
            f = open(file2, 'a+')
        except:
            f = open(file1, 'a+')
        f.write("\n")
        f.write(text)
        f.close()
    except:
        pass
    print(file)
    return ""

def getFiles(dirName):
    listOfFile = os.listdir(dirName)
    completeFileList = list()
    for file in listOfFile:
        completePath = os.path.join(dirName, file)
        if os.path.isdir(completePath):
            completeFileList = completeFileList + getFiles(completePath)
        else:
            completeFileList.append(completePath)
    return completeFileList

def cpyfile(original,target):
    shutil.copyfile(original, target)

dirName = os.getcwd()
listOfFiles = getFiles(dirName)
xx = ""
for i in range(len(listOfFiles)):
    a1 = listOfFiles[i]
    if ".ipynb" in a1 or ".py" in a1:
        if "init" not in a1 and ".pyc" not in a1 and "__" not in a1:
            xx = xx + chr(10) + a1

w2tx(os.getcwd() + "\\B.txt",xx)
#os.system('copy file1.txt file7.txt')
#cpyfile(os.getcwd() + "\\TBOT\\omfn\\Untitled.ipynb","C:\\Users\\kabir.omi\\omom")
    
    
    
    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pgfndb.py###
import time
from datetime import date
from datetime import datetime
from datetime import timedelta
import pyodbc
import requests as rs
import pandas as pd

tmnw = datetime.now()
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')

def general_qry():
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    qry = "SELECT * from [dbo].[pglog4]"
    df = pd.read_sql(qry, conx)
    print(df)
    print(df.shape[0])

def sms(msisdn,txt):
    sURL1 = "http://10.101.11.164:10144/cgi-bin/sendsms?user=tester&pass=foobar&to="
    sURL2 = "&from=10144&text="
    sURL_pgon = sURL1 + msisdn + sURL2 + txt
    resp = rs.get(sURL_pgon)
    print(resp)

def db_insert_pgon(ussd,code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    in_qry = '''INSERT INTO dbo.pglog4 (SMSID, SITECODE, MSISDN) VALUES (?,?,?)'''
    in_qry_1 = (ussd, code, msisdn)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    sms(str(msisdn),"PGSTART ACK AT " + qryst + " CODE:" + code)
    conx.close()

def db_query_duplicate(code):
        conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
        curs = conx.cursor()
        select_qry = "SELECT * FROM pglog4 WHERE SITECODE = '"+ code +"' AND STATUS_ACTIVE= 'TRUE'"
        curs.execute(select_qry)
        rows = curs.fetchone()
        bol = bool(rows)
        if bol == True:
            return "ACT_CASE_FOUND"
            conx.close()
        else:
            return "NO_ACT_CASE"
            conx.close()

def db_update_pgoff(code,msisdn):
    conx = pyodbc.connect('Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&')
    curs = conx.cursor()
    qry_1 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND STATUS_ACTIVE= 'TRUE')"
    #qryussd = "SELECT SMSID FROM pglog4 WHERE " + qry_1
    #ussd = curs.execute(qryussd)
    qry1 = "UPDATE dbo.pglog4 SET END_DATETIME = CURRENT_TIMESTAMP WHERE " + qry_1
    qry2 = "UPDATE dbo.pglog4 SET CASE_STATUS = 'Closed' WHERE " + qry_1
    curs.execute(qry1)
    conx.commit()
    curs.execute(qry2)
    conx.commit()
    qry_2 = "(SITECODE = '" + code + "' AND  MSISDN = " + msisdn + " AND CASE_STATUS= 'Closed')"
    qry3 = "UPDATE dbo.pglog4 SET STATUS_ACTIVE = '0' WHERE " + qry_2
    curs.execute(qry3)
    conx.commit()
    #print(ussd)
    #ftime = "SELECT START_DATEDATE FROM pglog4 WHERE SMSID = ? "
    #st = curs.execute(ftime,ussd)
    #pgruntime = 'From' + qryst + ' To '+ str(st)
    conx.close()
    sms(msisdn,"PGSTOP ACK AT " + qryst + ' Code: '+ code)

def main(ussd,code,msisdn,job):
    if job == "PGSTART":
        ans = db_query_duplicate(code)
        if ans == "NO_ACT_CASE":
            db_insert_pgon(str(ussd),code,str(msisdn))
            return 'PGON_DONE'
        else:
            #sms(msisdn,"PGSTART ALREADY LOGGED (Duplicate Entry)")
            return ""
    elif job == "PGSTOP":
        ans = db_query_duplicate(code)
        if ans == "ACT_CASE_FOUND":
            db_update_pgoff(code,str(msisdn))
            return 'PGOFF_DONE'
        else:
            #sms(msisdn,"NO PGON Found, Invalid PG OFF Request")
            return ""

#db_insert_pgon('223','DHGUL36','8801817184338')
#x = db_query_duplicate('PBSDR11')
#print(x)
#general_qry()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pgfunc.py###
import os
import time
from datetime import date
import requests as rs
import pyodbc

def served_check(flname,ussd):
    fo = open(flname,"r+")
    txt = fo.read()
    fo.close()
    if ussd in txt:
        return "old"
    else:
        return "new"

def served_entry(flname,ussd):
    fo = open(flname,"a")
    ussdmod = "," + ussd
    txt = fo.write(ussdmod)
    fo.close()

def db_insert_pgrun(ussd,code,mobile):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_query = "INSERT INTO dbo.pglog1 ( SMSID, SITECODE, MSISDN) VALUES (" + ussd + "," + code + "," + mobile + ");"
    curs.execute(in_query)
    curs.commit
    conx.close()
    print('sql table updated')

def filepath(flname):
    t = time.localtime()
    today = date.today()
    Name1 = today.strftime('%m%d%y')
    Name2 = time.strftime("%H%M", t)
    filenameExt = Name1 + "_" + Name2
    filepaths = os.getcwd() + "\\smple_download\\" + flname + filenameExt + ".csv"
    return filepaths

def sendsms(msisdn,txt):
    sURL1 = "http://10.101.11.164:10144/cgi-bin/sendsms?user=tester&pass=foobar&to="
    sURL2 = "&from=10144&text="
    sURL_pgon = sURL1 + msisdn + sURL2 + txt
    resp = rs.get(sURL_pgon)
    print(resp)

def txt_readbyline(ms, filepath):
    cnt = 0
    mstype = isinstance(ms,str)
    if mstype == False:
        ms = str(ms)
    with open(filepath) as f:
        for line in f:
            ln = line.strip()
            if ln in ms:
                cnt += 1
    return cnt
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pgmain.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs
import pg.pgfunc as fn
import pg.pgfndb as fndb
import pg.read_db as rdwt
import os

file = os.getcwd() + "\\" + "served.txt"
pgon = os.getcwd() + "\\" + "pgon.txt"
empnum = os.getcwd() + '\\msisdn_series.txt'

tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=2)
tmnw = datetime.now() - timedelta(minutes=2)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
UserRd = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=rocuser;Pwd=Roc@072$123"
UserSMS = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
conn = pyodbc.connect(UserEx)

def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "All2g") or (txtwht == "all2g") or (txtwht == "All2G") or (txtwht == "all2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "All3G") or (txtwht == "all3G") or (txtwht == "All3g") or (txtwht == "all3g"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "All4G") or (txtwht == "all4G") or (txtwht == "All4g") or (txtwht == "all4g"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "AllCount") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"

smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
dfsms = pd.read_sql(smsinbox, conn)
print(dfsms)
smsno = dfsms.shape[0]
if smsno != 0:
    for i in range(len(dfsms)):
        ussd = dfsms.loc[i, "USDLogId"]
        msisdn = dfsms.loc[i, "DESTADDR"]
        txt = dfsms.loc[i, "MESSAGE"]
        tm = dfsms.loc[i, "INSERT_TIME"]
        if len(txt) != 7 :
            if ("PGSTART" in txt) or ("pgstart" in txt) or ("Pgstart" in txt):
                code = txt[8:]
                codex = code.strip()
                xy = fndb.main(ussd,codex,msisdn,'PGSTART')
                print(xy)
                xz = rdwt.code_attr_update(code,ussd)
                print(xz)
            elif ("PGSTOP" in txt) or ("pgstop" in txt) or ("Pgstop" in txt):
                code = txt[7:]
                codex = code.strip()
                xy = fndb.main(ussd, codex, msisdn, 'PGSTOP')
                print(xy)
            elif ('All' in txt) or ('all' in txt) or ('SC' in txt) or ('count' in txt):
                ansr = fn.served_check(file, str(ussd))
                gval = fn.txt_readbyline(msisdn, empnum)
                if ansr == 'new' and gval == 1:
                    getval = siteinfo(txt)
                    if getval != "#" :
                        fn.sendsms(msisdn,getval)
                        fn.served_entry(file, str(ussd))
            else:
                print('No Need to Entertain')
else:
    print("no new sms")
conn.close()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\PGMAIN1406.py###
import pandas as pd
import pyodbc
from datetime import date
from datetime import datetime
from datetime import timedelta
import requests as rs
import pgfunc as fn
import pgfndb as fndb
import read_db as rdwt
import os

file = os.getcwd() + "\\" + "served.txt"
pgon = os.getcwd() + "\\" + "pgon.txt"
empnum = os.getcwd() + '\\empnumchk.txt'

tday = date.today()
tmdlta = datetime.now() + timedelta(minutes=2)
tmnw = datetime.now() - timedelta(minutes=2)
qryst = tmnw.strftime('%Y-%m-%d %H:%M:%S')
qryend = tmdlta.strftime('%Y-%m-%d %H:%M:%S')

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
UserRd = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=rocuser;Pwd=Roc@072$123"
UserSMS = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
conn = pyodbc.connect(UserEx)

def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "All2g") or (txtwht == "all2g") or (txtwht == "All2G") or (txtwht == "all2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "All3G") or (txtwht == "all3G") or (txtwht == "All3g") or (txtwht == "all3g"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "All4G") or (txtwht == "all4G") or (txtwht == "All4g") or (txtwht == "all4g"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "AllCount") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"

smsinbox = "SELECT * from [dbo].[USDLOG_ROCAPP] WHERE INSERT_TIME BETWEEN '" + qryst + "' AND '" + qryend + "';"
dfsms = pd.read_sql(smsinbox, conn)
print(dfsms)
smsno = dfsms.shape[0]
if smsno != 0:
    for i in range(len(dfsms)):
        ussd = dfsms.loc[i, "USDLogId"]
        msisdn = dfsms.loc[i, "DESTADDR"]
        txt = dfsms.loc[i, "MESSAGE"]
        tm = dfsms.loc[i, "INSERT_TIME"]
        if len(txt) != 7 :
            if ("PGSTART" in txt) or ("pgstart" in txt) or ("Pgstart" in txt):
                code = txt[8:]
                codex = code.strip()
                xy = fndb.main(ussd,codex,msisdn,'PGSTART')
                print(xy)
                xz = rdwt.code_attr_update(code,ussd)
                print(xz)
            elif ("PGSTOP" in txt) or ("pgstop" in txt) or ("Pgstop" in txt):
                code = txt[7:]
                codex = code.strip()
                xy = fndb.main(ussd, codex, msisdn, 'PGSTOP')
                print(xy)
            elif ('All' in txt) or ('all' in txt) or ('SC' in txt) or ('count' in txt):
                ansr = fn.served_check(file, str(ussd))
                gval = fn.txt_readbyline(msisdn, empnum)
                if ansr == 'new' and gval == 1:
                    getval = siteinfo(txt)
                    if getval != "#" :
                        fn.sendsms(msisdn,getval)
                        fn.served_entry(file, str(ussd))
            else:
                print('No Need to Entertain')
else:
    print("no new sms")
conn.close()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pn.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import rpa_shift.omdt as odt

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
pntxt = pt + '\\' + 'pntxt.txt'
savedirr = pt + '\\' + 'dw\sem_data.csv'

print(ExTime)

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('CELL' if ('CELL' in x) \
                else "NA"))))))))))

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    df_all.to_csv(savedirr)
    print()
    return df_all.to_dict()

def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()
    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()
    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt,txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\prep.py###

import pandas as pd
import numpy as np
import os
import lookup.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import db.db as sq
import func.fnfn as fn
from datetime import *




def top10(df0):
    pt = os.getcwd() + "\\T10.csv"
    dfx = pd.read_csv(pt)
    if 'CUSTOMATTR15' in df0.columns:
        df0 = df0.rename(columns={'CUSTOMATTR15':'CODE'})
    df3 = flk.vlookup(df0,dfx,'CODE','NA')
    df4 = fst.add_col_df(df3,'NEMTTE')
    df4['NWMTTR'] = df4.apply(lambda x : x.MTTR/60, axis = 1)
    df5 = df4.groupby(df4['CODE']).NWMTTR.sum()
    df6 = pd.DataFrame(df5,columns=['CODE','SMM'])
    df7 = flk.vlookup(df4,df6,'CODE','NA')
    df8 = flk.countif(df7,'CODE','CODE','CNT')
    print(df8)

def process_sem_data(df0):
    if 'CLEARTIMESTAMP' in df0.columns:
        df2 = fdt.datedif(df0,'MTTR','LASTOCCURRENCE','CLEARTIMESTAMP')
    else:
        df2 = fdt.datedif(df0,'AGING','LASTOCCURRENCE')
    df3 = fst.code_corr(df2)
    df4 = fst.catsemrw(df3)
    df5 = fst.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    df7 = fn.conct(df6,'CUSTOMATTR15','cat','CODECAT')
    df8 = df7.drop_duplicates(subset='CODECAT', keep="first", inplace=False)
    return df8
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\PyOra.py###
import pandas as pd
import cx_Oracle

conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)
qry = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from sia_alerts_status
            where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
            and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
            and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and
            SITECODE like '%DHPLB01%'"""
df = pd.read_sql(qry, con=conn)
print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\PyOracle.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
from datetime import datetime
from datetime import timedelta
import win32com.client

pt = os.getcwd() + "\\" + "csv_download\\"
today = date.today()
t = time.localtime()
td = today.strftime('%Y%m')
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt + folderName1 + folderName2 + '.csv')

def qry_delta(from_min,to_min): 
    tday = date.today()
    tmdlta_from_now = datetime.now() - timedelta('minutes='+ int(from_min))
    tmdlta_to_now = datetime.now() - timedelta('minutes='+ int(to_min))
    qry_from = tmdlta_from_now.strftime('%Y-%m-%d %H:%M:%S')
    qry_to = tmdlta_to_now.strftime('%Y-%m-%d %H:%M:%S')
    dyn_date = "TO_DATE('" + qry_from + "','dd/mm/yyyy hh:mi:ss') AND TO_DATE('" + qry_to + "','dd/mm/yyyy hh:mi:ss')"
    return dyn_date

conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

single_clk = """Select * from alerts_status where Summary IN ('2G SITE DOWN','3G SITE DOWN','4G SITE DOWN','HUW-MAINS FAILURE','HUW-DC VOLTAGE LOW','ERI-DC LOW VOLTAGE','ERI-AC MAINS FAILURE','ERI-AC MIANS FILT') 
and Summary not like 'Synthetic_Fluc' and Severity>0 and Type=1"""

query = "SELECT * FROM ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_" + td + ") WHERE " + qry_delta(300,0)
print(query)
print(qry_delta('400','0'))
#df = pd.read_sql(query, con=conn)
#print(df)
#df.to_csv(pth)













$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\pytext.py###
import os
pt = os.getcwd()
filename = pt + "\\python_created.txt"
f = open(filename,"w+")
f.write("This is line")
f.close()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\qbuilt.py###
import pandas as pd
import numpy as np
import os


def drop_cols(df, col2drop=[]):
    if len (col2drop) > 0:
        cols = df.columns.to_list ()
        ncols = []
        for i in range (len (cols)):
            match = 0
            for j in range (len (col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append (cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list ()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf


def ls2str(ls):
    st = ""
    for i in range (len (ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st


def pupd(col, val):
    lscol = col.split (',')
    lsval = val.split (',')
    if len (lscol) == len (lsval):
        x1 = ls2str (lscol)
        x2 = ls2str (lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x

def qbuilt(ndf, tbl, bycol, oncols=False, operator=True):
    udf = forupdate (ndf, bycol, oncols)
    dfx = drop_cols (ndf, bycol)
    ncols = dfx.columns.to_list ()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range (len (ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range (len (bycol)):
            if operator == False:
                x1 = str (bycol[j]) + " Like '" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                x1 = str (bycol[j]) + " ='" + str (ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str (ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str (ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range (len (ncols)):
            if oncols == False:
                a1 = str (ncols[n])
                a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str (ncols[n])
                mat = 0
                for j in range (len (oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str (ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into " + tbl + pupd (xu, yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append (qry)
        lsinsert.append (qryinsert)
    ddf = pd.DataFrame (list (zip (lsqry, lsinsert)), columns=['upd', 'ins'])
    return ddf

df = pd.read_csv(os.getcwd() + "\\ss.csv")
df = df.astype(str)
x = qbuilt(df,'xyz',['SERIAL'])
x.to_csv(os.getcwd() + "\\ssbuilt.csv")



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\raw_download.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import omdt as odt
import subprocess
import xlwings

print("RPA is Runnig in BackGround, Don't CLose")
scrpt_name = "ErrorHanddle_VBS.vbs"
#fpth_0 = os.getcwd() + "\\" + scrpt_name
#os.system(fpth_0)
#time.sleep( 3 )

pt = os.getcwd()
pt2 = pt + "\\download\\"
t = time.localtime()
today = date.today()
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt2 + folderName1 + folderName2 + '.csv')
pth2 = os.path.join(pt2 + folderName1 + '.csv')
print(pth)
conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

def timex():
    t = time.localtime()
    folderName2 = time.strftime("%H%M", t)
    return folderName2

selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,
            RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qstr4 = "WHERE Severity>0 and Type=1"
#qstr4 = "WHERE (TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970')"
YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")
qst1_1 = 'Select' + "*" + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '
qry_un1 = qst1_1 + qstr4
qry_un2 = qst2_2 + qstr4
tm1 = timex()
df = pd.read_sql(qry_un1, con=conn)
tm2 = timex()
print("downloaded")
df.to_csv(pth2)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rdwrt.py###
import os


def o_read(filepath):
    file1 = open(filepath,"r+")  
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\read_db.py###
import pandas as pd
import pyodbc

def code_attr_update(code,smsid):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(socdb)
    qry = "SELECT * FROM [dbo].[omidb] WHERE SITECODE='" + code + "'"
    qryans = pd.read_sql(qry, conn)
    rowno = qryans.shape[0]
    if rowno != 0:
        zn = qryans.loc[1,"REGION"]
        p1p2 = qryans.loc[1,"P1P2"]
        pg = qryans.loc[1,"PG"]
        owner = qryans.loc[1,"OWNER"]
        pwaut = qryans.loc[1,"PWR_AUT"]
        thn = qryans.loc[1,"THANA"]
        qryupd = "UPDATE [dbo].[pglog4] SET REGION='" + zn + "', PRIORITY='" + p1p2 + "',SITETYPE_PG='" + pg + \
                  "', POWER_AUTH='" + pwaut + "', THANA='" + thn + "', OWNER='" + owner + "' WHERE SMSID='" + str(smsid) + "'"
        cursor = conn.cursor()
        cursor.execute(qryupd)
        conn.commit()
        conn.close()
        return qryupd
    else:
        return 'sitecode not found: ' + code
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\Reg.py###
import sys
import Registry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\robisocbot.py###




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rocsms.py###
import requests


def rocsms(ms,text):
    url = "https://web1.robi.com.bd/apiresponse.php?user=robircouser&pass=Gqras@3789291&from=10144&to=" + str(ms) + "&text=" + text
    rs = requests.get(url)
    print(rs)

rocsms('+8801817184338','from py xx')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rpa_ahift_main.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import rpa_shift.omdt as odt

start = time.time()

t = time.localtime()
today = date.today()
f1 = today.strftime('%m%d%y')
f2 = time.strftime("%H%M", t)
pt = os.getcwd() + "\\T\\" + f1 + f2 + '.csv'


YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")

#selcol = ' * '
selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qst1_1 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '

conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

Code = "('DHMRP25','CGPCH19')"
P1 = "Select * from alerts_status where Summary IN " + Code
P2 = "Select" + selcol + "from alerts_status where"
Q1 = " and (TO_DATE(CLEARTIMESTAMP,'DD-MM-RRRR')='01-JAN-1970')"
Q2 = " and Severity>0 and Type=1"
Q3 = " Severity>0 and Type=1"
Qr1 = P2 + Q3
print(Qr1)
df = pd.read_sql(Qr1, con=conn)
end = time.time()
print('TIme Required: ')
print(end - start)
df.to_csv(pt)
print("file name: " + pt)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rpa_alert_status.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import omdt as odt
import xlwings
import wait_handdle as wth

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"

# lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x: '2G' if ('2G SITE DOWN' in x) \
    else ('3G' if ('3G SITE DOWN' in x) \
    else ('4G' if ('4G SITE DOWN' in x) \
    else ('MF' if ('MAIN' in x) \
    else ('DC' if ('VOLTAGE' in x) \
    else "NA"))))

ExTime = int(time.strftime("%M"))
print(ExTime)

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def MACRO_RUN(fpth,comnd):
    if comnd=='EX':
        excelpath = os.getcwd() + '\\xlsF\\A_SEMRW.xlsm'
        filepath = fpth
        excel_app = xlwings.App(visible=False)
        excel_book = excel_app.books.open(excelpath)
        x = excel_book.macro('init')
        x(filepath)
        time.sleep( 30 )
        return 'success'
    else:
        return 'Not Executed'


def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    return df_all.to_dict()


def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()


class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []

    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()

    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()

    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()

    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.read_csv(single)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt, txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))


#single = os.getcwd() + "\\" + "single.csv"
#pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rruocc.py###
import pandas as pd
import numpy as np
import os
import requests
import func.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import func.fnfn as fn
import db.db as sq
import prep as pr
import func.omdtfn as odt
from datetime import *

def custom_msg_sender(chatid,msg):
    TOKEN = "961035316:AAGWIlt5GjIkBz1QI1s6WKbwVnfubmn0m6E"
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


def code_corr(df):
    ndf = df
    for i in range(len(ndf)):
        Eky = str(ndf.loc[i,'EQUIPMENTKEY'])
        A15 = str(ndf.loc[i,'CUSTOMATTR15'])
        if A15 == 'UNKNOWN' and len(Eky) < 15:
            if len(Eky) == 7:
                df.loc[i,'CUSTOMATTR15'] = Eky
            elif len(Eky) == 10:
                df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
            elif '_' in str(Eky):
                fnd =  Eky.find('_')
                if fnd > 7:
                    df.loc[i,'CUSTOMATTR15'] = Eky[0:7]
                else:
                    try:
                        df.loc[i,'CUSTOMATTR15'] = Eky[fnd:7]
                    except:
                        df.loc[i,'CUSTOMATTR15'] = "UNKNOWN"
    return df


def smsprep_znwise(df,znname, c1,c2):
    zn = ['DHK_M','DHK_N','DHK_S','CTG_M','CTG_N','CTG_S','COM','BAR','KHL','KUS','MYM','NOA','RAJ','RANG','SYL']
    fst = ""
    for i in zn:
        st = ""
        for j in range(len(df)):
            if i == df.loc[j,znname]:
                if st == "":
                    st = i + ' XXX ' + chr(10) + df.loc[j,c1] + ': ' + str(df.loc[j,c2])
                else:
                    st = st + chr(10) + df.loc[j,c1] + ': ' + str(df.loc[j,c2])
        if len(st)> 10:
            ch10 = st.count(chr(10))
            stx = st.replace('XXX', ' || ' + str(ch10))
            if fst == "":
                fst = stx
            else:
                fst = fst + chr(10) + chr(10) + stx
            st = ""
            stx = ""
    return fst

def get_region(df):
    df4 = df
    df5 = fst.add_col_df(df4,'ShortCode')
    df5['ShortCode'] = df5.apply(lambda x : x.CUSTOMATTR15[0:5], axis = 1)
    cols = "ShortCode,Region"
    dfdb = sq.omdb(cols)
    df6 = flk.vlookup(df5,dfdb,'ShortCode','NA')
    return df6


def theft_occ(df1):
    df = fst.add_col_df(df1,'cat')
    df['cat'] = df.apply(lambda row: 'TH' if ('THEFT' in row.SUMMARY) else "other", axis = 1)
    df2 = df[~df['cat'].isin(['other'])]
    df4 = fst.add_col_df(df2,'DT')
    df4['DT'] = df4.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%b-%Y"), axis = 1)
    df6 = df4.reset_index()
    ddx = code_corr(df6)
    dd = odt.day_minus(1)
    df7 = ddx[ddx['DT'].isin([dd])]
    df8 = df7[~df7['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df9 = df8.reset_index()
    df10 = flk.countif(df9,'CUSTOMATTR15','CUSTOMATTR15','CNT')
    df10 = df10.drop_duplicates(subset='CUSTOMATTR15', keep='first')
    df11 = fst.add_col_df(df10,'GTLT')
    df11['GTLT'] = df11.apply(lambda row: 'GT10' if (row.CNT>=10) else "LT10", axis = 1)
    df11 = df11[df11['GTLT'].isin(['GT10'])]
    df12 = df11[['CUSTOMATTR15','CNT']]
    df13 = get_region(df12)
    getsms = smsprep_znwise(df13,'Region','CUSTOMATTR15','CNT')
    chtid = "-1001213797107"
    msghead1 = "RRU Theft Alarm Occurance 10 Plus"
    msghead2 = "on " + odt.day_minus(1)
    msghead = msghead1 + chr(10) + msghead2 + chr(10) + chr(10) + "SiteCode: Counts " + chr(10) + chr(10) + getsms
    fmsg = msghead.replace(chr(10),"%0a")
    custom_msg_sender("-1001213797107",fmsg)
    return 'done'

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\rru_report.py###
import pandas as pd
import numpy as np
import os
from datetime import date
import win32com.client
import subprocess
import time

def rru_lastday(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()

td = date.today()
pt = os.getcwd() + "\\rru_download\\" + "RRU_" + td.strftime('%Y-%m-%d') + ".csv"
ptmacro = os.getcwd() + "\\rru_download\\rru_mac.xlsm"
xlcls = os.getcwd() + "\\rru_download\\xlcls.vbs"

cols = ["SERIAL","EQUIPMENTKEY","CUSTOMATTR15","SUMMARY","LASTOCCURRENCE","CLEARTIMESTAMP","ALARMDETAILS"]
single = os.getcwd() + "\\" + "DWRRU.csv"
dcc1 = rru_lastday('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dcc1)
df2 = df[cols]
code= [df2['CUSTOMATTR15'].value_counts(dropna=False)]
ndf = pd.DataFrame(code).T
ndf.to_csv(pt)

print(pt)
xl = win32com.client.Dispatch("Excel.Application")
xl.Visible = True
book = xl.Workbooks.Open(ptmacro)
time.sleep( 50 )
xl.Application.Run("rru_mac.xlsm!init_rru", pt) #With Parameter
time.sleep( 10 )
xl.Application.Quit()
print('all sucess with python')
time.sleep( 10 )
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\runner.py###
import asyncio

async def periodic():
    while True:
        print('periodic')
        await asyncio.sleep(60)

def stop():
    task.cancel()

loop = asyncio.get_event_loop()
task = loop.create_task(periodic())

try:
    loop.run_until_complete(task)
except asyncio.CancelledError:
    pass
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\saymyname.py###


import os
import time

nam = ['42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','42','42','95','95','95','95','42','42','95','95','42','42','95','95','42','42','32','95','42','42','32','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','32','47','32','95','95','32','92','124','32','32','92','47','32','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','124','32','124','32','32','124','32','124','32','92','32','32','47','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','124','32','124','32','32','124','32','124','32','124','92','47','124','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','124','32','124','95','95','124','32','124','32','124','32','32','124','32','124','42','124','32','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','42','92','95','95','95','95','47','92','95','124','42','42','124','95','124','42','124','95','124','42','42','42','42','42','42','42','42','42','42','42','1042','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','42','1045','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','45','10']

def str2list(st):
    lsx = []
    try:
        ls = st.split()
        for n in range(len(ls)):
            lsx.append(ls[n])
        return lsx
    except:
        return lsx
    
def st2ls(st):
    ls = []
    for i in range(len(st)):
        ls.append(ord(st[i]))
    return ls

def ls2st(ls):
    hp = ""
    for i in range(len(ls)):
        if hp == "":
            hp = chr(ls[i])
        else:
            hp = hp + chr(ls[i])
    return hp

def aptxt(lsst,filename):
    fin = open(os.getcwd() + "\\" + filename + ".txt", "a+")
    hp = []
    if isinstance(lsst,list):
        for i in range(len(lsst)):
            hp.append(str(lsst[i]))
        xx = ",".join(list(hp)) + chr(10)
        fin.write(xx)
    else:
        fin.write(lsst)
    fin.close()

def prep(pth):
    fp = open(pth,"r")
    xx = fp.read()
    xy = xx.split("\n")
    ls1 = []
    ls2 = []
    xx=""
    for i in range(len(xy)):
        a1 = st2ls(xy[i])
        a2 = ls2st(a1)
        aptxt(a1,"A8")

sx = """91,42,42,42,42,42,42,95,95,95,95,42,42,95,95,42,42,95,95,42,42,32,95,42,42,32,42,42,42,42,42,42,42,33
42,42,42,42,42,32,47,32,95,95,32,92,124,32,32,92,47,32,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,124,32,124,32,32,124,32,124,32,92,32,32,47,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,124,32,124,32,32,124,32,124,32,124,92,47,124,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,124,32,124,95,95,124,32,124,32,124,32,32,124,32,124,42,124,32,124,42,42,42,42,42,42,42,42,42,33
42,42,42,42,42,42,92,95,95,95,95,47,92,95,124,42,42,124,95,124,42,124,95,124,42,42,42,42,42,42,42,42,93,33"""

def say_my_name():
    print("----------------------------------")
    time.sleep(1)
    xx = sx.replace("42","32")
    yy = xx.replace("33","xx")
    ls = yy.split("xx")
    hp = ""
    for i in range(len(ls)):
        xz = ls[i].split(",")
        hp = ""
        for n in range(len(xz)):
            if xz[n] == "":
                print(hp)
                hp = ""
            else:
                hp = hp + chr(int(xz[n]))
    print("---------------------------------")
        
say_my_name()
time.sleep(5)


#prep(os.getcwd() + "\\N2.txt")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry-checkpoint.py###
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2.0.4.0\n",
      "<class 'datetime.datetime'>\n",
      "select * FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE  AGENT LIKE 'U2000 IP' and LASTOCCURRENCE BETWEEN TO_DATE('26-12-2020 00:08:00','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('26-12-2020 23:50:00','DD-MM-YYYY HH24:MI:SS')\n",
      "Stat Time:  27-12-2020 21:26:12\n",
      "End Time:  27-12-2020 21:26:41\n",
      "Time Consumed:  218.3  mins\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cx_Oracle\n",
    "import os\n",
    "from datetime import *\n",
    "from dateutil.parser import *\n",
    "from dateutil.tz import *\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "nw = datetime.now()\n",
    "dtst = nw.strftime (\"%d%m%Y%H%M%S\")\n",
    "fl = os.getcwd() + \"\\\\dw\\\\\" + dtst + \".csv\"\n",
    "#print(fl)\n",
    "\n",
    "def sem_view_filter_cols():\n",
    "    df = pd.read_csv(os.getcwd() + \"\\\\col_filter_semdb_view_non_macro.csv\")\n",
    "    ls = df.iloc[:,0].to_list()\n",
    "    x = \",\".join(list(ls))\n",
    "    return x\n",
    "\n",
    "def timedelt(diff):\n",
    "    x = datetime.now ()\n",
    "    d = x + timedelta (hours=diff)\n",
    "    str_d = d.strftime (\"%d-%m-%Y %H:%M:%S\")\n",
    "    return str_d\n",
    "\n",
    "def tmx(t1=False):\n",
    "    nw = datetime.now()\n",
    "    dtst = nw.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    if t1 == False:\n",
    "        print(\"Stat Time: \", dtst)\n",
    "        return nw\n",
    "    else:\n",
    "        x = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "        print(\"End Time: \", dtst)\n",
    "        print(\"Time Consumed: \", x, \" mins\")\n",
    "        \n",
    "conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')\n",
    "print (conn.version)\n",
    "    \n",
    "def qryex(qr = False, flname = fl):\n",
    "    q = \"\"\n",
    "    if qr == False:\n",
    "        q1 = \"select \" + sem_view_filter_cols() + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0\"\n",
    "    else:\n",
    "        q1 = \"select \" + \"*\" + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE \" + str(qr)\n",
    "    print(q1)\n",
    "    st = tmx()\n",
    "    df = pd.read_sql(q1, con = conn)\n",
    "    et = tmx(st)\n",
    "    df.to_csv(os.getcwd() + \"\\\\dw\\\\\" + flname)\n",
    "    return df\n",
    "    \n",
    "def timebetween(t1,t2):\n",
    "    d1 = parse(t1)\n",
    "    d2 = parse(t2)\n",
    "    print(type(d1))\n",
    "    dd = \"LASTOCCURRENCE BETWEEN TO_DATE('\" + d1.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('\" +  d2.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS')\"\n",
    "    return dd\n",
    "\n",
    "#######################################################################################\n",
    "def qr1():\n",
    "    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')\n",
    "    Y21= qryex(x21,'EFDSDFSDFS.csv')\n",
    "\n",
    "def qr2():\n",
    "    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')\n",
    "    x22 = \" CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and \" + x21 \n",
    "    df= qryex(x22,'all_oneday_ip.csv')\n",
    "\n",
    "qr2()\n",
    "\n",
    "#xx = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "#print(xx)\n",
    "#x = relativedelta(\n",
    "    #print(datetime.strptime(\"22-12-2020 01:05\",\"%d-%m-%Y %H:%M:%S\"))- datetime.strptime(datetime.now(),\"%d-%m-%Y %H:%M:%S\").seconds / 60\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry.py###
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2.0.4.0\n",
      "<class 'datetime.datetime'>\n",
      "select * FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE  AGENT LIKE 'U2000 IP' and LASTOCCURRENCE BETWEEN TO_DATE('26-12-2020 00:08:00','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('26-12-2020 23:50:00','DD-MM-YYYY HH24:MI:SS')\n",
      "Stat Time:  27-12-2020 21:26:12\n",
      "End Time:  27-12-2020 21:26:41\n",
      "Time Consumed:  218.3  mins\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cx_Oracle\n",
    "import os\n",
    "from datetime import *\n",
    "from dateutil.parser import *\n",
    "from dateutil.tz import *\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "nw = datetime.now()\n",
    "dtst = nw.strftime (\"%d%m%Y%H%M%S\")\n",
    "fl = os.getcwd() + \"\\\\dw\\\\\" + dtst + \".csv\"\n",
    "#print(fl)\n",
    "\n",
    "def sem_view_filter_cols():\n",
    "    df = pd.read_csv(os.getcwd() + \"\\\\col_filter_semdb_view_non_macro.csv\")\n",
    "    ls = df.iloc[:,0].to_list()\n",
    "    x = \",\".join(list(ls))\n",
    "    return x\n",
    "\n",
    "def timedelt(diff):\n",
    "    x = datetime.now ()\n",
    "    d = x + timedelta (hours=diff)\n",
    "    str_d = d.strftime (\"%d-%m-%Y %H:%M:%S\")\n",
    "    return str_d\n",
    "\n",
    "def tmx(t1=False):\n",
    "    nw = datetime.now()\n",
    "    dtst = nw.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    if t1 == False:\n",
    "        print(\"Stat Time: \", dtst)\n",
    "        return nw\n",
    "    else:\n",
    "        x = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "        print(\"End Time: \", dtst)\n",
    "        print(\"Time Consumed: \", x, \" mins\")\n",
    "        \n",
    "conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')\n",
    "print (conn.version)\n",
    "    \n",
    "def qryex(qr = False, flname = fl):\n",
    "    q = \"\"\n",
    "    if qr == False:\n",
    "        q1 = \"select \" + sem_view_filter_cols() + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0\"\n",
    "    else:\n",
    "        q1 = \"select \" + \"*\" + \" FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE \" + str(qr)\n",
    "    print(q1)\n",
    "    st = tmx()\n",
    "    df = pd.read_sql(q1, con = conn)\n",
    "    et = tmx(st)\n",
    "    df.to_csv(os.getcwd() + \"\\\\dw\\\\\" + flname)\n",
    "    return df\n",
    "    \n",
    "def timebetween(t1,t2):\n",
    "    d1 = parse(t1)\n",
    "    d2 = parse(t2)\n",
    "    print(type(d1))\n",
    "    dd = \"LASTOCCURRENCE BETWEEN TO_DATE('\" + d1.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('\" +  d2.strftime(\"%d-%m-%Y %H:%M:%S\") + \"','DD-MM-YYYY HH24:MI:SS')\"\n",
    "    return dd\n",
    "\n",
    "#######################################################################################\n",
    "def qr1():\n",
    "    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')\n",
    "    Y21= qryex(x21,'EFDSDFSDFS.csv')\n",
    "\n",
    "def qr2():\n",
    "    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')\n",
    "    x22 = \" CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and \" + x21 \n",
    "    df= qryex(x22,'all_oneday_ip.csv')\n",
    "\n",
    "qr2()\n",
    "\n",
    "#xx = (parse(\"22-12-2020 01:05\") - datetime.now()).seconds / 60\n",
    "#print(xx)\n",
    "#x = relativedelta(\n",
    "    #print(datetime.strptime(\"22-12-2020 01:05\",\"%d-%m-%Y %H:%M:%S\"))- datetime.strptime(datetime.now(),\"%d-%m-%Y %H:%M:%S\").seconds / 60\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry_by_timestamp.py###
import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
print(flname)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        

def qryex(qr = False, flname = fl):
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(flname)
    conn.close()
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd
    
def qmain():
    x3 = timebetween("17-12-2020 00:00","19-12-2020 23:59")
    x1 = timebetween("20-12-2020 00:00","22-12-2020 23:59")
    x2 = timebetween("23-12-2020 00:00","25-12-2020 15:45")
    y1 = qryex(x1,"23_25.csv")
    y2 = qryex(x2,"20_22.csv")
    y3 = qryex(x3,"17_19.csv")

qmain()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\semqry_test.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client

pt = os.getcwd() + '//T.csv'
conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
Qr1 = "SELECT IDENTIFIER,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE FROM alerts_status WHERE Severity!='0'"
print(Qr1)
df = pd.read_sql(Qr1, con=conn)
end = time.time()
print('TIme Required: ')
print(end - start)
df.to_csv(pt)
print("file name: " + pt)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sem_rw_from_oracle.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import omdt as odt
import subprocess

pt = os.getcwd()
pt2 = pt + "\\"
ptxls = pt + "\\xlsF\\RW.xlsm"
ptbat = pt + "\\closexl.vbs"
subprocess.call("cscript closexl.vbs")
t = time.localtime()
today = date.today()
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt2 + folderName1 + folderName2 + '.csv')
print(pth)
print(conn.version)

def timex():
    t = time.localtime()
    folderName2 = time.strftime("%H%M", t)
    return folderName2

selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,
            RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qstr4 = "WHERE Severity>0 and Type=1"
YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")
qst1_1 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '
qry_un1 = qst1_1 + qstr4
qry_un2 = qst2_2 + qstr4
tm1 = timex()
df1 = pd.read_sql(qry_un1, con=conn)
tm2 = timex()
df2 = pd.read_sql(qry_un2, con=conn)
tm3 = timex()
print('execution start, mid, end: ' + tm1 + ',' + tm2 + ',' + tm3)
conn.close()
df3 = [df1,df2]
df = pd.concat(df3)
df.to_csv("F://Python//RPA_SHIFT//TestData//testdata.csv")
df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
dfmf = df[df['SUMMARY'].str.contains('MAIN')]
dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
df_cnct = [df2g,df3g,df4g,dfmf,dfdl]
df_all = pd.concat(df_cnct)
df_all.to_csv(pth)
df_final = df_all.rename(columns={'EQUIPMENTKEY':'Resource','CUSTOMATTR26':'AssociatedCR',
                                    'CUSTOMATTR24':'BCCH',
                                    'OWNERGID':'Incident Owner',
                                    'EVENTID':'Frequency',
                                    'TTREQUESTTIME':'TT Creation Time',
                                    'CUSTOMATTR19':'HVC_STATUS'})

print(df_final.columns)
#df_final.to_csv(pth)
parm = pth
#xl = win32com.client.Dispatch("Excel.Application")
#xl.Visible = False
#book = xl.Workbooks.Open(ptxls, False, False, None, '2986')
#xl.Application.Run("RW.xlsm!init", parm) #With Parameter
#time.sleep( 10 )
#subprocess.call("cscript closexl.vbs")
print('all sucess with python')
#xl.Application.Quit()
time.sleep( 3 )
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sem_rw_mod.py###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import win32com.client
import omdt as odt
import subprocess
import xlwings

print("RPA is Runnig in BackGround, Don't CLose")
scrpt_name = "ErrorHanddle_VBS.vbs"
#fpth_0 = os.getcwd() + "\\" + scrpt_name
#os.system(fpth_0)
#time.sleep( 3 )

pt = os.getcwd()
pt2 = pt + "\\download\\"
t = time.localtime()
today = date.today()
folderName1 = today.strftime('%m%d%y')
folderName2 = time.strftime("%H%M", t)
pth = os.path.join(pt2 + folderName1 + folderName2 + '.csv')
pth2 = os.path.join(pt2 + folderName1 + '.csv')
print(pth)
conn = cx_Oracle.connect('SEMHEDB', 'SEMHEDB', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn.version)

def timex():
    t = time.localtime()
    folderName2 = time.strftime("%H%M", t)
    return folderName2

selcol = """ SERIAL,SEVERITY,NODE,EQUIPMENTKEY,FIRSTOCCURRENCE,LASTOCCURRENCE,TALLY,CUSTOMATTR11,SUMMARY,CUSTOMATTR26,POSSIBLEROOTCAUSE,PARENTPOINTER,CUSTOMATTR23,RCASTATUS,TTSEQUENCE,TTSTATUS,CUSTOMATTR15,CUSTOMATTR24,ALERTKEY,RCAPARENTHISTORY,SUPPRESSESCL,TTFLAG,TTREQUESTTIME,CUSTOMATTR3,INHAND,OWNERGID,AGENT,MANAGER,EVENTID,INHANDEXPIRETIME,TTREQUESTTIME,CUSTOMATTR19,CLEARTIMESTAMP,SRCEMSIDENTIFIER,RCATIMESTAMP,
            RCATALLY,ADVCORRSERVERSERIAL,ADVCORRCAUSETYPE,ROOTCAUSEDESC,ACFLAG,CLEAREDBY """
qstr4 = "WHERE Severity>0"
YM1 = today.strftime('%Y%m')
YMT = odt.deltamonth(odt.nw(),-1)
YM2 = YMT.strftime("%Y%m")
qst1_1 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM1 + ') '
qst2_2 = 'Select' + selcol + 'from ALERTS_STATUS PARTITION (STATUS_MDA_SEM_DAT_' + YM2 + ') '
qry_un1 = qst1_1 + qstr4
qry_un2 = qst2_2 + qstr4
tm1 = timex()
df = pd.read_sql(qry_un1, con=conn)
tm2 = timex()
print("downloaded")
#df2 = pd.read_sql(qry_un2, con=conn)
#tm3 = timex()
#print('execution start, mid, end: ' + tm1 + ',' + tm2 + ',' + tm3)
#conn.close()
#df3 = [df1,df2]
#df = pd.concat(df3)
df.to_csv(pth2)
df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN', na=False)]
df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN', na=False)]
df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN', na=False)]
dfmf = df[df['SUMMARY'].str.contains('MAIN', na=False)]
dfdl = df[df['SUMMARY'].str.contains('DC LOW', na=False)]
dftmp = df[df['SUMMARY'].str.contains('TEMP', na=False)]
dfcell = df[df['SUMMARY'].str.contains('CELL DOWN', na=False)]
dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT', na=False)]
dfsmoke = df[df['SUMMARY'].str.contains('SMOKE ALARM', na=False)]
df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth,dfsmoke]
df_all = pd.concat(df_cnct)
df_final = df_all.rename(columns={'EQUIPMENTKEY':'Resource','CUSTOMATTR26':'AssociatedCR',
                                    'CUSTOMATTR24':'BCCH',
                                    'OWNERGID':'Incident Owner',
                                    'EVENTID':'Frequency',
                                    'TTREQUESTTIME':'TT Creation Time',
                                    'CUSTOMATTR19':'HVC_STATUS'})

#print(df_final.columns)
df_final.to_csv(pth)
parm = pth
print('csv download successfully')
excelpath = pt + '\\xlsF\\A_SEMRW.xlsm'
filepath= pth
excel_app = xlwings.App(visible=False)
excel_book = excel_app.books.open(excelpath)
# into brackets, the path of the macro
x = excel_book.macro('init')
x(filepath)
time.sleep( 3 )
conn
print('Closing Success')



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\single_sql.py###
import pandas as pd
import omsqlfn as fn
import pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def Update_insert_single(conn, tbl, listcols, listvalue, bycol, bycolv):
    cur = conn.cursor()
    cmd = ''
    x = CheckExist(conn, tbl, bycol, bycolv)
    if x != 0:
        cmd = "update " + tbl + ' set ' + fn.prep_update(listcols, listvalue) + ' where ' + bycol + "='" + bycolv + "'"
        print('Existing rows found, proceed for update', cmd)
    else:
        cmd = "insert into " + tbl + ' ' + fn.prep_insert(listcols, listvalue)
        print('no existing value found, proceed for insert \n', cmd)
    cur.execute(cmd)
    conn.commit()

def Query(conn, tbl = None, Ex = False, colname = False, condition = False):
    cur = conn.cursor()
    if Ex:
        if isinstance(Ex, str):
            df = pd.read_sql(Ex, conn)
            return df
            exit()
    if colname != False and tbl != None:
        x = ''
        qry = ''
        if isinstance(colname, list):
            for i in range(len(colname)):
                if x == '':
                    x = colname[i]
                else:
                    x = x + "," + colname[i]
        else:
            x = str(colname)
        if condition != False:
            y = ''
            if isinstance(condition, list):
                for i in range(len(condition)):
                    if y == '':
                        x = condition[i]
                    else:
                        y = y + " and " + condition[i]
                qry = "select " + x + " from " + tbl + " where " + y
            else:
                y = str(condition)
                qry = "select " + x + " from " + tbl + " where " + y
    print('query: ', qry)
    dfx = pd.read_sql(qry, con= conn)
    return dfx

def DeleteByCond(conn, tbl, col, cond):
    xx = "DELETE FROM " + tbl + " WHERE " + col + " Like '" + cond + "'"
    cur = conn.cursor()
    cur.execute(xx)
    conn.commit()

def DeleteDuplicate(conn, tbl, cond_col):
    qry = "delete t1 FROM " + tbl + " t1 INNER JOIN "+ tbl + " t2 where t1.SL < t2.SL and t1." + cond_col + " = t2." + cond_col
    cur = conn.cursor()
    cur.execute(qry)
    conn.commit()

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn


conn = MySql('root','admin','127.0.0.1:3306','omdb')
#print(Query(conn, tbl = 'mytable', Ex = "select * from eve"))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']))
#print(Query(conn, tbl = 'mytable', colname = ['Code', 'Zone']), condition = " Zone Like 'BAR'")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sitecount.py###
import pandas as pd
import pyodbc

UserEx = "Driver={SQL Server};Server=10.101.4.193;Database=ROC;Uid=om29861;Pwd=Roc@072$123"
conn = pyodbc.connect(UserEx)

def siteinfo(txtwht):
    bts_info = """\
                EXEC [dbo].[spDetailsBTSInfoReport];
            """
    nodeb_inf = """\
                        EXEC [dbo].[spDetailsNodeBInfoReport];
                        """
    enodeb_inf = """\
                        EXEC [dbo].[spDetails_eNodeBInfoReport];
                    """
    if (txtwht == "All2g") or (txtwht == "all2g") or (txtwht == "All2G") or (txtwht == "2G"):
        dfbts = pd.read_sql(bts_info, conn)
        dfbts0 = dfbts[dfbts['BTSTotal'] != 0]
        btsdif = dfbts.shape[0] - dfbts0.shape[0]
        currbts = dfbts.shape[0] - btsdif
        return "ALL ON AIRED 2G: " + str(currbts)
    elif (txtwht == "All3G") or (txtwht == "all3G") or (txtwht == "All3g") or (txtwht == "3G"):
        nbdf = pd.read_sql(nodeb_inf, conn)
        nb = nbdf.shape[0]
        return "ALL ON AIRED 3G: " + str(nb)
    elif (txtwht == "All4G") or (txtwht == "all4G") or (txtwht == "All4g") or (txtwht == "4G"):
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        return "ALL ON AIRED 4G: " + str(enb)
    elif (txtwht == "AllCount") or (txtwht == "SC"):
        df2G = pd.read_sql(bts_info, conn)
        allnode = df2G.shape[0]
        df2G1 = df2G[df2G['BTSTotal'] != 0]
        btsdif = df2G.shape[0] - df2G1.shape[0]
        bts = df2G.shape[0] - btsdif
        df_3G = pd.read_sql(nodeb_inf, conn)
        nb = df_3G.shape[0]
        enb_df = pd.read_sql(enodeb_inf, conn)
        enb = enb_df.shape[0]
        xstr = "ALL ONAIR" + "\n" + "Radio Node: " + str(allnode) + "\n" + "2G: " + str(bts) + "\n" + "3G: " + str(nb) + "\n" + "4G: " + str(enb)
        return xstr
    else:
        return "#"
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sitehistory.py###
import pandas as pd
import MySQLdb
import pyodbc

def fnx(code):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conn = pyodbc.connect(socdb)
    df1 = pd.read_sql("select * from sitebase", conn)
    df = df1[df1['Site_Code'].str.contains(code)]
    a1 =  'Site Owner: ' + df['Mergeco__Robi'].iloc[0]  + '\n'
    a2 =  'AT Code/Relocation Code :' + df['AT_Code'].iloc[0]  + '\n'
    a3 =  'Site Name: ' + df['Site_Name'].iloc[0]  + '\n'
    a4 =  'Lat-Long: ' + df['Lat'].iloc[0] + ' - ' + df['Lon'].iloc[0]  + '\n'
    a5 =  'Site Address :' + df['Site_Physical_Address'].iloc[0]  + '\n'
    a6 =  'Site Type:' + df['Site_Type'].iloc[0]  + '\n'
    a7 =  'Site Build: ' + df['Build'].iloc[0]  + '\n'
    a8 =  'Share Operator: ' + df['Share_Operator'].iloc[0]  + '\n'
    a9 =  'Operator Code: ' + df['Operator_Code'].iloc[0]  + '\n'
    a10 =  'Region: ' + df['Region_(15)'].iloc[0]  + '\n'
    a11 =  'Zone: ' + df['Zone'].iloc[0]  + '\n'
    a12 =  'Cluster Type:' + df['Clutter_Type'].iloc[0]  + '\n'
    a13 =  'Tech: ' + df['All_Tech'].iloc[0]  + '\n'
    a14 =  'Tech Band: ' + df['Tech_Band'].iloc[0]  + '\n'
    a15 =  'Vendor: ' + df['Vendor'].iloc[0]  + '\n'
    a16 =  'Site Priority: ' + df['Priority'].iloc[0]  + '\n'
    vchk = df['PG_Allowed_Not_'].iloc[0]
    if "Run allowed" in vchk:
        a17 =  'PG Restricted : ' + "No" + '\n'
    else:
        a17 =  'PG Restricted : ' + "Yes" + '\n'
    a18 =  'DG: ' + df['DG_Status'].iloc[0]  + '\n'
    a19 =  'Revenue(k): ' + df['Revenue_(in_K_BDT)'].iloc[0]  + '\n'
    aa = a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8 + a9 + a10 + a11 + a12 + a13 + a14 + a15 + a16 + a17 + a18 + a19
    return aa

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\socksi_py_online_chk.py###
#ref: https://stem.torproject.org/tutorials/to_russia_with_love.html
import socks  # SocksiPy module
import socket
import urllib

SOCKS_PORT = 7000

# Set socks proxy and wrap the urllib module

socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, '127.0.0.1', SOCKS_PORT)
socket.socket = socks.socksocket

# Perform DNS resolution through the socket

def getaddrinfo(*args):
  return [(socket.AF_INET, socket.SOCK_STREAM, 6, '', (args[0], args[1]))]

socket.getaddrinfo = getaddrinfo

def query(url):
  """
  Uses urllib to fetch a site using SocksiPy for Tor over the SOCKS_PORT.
  """

  try:
    return urllib.urlopen(url).read()
  except:
    return "Unable to reach %s" % url
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\socks_srv.py###
#ref: https://rushter.com/blog/python-socks-server/
from socketserver import ThreadingMixIn, TCPServer, StreamRequestHandler

class ThreadingTCPServer(ThreadingMixIn, TCPServer):
    pass

class SocksProxy(StreamRequestHandler):
    def handle(self):
        # Our main logic will be here
        pass

if __name__ == '__main__':
    with ThreadingTCPServer(('127.0.0.1', 9011), SocksProxy) as server:
        server.serve_forever()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\socks_stat.py###
#ref: https://stem.torproject.org/api/connection.html

import requests as r

def sockchk_1(ip):
    proxycheck_io = "830284-700030-f06940-3c6410"
    apilink = "http://proxycheck.io/v2/" + ip + "?key=830284-700030-f06940-3c6410&asn=1"
    rs = r.get(apilink)
    jsonResponse = rs.json()
    print(jsonResponse)
    
    
sockchk_1('45.72.6.167')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sqdev.py###
import pandas as pd
import os
import omsql.InsUpd as ii



pt = os.getcwd() + '\\OMDB.csv'
df = pd.read_csv(pt)
cond = ['Zone', 'ULKA']
dfx = df[cond]
print(dfx)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sql.py###
import pandas as pd
import time
import pyodbc
import omfn.xdttm as odt
#from omsql.omsq import *

td = odt.Now()
tday = td.strftime('%Y-%m-%d')
socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"

def auser(msg1):
    conx = pyodbc.connect(socdb)
    print(msg1)
    msgspl = msg1.split(',')
    colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
    valu = "'" + msgspl[1] + "','" + str(msgspl[2]) + "','" + tday + "','" + msgspl[3] + "','Y','Y','Y'"
    qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
    qry2 = """insert into om_socbot_access (NAME,UID,JOIN_DATE,MSISDN) values ('" + msgspl[1] + "','" + msgspl[2] + "','2020-11-01','" + msgspl[3] "')"""
    print(qry)
    cr = conx.cursor()
    try:
        cr.execute(qry)
    except:
        cr.execute(qry2)
    cr.commit()
    return "user added successfully"
    #except:
        #return "useradd,halim vai,667675107,01819210773"

def botusrlist():
    conx = pyodbc.connect(socdb)
    qry = 'select * from om_socbot_access'
    df = pd.read_sql(qry, conx)
    st2 = "list of user"
    for i in range(len(df)):
        if df.loc[i,'MSISDN'] is None:
            msisd = 'NA'
        else:
            msisd = df.loc[i,'MSISDN']
        st = str(i) + '. ' + df.loc[i,'NAME'] + ', ' + df.loc[i,'UID'] + ", " + msisd
        st2 = st2 + chr(10) + st
    return st2


def periodic_contacts(contact_With_cmd):
    conn = pyodbc.connect(socdb)
    x = ''
    cur = conn.cursor()
    contact_With_cmd = contact_With_cmd.replace(' ','')
    comma = contact_With_cmd.count(',')
    if comma > 1:
        split_con = contact_With_cmd.split(',')
        cmd = split_con[2]
        contact = split_con[1]
    elif comma == 1:
        split_con = contact_With_cmd.split(',')
        cmd = None
        contact = split_con[1]
    else:
        return "correct command is \n periodic,01817183XXX,add"
    tbl = 'PeriCon'
    rtxt = ''
    cont = str(contact)
    cont2 = cont.replace(' ', '')
    if len(cont2) > 11 :
        fcn = cont2[-11:len(cont2)]
    else:
        if len(cont2) < 11:
            return 'please provide 11 digit number'
        else:
            fcn = cont2
    cr = conn.cursor()        
    if cmd == 'all' or 'all' in contact_With_cmd:
        rs = x.Ex("select * from " + tbl)
        st = ''
        for i in range(len(rs)):
            y = str(i) + '. ' + rs.loc[i, 'Number']
            if st == '':
                st = 'total number: ' + str(rs.shape[0]) + chr(10) + chr(10) + y
            else:
                st = st + chr(10) + y
        return st
    else:
        qry = 'select * from ' + tbl + " where Number = '" + fcn + "' or  Number like '" + fcn + "'"
        rs = pd.read_sql(qry, con = conn)
        if rs.shape[0] == 0:
            rtxt = 'number does not exists'
        else:
            rtxt = 'number exist in database'
        if 'check' in cmd or 'check' in contact_With_cmd:
            return rtxt
        elif 'add' in cmd and rtxt == 'number does not exists':
            try:
                qry = "insert into " + tbl + " (Number) values ('" + fcn + "')"
                cur.execute(qry)
                conn.commit
                print(qry)
                return 'added successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'remove' in cmd and rtxt == 'number exist in database':
            try:
                xx = "DELETE FROM " + tbl + " WHERE Number Like '" + fcn + "'"
                cur.execute(xx)
                conn.commit
                return 'deleted successfully'
            except:
                return 'try later, db connectivity blocked, please checl 121 pc or inform admin'
        elif 'add' in cmd and rtxt == 'number exist in database':
            return 'number exist in database'
        elif 'remove' in cmd and rtxt == 'number does not exists':
            return 'number does not exists'
        else:
            return 'please make query correctly'


#print(botusrlist())
#adduser('adduser,SMx2,615558497,0181817183680')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sqltdb.py###
import sqlite3
import os
import pandas as pd

pt = os.getcwd()
mydb = pt + "//served.db"
cn = sqlite3.connect(mydb)
c = cn.cursor()

def createtbl():
    c.execute('''CREATE TABLE ussdlg (ussd text, tm text);''')
    cn.commit()

def insertussd(ussd):
    try:
        usd = str(ussd)
        sql = "INSERT INTO ussdlg (ussd, tm) VALUES ('" + usd + "','NAAA')"
        count = c.execute(sql)
        cn.commit()
        return "S"
    except:
        return "F"
    
def queryussd(ussd):
    usd = str(ussd)
    c.execute('''SELECT * FROM ussdlg''')
    df = pd.DataFrame(c.fetchall(), columns=['ussd','tm'])
    if df.shape[0] != 0:
        df1 = df[df['ussd'].isin([usd])]
        if df1.shape[0] != 0:
            return 1
        else:
            return 0

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\sshlogin.py###
import paramiko
import sys
import time
import os

def Write2TxtList(dr,filename,content):
    flpath = dr + '\\' + filename
    print(flpath)
    fl = open(flpath, 'w')
    cont = "".join(content)
    fl.write(cont + '\n')
    fl.close()

class server():
    def __init__(self,HOST):
        self.USER = "ak2986"
        self.PASS = "Robi@123"
        self.PORT = 22
        self.c1 = paramiko.SSHClient()
        self.c1.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        self.c1.connect(HOST,port=self.PORT,username=self.USER,password=self.PASS)
        print ("SSH connection to %s established" %HOST)
    def excmd(self,cmd):
        c1 = self.c1
        stdin, stdout, stderr = c1.exec_command(cmd)        
        output = stdout.readlines()
        opt = "".join(output)
        print(opt)
        return opt
    def conn_cls(self):
        c1 = self.c1
        c1.close()
        print('connection close successfully')

#Write2TxtList(os.getcwd(), 'OutputLog.txt', opt)
ossip = "10.16.214.103"
x = server(ossip)
#y = x.excmd('ls')
#Write2TxtList(os.getcwd(), 'OutputLog.txt', y)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\T1.py###
import pandas as pd
from datetime import *
import os
import TD1 as td

class omidf:
    def __init__(self, dfx):
        self.df = dfx
    def DateTime(self, ndf = pd.DataFrame([])):
        if len(ndf) <= 1:
            print(self.df)
        else:
            print(ndf)

def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (minutes=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

#db = pd.read_csv(os.getcwd() + "\\OMDB.csv")
df = pd.read_csv(os.getcwd() + "\\csv\\DT.csv")
#df = df.rename(columns={'CUSTOMATTR15':'Code'})
#print(df)
df.set_index('LASTOCCURRENCE')['16/11/2020':'30/11/2020'].head()
print(df)
#pickcols()
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)








#df1 = dfdiff(df,'LASTOCCURRENCE')
#df1 = datetime_convert_format(df,'CLEARTIMESTAMP')
#df2 = datetime_convert_format(df1,'CLEARTIMESTAMP',"%d/%m/%Y %H:%M:%S")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tapi.py###
import pandas as pd
from datetime import *
import os
import TD1 as td

class omidf:
    def __init__(self, dfx):
        self.df = dfx
    def DateTime(self, ndf = pd.DataFrame([])):
        if len(ndf) <= 1:
            print(self.df)
        else:
            print(ndf)

def conv_lst_dic(lsKy, lsVal):
    try:
        dc = dict (zip (lsKy, lsVal))
        return dc
    except:
        print ('err')

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (minutes=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

#db = pd.read_csv(os.getcwd() + "\\OMDB.csv")
df = pd.read_csv(os.getcwd() + "\\csv\\DT.csv")
#df = df.rename(columns={'CUSTOMATTR15':'Code'})
#print(df)
df.set_index('LASTOCCURRENCE')['16/11/2020':'30/11/2020'].head()
print(df)
#pickcols()
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)








#df1 = dfdiff(df,'LASTOCCURRENCE')
#df1 = datetime_convert_format(df,'CLEARTIMESTAMP')
#df2 = datetime_convert_format(df1,'CLEARTIMESTAMP',"%d/%m/%Y %H:%M:%S")

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbl_mssql.py###
import pandas as pd
import pyodbc, os
import datetime

def mod_cols_name(df):
    cols = df.columns.to_list()
    sqlkey = ['ADD','ALTER','ALL','AND','ANY',
              'AS','ASC','BETWEEN','CASE','CHECK','COLUMN','CONSTRAINT',
              'CREATE','DATABASE','DEFAULT','DELETE','DESC','DISTINCT','DROP','EXEC','EXISTS','FROM',
              'HAVING','IN','INDEX','JOIN','LIKE','LIMIT','NOT','OR','PROCEDURE',
              'ROWNUM','SELECT','SET','TABLE','TOP','UNION','UNIQUE','UPDATE','VALUES','VIEW','WHERE']
    for i in range(len(cols)):
        st = cols[i]
        stmod = st.replace(' ','_')
        for n in sqlkey:
            if stmod == n:
                xx = '_' + stmod
                stmod = xx
        if st != stmod:
            df = df.rename(columns = {st:stmod})
    return df

def sql_lstyp(d_type):
    addID = "NULL"
    if d_type == 'Int64':
        return "INT " + addID
    elif d_type == 'datetime64[ns]':
        return "DATETIME " + addID
    elif d_type == 'Float64':
        return "FLOAT " + addID
    else:
        return "TEXT " + addID

def CT_MSSQL(conn, tablename, list_col, list_type = []):
    st = ""
    finalstr = ''
    x = ""
    cur = conn.cursor()
    try:
        cur.execute('select 1 from ' + tablename)
        print('table already exist')
        exit
    except:
        for i in range(len(list_col)):
            x = ''
            col = list_col[i]
            if len(list_type) != 0:
                lsty = list_type[i]
                x =  '"' + col.replace(" ","_") + '" ' + str(lsty)
            else:
                x = '"' + col.replace(" ","_") + '" TEXT NULL'
            if st == "":
                addsl = " SL INT PRIMARY KEY IDENTITY (1, 1), "
                st = 'CREATE TABLE "' + tablename + '" (' + str(x)
            else:
                st = st + ',' + str(x)
        else:
            finalstr = st + ')'
            try:
                cur.execute(finalstr)
                conn.commit()
                print('table created succssfully with cmd', finalstr)
            except:
                print('table creation failed', finalstr)

def df_dtype_conv(df):
    ndf = df.convert_dtypes()
    cols = ndf.columns.to_list()
    for i in range(len(cols)):
        col = cols[i]
        if ndf[col].dtypes == 'string':
            try:
                ndf[col] = ndf.apply(lambda x : pd.to_datetime(x[col]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                ndf[col] = pd.to_datetime(ndf[col])
            except:
                pass
    return ndf

def is_table_exist(tbl, conn):
    qry = "SELECT 1 FROM " + tbl
    try:
        cr = conn.cursor()
        rs = cr.execute(qry)
        print('table already exist')
    except:
        print('table creation failed')

def CreateTable_MSSQL(df, tablename, conn):
    dfx = mod_cols_name(df)
    ndf = df_dtype_conv(dfx)
    lscol = ndf.columns.to_list()
    lstype = []
    q = 0
    for col in range(len(lscol)):
        q = q + 1
        try:
            cl = lscol[col]
            dtyp = ndf[cl].dtypes
            lstype.append(sql_lstyp(dtyp))
        except:
            print('error for ', q, ' ', ndf[cl].dtypes)        
    CT_MSSQL(conn, tablename, lscol, lstype)
        
def MsSql(user, password, host, db):
    #socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    cstr = "Driver={SQL Server};SERVER=" + host + ";DATABASE=" + db + ";UID=" + user + ";PWD=" + password
    conn = pyodbc.connect(cstr)
    return conn
    


#lser = df_to_sql(ndf, 'om1', 'TAXW3', conn, oncolumn = 'ALL', bycolumn = ['CustomAttr15'])

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbl_mysql.py###
import pandas as pd
import os, time
import datetime
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def df_dtype_conv(dfn):
    df = dfn.apply(lambda x: x.replace("'",''))
    ndf = df.convert_dtypes()
    cols = ndf.columns.to_list()
    for i in range(len(cols)):
        col = cols[i]
        if ndf[col].dtypes == 'string':
            try:
                ndf[col] = ndf.apply(lambda x : pd.to_datetime(x[col]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                ndf[col] = pd.to_datetime(ndf[col])
            except:
                pass
    return ndf

def mysql_lstyp(d_type):
    addID = "NULL DEFAULT NULL"
    if d_type == 'Int64':
        return "INT " + addID
    elif d_type == 'datetime64[ns]':
        return "DATETIME " + addID
    elif d_type == 'Float64':
        return "FLOAT " + addID
    else:
        return "TEXT " + addID

def is_table_exist(tbl, conn):
    qry = "SELECT 1 FROM " + tbl
    try:
        cr = conn.cursor()
        rs = cr.execute(qry)
        print('table already exist')
    except:
        print('table creation failed')

def CreateTable_MYSQL(connection, tablename, df = None, table_col = False, table_col_datatype = False, space = '_'):
    addID = "SL INT AUTO_INCREMENT PRIMARY KEY, "
    addID = ""
    st = ""
    cr = connection.cursor()
    try:
        cr.execute()
    except:
        if table_col != False:
            if table_col_datatype == False:
                typ = 'TEXT NULL DEFAULT NULL'
                for i in range(len(table_col)):
                    x = "`" + table_col[i].replace(' ',space) + "` " + typ
                    if st == "":
                        st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + x
                    else:
                        st = st + ', ' + x
                return st
            else:
                for i in range(len(table_col)):
                    x = "`" + table_col[i].replace(' ',space) + "` " + table_col_datatype[i]
                    if st == "":
                        st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + addID + x
                    else:
                        st = st + ', ' + x
                return st
        elif df.shape[0] != 0 and table_col == False:
            xdf = df_dtype_conv(df)
            df = xdf
            table_col = df.columns.to_list()
            for i in range(len(table_col)):
                x = "`" + table_col[i].replace(' ',space) + "` " + mysql_lstyp(df[table_col[i]].dtypes)
                if st == "":
                    st = "CREATE TABLE IF NOT EXISTS `" + tablename + "` ( " + x
                else:
                    st = st + ', ' + x
        else:
            print("please pass, df = True or table_col = True")
            return ""
            exit
        sst = st + ") ENGINE = InnoDB CHARSET=utf32 COLLATE utf32_general_ci"
        print(sst)
        try:
            cr.execute(sst)
            connection.commit()
            print('table creation successfull', ' table name ', tablename)
        except:
            print('table creation failed')
            print(sst)
        return sst
        


            
            
            
            
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbotmain.py###
import pandas as pd
import cx_Oracle
import sys
import time
import os
import telepot
from telepot.loop import MessageLoop
import pyodbc
import subprocess
from pprint import pprint
import tbot.tbot_extend_1 as tex
import tbot.sitehistory as st
import tbot.tbot_single_site_status as stst
import omfn.xmssq as xmq
import requests

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
bot = telepot.Bot(TOKEN)

msq = xmq.mssq()

def custom_msg_sender(chatid,msg):
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)

def addme(uid,txt):
    if '$$' in txt:
        print(txt)
        st = txt
        nst = st.replace('$$', '')
        sst = nst.split(' ')
        print(sst)
        if len(sst) == 5:
            print(sst[2])
            msq.bot_usr_add(sst[1], str(uid), sst[3], str(sst[2]))
        else:
            print(len(sst))
        #bot_usr_add()
    else:
        fmt = "'Name 018XXXXXXXX Passcode'"
        st = "OK, Then" + '\n' + "send info like below format \n $$ Name 018XXXXXXXX Passcode $$ \n \n if u send me wrong format i did not reply"
        custom_msg_sender(uid,st)

def site_bio(txt,chat_id):
    cd = txt.upper()
    bot.sendMessage(chat_id, 'processing request for ' + cd + ' , please wait')
    getval = stst.query(cd)
    gethis = st.fnx(cd)
    txtx = getval + '\n' + '\n' + 'Site Details:' + '\n' + gethis
    bot.sendMessage(chat_id,txtx)
    return 'done'

def add_inc_notes(txt,chat_id):
    st = txt.split('-')
    print(st[1])
    x = msq.apend_into('incident_tracker_v2','sm_comment_tele', st[1], 'Incident_ID', st[0].strip())
    return x

def query_hanndler(code):
    return code

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if (content_type == 'text'):
        txt = msg['text']
        cht = msg['chat']
        frm = msg['from']
        fname = frm['first_name']
        uid = frm['id']
        cid = cht['id']
        ctype = cht['type']
        user_auth = msq.auth_check_db(str(uid), ctype)
        bot.sendMessage('671462535', user_auth)
        txupr = txt.upper()
        if user_auth == '1' or user_auth == 1:
            if 'hi' in txt:
                bot.sendMessage(chat_id, txt)
            elif ("ADD" in txupr or "RMV" in txupr or "LIST" in txupr):
                gtval = tex.M_handdler(txupr, msg)
                bot.sendMessage(chat_id, gtval)
            elif len(txt) == 7 and cid == uid:
                rs = site_bio(txt,chat_id)
                print(rs)
            elif ("INC0" in txupr or "RDTX" in txupr):
                print('add_inc_notes')
                rs = add_inc_notes(txupr,chat_id)
                bot.sendMessage(chat_id, rs)
        elif (user_auth == '0' or user_auth == 0) and ('ADDME' in txupr or '$' in txt):
                addme(uid, txt)
        else:
            bot.sendMessage(cid, 'You are not autorized')
            bot.sendMessage('671462535', fname + ', ID: ' + str(uid))

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_extend.py###
import pyodbc
import pandas as pd
#import MySQLdb

#def stname(code):
    #nm = 'NP'
    #conn= MySQLdb.connect("localhost","root","","ops_portal")
    #df = pd.read_sql("select * from stbase3 Where Site_Code='" + code + "'", conn)
   # rw = df.shape[0]
   # print("~~~~~")
   # print(rw)
   # print("~~~~~")
   # if rw != 0:
  ##      nm = df['Site_Name'].iloc[0] + '\n'
  #  return nm

def add_site(code,name,grp):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = '''INSERT INTO special_sites (SiteCode, Name, Gropu) VALUES (?,?,?)'''
    in_qry_1 = (code,name,grp)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()
    return "site added in list"
    
def rmv_site(code):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = "DELETE FROM special_sites WHERE SiteCode='" + code + "'"
    curs.execute(in_qry)
    conx.commit()
    conx.close()
    return "site removed from list"

def list_site():
    lst = ''
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from special_sites"
    df = pd.read_sql(qry, conx)
    for ind in df.index:
        lst = lst + '\n' + df['SiteCode'][ind] + "," + df['Name'][ind]
    return lst

def M_handdler(text):
    rval = 'please provide correct format'
    if 'ADD' in text:
        txt = text.strip()
        stsplit = txt.split(' ')
        ln = len(stsplit)
        if ln == 4:
            rval = add_site(stsplit[1],stsplit[2],stsplit[3])
        elif ln == 3:
            rval = add_site(stsplit[1], stsplit[2], "NA")
        elif ln == 2:
            rval = add_site(stsplit[1], stname(stsplit[1]), "NA")
        else:
            rval = 'format like:: ADD,DHGUL19,UDAY TOWER,VIP'
    elif 'RMV' in text:
        txt = text.strip()
        stsplit = txt.split(' ')
        ln = len(stsplit)
        if ln == 2:
            rval = rmv_site(stsplit[1])
    elif 'LIST' in text:
        rval = list_site()
    else:
        print('please provide correct format')
    return rval

tx = "ADD,PBSDR01,PABNA SADAR,NA"
tx2 = 'LIST'
#if ('add,' in text) or ('rmv,' in text) or ('list,' in text):
print(M_handdler(tx2))


    

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_extend_1.py###
import pyodbc
import pandas as pd
import MySQLdb

def stname(code):
    nm = 'NP'
    conn= MySQLdb.connect("localhost","root","","ops_portal")
    df = pd.read_sql("select * from stbase3 Where Site_Code='" + code + "'", conn)
    rw = df.shape[0]
    print("~~~~~")
    print(rw)
    print("~~~~~")
    if rw != 0:
        nm = df['Site_Name'].iloc[0] + '\n'
    return nm


def add_site(code, name, Mask, Tgrp, OwnerNm):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = '''INSERT INTO custom_sites (SiteCode, Name, MaskID, TeleGroup, OwnerName) VALUES (?,?,?,?,?)'''
    in_qry_1 = (code, name, Mask, Tgrp, OwnerNm)
    curs.execute(in_qry, in_qry_1)
    conx.commit()
    conx.close()
    return "site added in list"


def rmv_site(code, Mask, Tgrp):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    curs = conx.cursor()
    in_qry = "DELETE FROM custom_sites WHERE SiteCode='" + code + "'AND MaskID='" + Mask + "'"
    curs.execute(in_qry)
    conx.commit()
    conx.close()
    rval = 'Sites Removed From:' + '\n' + Tgrp
    return rval

def list_site(Mask, Tgrp):
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where MaskID='" + str(Mask) + "'"
    df = pd.read_sql(qry, conx)
    lst1 = '\n'
    for ind in df.index:
        lst1 = lst1 + '\n' + df['SiteCode'][ind] + "," + df['Name'][ind]
    rval = Tgrp + ' Sites:' + '\n' + lst1
    return rval

def list_site_all(OwNm):
    lst = ''
    socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
    conx = pyodbc.connect(socdb)
    qry = "Select * from custom_sites where OwnerName='" + OwNm + "'"
    df = pd.read_sql(qry, conx)
    for ind in df.index:
        lst = lst + '\n' + df['SiteCode'][ind] + "," + ' Group: ' + df['TeleGroup'][ind]
    rval = OwNm + ' Custom Sites List:' + '\n' + lst
    return rval

#txupr, str(uid), str(cid), msg
def M_handdler(text,msg):
    cht = msg['chat']
    frm = msg['from']
    ctype = cht['type']
    if ctype == 'group':
        GroupName = cht['title']
        GroupMask = cht['id']
        OwName = frm['first_name']
        rval = 'please provide correct format'
        GMask = GroupMask
        GN = GroupName
        if 'ADDBIG' in text:
            cd = text.split(",")
            i = 0
            for val in cd:
                rval = add_site(val, stname(val), GMask, GN, OwName)
                i = i + 1
                else:
                    rval = str(i) + " Sites Added Successfully"
        elif 'ADD' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 4:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 3:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            elif ln == 2:
                rval = add_site(stsplit[1], stname(stsplit[1]), GMask, GN, OwName)
            else:
                rval = 'format like:: ADD DHGUL19'
        elif 'RMV' in text:
            txt = text.strip()
            stsplit = txt.split(' ')
            ln = len(stsplit)
            if ln == 2:
                rval = rmv_site(stsplit[1], str(GMask), GN)
        elif 'LIST' in text:
            rval = list_site(GMask, GN)
        else:
            print('please provide correct format')
        return rval
    else:
        return 'this feature only available in a group'


#tx = "ADD,PBSDR01,PABNA SADAR,NA"
#tx2 = 'LIST'
# if ('add,' in text) or ('rmv,' in text) or ('list,' in text):
#print(M_handdler(tx2))





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_prod1.py###
import time
import telepot
from telepot.loop import MessageLoop
from pprint import pprint


TechSOCBOT = '1228075595:AAGYj2ck_yErfmVQFfW1xb7pzpSjTfVpadE'
bot = telepot.Bot(TechSOCBOT)

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if (content_type == 'text'):
        print('ok')

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_Production.py###
import time
import telepot
from telepot.loop import MessageLoop
from pprint import pprint
import tbot.tbot_prod1 as techsoc

akomibot = "1054945336:AAGv-B9ojejhA0ohDwRltTs5mYnOX8lK55M" #akomibot
bot = telepot.Bot(akomibot)

def handle(msg):
    pprint(msg)
    content_type, chat_type, chat_id = telepot.glance(msg)
    if (content_type == 'text'):
        bot.sendMessage(chat_id, "hello")

MessageLoop(bot, handle).run_as_thread()
print('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_single_site_status.py###
import pandas as pd
import cx_Oracle

def query(code):
    conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn)
    qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
    Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,
    ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
    where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
    and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
    and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%"""
    qry2 = qry1 + code + "%'"""
    try:
        df = pd.read_sql(qry2, con=conn)
        print('try success')
    except:
        connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        df = pd.read_sql(qry2, con=connx)
        print('Except trigger')
    print(df)
    rows = df.shape[0]
    heap = code + ":"
    if rows != 0:
        for i in range(0, len(df)):
            tech = df.iloc[i]['TECHNOLOGY']
            tm = df.iloc[i]['STARTTIME']
            if '2G' in tech:
                heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
            if '3G' in tech:
                heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
            if '4G' in tech:
                heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
            # print(heap)
    else:
        return heap + '\nAll Tech are up'
    return heap
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tbot_site_stat_old.py###
import pandas as pd
import cx_Oracle
import sys
import time
import os
import telepot
from telepot.loop import MessageLoop
import sitehistory as st
import subprocess

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
bot = telepot.Bot(TOKEN)
auth_file = os.getcwd() + "\\" + 'users.txt'
conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print(conn)
def query(code):
    qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
    Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
    where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
    and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
    and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%""" 
    qry2 = qry1 + code + "%'"
    try:
        df = pd.read_sql(qry2, con=conn)
        print('try success')
    except:
        connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        df = pd.read_sql(qry2, con=connx)
        print('Except trigger')
    print(df)
    rows = df.shape[0]
    heap = code + ":"
    if rows != 0:
        for i in range(0,len(df)):
            tech = df.iloc[i]['TECHNOLOGY']
            tm = df.iloc[i]['STARTTIME']
            if '2G' in tech:
                heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
            if '3G' in tech:
                heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
            if '4G' in tech:
                heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
            #print(heap)
    else:
        return heap + '\nAll Tech are up'
    return heap

def auth_check(usrname,firstname):
    fo = open(auth_file,"r+")
    txt = fo.read()
    fo.close()
    if (usrname in txt) or (firstname in txt):
        print("auth chk send ok")
        return "OK"
    else:
        print("auth chk send not ok")
        return "NOT"

def rdpcls():
    subprocess.call(["E:\OmProject\Project20\Tele_BOT\rdp_cls.bat"])
    return "done"

def query_hanndler(code):
    return code

def handle(msg):
    content_type, chat_type, chat_id = telepot.glance(msg)
    if content_type == 'text':
        txt = msg['text']
        cid = chat_id
        frm = msg['from']
        #uname = msg['from']['last_name']
        uname = ""
        fname = msg['from']['first_name']
        print(uname)
        print(cid)
        apprv = auth_check(uname,fname)
        if apprv == "OK":
            if len(txt) == 7:
                cd = txt.upper()
                bot.sendMessage(chat_id, 'processing request for '+ cd + ' ,please wait')
                getval = query(cd)
                gethis = st.fnx(cd)
                txtx = getval + '\n' + '\n' + 'Site Details:' + '\n' + gethis
                bot.sendMessage(chat_id, txtx)
                bot.sendMessage('671462535', txtx)
            elif 'help' in txt:
                bot.sendMessage(chat_id, 'just provide sitecode to know status')
            elif 'rdp' in txt:
                gtval = rdpcls()
                bot.sendMessage(chat_id, 'Killed')
            else:
                bot.sendMessage(chat_id, 'Please Provide sitecode without space')
        else:
            bot.sendMessage(chat_id, 'You are not autorized')
            
MessageLoop(bot, handle).run_as_thread()
print ('Listening ...')

while 1:
    time.sleep(10)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TD1.py###
import pandas as pd
from datetime import *
import os

def sec_to_dur(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def dfdiff(df, LO, CLR = False):
    df = df.astype (str)
    if CLR == False:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df = df.assign (DUR=df.apply (lambda x: pd.Timedelta (datetime.now() - x[LO]).seconds / 60, axis=1))
        return df
    else:
        df[LO] = df.apply (lambda x: pd.to_datetime (x[LO]), axis=1)
        df[CLR] = df.apply (lambda x: pd.to_datetime (x[CLR]), axis=1)
        df = df.assign(DUR=df.apply (lambda x: pd.Timedelta (x[LO] - x[CLR]).seconds / 60 if (
                x[CLR].year >= 2019) else "ACT", axis=1))
        return df

def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def datetime_convert_format(df, col, fmt="%Y/%m/%d %H:%M:%S"):
    try:
        df[col] = df[col].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime(fmt))
        return df
    except:
        df[col] = df[col].apply(lambda x: pd.to_datetime (x, errors='coerce', yearfirst=True, cache=True).strftime(fmt))
        return df

def vL(df_Main, df_Ref, col='Code', pick_from_ref = ['Zone']):
    ls = df_Main.columns.to_list ()
    df1 = df_Main.merge (df_Ref, how='right', on=col)
    for i in pick_from_ref:
        ls.append(str(i))
    else:
        dfx = df1[ls]
        return dfx



#vlook = vL(df, db, col='Code', pick_from_ref=['Zone','Cluster'])
#df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
#df = df.astype(str)
#print(df.columns)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\telebot.py###
import sys
import time
import telepot
from telepot.loop import MessageLoop
import json

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'
bot = telepot.Bot(TOKEN)

def query_hanndler(code):
    return code

def handle(msg):
    content_type, chat_type, chat_id = telepot.glance(msg)
    print(content_type, chat_type, chat_id)
    if content_type == 'text':
        ctype = content_type
        txt = msg['text']
        if txt == "Clean and clear":
            bot.sendMessage(chat_id, "price 150TK")
        elif len(txt) == 7:
            getval = query_hanndler(txt)
            bot.sendMessage(chat_id, getval)
        else:
            bot.sendMessage(chat_id, 'what is name of facewash?')
            
        
MessageLoop(bot, handle).run_as_thread()
print ('Listening ...')

while 1:
    time.sleep(10)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\telethon_om.py###
from telethon.sync import TelegramClient

def omi():
    api_id = 628127
    api_hash = 'db7fa09d585d6eedddd0df5973f3239b'
    phone = '+8801817184338'
    client = TelegramClient(phone, api_id, api_hash)
    client.connect()
    if not client.is_user_authorized():
        client.send_code_request(phone)
        client.sign_in(phone, input('Enter the code: '))
        print(client.get_me().stringify())
    
def smpool():
    api_id = 1621549
    api_hash = '6b06c3cf6e7004803b11c79f80e1b8bf'
    phone = '+8801817183680'
    client = TelegramClient(phone, api_id, api_hash)

omi()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\test.py###
import MySQLdb
import pandas as pd
import os

conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "sem_raw.csv"

def dic_df_parse(dic,zn,zn_colname,parsecol_1,parsecol_2,parsecol_3):
    hp = ""
    #count = 0
    nd = pd.DataFrame(dic)
    ndf = nd[nd[zn_colname].str.contains(zn, na=False)]
    for ind in ndf.index:
        code = str(ndf[parsecol_1][ind])
        lo = str(ndf[parsecol_2][ind])
        resource = str(ndf[parsecol_3][ind])
        hp = hp + " \n"  + code + " || " + lo + " || " + resource
    z = zn + ': \n' + hp
    return z

dfc = pd.read_csv(file)
dic = dfc.to_dict()
gval = dic_df_parse(dic,'DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
print(gval)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\test3.py###

import socket
import Queue
import threading
import time
import os
import sys
from random import *
from struct import *





def getSocksVersion(self, proxy):
        host = proxy.split(":")[0]
        try:
            port = int(proxy.split(":")[1])
            if port < 0 or port > 65536:
                print "Invalid: " + proxy
                return 0
        except:
            print "Invalid: " + proxy
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(self.timeout)
        try:
            s.connect((host, port))
            if(self.isSocks4(host, port, s)):
                s.close()
                return 5
            elif(self.isSocks5(host, port, s)):
                s.close()
                return 4
            else:
                ("Not a SOCKS: " + proxy)
                s.close()
                return 0
        except socket.timeout:
            print "Timeout: " + proxy
            s.close()
            return 0
        except socket.error:
            print "Connection refused: " + proxy
            s.close()
            return 0

getSocksVersion('45.72.6.167:8000')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\testapi.py###
import json
import requests
import os
from pprint import pprint

def api_ip2asn(ip):
    url = "https://api.iptoasn.com/v1/as/ip/" + ip
    x = requests.get(url)
    y = x.json()
    return y["as_description"]    
api_ip2asn("38.114.23.4")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\textfl.py###
import os

fpth = os.getcwd() + "//txtfile"
grp = os.getcwd() + "//rpa_group"
grponlymask = grp + "//grpmask.txt"
grpmask_and_head = grp + "//grmask_head.txt"

def srctxt_exact(content,srcstr):
    ls = []
    for ln in content:
        lnx = ln.strip()
        if srcstr == lnx:
            ls.append(lnx)
    return ls
            
def srctxt_partial(content,srcstr):
    ls = []
    for ln in content:
        lnx = ln.strip()
        if srcstr in lnx:
            ls.append(lnx)
    return ls

def rdline(flname):
    fl  = open(flname, "r") 
    contents =fl.readlines()
    fl.close()
    return contents
        
def rdall(flname):
    fl  = open(flname, "r") 
    contents =fl.read()
    fl.close()
    return contents
    
def wrt(flname,content):
    fl  = open(flname, "w+", encoding="utf-8")
    fl.write(content)
    fl.close()
    
def apnd(flname,content):
    fl  = open(flname, "a+")
    fl.write(content)
    fl.close()
    
def get_list_txt_file(dirr):
    fl = os.listdir(dirr)
    ls = []
    for f in fl:
        if f.endswith('.txt'):
            ls.append(f)
    return ls

def pick_rpa_group():
    lst = get_list_txt_file(fpth)
    st = ""
    sthd = ""
    for i in range(len(lst)):
        pth = fpth + "//" + lst[i]
        contents = rdline(pth)
        n = 0
        for f in contents:
            fr = f.find('-R')
            fd = f.find('$')
            grpname = f[0:fr-1]
            grpmask = f[fd+1:len(f)-1]
            grpcon = grpmask + "," + grpname
            if grpmask not in st:
                st = st + "\n" + grpmask
            if grpmask not in sthd:
                n = n + 1
                sthd = sthd + "\n" + grpcon
        print(st)
        print(sthd)
        wrt(grponlymask,st)
        wrt(grpmask_and_head,sthd)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\top5.py###
import pandas as pd
import numpy as np
import os
import requests
import func.lookup as look
import func.fnstr as fst
import func.fndatetime as fdt
import func.fnlook as flk
import func.omdtfn as odt
import func.fnfn as fn
import db.db as sq
import prep as pr
from datetime import *


def custom_msg_sender_top5(chatid,msg):
    TOKEN = "961035316:AAGWIlt5GjIkBz1QI1s6WKbwVnfubmn0m6E"
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


TSS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else "other"
                ))

def map_customer(df):
    df4 = df
    df4 = df4.rename(columns={'CUSTOMATTR15':'CODE'})
    pt = os.getcwd() + "\\db\\T70.csv"
    df5 = pd.read_csv(pt)
    df6 = flk.vlookup(df4,df5,'CODE','NA')
    return df6

def mod_techwise(df14):
    try:
        df15 = df14.groupby(df14['CODE']).MTTR.sum().to_frame(name = 'SMX').reset_index()
        df17 = df14.merge(df15, on='CODE')
        df17 = df17.drop_duplicates(subset='CODE',keep='last', inplace = False)
        df17['SMX'] = df17['SMX'].round(decimals=2)
        df18 = df17.sort_values('CODE')
        df19 = df18[['CODE','CName','CNT','SMX']]
        arr = df19.to_numpy()
        rw, col = arr.shape
        stx = ""
        for i in range(rw):
            if arr[i][3] > 2:
                if stx == "":
                    stx = arr[i][1] + chr(10) + arr[i][0] + ': ' + str(arr[i][2]) + '/' + str(arr[i][3]) + ' min'
                else:
                    stx = stx + chr(10) + chr(10) + arr[i][1] + chr(10) + arr[i][0] + ': ' + str(arr[i][2]) + '/' + str(arr[i][3]) + 'min'
        return stx
    except:
        return "NA"

def top5_outage_report(df0):
    df1 = df0
    df = fst.add_col_df(df1,'cat')
    df['cat'] = df.apply(lambda row: TSS(row.SUMMARY) , axis = 1)
    df2 = df[~df['cat'].isin(['other'])]
    df4 = fst.add_col_df(df2,'DT')
    df4['DT'] = df4.apply(lambda x : pd.to_datetime(x.LASTOCCURRENCE).strftime("%d-%b-%Y"), axis = 1)
    df6 = fst.add_col_df(df4,'CLRYR')
    df6['CLRYR'] = df6.apply(lambda x : pd.to_datetime(x.CLEARTIMESTAMP).strftime("%Y"), axis = 1)
    dd = odt.day_minus_dy(1)
    df7 = df6[df6.DT.str.contains(dd) & df6.CLRYR.str.contains('2020')]
    df11 = map_customer(df7)
    df12 = flk.countif(df11,'CName','CName','CNT')
    df13 = df12[['CODE','LASTOCCURRENCE','CLEARTIMESTAMP','cat','CName','GName', 'CNT']]
    df14 = fdt.datedif(df13,'MTTR','LASTOCCURRENCE','CLEARTIMESTAMP')
    df2G = df14[df14.cat.str.contains('2G')]
    df3G = df14[df14.cat.str.contains('3G')]
    df4G = df14[df14.cat.str.contains('4G')]
    G2 = "2G: " + chr(10) + mod_techwise(df2G)
    G3 = "3G: " + chr(10) + mod_techwise(df3G)
    G4 = "4G: " + chr(10) + mod_techwise(df4G)
    GG = G2 + chr(10) + chr(10) + G3 + chr(10) + chr(10) + G4
    fstx = "VIP TOP 5 Sites" + chr(10) +"Outage Count and Durtaion " + chr(10) + "on " + odt.day_minus(1) + chr(10) + chr(10) + "code: count/sum of duration" + chr(10) + chr(10) + GG
    fmsg1 = fstx.replace("&","and")
    fmsg = fmsg1.replace(chr(10),"%0a")
    custom_msg_sender_top5("-352454352",fmsg)
    print('top5 done')

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TS.py###
import pandas as pd
import numpy as np
import os
import datetime
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\'")
        s2 = s1.replace(":","\:")
        return s2

def col_space_rmv(ndf, space = '_'):
    df = ndf.replace (np.nan, '')
    dfcol = df.columns.to_list()
    for i in range(len(dfcol)):
        try:
            df = df.rename(columns={dfcol[i]:dfcol[i].replace(' ', space)})
        except:
            pass
    return df
        
        
def dtype_match_mysql(db, table, conn, ndf):
    df = ndf.replace (np.nan, '')
    dfcol = df.columns.to_list()
    for i in range(len(dfcol)):
        df = df.rename(columns={dfcol[i]:dfcol[i].replace(' ', '_')})
    dic = mysql_table_colinfo(db, table)
    try:
        colunmatch = []
        q = 0
        Y = 1
        for i in range(len(dbcols)):
            dbty = get_key(dic, dbcols[i])
            st = dbcols[i]
            q = q + 1
            try:
                xdf = df[st]
            except:
                Y = 0
                notmat = 'column not matched: - ' + st
                print(notmat)
            if Y == 1:
                print('dtype_match: ', dbty)
                try:
                    if dbty == 'int':
                        df[st] = df[st].astype(int)
                    elif dbty == 'float':
                        df[st] = df[st].astype(float)
                    elif dbty == 'datetime':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
                    elif dbty == 'date':
                        df[st] = df.apply(lambda x : pd.to_datetime(x[st]).strftime("%Y-%m-%d"), axis = 1)
                    else:
                        df = df.apply(lambda x: x.replace("'","\'"))
                except:
                    pass
                q = q + 1
        return df
    except:
        print(comment1, '-', 'error occuruced for dbcols: ', st , ' at position ', q)
         
def insert_into_mysql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            if lsval[i] != '' and lsval[i] is not None:
                dtype = get_key(dic,lscol[i])
                if dtype == 'text' or dtype == 'varchar':
                    valmod = modstr(lsval[i])
                else:
                    valmod = str(lsval[i])
                if val == '':
                    col = lscol[i]
                    val = "'" + valmod + "'"
                else:
                    col = col + ',' + lscol[i]
                    val = val + ',' + "'" + valmod + "'"
            else:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""
                
def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn    



def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                df[cname] = df[cname].fillna('NA')
                df[cname] = df.apply(lambda x: x[cname].replace("'","\'"))
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
                df[cname] = df[cname].replace(np.nan, 0)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
                df[cname] = df[cname].replace(np.nan, 0)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df[cname].replace(np.nan, '')
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df[cname].replace(np.nan, '')
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df[cname].replace(np.nan, '')
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def main():
    pt = os.getcwd() + "\\sclick.csv"
    ndf = pd.read_csv(pt)
    xdf = ndf.convert_dtypes()
    conn = MySql('root','admin','127.0.0.1:3306','om1')
    dc = mysql_table_colinfo('om1', 'TAXW3', conn)
    dfn = dtype_match_dbdf(xdf, dc)
    df = col_space_rmv(dfn, "_")
    q = 0
    rwval = []
    colval = df.columns.to_list()
    for (indx, rwseries) in df.iterrows():
        q = q + 1
        if q == 5:
            break
        rwval = rwseries.values.tolist()
        x = insert_into_mysql('TAXW3', dc, colval, rwval)
        print(x)
#main()      
pt = os.getcwd() + "\\sclick.csv"
ndf = pd.read_csv(pt)
xdf = ndf.convert_dtypes()


#conn = MySql('root','admin','127.0.0.1:3306','om1')
#dc = mysql_table_colinfo('om1', 'TAXW3', conn)
#df = dtype_match_dbdf(xdf, dc)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TS2.py###
import pandas as pd
import numpy as np
import os
import datetime
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import upin as upd

def get_server_name(db, table, conn):
    try:
        qry = 'EXPLAIN ' + db + '.' + table
        dfx = pd.read_sql(qry, con = conn)
        return "MYSQL"
    except:
        try:
            qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
            dfx = pd.read_sql(qry, con= conn)
            return "MSSQL"
        except:
            return "only MYSQL and MSSQL is Supported"

def mssql_table_colname(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    return dbcols

def mssql_table_colinfo(db, table, conn):
    qry = "SELECT * FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = '" + table + "' ORDER BY ORDINAL_POSITION"
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['COLUMN_NAME'].to_list()
    dbcolType = dfx['DATA_TYPE'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def mysql_table_colname(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    return dbcols

def mysql_table_colinfo(db, table, conn):
    qry = 'EXPLAIN ' + db + '.' + table
    dfx = pd.read_sql(qry, con = conn)
    dbcols = dfx['Field'].to_list()
    dbcolType = dfx['Type'].to_list()
    dc= zip(dbcols, dbcolType)
    dic = dict(dc)
    return dic

def MySql(user, password, host, db):
    constr = 'mysql+mysqlconnector://' + user + ':' + password + '@' + host + '/' + db
    engine = create_engine(constr, echo=False)
    conn = engine.raw_connection()
    return conn

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key
            
def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def dtype_match_dbdf(dataframe, table_col_coltype = {}):
    df = dataframe
    dc = table_col_coltype
    for Kycol in dc:
        cname = Kycol
        ctype = dc[Kycol]
        try:
            if 'text' in ctype or 'varchar' in ctype:
                pass
            elif 'int' in ctype:
                df[cname] = df[cname].astype(int)
            elif 'float' in ctype:
                df[cname] = df[cname].astype(float)
            elif 'datetime' in ctype or 'timestamp' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d %H:%M:%S"), axis = 1)
            elif 'date' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%Y-%m-%d"), axis = 1)
            elif 'time' in ctype:
                df[cname] = df.apply(lambda x : pd.to_datetime(x[cname]).strftime("%H:%M:%S"), axis = 1)
            else:
                pass
        except:
            pass
    return df

def fuzzymatch(str1,str2, uplow = True):
    if uplow == True:
        s1 = str1.lower()
        s2 = str2.lower()
        ls1 = []
        ls2 = []
        for i in s1:
            ls1.append(i)
        for n in s2:
            ls2.append(n)
        q = 0
        succ = 0
        fail = 0
        if len(ls1) <= len(ls2):
            for j in range(len(ls1)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        else:
             for j in range(len(ls2)):
                q = q + 1
                if ls1[j] == ls2[j]:
                    succ = succ + 1
                else:
                    fail = fail + 1
        try:
            spercent = round((succ/q)*100,2)
        except:
            spercent = 0
        return spercent

def colchk_dbdf(coldb = [], coldf = []):
    if isinstance(coldb, list) and isinstance(coldf, list):
        cdb = coldb
        cdf = coldf
        cdb.sort
        coldf.sort
        nonmat = []
        for i in range(len(cdb)):
            d1 = cdb[i]
            mat = 0
            for j in range(len(cdf)):
                if d1 == cdf[j]:
                    mat = 1
                    break
            if mat == 0:
                nonmat.append(d1)
        return nonmat

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""



def df_to_sql(dataframe, dbname, tablename, conn, oncolumn = "ALL", bycolumn = None, how = 'append'):
    srv = get_server_name(dbname, tablename, conn)
    print(srv)
    if srv == 'other':
        exit()
    cr = conn.cursor()
    try:
        cr.execute('select 1 from '+ tablename)
    except:
        print('table does not exits')
        exit()
    if oncolumn != 'ALL' and bycolumn == None:
        dataframe = dataframe[oncolumn]
    ndf = dataframe.replace(r'^\s*$', np.nan, regex=True)
    xdf = ndf.convert_dtypes()
    dfcol = xdf.columns.to_list()
    if srv == "MYSQL":
        dbcol = mysql_table_colname(dbname, tablename, conn) #function call
    elif srv == "MSSQL":
        dbcol = mssql_table_colname(dbname, tablename, conn) #function call
    nonmat = colchk_dbdf(dbcol,dfcol)
    dfc = []
    rnmcol = {}
    if len(nonmat) != 0:
        for n in range(len(nonmat)):
            dbc = nonmat[n]
            y = 0
            for i in range(len(dfcol)):
                x = fuzzymatch(dbc, dfcol[i])
                #print(dbc,' - ',  dfcol[i], ' p- ', x, ' max ', y)
                if x >= y:
                    y = x
                    dfcl = dfcol[i]
            else:
                dfc.append(dfcl)
                rnmcol[dfcl] = dbc
    xdf = xdf.rename(columns = rnmcol)
    if srv == "MYSQL":
        dc = mysql_table_colinfo(dbname, tablename, conn)  #mysql function call
    elif srv == "MSSQL":
        dc = mssql_table_colinfo(dbname, tablename, conn)  #mysql function call
    df = dtype_match_dbdf(xdf, dc) #function call
    if bycolumn == None:
        q = 0
        rwval = []
        colval = df.columns.to_list()
        er = []
        for (indx, rwseries) in df.iterrows():
            q = q + 1
            rwval = rwseries.values.tolist()
            x = insert_into_sql(tablename, dc, colval, rwval)
            try:
                cr.execute(x)
            except:
                er.append(x)
                qq = "dfrow: " + str(q)
                er.insert(0, qq)
        print('row inserted: ', q - len(er), ' error found for rows: ', len(er), ", get error in return")
        return er
    else:
        tableprop = dc
        upd.UPIN(df, tablename, tableprop, conn, bycols = bycolumn)

    

pt = os.getcwd() + "\\sclick.csv"
ndf = pd.read_csv(pt)
conn = MySql('root','admin','127.0.0.1:3306','om1')
lser = df_to_sql(ndf, 'om1', 'TAXW3', conn, oncolumn = 'ALL', bycolumn = ['CustomAttr15'], how = 'replace')



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TST.py###
import os
import time


print("i am omi")
time.sleep(5)
print("exit")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\tstststs.py###
import pandas as pd

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

# way of calling - print(countif(df['Colname'],"value_to_check"))
# we call above countif function using loop on dataframe and can store the result into a new column as following.
def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"


df = pd.DataFrame({
    'column_1': ['g', 't', 'n', 'w', 'n', 'g']
})

print(match('n',df['column_1'],"Last"))

df = df.assign(new_column = "NA")
list_as_range = df['column_1'].values.tolist()   #column_1 is the column name (can be any column)
for i in range(len(df)):
    cell_value = df.loc[i,'column_1']   #column_1 is the column name (can be any column)
    df.loc[i,'new_column'] = countif(list_as_range, cell_value)   #calling above functions
#print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TT.py###
import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\DevMeterials\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (minutes=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d


def parse_date_fuzzy(string, first='day'):
    try:
        if first == 'day':
            x = parse(string, fuzzy=True, dayfirst=True)
        elif first == 'year':
            x = parse(string, fuzzy=True, yearfirst=True)
        else:
            x = parse(string, fuzzy=True)
        return x.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return ""

    
def timebetween(t1,t2):
    d1 = parse_date_fuzzy(t1)
    d2 = parse_date_fuzzy(t2)
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1 + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + d2 + "','DD-MM-YYYY HH24:MI:SS')"
    print(dd)

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
flname = os.getcwd() + "\\" + dtst + "csv"

def qry(qq, savefile=dtst):
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE "
    qry = q1 + qq
    print(qry)
    #df = pd.read_sql(qry, con = conn)
    #print(df)
    #df.to_csv(os.getcwd() + "\\dw.csv", index = False)
    #print("success")
    
qry("SEVERITY>0")
    
    
def customize():
    print (conn.version)
    allactive = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    print(allactive)
    df = pd.read_sql(allactive, con = conn)
    print(df)
    df.to_csv(os.getcwd() + "\\dw.csv", index = False)
    
#timebetween("22-12-2020 01:00","22-12-2020 02:00")
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\TXX.py###


import pandas as pd
import numpy as np
from datetime import *
import os


dfdb = pd.read_csv(db)
df = pd.read_sql('select * from big5', con = conn)
df0 = df.rename(columns=str.upper)
    ls = text2list(semcol)
    df1 = df0[ls]
    dc = text2dic(cat)
    df1['cat'] = df1.apply(lambda x: getkey(dc, x.SUMMARY) , axis = 1)
    df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
    df2 = df1.merge(dfdb, on='Code')
x = datetime.now()
y = datetime.strftime(x, "%m-%d-%Y %H:%M:%S")
svpt = os.getcwd() + "\\OMDW.csv"
df = pd.read_csv(svpt)
df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'])
df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
df = df.assign(NW = y)
df['DUR'] = df.apply(lambda x : pd.to_datetime(x.NW) - pd.to_datetime(x.LASTOCCURRENCE) ,axis=1)
df['DUR'] = df['DUR'].astype('timedelta64[m]')
print(df)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\upin.py###
import pandas as pd
import numpy as np
import os
from df_to_sql.write2text import *


def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df


def qrybuilt(tbl, ndf, bycol, oncols = False):
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        for j in range(len(bycol)):
            x1 = str(bycol[j]) + "='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
            else:
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                else:
                    y = y + "," + a1 + '=' + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                    else:
                        y = y + "," + a1 + '=' + a2
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
    return lsqry

def CheckExist(conn , tbl, colname, values):
    qry = "select * from " + tbl + " where " + colname + "='" + values + "'"
    dfx = pd.read_sql(qry, conn)
    rw = dfx.shape[0]
    return rw

def get_key(my_dict, val):
    for value, key in my_dict.items():
        if value == val:
            return key

def modstr(strval):
    if isinstance(strval, str):
        s1 = strval.replace("'","\\'")
        s2 = s1.replace(":","\\:")
        return s2

def insert_into_sql(tbl, tbl_property, lscol, lsval):
    col = ''
    val = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list) and len(lscol) == len(lsval):
        for i in range(len(lscol)):
            valmod = ''
            try:
                if lsval[i] != '' and lsval[i] is not None:
                    dtype = get_key(dic,lscol[i])
                    if dtype == 'text' or dtype == 'varchar':
                        valmod = modstr(lsval[i])
                    else:
                        valmod = str(lsval[i])
                    if val == '':
                        col = lscol[i]
                        val = "'" + valmod + "'"
                    else:
                        col = col + ',' + lscol[i]
                        val = val + ',' + "'" + valmod + "'"
                else:
                    pass
            except:
                pass
        qry = "insert into " + tbl + " (" + col + ") values (" + val + ")"
        return qry
    else:
        return ""

def prep_update(tbl, tbl_property, lscol,lsval):
    hp = ''
    stval = ''
    dic = tbl_property
    if isinstance(lscol, list) and isinstance(lsval, list):
        if len(lscol) == len(lsval):
            for i in range(len(lscol)):
                try:
                    if lsval[i] is not None and lsval[i] !='':
                        dtype = get_key(dic,lscol[i])
                        if dtype == 'text' or dtype == 'varchar':
                            stval = modstr(lsval[i])
                        else:
                            stval = str(lsval[i])
                        x = lscol[i] + "='" + stval + "'"
                        if hp == '':
                            hp = x
                        else:
                            hp = hp + ',' + x
                    else:
                        pass
                except:
                    pass
        else:
            print('num of col and value are not same')
        return hp
    elif isinstance(lscol, str) and isinstance(lsval, str):
        hp = ""
        comma = lsval.count(',')
        invertcomma = lsval.count("'")
        if invertcomma == (comma+1)*2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            print(x1,x2)
            for i in range(len(x1)):
                x = x1[i] + "=" + x2[i]
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        if invertcomma <= 2:
            x1 = lscol.split(',')
            x2 = lsval.split(',')
            for i in range(len(x1)):
                x = str(x1[i]) + "='" + str(x2[i]) + "'"
                if hp == '':
                    hp = x
                else:
                    hp = hp + ',' + x
        return hp

def UPIN(df, tbl, tblproperty, conn, bycols, oncols = False, operations = "and"):
    cr = conn.cursor()
    er = 0
    lser = []
    if isinstance(bycols, list):
        xdf = None
        bydf = df[bycols]
        ndf = drop_cols(df, bycols)
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        for n in range(len(bycols)):
            fcols_pbycol.append(bycols[n])
        dfup = df[fcols_pbycol]
        x = ''
        #print(fcols, fcols_pbycol, len(fcols), len(fcols_pbycol))
        lsqry = []
        for i in range(len(df)):
            x = ''
            for j in range(len(bycols)):
                lss = bycols[j]
                lsv = df.loc[i,lss]
                st = str(lss) + "='" + str(lsv) + "'"
                if x == '':
                    x = st
                else:
                    x = x + " " + operation + " " + st
            qr = "select * from " + tbl + " where " + x
            dfx = pd.read_sql(qr, conn)
            rw = dfx.shape[0]
            ls = []
            if rw != 0:
                for n in range(len(fcols)):
                    ls.append(df.loc[i, fcols[n]])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + x
            else:
                for n in range(len(fcols_pbycol)):
                    ax = df.loc[i, fcols_pbycol[n]]
                    ls.append(ax)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            try:
                cr.execute(qry)
            except:
                lser.append(qry)
                er = er + 1
                print('error sql: ', qry)
                if er > 500:
                    wrt2txt(excmd, 'exe_error')
                    print('exiting as error greater than 500 rows')
                    exit()
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
    elif isinstance(bycols, str):
        xdf = None
        byc = df[bycols].values.tolist()
        ndf = drop_cols(df, [bycols])
        if oncols:
            xdf = ndf[oncols]
        else:
            xdf = ndf
        fcols = xdf.columns.to_list()
        fcols_pbycol = xdf.columns.to_list()
        fcols_pbycol.append(bycols)
        lsqry = []
        for i in range(len(byc)):
            condval = byc[i]
            rs = CheckExist(conn, tbl, bycols, condval)
            ls = []
            if rs != 0:
                for c1 in xdf:
                    ls.append(xdf.loc[i,c1])
                qry = "update " + tbl + ' set ' + prep_update(tbl, tblproperty, fcols,ls) + ' where ' + bycols + "='" + condval + "'"
            else:
                for c1 in ndf:
                    ls.append(ndf.loc[i,c1])
                ls.append(condval)
                qry = insert_into_sql(tbl, tblproperty , fcols_pbycol,ls)
            print(qry)
            cr.execute(qry)
            lsqry.append(qry)
        conn.commit()
        print('update done for ', len(lsqry), ' rows ')
        return lsqry
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbafn.py###
#import MySQLdb
import pandas as pd
import os
import numpy

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "RobiLive.csv"

class pyvb:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
    def PrintDf(self):
        print(self.df)
    def print_all_row_comm_seperated(self):
        lrw = (self.arr).shape[0]
        lcol = (self.arr).shape[1]
        i = 0
        hp = ''
        heap = ''
        while i < lrw:
            hp = ''
            j = 0
            while j < lcol:
                if hp == '':
                    hp = str(self.arr[i][j])
                else:
                    hp = hp + ', ' + str(self.arr[i][j])
                j = j + 1
            heap = heap + '\n' + str(hp)
            i = i + 1
        return heap
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
    def make_qry_str_sitecode(self,colname):
        lst = self.df[colname].to_list()
        hp = 0
        n = 0
        for i in lst:
            n = n + 1
            if n == 1:
                hp = "'" + i + "'"
            else:
                hp = hp + ',' + "'" + i + "'"
        return hp
    def vbprint_row_after_row(self, colinlist):
        hd = ''
        for x in colinlist:
            if hd == '':
                hd = x
            else:
                hd = hd + ', ' + x
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                count = count + 1
            if cnt == 0:
                heap = hd + '\n' + hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
        return heap
    def vbprint_col_comma(self, colinlist):
        ndf = self.df[colinlist]
        cnt = 0
        heap = ''
        for r in range(ndf.shape[0]):
            count = 0
            for c in range(ndf.shape[1]):
                if count == 0:
                    hp = str(ndf.iloc[r, c])
                else:
                    hp = hp + ', ' + str(ndf.iloc[r, c])
                    count = count + 1
            if cnt == 0:
                heap = hp
            else:
                heap = heap + '\n' + hp
            cnt = 1
            hp = ''
        print(heap)
        #dfc = pd.read_csv(file)
#dic = dfc.to_dict()

#mli = ['LastOccurrence', 'Tally','CustomAttr11']
#pv.Row_Item_From_List(9,mli)

#pv2 = pyvb(dic,mli)
#pv.PrintDf()
#pv2.PrintDf_ByList()
#gval = pv.MatchParse('DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
#print(gval)
#print(pv.VbMatch_Col('DHKTL04',3))
#print(pv.VbMatch_Row('CustomAttr15',0))
#pv.PrintLst()
#df = pd.read_csv(file)
#print(df)
#dic = df.to_dict()
#lst = ['Site Code','LTE Status','Priority']
#pv2 = pyvb(dic)
#print(pv2.print_all_row_comm_seperated())
#print(pv2.vbprint_row_after_row(lst))
#print(pv.make_qry_str('INTERNALLAST'))
#pv.make_qry_str(lst)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbcls1.py###
import pandas as pd
import numpy as np


class omdf:
    def __init__(self,dff):
        self.df = dff
        self.arr = self.df.to_numpy()
    def df_add_col_instr(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_add_col_dic(self,colname,newcol,dic):
        self.df[newcol] = self.df['scode'].map(dic)
        return self.df.to_dict()
    def df_add_col_slice_str(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_rmv_column(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()
    def df_countif(self,column_name,newcolumn_name):
        code = pd.Series(self.df[column_name])
        lst = code.values.tolist()
        dic = {}
        for i in lst:
            dic[i] = lst.count(i)
        df_occ = pd.DataFrame(dic.items(),columns=[column_name, newcolumn_name])
        mdf = self.df.merge(df_occ, on=column_name)
        return mdf
    def df_instr(self,colname,srcstr):
        self.df[srcstr] = list(map(lambda x: x.count(srcstr), self.df[colname]))
        return self.df
    def df_vlookup(self,df2,common_colname):
        mdf = self.df.merge(df2, on=common_colname)
        return mdf




class pyvb:
    def __init__(self, dic, li=[]):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = self.df[li]
    def PrintDf(self):
        print(self.df)
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbcntifs.py###
import pandas as pd
df = pd.DataFrame({
    'name_code': ['c001','c002','c022', 'c2002', 'c2222'],
    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],
    'age': [18.5, 21.2, 22.5, 22, 23]
})
print("Original DataFrame:")
print(df)
print("\nCount occurrence of 2 in date_of_birth column:")
df['count'] = list(map(lambda x: x.count("2"), df['name_code']))
print(df)


products = {'Product': ['Tablet','iPhone','Laptop','Monitor'],
            'Price': [250,800,1200,300]
            }

df = pd.DataFrame(products, columns= ['Product', 'Price'])

products_list = df.values.tolist()
print (products_list)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbdf.py###
import pandas as pd
import numpy as np
from dateutil.parser import *
from datetime import *
import time

def add_col_df(df, colname, colval=False, indx=False):
    if not indx:
        if not colval:
            ndf = df.assign (coln='NWC')
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
        else:
            ndf = df.assign (coln=colval)
            ndf.rename (columns={'coln': colname}, inplace=True)
            return ndf
    else:
        if colval == False:
            df.insert (indx, colname, 'NWC', allow_duplicates=False)
            return df
        else:
            df.insert (indx, colname, colval, allow_duplicates=False)
            return df

def conv_to_datetime(df1, col):
    df1[col] = pd.to_datetime (df1[col], errors='coerce')
    return df1

def pick_by_day(df1, day):
    df2 = df1[df1['LASTOCCURRENCE'].dt.day == d1]

def pick_except_year(df1, yr):
    df2 = df1[df1['CLEARTIMESTAMP'].dt.year != yr]
    return df2

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"

def instr(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.find(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.find(search_str)
        return x

def instrrev(main_str, search_str, start_position = False):
    if (start_position == False):
        x = main_str.rfind(search_str)
        return x
    else:
        ln = len(main_str) - start_position
        y = main_str[-ln:]
        x = y.rfind(search_str)
        return x

def duration(sec):
    time = float(sec)
    day = time // (24 * 3600)
    time = time % (24 * 3600)
    hour = time // 3600
    time %= 3600
    minutes = time // 60
    time %= 60
    seconds = time
    return "%d:%d:%d" % (hour + 24*day, minutes, seconds)

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            x = duration(abs(d1 - d2).total_seconds())
            return x
    except:
        return ""
    
    
def datediff_ondf(df1, newcolname, col1, col2=False):
    try:
        if col2 != False:
            df1 = conv_to_datetime (df1, col1)
            df1 = conv_to_datetime (df1, col2)
            df1 = pick_except_year (df1, 1970)
            df2 = add_col_df (df1, newcolname)
            df2[newcolname] = df2[col2] - df2[col1]
            df2[newcolname] = df2[newcolname].astype ('timedelta64[m]')
            return df2
        else:
            df1 = conv_to_datetime (df1, col1)
            df2 = add_col_df (df1, 'now', datetime.now ())
            df2 = conv_to_datetime (df2, 'now')
            df3 = add_col_df (df2, newcolname)
            df3[newcolname] = df3['now'] - df3[col1]
            df3[newcolname] = df3[newcolname].astype ('timedelta64[m]')
            df3.drop ('now', axis='columns', inplace=True)
            return df3
    except:
        print ("format like: datediff(df1,newcolname,colname,colname=False), it must not pd.core.series.Series")

def aplist(L1,L2):
    ls = []
    if isinstance(L1, pd.core.series.Series) and isinstance(L2, pd.core.series.Series):
        ls1 = L1.to_list()
        ls2 = L2.to_list()
        ls = [i + j for i, j in zip(ls1, ls2)]
    elif isinstance(L1, list) and isinstance(L2, list):
        ls = [i + j for i, j in zip(L1, L2)]
    elif isinstance(L1, pd.core.series.Series) and isinstance(L2, str):
        ls1 = L1.to_list()
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    elif isinstance(L1, list) and isinstance(L2, str):
        for i in range(len(ls1)):
            ni = str(ls1[i]) + L2
            ls.append(ni)
    else:
        print('arg1 can be list or pd.core.series.Series and arg2 can be string')
    return ls

def countifs(df0,*argv):
    df = df0
    rngmod = len(argv) % 2
    n = 0
    m = 0
    ls = []
    stst = ""
    pds_cnt = 0
    st_cnt = 0
    cnt = -1
    if len(argv) > 0:
        while n<len(argv):
            if isinstance(argv[n], pd.core.series.Series):
                pds_cnt = pds_cnt + 1
            elif isinstance(argv[n], str):
                st_cnt = st_cnt + 1
            else:
                xx = 'incorrect datatype, datatype can be "str" or "pd.core.series.Series" only'
                return xx
            n = n + 1
        n = 0
        if st_cnt != 0:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                elif isinstance(argv[n], str):
                    if stst == "":
                        stst = argv[n]
                    else:
                        stst = stst + argv[n]
                n = n + 1
            try:
                cnt = ls.count(stst)
            except:
                cnt = 0
        else:
            while n<len(argv):
                if isinstance(argv[n], pd.core.series.Series):
                    if len(ls) <= 1:
                        ls = argv[n].to_list()
                    else:
                        ls0 = argv[n].to_list()
                        ls1 = aplist(ls,ls0)
                        ls = ls1
                n = n + 1
            df1 = add_col_df(df,'NC1')
            df1['NC1'] = pd.Series(ls)
            df2 = df1.groupby(['NC1']).NC1.count().to_frame(name = 'cnt').reset_index()
            df = df1.merge(df2, on='NC1')
            df = df.drop('NC1', axis='columns')
        if cnt == -1:
            return df
        else:
            return cnt

def match(srcstr,list_as_range,start_from = False):
    try:
        if start_from == False or start_from == "First":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                return indices[0]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                return indices[0]
            else:
                return "none"
        elif start_from == "Last":
            if isinstance(list_as_range,list):
                indices = [i for i, x in enumerate(list_as_range) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            elif isinstance(list_as_range, pd.core.series.Series):
                col_range_list = list_as_range.values.tolist()
                indices = [i for i, x in enumerate(col_range_list) if x == srcstr]
                ln = len(indices)
                return indices[ln-1]
            else:
                return "none"
    except:
        return "NA"

def vlookup(lookup_str_or_df, ref_df_or_dict, ref_match_col_name, ref_pic_pick_col_name):
    if isinstance(lookup_str_or_df, pd.DataFrame):
        print("here")
        if isinstance(ref_df_or_dict,dict):
            lookup_str_or_df[ref_pic_pick_col_name] = lookup_str_or_df.reset_index()[ref_match_col_name].map(ref_df_or_dict).values
            return lookup_str_or_df
        else:
            df = ref_df_or_dict[[ref_match_col_name,ref_pic_pick_col_name]]
            print(df)
            ndf = lookup_str_or_df.merge(df, on=ref_match_col_name)
            return ndf                   
    if isinstance(lookup_str_or_df, str):
        try:
            if isinstance(ref_df_or_dict,dict):
                lsky = list(ref_df_or_dict.keys())
                lsval = list(ref_df_or_dict.values())
                indx = [i for i, x in enumerate(lsky) if x == lookup_str_or_df]
                return lsval[indx[0]]
            elif isinstance(ref_df_or_dict,pd.DataFrame):
                list_as_range = ref_df_or_dict[ref_match_col_name].values.tolist()
                pick_list = ref_df_or_dict[ref_pic_pick_col_name].values.tolist()
                indx = [i for i, x in enumerate(list_as_range) if x == lookup_str_or_df]
                return pick_list[indx[0]]
        except:
            return "none"


#print(match('n',df['column_1'],"Last"))
#d1 = "2020-11-06 13:05"
#d2 = "10-02-2020 11:05"
#nw = datetime.now()
#print(datediff('',d1,nw))
#a = "DHSDR01WC"
#print(instr(a,"SDR"))
#print(instr(a,"werqw", 1))
#print(vlookup(df,my_dict,"scode","state"))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbfn.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = "E:\\GIT\\OmProject\\OmPY\\omfn4\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]



def df_add_list_col(dfx,nc,nwlst):
    dfx[nc] = np.nan
    dfx[nwcol] = np.array(nwlst)
    return dfx

def vlookup(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        lst = df[dt_col1]
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        lst = df[dt_col1]
        clr = df[dt_col2]
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    df[nwcol] = np.nan
    df[nwcol] = np.array(ls)
    print('In Minutes')
    return df

def process_sem_raw(df):
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CUSTOMATTR15']
    LL2 = df1['LASTOCCURRENCE']
    LL3 = df1['CLEARTIMESTAMP']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    print(ndf3)

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , Ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(df, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(df,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs(df,refcol,numeric_col):
    df['agsum'] = df.groupby(refcol)[numeric_col].sum()
    return df
    #df['agsum'] = df.groupby('pet').treats.transform('sum')

def match(df,indx,typ):
    pass

df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
#print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
#print(asq)

sm = sumifs(asq,'CUSTOMATTR15','AG')
print(sm)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbfn1.py###
import pandas as pd
import numpy as np
import os
from datetime import *
pd.options.mode.chained_assignment = None  # default='warn'

pt = os.getcwd()
alarm = "E:\\GIT\\OmProject\\OmPY\\omfn4\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]



def df_add_list_col(dfx,nc,nwlst):
    dfx[nc] = np.nan
    dfx[nwcol] = np.array(nwlst)
    return dfx

def vlookup(df,refdic,refcol,nwcol):
    df[nwcol] = df.reset_index()[refcol].map(refdic).values
    return df

def str_cut(df,lst,newcolname,lft,rht):
    df.replace(r'^\s*$', 'UNK', regex=True)
    ls = list(map (lambda x: str(x[lft:rht]) if (len(str(x)) >= 6) else "NF", lst))
    df[newcolname] = np.nan
    df[newcolname] = np.array(ls)
    return df

def filter_e_3col(df,c1,c1val,c2,c2val,c3,c3val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val) & (df[c3]==c3val)]
    return df0
def filter_e_2col(df,c1,c1val,c2,c2val):
    df0 = df.loc[(df[c1]==c1val) & (df[c2]==c2val)]
    return df0
def filter_e_1col(df,c1,c1val):
    df0 = df.loc[(df[c1]==c1val)]
    return df0

def filter_p_ncol(ndf,refdic,oncolumn,newcol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    for i in range(len(df)):
        fnd = 0
        val = df.loc[i,oncolumn]
        for ky,vl in refdic.items():
            if ky in val:
                fnd = 1
                df.loc[i,newcol] = vl
                break
        if fnd == 0:
            df.loc[i,newcol] = "other"
    return df


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def cond_apply_list(lst,whichfn, clr = []):
    if whichfn == 'codecut':
        ls = list(map (lambda x: str(x[0:5]) if (len(str(x)) >= 6) else "NF", lst))
        return ls
    elif whichfn == 'agact':
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
        return ls
    elif whichfn == 'agclr':
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
        return ls

def datedif(ndf,nwcol,dt_col1,dt_col2 = False):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if dt_col2 == False:
        lst = df[dt_col1]
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lst))
    else:
        lst = df[dt_col1]
        clr = df[dt_col2]
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", clr,lst))
    df[nwcol] = np.nan
    df[nwcol] = np.array(ls)
    print('In Minutes')
    return df

def process_sem_raw(df):
    df1 = df[['SERIAL','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
    LL1 = df1['CUSTOMATTR15']
    LL2 = df1['LASTOCCURRENCE']
    LL3 = df1['CLEARTIMESTAMP']
    sc = cond_apply_list(LL1,'codecut')
    ag = cond_apply_list(LL2,'agact')
    agclr = cond_apply_list(LL2,'agclr',LL3)
    ndf1 = df_add_list_col(df1,'scode',sc)
    ndf2 = df_add_list_col(ndf1,'aging_now',ag)
    ndf3 = df_add_list_col(ndf2,'MTTR',ag)
    print(ndf3)

def countifs(ndf, c1 , ref1, c2 = False, ref2 = False, c3 = False , Ref3 = False):
    c = 1
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    if c2 != False:
        if c3 != False:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2) & (df[c3]==ref3)]
        else:
            df0 = df.loc[(df[c1]==ref1) & (df[c2]==ref2)]
    else:
        df0 = df.loc[(df[c1]==ref1)]
    return df0.shape[0]

def rmv_duplicates(df, list_of_columns):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.drop_duplicates(subset=list_of_columns)
    return df

def sorting(df,oncol):
    df = ndf.replace(r'^\s*$', np.nan, regex=True)
    df.sort_values(by=oncol, ascending=False)

def sumifs(df,refcol,numeric_col):
    df['agsum'] = df.groupby(refcol)[numeric_col].sum()
    return df
    #df['agsum'] = df.groupby('pet').treats.transform('sum')

def match(df,indx,typ):
    pass

df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3','IDENTIFIER']]
#xxx = str_cut(df1,df1['CUSTOMATTR15'],'shortcode',0,5)
lx = ['2G SITE','3G SITE']
dc = {'2G SITE':'2G','3G SITE':'3G'}
dc2 = {'HUW-2G SITE DOWN':"HW",'ERI-3G SITE DOWN':'ERI'}
#aq = filter_p(df1,lx,'SUMMARY')
#print(aq['SUMMARY'])
#aw = filter_p_ncol(df1,dc,'SUMMARY','cat')
#print(aw)
aqq = vlookup(df1,dc2,'SUMMARY','VLOOKUP')
print(aqq)
#print(aqq.loc[(aqq['VLOOKUP']=='ERI')])
#print(aqq.columns)
#x = df_add_col(df1,'scode','codecut')
#print(x)
#y = filter_e_2col(aqq,'SUMMARY','ERI-2G SITE DOWN','VLOOKUP','ERI',)
#x = countifs(aqq,'SUMMARY','ERI-3G SITE DOWN','VLOOKUP','ERI')
#print(y)
lst = ['SUMMARY','VLOOKUP']
za = aqq.drop_duplicates(subset=lst)
#print(za)

asq = datedif(df1,'AG','LASTOCCURRENCE')
#print(asq)

sm = sumifs(asq,'CUSTOMATTR15','AG')
print(sm)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbfn2.py###
import pandas as pd
import numpy as np

def join_list(ls1, ls2, ls3):
    ToDf = pd.DataFrame(zip(ls1, ls2, ls3))
    return ToDf

def add_col_df(df, colname, indx=False):
    if indx == False:
        ndf = df.assign(coln = 'NWC')
        ndf.rename(columns = {'coln': colname}, inplace = True)
        return ndf
    else:
        df.insert(indx, colname, 'NWC', allow_duplicates=False)
        return df

def conv_lst_dic(lsKy,lsVal):
    try:
        dc = dict(zip(lsKy, lsVal))
    except:
        print('err')
    return dc

def add_list_as_column(df,nlst):
    #ls = df.values.tolist()
    df = df.append(pd.DataFrame(nlst,columns=['col1','col2']),ignore_index=True)
    print(df)

def map_df_dic(df0,dc,onkey_col,newcolname):
    df = add_col_df(df0,newcolname)
    df[newcolname] = df[onkey_col].map(dc)
    return df

def vlookup(df0,refdic,refcol,nwcol):
    try:
        df = add_col_df(df0, nwcol)
        df[nwcol] = df.reset_index()[refcol].map(refdic).values
        return df
    except:
        df = map_df_dic(df0,refdic,refcol,nwcol)
        return df

def countif(df0,refcolumn,datacol,newcolname = False):
    if isinstance(refcolumn,str):
        df = add_col_df(df0, newcolname)
        rdf = df[refcolumn]
        reflst = rdf.values.tolist()
        vdf = df[datacol]
        nwlst = []
        for i in vdf:
            try:
                count = reflst.count(i)
                nwlst.append(count)
            except:
                nwlst.append('0')
    df[newcolname] = nwlst
    return df


l0 = ["0", "1", "2", "3", "4"]
l1 = ["Amar", "Barsha", "Barsha", "Tanmay", "Misbah"]
l2 = ["Alpha", "Bravo", "Charlie", "Tango", "Mike"]
l4 = [["Amar", "Barsha", "Carlos", "Tanmay", "Misbah"],["Alpha", "Bravo", "Charlie", "Tango", "Mike"]]
l5 = ['A','B','C','D','E']
l6 = ['DHK', 'RAJ', 'CTG', 'SYL', 'MYN']
l7 = [['DHK, P1'], ['DHK, P2'] , ['DHK, P3'] , ['DHK, P4'] , ['DHK, P5']]

df1 = join_list(l0, l1, l2)
df1.columns = ['1','2','3']
dc1 = conv_lst_dic(l0,l6)
#print(dc1)
dc2 = conv_lst_dic(l0,l7)
#print(dc2)
l8 = df1['1']
l9 = df1 [['2','3']]
l10 = l9.values.tolist()
dc3 = conv_lst_dic(l0,l7)
#print(dc3)
#print(df1)
df2 = pd.DataFrame(dc3)
#print(df2)

x = vlookup(df1,dc3,'1','TOTO')

#print(x)
ts = x['2']
lx = ts.values.tolist()
cnt = lx.count('Barsha')
#print(cnt)
x = countif(x,'2','2',"ONCOL2")
#p = add_col_df(df,'Test',1)
#add_list_as_column(df,l4)
#datatype_conversion = df['Customer Number'].astype('int')


def conct(a1,a2):
    ls = []
    strn = ""
    for i in range(len(a1)):
        strn = strn + str(a1[i]) + str(a2[i])
    return strn

def conct1(arg1,arg2):
    if isinstance(arg1, list) and isinstance(arg2, list):
        ls = []
        for i in range(arg1):
            ls.append(str([i]) + str(arg2[i]))
        return ls
    else:
        ag1 = arg1.values.tolist()
        ag2 = arg2.values.tolist()
        ls = []
        for i in range(ag1):
            ls.append(str([i]) + str(ag2[i]))
        return ls

def countifz(df,*argv):
    if isinstance(df,pd.DataFrame):
        if len(argv) % 2 != 0:
            print('need conditions for every ref range have')
        else:
            rng = len(argv) / 2
            i = 0
            j = 2
            A1 = ""
            B1 = ""
            X1 = []
            X2 = []
            while i < rng:
                if j > rng:
                    A1 = A1 + (df[argv[i]])
                    B1 = B1 + (df[argv[i+1]])
                    i = i + 2
                else:
                    A1 = A1 + (conct(df[argv[i]],df[argv[j]]))
                    B1 = B1 + (conct(df[argv[i+1]],df[argv[j+1]]))
                    i = i + 2
                    j = j + 2
                X1.append(A1)
                X2.append(B1)
            print(X1,X2)
    else:
        print('first parameter must be dataframe (full data range)')


countifz(x, '1', '1', '3', '3')




$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\vbt.py###
import pandas as pd
import numpy as np
import os
import func.fnfn as fn

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"

df = pd.read_csv(pt2)
#print(df.columns)
#df = df.assign(new_column = "NA") # column inserted at last, here new_column = column name and "NA" = rows value of new column

def concat(df, column_1, column_2, new_column_name):
    df = df.assign(new_column = "NA")
    df.rename(columns = {'new_column': new_column_name}, inplace = True)
    for i in range(len(df)):
        data_1 = df.loc[i,column_1]
        data_2 = df.loc[i,column_2]
        df.loc[i,new_column_name] = str(data_1) + str(data_2)
    return df

def countif(col_as_range,criteria):
    # col_as_range can be list or daraframe series
    if isinstance(col_as_range,list):
        count = col_as_range.count(criteria)
        return count
    elif isinstance(col_as_range, pd.core.series.Series):
        col_range_list = col_as_range.values.tolist()
        count = col_range_list.count(criteria)
        return count
    else:
        return "none"


print(countif(df['CUSTOMATTR15'],"FNCGL06"))



def countif_apply_on_col(df0,ref_col_as_range,ref_col_for_Cells):
    if isinstance(ref_col_as_range,str):
        df = df0.assign(coln = 'NA')
        rdf = df[ref_col_as_range]
        reflst = rdf.values.tolist()
        vdf = df[ref_col_for_Cells]
        nwlst = []
        for i in vdf:
            try:
                count = reflst.count(i)
                nwlst.append(count)
            except:
                nwlst.append('0')
    df['coln'] = nwlst
    return df

def datediff(unit,datetime1,datetime2):
    d1 = ""
    d2 = ""
    try:
        if isinstance(datetime1, str):
            d1 = parse(datetime1)
        elif isinstance(datetime1, datetime):
            d1 = datetime1
        if isinstance(datetime2, str):
            d2 = parse(datetime2)
        elif isinstance(datetime2, datetime):
            d2 = datetime2
        if unit == 'n':
            return round(abs((d1 - d2)).total_seconds()/60,3)
        elif unit == 'h':
            return round(abs((d1 - d2)).total_seconds()/3600,3)
        elif unit == 's':
            return round(abs((d1 - d2)).total_seconds(),3)
        elif unit == '':
            return abs(d1 - d2)
        elif len(unit)>3:
            x = abs(d1 - d2)
            print(x)
            try:
                return datetime.strftime(x,"%Y%M%d")
            except:
                return "format not appropriate"
    except:
        return "NA"


xx = countif_apply_on_col(df,'CUSTOMATTR15','CUSTOMATTR15')
print(xx)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\wait_handdle.py###
import time as tm
from datetime import *

ts= tm.time()
n = datetime.now()
td = date.today()

def wait_handdle(ex_time):
    Mn = int(n.strftime("%M"))
    if ex_time==55:
        if Mn>=55:
            wt = (60-Mn)*60
            print('Waiting for second: ', str(wt))
            tm.sleep(wt)
            return "EX"
        elif Mn >= 0 and Mn <= 15:
            return "EX"
        elif Mn >= 16 and Mn < 25:
            return "STOP"
        else:
            return "STOP"
    elif ex_time==25:
        if Mn>=25 and Mn<30:
            tm.sleep((30-Mn)*60)
            return "EX"
        elif Mn >= 30 and Mn <= 45:
            return "EX"
        elif Mn >= 45 and Mn < 55:
            return "STOP"
        else:
            return "STOP"
    else:
        return "EX"






$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinMain.py###
import sys
import os
import wmi
import subprocess

def ex(cmd):
    command = os.popen(cmd).read()
    return command
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinNetsh.py###
import subprocess

def ex(cmd):
    command = subprocess.popen(cmd).read()
    return command


def set_proxy(proxy_ip):
   print('x')







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinReg.py###
import subprocess
import os
import wmi



def addkey():


def editkey():
    
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WinWmi.py###
import os
import wmi
import winreg

ip = '173.0.54.190'
username = 'OMI'
password = '1q2w3eaz$'
from socket import *
#connection = wmi.WMI(ip, user=username, password=password)

r = wmi.WMI(ip, user=username, password=password).Registry()
result, names = r.EnumKey (hDefKey=0x80000001,sSubKeyName=r"Software")
for ky in names:
    print(ky)


def netsh_proxy(ip,port):
    x = "netsh winhttp set proxy " + ip + ':' + port
    os.system(x)

def addkey(ip,prt):
    x1 = "reg add 'HKCU\Software\Microsoft\Windows\CurrentVersion\Internet Settings / v ProxyEnable / t REG_DWORD / d 1'"
    x2 = "reg add 'HKCU\Software\Microsoft\Windows\CurrentVersion\Internet Settings /v ProxyServer /t REG_SZ /d '" + ip + ':' + prt

addkey('23.160.192.180','2016')
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\WMI_T.py###

#http://timgolden.me.uk/python/wmi/tutorial.html

import wmi
import os
import subprocess

def ex(cmd):
    command = os.popen(cmd).read()
    return command

def os_version():
    c = wmi.WMI()
    for os in c.Win32_OperatingSystem():
        print(os.Caption)
  
#x = os.system('ipconfig')
#os.system("netsh interface show interface")
#x = subprocess.call('netsh interface ipv4 show interface')
#y = ex('powershell "get-wmiobject win32_networkadapter | select netconnectionid, name, InterfaceIndex, netconnectionstatus"')
y = ex('powershell "Get-NetConnectionProfile"')


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\write2text.py###


import time, os
import datetime
from datetime import *

def tm():
    nw = datetime.now()
    thistm = nw.strftime("%Y%m%d_%H%M%S")
    return thistm

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        flpath = os.getcwd() + filename + '_' + tm() + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xdbfn_sem.py###
import pandas as pd
import cx_Oracle
import time as tmm
import os
from datetime import date
import win32com.client
import xdttm as odt

class omdb:
    def __init__(self):
        self.orc_con_str = "'SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd'"
        self.mssq_con_str = "'Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&'"
        self.cdir = os.getcwd() + '\\'
        self.today = date.today()
    def orc_all_active(self,tbl,selcol):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        tim1 = tmm.localtime()
        dy_p = odt.day_minus(7)
        dy_f = odt.day_plus(1)
        Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
        Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
        QF = "SELECT" + selcol + Q1 + Q2
        print(tmm.strftime("%H%M", tim1))
        print('----------------')
        print(QF)
        df = pd.read_sql(QF, con=conn)
        print('----------------')
        tim2 = tmm.localtime()
        print(df.shape[0])
        print(tmm.strftime("%H%M", tim2))
        df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
        df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
        df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
        dfmf = df[df['SUMMARY'].str.contains('MAIN')]
        dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
        dftmp = df[df['SUMMARY'].str.contains('TEMP')]
        dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
        dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
        df_cnct = [df2g, df3g, df4g, dfmf, dfdl, dftmp, dfcell, dfth]
        df_all = pd.concat(df_cnct)
        df_final = df_all.rename(columns={'EQUIPMENTKEY': 'Resource', 'CUSTOMATTR26': 'AssociatedCR',
                                          'CUSTOMATTR24': 'BCCH',
                                          'OWNERGID': 'Incident Owner',
                                          'EVENTID': 'Frequency',
                                          'TTREQUESTTIME': 'TT Creation Time'})
        dic = df_final.to_dict()
        conn.close()
        return dic
    def orc_qry_on_cond(self, tbl, cond, fdt, tdt):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        Q2 = "(LASTOCCURRENCE BETWEEN TO_DATE('" + fdt + "','DD-MM-RRRR') AND TO_DATE('" + tdt + "','DD-MM-RRRR'))"
        QF = "SELECT * from " + tbl + " WHERE " + cond + ' AND ' + Q2
        print(QF)
        tim1 = tmm.localtime()
        print(tmm.strftime("%H%M", tim1))
        print('----------------')
        df = pd.read_sql(QF, con=conn)
        tim2 = tmm.localtime()
        print(tmm.strftime("%H%M", tim2))
        print('----------------')
        dic = df.to_dict()
        conn.close()
        return dic
    def orc_qry_all_active(self, tbl, cond):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        qry1 = "Select * from " + tbl + " WHERE " + cond
        print(qry1)
        tim1 = tmm.localtime()
        print(tmm.strftime("%H%M", tim1))
        df = pd.read_sql(qry1, con=conn)
        tim2 = tmm.localtime()
        print(tmm.strftime("%H%M", tim2))
        print('----------------')
        dic = df.to_dict()
        conn.close()
        return dic

    def orc_qry_by_code(self,code):
        conn = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
        print(conn.version)
        qry1 = """Select * from (select distinct Summary AlarmText,(Case when Summary like '%2G%' then '2G' when 
        Summary like '%3G%' then '3G' else '4G' end) as Technology,CUSTOMATTR15 as SITECODE,FIRSTOCCURRENCE StartTime,ROUND((Sysdate-FIRSTOCCURRENCE)*24*60,2) DurationMIn,CLEARTIMESTAMP EndTime,CUSTOMATTR26 CRNumber,TTRequestTime, TTSequence, CUSTOMATTR23 as CI from alerts_status
        where FirstOccurrence between TO_DATE(TO_CHAR(SYSDATE - 7, 'YYYYMMDD') || '0000', 'YYYYMMDDHH24MI')  and TO_DATE(TO_CHAR(SYSDATE, 'YYYYMMDD') || '2359', 'YYYYMMDDHH24MI')
        and X733EventType = 100 and agent != 'Total Site Down'--and CUSTOMATTR15 != 'UNKNOWN'
        and Severity!= 0 and CustomAttr27 in (0,1) and Manager <> 'TSD Automation')t where t.Technology IN ('2G','3G','4G') and SITECODE like '%"""
        qry2 = qry1 + code + "%'"
        try:
            df = pd.read_sql(qry2, con=conn)
            print('try success')
        except:
            connx = cx_Oracle.connect('SOC_READ', 'soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
            df = pd.read_sql(qry2, con=connx)
            print('Except trigger')
        print(df)
        rows = df.shape[0]
        heap = code + ":"
        if rows != 0:
            for i in range(0, len(df)):
                tech = df.iloc[i]['TECHNOLOGY']
                tm = df.iloc[i]['STARTTIME']
                if '2G' in tech:
                    heap = heap + '\n' + "2G: Down, " + "Downtime: " + str(tm)
                if '3G' in tech:
                    heap = heap + '\n' + "3G: Down, " + "Downtime: " + str(tm)
                if '4G' in tech:
                    heap = heap + '\n' + "4G: Down, " + "Downtime: " + str(tm)
                # print(heap)
        else:
            return heap + '\nAll Tech are up'
        return heap


dy_from = odt.day_minus(3)
dy_to = odt.day_plus(1)
pth = os.getcwd() + '\\' + 'stcode.csv'
x = omdb()
#dc = x.orc_all_active('SEMHEDB.ALERTS_STATUS_V_FULL',' * ')
#dc = x.orc_all_active('SEMHEDB.ALERTS_STATUS',' * ')
cond1 = 'SEVERITY BETWEEN 1 AND 5 AND ALERTGROUP IN'
alrt_grp = """'SyntheticSiteDownAlarm','Processing Error Alarm:Cell Unavailable','Processing Error Alarm:NodeB Unavailable',
'Quality of Service Alarm:UMTS Cell Unavailable','Quality of Service Alarm:Local Cell Unusable','Processing Error Alarm:CSL Fault',
'Communication Alarm:OML Fault','Processing Error Alarm:GSM Cell out of Service','ET_PROCESSING_ERROR_ALARM','ET_QUALITY_OF_SERVICE_ALARM',
'ET_COMMUNICATIONS_ALARM','ET_EQUIPMENT_ALARM','Processing Error Alarm'"""
condition = cond1 + ' (' + alrt_grp + ')'
#dc = x.orc_qry_on_cond('SEMHEDB.ALERTS_STATUS',condition,dy_from,dy_to)
#df = pd.DataFrame(dc)
#df.to_csv(pth)

cond2 = "Summary IN ('2G SITE DOWN','3G SITE DOWN','4G SITE DOWN','MAINS FAIL','VOLTAGE','CELL DOWN') and Summary not like 'Synthetic_Fluc' and (Severity between 1 and 5) and Type=1"
cond3 = "Severity between 1 and 5 AND Summary IN ('2G SITE DOWN','3G SITE DOWN','4G SITE DOWN','HUW-MAINS FAILURE','HUW-DC VOLTAGE LOW','ERI-DC LOW VOLTAGE','ERI-AC MAINS FAILURE','ERI-AC MIANS FILT') and Summary not like 'Synthetic_Fluc'"
dc = x.orc_qry_all_active('SEMHEDB.ALERTS_STATUS',cond3)
#cd = "'DHSVRJ4','CGDMG39','NOSBC23'"
df = pd.DataFrame(dc)
print(df)
df.to_csv(pth)
#print(x.orc_qry_by_code('JPISL15'))
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xdttm.py###
import time
from datetime import *
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *

n = datetime.now()
td = date.today()

def Now():
    return n

def nw():
    nw_str = n.strftime("%Y-%m-%d %H:%M:%S")
    return nw_str

def min_plus(diff):
    d = n + timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def min_minus(diff):
    d = n - timedelta(minutes=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d


def hr_plus(diff):
    d = n + timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d

def hr_minus(diff):
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%Y-%m-%d %H:%M:%S")
    return str_d

def curr_day():
    return td.strftime('%d')

def curr_month():
    return td.strftime('%m')

def curr_year():
    return td.strftime('%Y')

def curr_date():
    return td.strftime('%Y-%m-%d')

def date_between(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2 = datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    return abs(d2 - d1).days


def aging(date1, date2):
    d1 = datetime.strptime(date1, "%Y-%m-%d %H:%M:%S")
    d2= datetime.strptime(date2, "%Y-%m-%d %H:%M:%S")
    mn = abs(d2 - d1)
    return mn


def deltamonth(dt, diff):
    dx = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
    delt = dx + relativedelta(months=diff)
    return delt


def day_minus(diff):
    d = td - timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d


def day_plus(diff):
    d = td + timedelta(days=diff)
    str_d = d.strftime("%d-%b-%Y")
    return str_d

# def date_str(dt):
# def fmt_to_datetime():
# def fmt_to_str():
# delta_month(nw(),-4)
# def month_delta(dt,diff):
# d1 = datetime.strptime(dt, "%Y-%m-%d %H:%M:%S")
# def day_delta(dt,diff):
# def date_minus(dt, diff):
# def month_minus(dt, diff):
# def year_minus(dt, diff):
# print(aging(nw(),'2020-06-13 00:00:00'))
# print(min_plus(500))
# print(min_minus(500))
# print(hr_plus(2))







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xlread.py###
import pandas as pd
from pandas import ExcelWriter
from pandas import ExcelFile
import os, sys
import argparse

parser = argparse.ArgumentParser(description='Script so useful.')

def read_csv_xls(pth, sht = None):
    df = ''
    if sht == None:
        df = pd.read_csv(pt)
    else:
        df = pd.read_excel(pt, sheet_name = sht)
    print(df)
    
args = parser.parse_args()
print(args)
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xmssq.py###
import pandas as pd
import pyodbc
import omfn.xdttm as odt
import omfn.vbafn as vbf
import requests

TOKEN = '1184517046:AAFBnQe_HRMx4ANWbebp8W8rzQMlRb07nG4'

def custom_msg_sender(chatid, msg):
    url = "https://api.telegram.org/bot" + TOKEN + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)


class mssq:
    def __init__(self):
        self.socdb = "Driver={SQL Server};SERVER=192.168.88.121;DATABASE=SOC_Roster;UID=sa;PWD=Robi456&"
        self.conx = pyodbc.connect(self.socdb)

    def check_existance_by_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        rw = df.shape[0]
        return rw

    def query_full_tbl(self, tbl):
        qry = "select * from " + tbl
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def insert_new_entry(self, tbl, colnames, values):
        qry = "insert into " + tbl + " (" + colnames + ") values (" + values + ")"
        print(qry)
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        print(rs)

    def apend_into(self, tbl, colname, value, refcolname, refvalue):
        qry1 = "select " + colname + " from " + tbl + " where " + refcolname + "='" + refvalue + "'"
        print(qry1)
        curs = self.conx.cursor()
        rsl = curs.execute(qry1)
        rs = rsl.fetchall()
        print(rs)
        vl = value
        qry = "UPDATE " + tbl + " SET " + colname + "='" + vl + "' WHERE " + refcolname + "='" + refvalue + "'"
        print(qry)
        rs2 = curs.execute(qry)
        print(rs2)

    def query_by_single_ref(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + "='" + value + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_by_double_ref(self, tbl, colname1, value1, colname2, value2):
        qry = "select * from " + tbl + " where " + colname1 + "='" + value1 + "' AND " + colname2 + "='" + value2 + "'"
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def query_string(self, tbl, colname, value):
        qry = "select * from " + tbl + " where " + colname + " like " + value
        print(qry)
        df = pd.read_sql(qry, self.conx)
        dic = df.to_dict()
        return dic

    def upd_by_ref(self, tbl, colnames, values, ref, refvalue):
        qry = "UPDATE " + tbl + " SET " + colnames + "='" + values + "' WHERE " + ref + "='" + refvalue + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'updated'
    def del_by_ref(self, tbl, colname, value):
        qry = "DELETE FROM " + tbl + " WHERE " + colname + "='" + value + "'"
        curs = self.conx.cursor()
        rs = curs.execute(qry)
        return 'deleted'
    def bot_usr_add(self, nam, uid, pas, msisdn):
        td = odt.Now()
        tday = td.strftime('%Y-%m-%d')
        print(tday)
        dt = td.strftime('%d')
        mn = td.strftime("%m")
        wkdy = td.strftime('%a')
        valu = ""
        ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
        print('psscode=', ps)
        if pas == ps or pas == '07085122':
            colnm = "NAME,UID,JOIN_DATE,MSISDN,Status,GroupEnabled,Special"
            valu = "'" + nam + "','" + uid + "','" + tday + "','" + msisdn + "','Y','N','N'"
            qry = "insert into om_socbot_access (" + colnm + ") values (" + valu + ")"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            print(rs)
            custom_msg_sender(uid, 'congrats, write help to the secrat to use me')
        else:
            custom_msg_sender(uid, 'you send wrong passcode')
        self.conx.close()
    def bot_usr_list(self, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = 'select * from om_socbot_access'
            df = pd.read_sql(qry, self.conx)
            dic = df.to_dict()
            x = vbf.pyvb(dic)
            return x.print_all_row_comm_seperated()

    def bot_usr_delete(self, sl, secrat):
        secr = "07085122"
        if secrat == secr or secrat == 'jahid1998':
            qry = "DELETE FROM om_socbot_access WHERE SL ='" + sl + "'"
            print(qry)
            curs = self.conx.cursor()
            rs = curs.execute(qry)
            return 'user deleted success'

    def bot_today_pass(self, secrat):
        if secrat == '07085122' or secrat == 'jahid1998':
            td = odt.Now()
            tday = td.strftime('%Y-%m-%d')
            print(tday)
            dt = td.strftime('%d')
            mn = td.strftime("%m")
            wkdy = td.strftime('%a')
            valu = ""
            ps = wkdy[2] + dt[0] + wkdy[1] + dt[1] + wkdy[0] + 'ao' + mn + 'io'
            return ps
        else:
            return 'unauthorized attempt'
    def auth_check_db(self, uid, qryfrom):
        df1 = pd.read_sql("select * from om_socbot_access", self.conx)
        df = df1[df1['UID'].str.contains(uid)]
        x = df.shape[0]
        if x == 0:
            return str(x)
        else:
            Status = df['Status'].iloc[0]
            special = df['Special'].iloc[0]
            if qryfrom != 'private' and special != 'Y':
                return 0
            elif qryfrom == 'private' and Status == 'Y':
                return '1'
            elif special == 'Y':
                return '1'


x = mssq()
# print(x.check_existance_by_ref('incident_tracker_v2','Incident_ID','INY00001138080'))
# df = pd.DataFrame(x.query_full_tbl('incident_tracker_v2'))
# x.bot_usr_delete('4','07085122')
print(x.bot_usr_list('07085122'))
#
# vl = ""
# x.insert_new_entry('om_socbot_access',colnm,vl)
# print(df)

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\xxtest.py###
import pandas as pd
import cx_Oracle, pyodbc, requests, os, time
from mysql import *
from sqlalchemy import create_engine
import OmSQ.omsqlfn as fn
import OmSQ.InsUpd as fni
from datetime import *
$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\zFluc.py###
import pandas as pd
import numpy as np
from datetime import *
import cx_Oracle

def cols():
    ls = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP',
          'CUSTOMATTR3','EventId','X733CorrNotif','X733EventType','X733ProbableCause','X733SpecificProb',
          'CorrelateTopologyKey','TTSequence','TTStatus','TTUpdate','TTUser','CustomAttr10','CustomAttr11',
          'CustomAttr12','CustomAttr13','CustomAttr5','CustomAttr26']
    hp = ''
    for i in range(len(ls)):
        if hp == '':
            hp = ls[i].upper()
        else:
            hp = hp + ',' + ls[i].upper()
    return hp


def last24hr():
    conn = cx_Oracle.connect('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    d1 = datetime.now() + timedelta(hours=-23)
    dtfrom = d1.strftime("%d-%m-%Y %H:00:00")
    d2 = datetime.now() + timedelta(hours=1)
    dtto = d2.strftime("%d-%m-%Y %H:00:00")
    st = cols()
    print(st)
    q0 = "SELECT " + cols() + " FROM SEMHEDB.ALERTS_STATUS WHERE SERIAL IN"
    q1 = "SELECT SERIAL FROM SEMHEDB.ALERTS_STATUS WHERE LASTOCCURRENCE BETWEEN TO_DATE('" + str(dtfrom) + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + str(dtto) + "','DD-MM-YYYY HH24:MI:SS')"
    q2 = "AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')"
    qry = q0 + '(' + q1 + " AND " + q2 + ')'
    print(qry)
    df = pd.read_sql(qry, con = conn)
    df.to_csv(os.getcwd() + "\\OMDW.csv")
    print(os.getcwd() + "\\OMDW.csv")

last24hr()

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Py1\zFluc0.py###
import pandas as pd
import numpy as np
from datetime import *
import cx_Oracle

def cols():
    ls = ['SERIAL','NODE','EQUIPMENTKEY','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP',
          'CUSTOMATTR3','EventId','X733CorrNotif','X733EventType','X733ProbableCause','X733SpecificProb',
          'CorrelateTopologyKey','TTSequence','TTStatus','TTUpdate','TTUser','CustomAttr10','CustomAttr11',
          'CustomAttr12','CustomAttr13','CustomAttr5','CustomAttr26']
    hp = ''
    for i in range(len(ls)):
        if hp == '':
            hp = ls[i].upper()
        else:
            hp = hp + ',' + ls[i].upper()
    return hp


def last24hr():
    conn = cx_Oracle.connect('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    d1 = datetime.now() + timedelta(hours=-23)
    dtfrom = d1.strftime("%d-%m-%Y %H:00:00")
    d2 = datetime.now() + timedelta(hours=1)
    dtto = d2.strftime("%d-%m-%Y %H:00:00")
    st = cols()
    print(st)
    q0 = "SELECT " + cols() + " FROM SEMHEDB.ALERTS_STATUS WHERE SERIAL IN"
    q1 = "SELECT SERIAL FROM SEMHEDB.ALERTS_STATUS WHERE LASTOCCURRENCE BETWEEN TO_DATE('" + str(dtfrom) + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + str(dtto) + "','DD-MM-YYYY HH24:MI:SS')"
    q2 = "AGENT IN ('U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP')"
    qry = q0 + '(' + q1 + " AND " + q2 + ')'
    print(qry)
    df = pd.read_sql(qry, con = conn)
    df.to_csv(os.getcwd() + "\\OMDW.csv")
    print(os.getcwd() + "\\OMDW.csv")

last24hr()

$$$$$$$$$


$$$$$$$$$

