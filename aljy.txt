

###d:\omEngin\Z_ALL_FILE\Jy1\10152020-21-XAQ-Untitled-checkpoint.txt###

$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\10152020-23-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1022020-549-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import numpy as np
import os
import MySQLdb
import csv

conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")

pt = os.getcwd()
proxy = pt + '\\hideme.csv'
db = pt + '\\ip2as.csv'

def add_col(dA,c):
    rw, col = dA.shape
    lst = []
    for i in range(rw):
        x = dA[i][c]
        y = x.rfind('.')
        s = x[0:y]
        lst.append(s)
    dA = np.append(dA, np.array([lst]).transpose(), axis=1)
    return dA

dpx = pd.read_csv(proxy,delimiter=';')
ddb = pd.read_csv(db)
dpx1 = dpx[['ip','port']]
dA = dpx1.to_numpy()
z = add_col(dA,0)
df1 = pd.DataFrame(z,columns=['ip','port','IPMOD'])
df = pd.read_sql("select * from ipasn10",conn)
fdf = df1.merge(df, on='IPMOD')
fdf.to_csv(pt + '\\merged.csv')
print(fdf)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1022020-550-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
import MySQLdb
import csv

conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")

pt = os.getcwd()
proxy = pt + '\\hideme.csv'
db = pt + '\\ip2as.csv'

def add_col(dA,c):
    rw, col = dA.shape
    lst = []
    for i in range(rw):
        x = dA[i][c]
        y = x.rfind('.')
        s = x[0:y]
        lst.append(s)
    dA = np.append(dA, np.array([lst]).transpose(), axis=1)
    return dA

dpx = pd.read_csv(proxy,delimiter=';')
ddb = pd.read_csv(db)
dpx1 = dpx[['ip','port']]
dA = dpx1.to_numpy()
z = add_col(dA,0)
df1 = pd.DataFrame(z,columns=['ip','port','IPMOD'])
df = pd.read_sql("select * from ipasn10",conn)
fdf = df1.merge(df, on='IPMOD')
fdf.to_csv(pt + '\\merged.csv')
print(fdf)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\10232020-2350-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


import pandas as pd
import numpy as np
import os
import func.fnsem as sem
import func.fndatetime as fdt
import db.db as sq
from datetime import *


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\10232020-2350-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


import pandas as pd
import numpy as np
import os
import func.fnsem as sem
import func.fndatetime as fdt
import db.db as sq
from datetime import *


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1062020-1023-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[16]:


import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result
    return result

def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)
            print('x')

def printField(ele, prefix):
    print (prefix, ":" , ele)


def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

def printall():
    pth = os.getcwd()
    print(pth)
    s1 = pth + '\\sample2.json'
    with open(s1, "r") as jsonFile:
            x = json.load(jsonFile)
            get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            printField(data[element], element)
            
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
#json_loop(data)

def prky(data):
    for key in data:
        print(key)
        #print(key, '->', data[key])

def Convert(lst):
    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}
    print(res_dct)        

nd1 = data['result']
d1 = dict.fromkeys(nd1[1] , 1)
d2 = { i : nd1[i] for i in range(0, len(nd1[1]) ) }
for i in range(len(nd1)):
    json_loop(nd1[i])


# In[11]:


print(x)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1062020-1025-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[22]:


import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result
    return result

def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)
            kk = jsonObject[ele],  prefix+"."+ele
            

def printField(ele, prefix):
    print (prefix, ":" , ele)


def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

def printall():
    pth = os.getcwd()
    print(pth)
    s1 = pth + '\\sample2.json'
    with open(s1, "r") as jsonFile:
            x = json.load(jsonFile)
            get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            printField(data[element], element)
            
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
#json_loop(data)

def prky(data):
    for key in data:
        print(key)
        #print(key, '->', data[key])

def Convert(lst):
    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}
    print(res_dct)        

nd1 = data['result']
d1 = dict.fromkeys(nd1[1] , 1)
d2 = { i : nd1[i] for i in range(0, len(nd1[1]) ) }
for i in range(len(nd1)):
    json_loop(nd1[i])


# In[11]:


print(x)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1062020-2353-XAQ-Untitled1-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[22]:


import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result
    return result

def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)
            kk = jsonObject[ele],  prefix+"."+ele
            

def printField(ele, prefix):
    print (prefix, ":" , ele)


def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

def printall():
    pth = os.getcwd()
    print(pth)
    s1 = pth + '\\sample2.json'
    with open(s1, "r") as jsonFile:
            x = json.load(jsonFile)
            get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            printField(data[element], element)
            
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
#json_loop(data)

def prky(data):
    for key in data:
        print(key)
        #print(key, '->', data[key])

def Convert(lst):
    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}
    print(res_dct)        

nd1 = data['result']
d1 = dict.fromkeys(nd1[1] , 1)
d2 = { i : nd1[i] for i in range(0, len(nd1[1]) ) }
for i in range(len(nd1)):
    json_loop(nd1[i])


# In[11]:


print(x)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1062020-2353-XAQ-Untitled1.txt###
#!/usr/bin/env python
# coding: utf-8

# In[22]:


import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result
    return result

def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)
            kk = jsonObject[ele],  prefix+"."+ele
            

def printField(ele, prefix):
    print (prefix, ":" , ele)


def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

def printall():
    pth = os.getcwd()
    print(pth)
    s1 = pth + '\\sample2.json'
    with open(s1, "r") as jsonFile:
            x = json.load(jsonFile)
            get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            printField(data[element], element)
            
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
#json_loop(data)

def prky(data):
    for key in data:
        print(key)
        #print(key, '->', data[key])

def Convert(lst):
    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}
    print(res_dct)        

nd1 = data['result']
d1 = dict.fromkeys(nd1[1] , 1)
d2 = { i : nd1[i] for i in range(0, len(nd1[1]) ) }
for i in range(len(nd1)):
    json_loop(nd1[i])


# In[11]:


print(x)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1072020-00-XAQ-Untitled-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[22]:


import json
import requests
import os

def find_from_dict(key, dictionary):
    for k, v in dictionary.iteritems():
        if k == key:
            yield v
        elif isinstance(v, dict):
            for result in find(key, v):
                yield result
        elif isinstance(v, list):
            for d in v:
                for result in find(key, d):
                    yield result
    return result

def checkList(ele, prefix):
    for i in range(len(ele)):
        if (isinstance(ele[i], list)):
            checkList(ele[i], prefix+"["+str(i)+"]")
        elif (isinstance(ele[i], str)):
            printField(ele[i], prefix+"["+str(i)+"]")
        else:
            checkDict(ele[i], prefix+"["+str(i)+"]")

def checkDict(jsonObject, prefix):
    for ele in jsonObject:
        if (isinstance(jsonObject[ele], dict)):
            checkDict(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], list)):
            checkList(jsonObject[ele], prefix+"."+ele)
        elif (isinstance(jsonObject[ele], str)):
            printField(jsonObject[ele],  prefix+"."+ele)
            kk = jsonObject[ele],  prefix+"."+ele
            

def printField(ele, prefix):
    print (prefix, ":" , ele)


def get_all_values(nested_dictionary):
    for key, value in nested_dictionary.items():
        if type(value) is dict:
            get_all_values(value)
        else:
            print(key, ":", value)

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])

def printall():
    pth = os.getcwd()
    print(pth)
    s1 = pth + '\\sample2.json'
    with open(s1, "r") as jsonFile:
            x = json.load(jsonFile)
            get_all_values(x)

def json_loop(data):
    for element in data: #If Json Field value is a Nested Json
        if (isinstance(data[element], dict)):
            checkDict(data[element], element)
        #If Json Field value is a list
        elif (isinstance(data[element], list)):
            checkList(data[element], element)
        #If Json Field value is a string
        elif (isinstance(data[element], str)):
            printField(data[element], element)
            
tele_sender = "https://api.telegram.org/bot1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js/getupdates"
response = requests.get(tele_sender)
data = response.json()
#json_loop(data)

def prky(data):
    for key in data:
        print(key)
        #print(key, '->', data[key])

def Convert(lst):
    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}
    print(res_dct)        

nd1 = data['result']
d1 = dict.fromkeys(nd1[1] , 1)
d2 = { i : nd1[i] for i in range(0, len(nd1[1]) ) }
for i in range(len(nd1)):
    json_loop(nd1[i])


# In[11]:


print(x)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1082020-128-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import os
import sqlite3

pt = os.getcwd()
alarm = pt + "\\C.csv"

df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]


con = sqlite3.connect('omdb.db')
def create_tbl():
    cr = con.cursor()
    cr.execute("CREATE TABLE hs(SERIAL,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP,CUSTOMATTR3)")
    con.commit()

def uoload_data(df1,dbname):
    df1.to_sql("'" + dbname + "'", con)

def delete_data(dbname):
    pass



def concat(v1,v2):
    z = str(v1) + '-' + str(v2)
    return z

CDCT = lambda x : x[:4] if (len(x) >= 6) else "NF"

def df_add_col(dff,nwcol,whichfn):
    df = dff.replace(r'^\s*$', np.NaN, regex=True)
    if whichfn == 'concat':
        for i in range(len(df)):
            df.loc[i,nwcol] = concat(df.loc[i,"CUSTOMATTR15"],df.loc[i,"SUMMARY"])
        return df
    elif whichfn == 'codecut':
        dfx = df.convert_dtypes()
        dfx = dfx.assign(scode = lambda x: CDCT(x.CUSTOMATTR15), axis=1)
        return dfx
    elif whichfn == 'datediff':
        df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].astype('datetime64[ns]')



x = df_add_col(df1,'scode','codecut')
print(x['scode'])





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1092020-1710-XAQ-Untitled1.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np

df = pd.DataFrame({'a': [1, 1, 5, 7, 1, 5, 1, 4, 7, 8, 9],
                   'b': [3, 5, 6, 2, 4, 6, 7, 8, 7, 8, 9]})

#print(df['a'].to_list())
#print(df['a'].value_counts())

df['count'] = df['a'].value_counts()
#df2 = df.replace(np.nan,0)
print(df)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1092020-80-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[8]:


import pandas as pd
import numpy as np
import os
import sqlite3

pt = os.getcwd()
alarm = pt + "\\C.csv"


def conv_2_list(ls1, ls2, ls3):
    ToDf = pd.DataFrame(zip(ls1, ls2, l3))
    print(Todf)
    

l0 = ["0", "1", "2", "3", "4"]
l1 = ["Amar", "Barsha", "Carlos", "Tanmay", "Misbah"] 
l2 = ["Alpha", "Bravo", "Charlie", "Tango", "Mike"] 
#conv_2_list(l0,l1,l2)


def concat(v1,v2):
    z = str(v1) + '-' + str(v2)
    return z

CDCT = lambda x : x[:4] if (len(x) >= 6) else "NF"

def df_add_col(dff,nwcol):
    df = dff.replace(r'^\s*$', np.NaN, regex=True)
    for i in range(len(df)):
        df.loc[i,nwcol] = concat(df.loc[i,"CUSTOMATTR15"],df.loc[i,"SUMMARY"])
    return df




df0 = pd.read_csv(alarm)
df1 = df0[['SERIAL','CUSTOMATTR15','SUMMARY','LASTOCCURRENCE','CLEARTIMESTAMP','CUSTOMATTR3']]
x = df_add_col(df1,'scode')
ls = x.columns.to_list()
print(ls)
#print(x)





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\12192020-1914-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[54]:


import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *

print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
df = pd.read_csv(os.getcwd() + "\\B1.csv")
nw = datetime.now()



TS1 = lambda x: '2' if ('2G SITE DOWN' in x)     else ('2' if ('2G CELL DOWN' in x)     else ('3' if ('3G SITE DOWN' in x)     else ('3' if ('3G CELL DOWN' in x)     else ('4' if ('4G SITE DOWN' in x)     else ('4' if ('4G CELL DOWN' in x)     else ('2' if ('OML' in x)     else "0"))))))

TS2 = lambda x: '2' if ('2G SITE DOWN' in x)     else ('22' if ('2G CELL DOWN' in x)     else ('3' if ('3G SITE DOWN' in x)     else ('33' if ('3G CELL DOWN' in x)     else ('4' if ('4G SITE DOWN' in x)     else ('44' if ('4G CELL DOWN' in x)     else ('2' if ('OML' in x)     else "0"))))))


DCAT = lambda x: 'H2' if (x < 300) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    df2.to_csv(os.getcwd() + "\\P3.csv", index = False)
    df3 = df2.drop_duplicates(subset=['CD_TM_CT2'], inplace=False, ignore_index=True)
    df3 = df3.reset_index()
    df4 = df3.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    df4 = df4.reset_index()
    df4.to_csv(os.getcwd() + "\\P5.csv", index = False)
    return df4

def Part2(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    #df.to_csv(os.getcwd() + "\\P6.csv", index = False)
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\"IAMPY".csv", index = False)
    #df['H12'] = df['H12'].fillna(0, inplace=True)
    #df['H2'] = df['H2'].fillna(0, inplace=True)
    print(df)
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    

#pvt = fdf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt', aggfunc='sum').reset_index()

fdf = extrafeat(df)
Part2(fdf)
#pvt(fdf)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1222020-1621-XAQ-AA-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import sys, os
import pandas as pd
import MySQLdb
from fnfn import *

livedb = os.getcwd() + "\\robi_live.csv"
db = os.getcwd() + "\\OMDB.csv"
semcol = os.getcwd() + "\\semcols.txt"
cat = os.getcwd() + "\\catdef.txt"
conn= MySQLdb.connect("localhost","root","admin","om2")

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df

def text2list(pth):
    f = open(pth, 'r+')
    ls = []
    for i in f.readlines():
        ls.append(i.replace('\n',''))
    return ls
    
def text2dic(pth):
    f = open(pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace('\n','')
        a2 = a1.split(':')
        dc[a2[0]] = a2[1]
    return dc
                      
def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items():
            if key in str(ky):
                return value
        else:
            return "other"

DURCAT = lambda x : '<2H' if (x < 120)                 else ('<12H' if (x < 240)                 else ('<24H' if (x < 360)                 ))
    

def part1():
    dfdb = pd.read_csv(db)
    df = pd.read_sql('select * from big5', con = conn)
    df0 = df.rename(columns=str.upper)
    ls = text2list(semcol)
    df1 = df0[ls]
    dc = text2dic(cat)
    df1['cat'] = df1.apply(lambda x: getkey(dc, x.SUMMARY) , axis = 1)
    df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
    df2 = df1.merge(dfdb, on='Code')
    df2['LASTOCCURRENCE'] = pd.to_datetime(df2['LASTOCCURRENCE'], errors='coerce')
    #df2['CLEARTIMESTAMP'] = pd.to_datetime(df2['CLEARTIMESTAMP'], errors='coerce')
    df2['DUR'] = df2.apply(lambda x : abs(datetime.now() - x['LASTOCCURRENCE']) ,axis=1)
    df2['DUR'] = df2['DUR'].astype('timedelta64[m]')
    df2['DURCAT'] = df2.apply(lambda x: DURCAT(x.DUR), axis = 1)
    xdf = df2[df2['cat'].isin(['2G','3G','4G']) & df2['DURCAT'].isin(['<2H','<12H'])]
    dfx1 = oFn1(xdf,['EQUIPMENTKEY','cat','DURCAT'], EQUIPMENTKEY='EQUIPMENTKEY', cat ='cat', DURCAT = '<2H')
    print(dfx1)
    dfx2 = oFn1(dfx1,['EQUIPMENTKEY','cat','DURCAT'], EQUIPMENTKEY='EQUIPMENTKEY', cat ='cat', DURCAT = '<12H')
    return dfx2


class sem:
    def __init__(self, ndf):
        self.mdf = ndf
        self.df = ndf
    def P1(self, df):
        print('x')
        
#svpt = os.getcwd() + "\\OMT.csv"
df = part1()
print(df)

def xx():
    xdf = df[df['cat'].isin(['2G','3G','4G']) & df['DURCAT'].isin(['<2H','<12H'])]
    xdf.to_csv()
    xdf = xdf.replace(np.nan, 0)
    df3 = xdf.groupby(['DURCAT','EQUIPMENTKEY']).DURCAT.count()
    df4 = df3.to_frame (name='AB').reset_index ()
    df5 = df4[(df4.DURCAT == '<2H') & (df4['AB'] > 1)]
    df6 = df4[(df4.DURCAT == '<12H')]
    print(df6)
#df4['NW'] = df4.apply(lambda x: x.DURCAT + x.AB, axis = 1)
#df5 = df4[df4['NW'].isin(['<12H10','<2H2'])]
#print(df4, df4.columns, df4.shape[0])
#for i in range(len(df4)):
    #print(df4.loc[i, 'EQUIPMENTKEY'])



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1222020-1621-XAQ-AA.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import sys, os
import pandas as pd
import MySQLdb
from fnfn import *

livedb = os.getcwd() + "\\robi_live.csv"
db = os.getcwd() + "\\OMDB.csv"
semcol = os.getcwd() + "\\semcols.txt"
cat = os.getcwd() + "\\catdef.txt"
conn= MySQLdb.connect("localhost","root","admin","om2")

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df

def text2list(pth):
    f = open(pth, 'r+')
    ls = []
    for i in f.readlines():
        ls.append(i.replace('\n',''))
    return ls
    
def text2dic(pth):
    f = open(pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace('\n','')
        a2 = a1.split(':')
        dc[a2[0]] = a2[1]
    return dc
                      
def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items():
            if key in str(ky):
                return value
        else:
            return "other"

DURCAT = lambda x : '<2H' if (x < 120)                 else ('<12H' if (x < 240)                 else ('<24H' if (x < 360)                 ))
    

def part1():
    dfdb = pd.read_csv(db)
    df = pd.read_sql('select * from big5', con = conn)
    df0 = df.rename(columns=str.upper)
    ls = text2list(semcol)
    df1 = df0[ls]
    dc = text2dic(cat)
    df1['cat'] = df1.apply(lambda x: getkey(dc, x.SUMMARY) , axis = 1)
    df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
    df2 = df1.merge(dfdb, on='Code')
    df2['LASTOCCURRENCE'] = pd.to_datetime(df2['LASTOCCURRENCE'], errors='coerce')
    #df2['CLEARTIMESTAMP'] = pd.to_datetime(df2['CLEARTIMESTAMP'], errors='coerce')
    df2['DUR'] = df2.apply(lambda x : abs(datetime.now() - x['LASTOCCURRENCE']) ,axis=1)
    df2['DUR'] = df2['DUR'].astype('timedelta64[m]')
    df2['DURCAT'] = df2.apply(lambda x: DURCAT(x.DUR), axis = 1)
    xdf = df2[df2['cat'].isin(['2G','3G','4G']) & df2['DURCAT'].isin(['<2H','<12H'])]
    dfx1 = oFn1(xdf,['EQUIPMENTKEY','cat','DURCAT'], EQUIPMENTKEY='EQUIPMENTKEY', cat ='cat', DURCAT = '<2H')
    print(dfx1)
    dfx2 = oFn1(dfx1,['EQUIPMENTKEY','cat','DURCAT'], EQUIPMENTKEY='EQUIPMENTKEY', cat ='cat', DURCAT = '<12H')
    return dfx2


class sem:
    def __init__(self, ndf):
        self.mdf = ndf
        self.df = ndf
    def P1(self, df):
        print('x')
        
#svpt = os.getcwd() + "\\OMT.csv"
df = part1()
print(df)

def xx():
    xdf = df[df['cat'].isin(['2G','3G','4G']) & df['DURCAT'].isin(['<2H','<12H'])]
    xdf.to_csv()
    xdf = xdf.replace(np.nan, 0)
    df3 = xdf.groupby(['DURCAT','EQUIPMENTKEY']).DURCAT.count()
    df4 = df3.to_frame (name='AB').reset_index ()
    df5 = df4[(df4.DURCAT == '<2H') & (df4['AB'] > 1)]
    df6 = df4[(df4.DURCAT == '<12H')]
    print(df6)
#df4['NW'] = df4.apply(lambda x: x.DURCAT + x.AB, axis = 1)
#df5 = df4[df4['NW'].isin(['<12H10','<2H2'])]
#print(df4, df4.columns, df4.shape[0])
#for i in range(len(df4)):
    #print(df4.loc[i, 'EQUIPMENTKEY'])



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\12232020-1844-XAQ-Untitled1.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
from saymyname import *
from oDT import *
import os

def cols():
    fp = open(os.getcwd() + "\\csv\\col.txt")
    tx = fp.read()
    fp.close()
    return tx.split("\n")

def csv_mini():
    ls = cols()
    df = pd.read_csv(os.getcwd() + "\\csv\\OMTX1.csv", low_memory=False)
    df1 = df[ls]
    df1.to_csv(os.getcwd() + "\\csv\\OMTX_M.csv", index = False)

    
df = pd.read_csv(os.getcwd() + "\\csv\\OMTX_M.csv", low_memory=False)
print(df)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\12232020-1846-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[39]:


import pandas as pd
import os

#opt = itertools.islice(ls, len(ls))
#st = map(lambda x : )

def parsecode(txt):
    df = pd.read_csv(os.getcwd() + '\\OMDB.csv')
    ls = df['Code'].to_list()
    code = []
    q = 0
    for i in range(len(ls)):
        text = txt
        if ls[i] in text:
            n = text.find(ls[i])
            st = text[n:n+7]
            code.append(st)
            txt = txt.replace(ls[i],'')
            q = q + 1
    else:
        if q == 0:
            return ''
        else:
            return code
        
def qry_by_code(code, tbl = None, col = None):
    if tbl is None and col is None:
        a1 = "select Incident_Notification,Down_Time,Up_Time,Major_Cause,Action_Taken,Link_ID_Site_ID,Incident_ID from omdb.inc_tracker_mysql where ("
        a2 = " No_of_2G_Impacted_sites Like '%" + code + "%' or No_of_3G_Impacted_sites like '%" + code + "%' or No_of_4G_Impacted_Sites like '%" + code + "%' or Incident_Notification Like '%" + code 
        a3 = "%') order by Down_Time desc"
        aa = a1 + a2 + a3
        return aa
    else:
        return ""
            
a = "sevear problem found at and nobgm07 due to hartal."
rs = parsecode(a.upper())
print('ret val', rs)
if len(rs) == 1:
    code = rs[0]
    try:
        cd = int(code[6:7])
        qry = qry_by_code(code)
        conn = conn_brocker()
        df = pd.read(qry, con = conn)
        if df.shape[0] != 0:
            rn = 0
            st = ""
            if df.shape[0] > 3:
                st = "last 3 incident out of " + df.shape[0]
                rn = 3
            else:
                st = "incident found " + df.shape[0] + chr(10)
                rn = df.shape[0]
            for i in range(rn):
                tmp = chr(10)
                for j in df:
                    tmp = tmp + chr(10) + df.loc[i,j]
                else:
                    st = st + chr(10) + str(i) + tmp
            else:
                return st
        else:
            return 0
    except:
        print('not code')
    
    


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1232020-2235-XAQ-Untitled1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import MySQLdb, os, pyodbc
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fluctuation as fl


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

pt = os.getcwd() + "\\"
df = pd.read_csv(pt + 'SEMQRY.csv')
#print(df)
#df = semqry()
#df = df.astype (str)
#print(df.dtypes)
#xxx = main(df)
df = df.astype (str)
df1 = fl.catmap_mod(df)
df1.columns
df2 = filter_p(df1, ['2G', '3G', '4G'], 'CATX')
df3 = filter_p(df1, ['other'], 'CATX')     


# In[ ]:





# In[4]:


df2


# In[3]:


df3


# In[5]:


df4 = filter_p(df2, ['other'], 'CAT')


# In[6]:


df4


# In[7]:


df2


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1232020-2245-XAQ-Untitled2-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import time as tm
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        nx = datetime.now()
        flpath = os.getcwd() + filename + '_' + nx.strftime("%H%M%S") + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120)     else ('H12' if (x < 720)    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x)     else ('2G' if ('2G CELL DOWN' in x)     else ('3G' if ('3G SITE DOWN' in x)     else ('3G' if ('3G CELL DOWN' in x)     else ('4G' if ('4G SITE DOWN' in x)     else ('4G' if ('4G CELL DOWN' in x)     else ('2G' if ('OML' in x)     else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    return odf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    return xdf
    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    try:
        q = tmsg(msk, "SITE " + GG2)
        q = tmsg (msk, "CELL " + GG2C)
        q = tmsg (msk, "SITE " + GG3)
        q = tmsg (msk, "CELL " + GG3C)
        q = tmsg (msk, "SITE " + GG4)
        q = tmsg (msk, "CELL " + GG4C)
    except:
        wrt2txt(GG2)
        tm.sleep(1)
        wrt2txt(GG2C)
        tm.sleep(1)
        wrt2txt(GG3)
    print('done')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
df = semqry()
main(df)




# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1232020-2259-XAQ-Untitled1.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import MySQLdb, os, pyodbc
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *
import fluctuation as fl


def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

pt = os.getcwd() + "\\"
df = pd.read_csv(pt + 'SEMQRY.csv')
#print(df)
#df = semqry()
#df = df.astype (str)
#print(df.dtypes)
#xxx = main(df)
df = df.astype (str)
df1 = fl.catmap_mod(df)
df1.columns
df2 = filter_p(df1, ['2G', '3G', '4G'], 'CATX')
df3 = filter_p(df1, ['other'], 'CATX')


# In[ ]:





# In[4]:


df2


# In[3]:


df3


# In[5]:


df4 = filter_p(df2, ['other'], 'CAT')


# In[6]:


df4


# In[7]:


df2


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1232020-2321-XAQ-Untitled2.py###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


import time as tm
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        nx = datetime.now()
        flpath = os.getcwd() + filename + '_' + nx.strftime("%H%M%S") + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120)     else ('H12' if (x < 720)    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x)     else ('2G' if ('2G CELL DOWN' in x)     else ('3G' if ('3G SITE DOWN' in x)     else ('3G' if ('3G CELL DOWN' in x)     else ('4G' if ('4G SITE DOWN' in x)     else ('4G' if ('4G CELL DOWN' in x)     else ('2G' if ('OML' in x)     else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    return odf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    return xdf
    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    try:
        q = tmsg(msk, "SITE " + GG2)
        q = tmsg (msk, "CELL " + GG2C)
        q = tmsg (msk, "SITE " + GG3)
        q = tmsg (msk, "CELL " + GG3C)
        q = tmsg (msk, "SITE " + GG4)
        q = tmsg (msk, "CELL " + GG4C)
    except:
        wrt2txt(GG2)
        tm.sleep(1)
        wrt2txt(GG2C)
        tm.sleep(1)
        wrt2txt(GG3)
    print('done')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
df = semqry()
main(df)




# In[ ]:






$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1242020-180-XAQ-Untitled-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


import time as tm
import os, cx_Oracle
from datetime import *
import requests
import MySQLdb
import numpy as np
import pandas as pd
from fn import *
from oDT import *

livedb = os.getcwd () + "\\robi_live.csv"
db = os.getcwd () + "\\OMDB.csv"
semcol = os.getcwd () + "\\semcols.txt"
CAT = os.getcwd () + "\\CATdef.txt"
try:
    mysqlconn = MySQLdb.connect ("localhost", "root", "admin", "om2")
except:
    mysqlconn = ""


n = datetime.now ()
tm = n.strftime("%H:%M") + " on " + n.strftime ("%m-%d-%Y")

def wrt2txt(contents, filename = 'excmd', flpath = None):
    if flpath == None:
        nx = datetime.now()
        flpath = os.getcwd() + filename + '_' + nx.strftime("%H%M%S") + '.txt'
    content = "executed commands"
    if isinstance(contents, list):
        for i in range(len(contents)):
            content = content + chr(10) + contents[i]
    else:
        content = contents
    try:
        f = open(flpath, 'w+')
        f.write(content)
        f.close()
        print('print from wrt2txt, *success*', flpath, chr(10))
    except:
        lastslash = flpath.rfind('\\')
        flname = flpath[-lastslash :len(flpath)-4]
        print(flname)
        os.system("taskkill /F /FI '"+ flname + "' /T")
        time.sleep(2)
        try:
            f = open(flpath, 'w+')
            f.write(content)
            f.close()
            print('print from wrt2txt, *success*', flpath, chr(10))
        except:
            print('def wrt2txt *failed* ', flpath, chr(10))

def tmsg(chatid,msg):
    TOK = "1176189570:AAEfPi9TIZIbnhWi4Ko6KQev2Iv7UbMw5js"
    url = "https://api.telegram.org/bot" + TOK + "/sendMessage?chat_id=" + str(chatid) + "&text=" + msg
    requests.get(url)
    return ""

def hr_minus(diff):
    x = datetime.now ()
    d = x - timedelta (hours=diff)
    str_d = d.strftime ("%m-%d-%Y %H:%M:%S")
    return str_d

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def semqry():
    conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print (conn.version)
    agent = ['U2000 TX','Ericsson OSS','EricssonOSS','Huawei U2000 vEPC','Huawei U2020','LTE_BR1_5','MV36-PFM3-MIB','BusinessRule14','BusinessRule14_ERI_ABIP']
    cols = "SERIAL,NODE,AGENT,ALERTGROUP,SEVERITY,LOCALSECOBJ,X733EVENTTYPE,X733SPECIFICPROB,MANAGEDOBJCLASS,GEOINFO,CUSTOMATTR3,CUSTOMATTR5,CUSTOMATTR25,TTSEQUENCE,TTSTATUS,SRCDOMAIN,CUSTOMATTR26,OUTAGEDURATION,TALLY,ALARMDETAILS,EQUIPMENTKEY,CUSTOMATTR15,SUMMARY,LASTOCCURRENCE,CLEARTIMESTAMP"
    q1 = "SELECT " +  cols + " FROM SEMHEDB.ALERTS_STATUS WHERE "
    STDT = timedelt(-22)
    ENDT = timedelt(1)
    q2 = "LASTOCCURRENCE BETWEEN TO_DATE('" + STDT + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" + ENDT + "','DD-MM-YYYY HH24:MI:SS')"
    q3 = q1 + q2
    print(q3)
    print('starts: ', datetime.now())
    df = pd.read_sql(q3, con=conn)
    df.to_csv(os.getcwd () + "\\SEMQRY.csv")
    print ('ends: ', datetime.now())
    print(df.shape[0])
    print(df.columns)
    df1 = df[df['AGENT'].isin([agent])]
    print (df.shape[0])
    print(os.getcwd () + "\\SEMQRY.csv")
    return df1

def filter_p(df,reflst,oncolumn):
    i = 0
    dfx = pd.DataFrame([])
    rw = 0
    for k in reflst:
        i = i + 1
        ndf = df[df[oncolumn].str.contains(k)]
        rw = ndf.shape[0]
        if rw >= 2:
            if i == 1:
                dfx = ndf
            else:
                dfy = pd.concat([dfx,ndf])
                dfx = dfy
                dfy = pd.DataFrame([])
    else:
        return dfx

def text2list(pth):
    f = open (pth, 'r+')
    ls = []
    for i in f.readlines ():
        ls.append (i.replace ('\n', ''))
    return ls


def text2dic(pth):
    f = open (pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace ('\n', '')
        a2 = a1.split (':')
        dc[a2[0]] = a2[1]
    return dc


def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return "other"


DRCAT = lambda x: 'H2' if (x < 120)     else ('H12' if (x < 720)    else ('H24'))

TS = lambda x: '2G' if ('2G SITE DOWN' in x)     else ('2G' if ('2G CELL DOWN' in x)     else ('3G' if ('3G SITE DOWN' in x)     else ('3G' if ('3G CELL DOWN' in x)     else ('4G' if ('4G SITE DOWN' in x)     else ('4G' if ('4G CELL DOWN' in x)     else ('2G' if ('OML' in x)     else "other"))))))


def extrafeat(xdf, tmdelta = 0):
    xdf = xdf.rename (columns=str.upper)
    df = xdf.assign (DURCAT='0')
    df = df.assign (LO='0')
    df = df.assign (CDLO='0')
    df = df.assign (CDLOTECH='0')
    df['DURCAT'] = df.apply (lambda x: DRCAT (x.DUR), axis=1)
    df['LO'] = df.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%d%m%y%H%M"), axis=1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat (df['LO'])
    df['CDLOTECH'] = df['CDLO'].str.cat (df['CATX'])
    print('done duration')
    return df

def prob(df):
    xdf = filter_p(df, ['2G', '3G', '4G'], 'CATX')
    ndf = countifs(xdf, xdf['CUSTOMATTR15'], xdf['CUSTOMATTR15'], xdf['DURCAT'], xdf['DURCAT'])
    odf = countifs(ndf, xdf['EQUIPMENTKEY'], xdf['EQUIPMENTKEY'], xdf['DURCAT'], xdf['DURCAT'])
    print(odf.shape[0])
    try:
        odf.to_csv (os.getcwd () + "\\FINAL12.csv", index=False)
    except:
        odf.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    print('final', odf.shape[0])
    return odf

def catmap_mod(df):
    print("strart operation..............")
    dfdb1 = pd.read_csv (db)
    dfdb = dfdb1[['Code', 'Zone']]
    df0 = df.rename (columns=str.upper)
    ls = text2list (semcol)
    df1 = df0[ls]
    dc = text2dic (CAT)
    df1 = df1.assign (CAT='0')
    df1 = df1.assign (CATX='0')
    df1 = df1.assign (Code='0')
    df1['CAT'] = df1.apply (lambda x: getkey (dc, x.SUMMARY), axis=1)
    df1['CATX'] = df1.apply (lambda x: TS (x.SUMMARY), axis=1)
    df1['Code'] = df1.apply (lambda x: x.CUSTOMATTR15[0:5], axis=1)
    df2 = df1.merge (dfdb, on='Code')
    try:
        df3 = DateDiff(df2, "DUR", "LASTOCCURRENCE")
    except:
        df3 = datediff_ondf(df2, "DUR", 'LASTOCCURRENCE')
    df3.to_csv(os.getcwd () + "\\FINAL11.csv", index=False)
    df4 = extrafeat(df3)
    xdf = df4.replace (np.nan, 0)
    return xdf
    

def sort_rvmdup(df):
    df1 = df.sort_values(by=['CAT','CDLO'], ascending=True)
    df1 = df1.drop_duplicates(subset=['CDLOTECH'], inplace=False, ignore_index=True)
    df1.to_csv (os.getcwd () + "\\FINAL13.csv", index=False)
    #df2 = df1.groupby(['DURCAT','EQUIPMENTKEY','CAT'])['CUSTOMATTR15'].count()
    pvt = df1.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt_x', aggfunc='sum').reset_index()
    ndf = pvt[(pvt['H2'] > 2) & (pvt['H12'] > 10)]
    return ndf

def fmtmsg_techwise(ndf, name_thread_col, ls_datacol, name_catcol, cat_text):
    lss = []
    hpx = ""
    colx = ndf.columns.to_list()
    print(colx)
    df = ndf[["CUSTOMATTR15","CAT","H2","H12"]]
    for n in range(len(df)):
        cat = df.iloc[n, 1]
        if str(cat) == cat_text:
            try:
                code = df.iloc[n, 0] + ": " + str(df.iloc[n, 2]) + " | " + str(df.iloc[n, 3])
                lss.append(code)
                hpx = hpx + chr(10) + code
            except:
                pass
        else:
            pass
    print(lss)
    return hpx
        

def main(df):
    ls = ['H2', 'H12']
    df = df.astype (str)
    df1 = catmap_mod(df)
    df1 = df1.astype (str)
    df0 = prob(df1)
    df2 = sort_rvmdup(df0)
    print('2')
    df2.to_csv(os.getcwd () + "\\pvt.csv", index = False)
    df2 = pd.read_csv(os.getcwd () + "\\pvt.csv")
    df2 = df2.astype (str)
    print(df2.dtypes)
    G2 = "2G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '2') + chr (10) + chr (10)
    G2CELL = "2G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '22') + chr (10) + chr (10)
    G3 = "3G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '3') + chr (10) + chr (10)
    G3CELL = "3G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '33') + chr (10) + chr (10)
    G4 = "4G:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '4') + chr (10) + chr (10)
    G4CELL = "4G CELL:" + chr (10) + fmtmsg_techwise (df2, 'CUSTOMATTR15', ['H2', 'H12'], 'CAT', '44') + chr (10) + chr (10)
    HD1 = "FLUCTUATION STATUS" + chr (10) + "at " + tm + chr (10) + chr (10)
    HD2 = "Code : 2Hr | H12r" + chr (10) + chr (10)
    TR1 = "Note: sites fluctuates >10 times in last 2hr and fluctuations found in last H12r"
    GG2 = "2G " + HD1 + HD2 + G2 + TR1
    GG2C = "2G CELL" + HD1 + HD2 + G2CELL + TR1
    msk = '-407548960'
    GG3 = "3G " + HD1 + HD2 + G3 + TR1
    GG3C = "3G CELL" + HD1 + HD2 + G3CELL + TR1
    GG4 = "4G " + HD1 + HD2 + G4 + TR1
    GG4C = "4G CELL" + HD1 + HD2 + G4CELL + TR1
    try:
        q = tmsg(msk, "SITE " + GG2)
        q = tmsg (msk, "CELL " + GG2C)
        q = tmsg (msk, "SITE " + GG3)
        q = tmsg (msk, "CELL " + GG3C)
        q = tmsg (msk, "SITE " + GG4)
        q = tmsg (msk, "CELL " + GG4C)
    except:
        wrt2txt(GG2)
        tm.sleep(1)
        wrt2txt(GG2C)
        tm.sleep(1)
        wrt2txt(GG3)
    print('done')

print(os.getcwd())
#svpt = os.getcwd () + "\\SEMQRY.csv"
#df = pd.read_csv (svpt, low_memory=False)
df = semqry()
main(df)




# In[ ]:






$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1252020-1912-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
from fn import *
import os


def d_diff(ls1, ls2):
    #serialize and convert using dateutil.parser and datetime.strftime
    if len(ls1) == len(ls2):
        lss = []
        for i in range(len(ls1)):
            try:
                dt1 = parse(str(ls1[i]))
                dt2 = parse(str(ls2[i]))
                if '1970' not in ls2[i]):
                    diff = (dt2 - dt1)
                    lss.append(diff)
                else:
                    diff = (datetime.now() - dt1)
                    lss.append(diff)
            except:
                lss.append('')
        else:
            return lss

diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def makelist_dttm_now(ln):
    nw = datetime.now()
    st = nw.strftime("%d/%m/%Y %H:%M")
    ls = []
    for i in range(ln):
        ls.append(st)
    return ls

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls
        

def DateDif(DT1, DT2 = None):
    TM1 = formatchk(DT1)
    if DT2 is None:
        TM2 = makelist_dttm_now(len(DT1))
    else:
        TM2 = formatchk(DT2)
    try:
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM1, TM2))
        return dur
    except:
        TM11 = datetime_re_format(TM1)
        TM22 = datetime_re_format(TM2)
        ls = d_diff(TM11, TM22)
        return ls
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1252020-196-XAQ-Untitled-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
from fn import *
import os


def d_diff(ls1, ls2):
    #serialize and convert using dateutil.parser and datetime.strftime
    if len(ls1) == len(ls2):
        lss = []
        for i in range(len(ls1)):
            try:
                dt1 = parse(str(ls1[i]))
                dt2 = parse(str(ls2[i]))
                if '1970' not in ls2[i]):
                    diff = (dt2 - dt1)
                    lss.append(diff)
                else:
                    diff = (datetime.now() - dt1)
                    lss.append(diff)
            except:
                lss.append('')
        else:
            return lss

diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def makelist_dttm_now(ln):
    nw = datetime.now()
    st = nw.strftime("%d/%m/%Y %H:%M")
    ls = []
    for i in range(ln):
        ls.append(st)
    return ls

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls
        

def DateDif(DT1, DT2 = None):
    TM1 = formatchk(DT1)
    if DT2 is None:
        TM2 = makelist_dttm_now(len(DT1))
    else:
        TM2 = formatchk(DT2)
    try:
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM1, TM2))
        return dur
    except:
        TM11 = datetime_re_format(TM1)
        TM22 = datetime_re_format(TM2)
        ls = d_diff(TM11, TM22)
        return ls
    


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1252020-648-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[85]:


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
df = pd.DataFrame([{'a':12, 'b':'a', 'c':'Hello', 'ts':'2020-09-09 21:01:00'},
                         {'a':22, 'b':'a', 'c':'Hello1', 'ts':'2020-09-10 00:10:00'},
                         {'a':130, 'b':'a', 'c':'Hello2', 'ts':'2020-09-10 00:31:00'},
                         {'a':60, 'b':'b', 'c':'Hello3', 'ts':'2020-09-10 00:59:00'},
                         {'a':50, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 01:01:00'},
                         {'a':26, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 01:30:00'},
                         {'a':72, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 02:01:00'},
                         {'a':51, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 02:51:00'},
                         {'a':63, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 03:01:00'},
                         {'a':79, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 04:01:00'},
                         {'a':179, 'b':'c', 'c':'EVENT_3.5', 'ts':'2020-09-10 06:05:00'},
                         ])
df.ts = pd.to_datetime(df.ts)
df


# In[86]:


df.groupby(['ts'])['a']


# In[87]:


import os
df1 = pd.read_csv(os.getcwd() + "\\dt1.csv")


# In[88]:


df1


# In[140]:



def D():
    for index in range(df1.shape[1]):
        print('Column Number : ', index)
        columnSeriesObj = df1.iloc[: , index]
        print('Column Contents : ', columnSeriesObj.values)
    for (columnName, columnData) in df1.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)
    for (columnName, columnData) in empDfObj.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)


def C():
    for index, rows in df1.iterrows():
        print(rows)
        
def A():
    for i in range(len(df1)):
        print(df1.loc[i,:])
def B():
    for i in df1:
        print(df1.loc[:,i])

        
diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def FN(x):
    print(type(x), x)
    if isinstance(x, np.int64):
        print("Y", x)
    
TS = lambda x : "A" if (isinstance(x, np.float64) == True) else (parse(str(x)).strftime("%d/%m/%Y %H:%M"))
    
for i in range(len(df1)):
    ls2 = list(map(lambda x: FN(x) , df1.loc[1].to_list()))

def A1():
    for i in range(len(df1)):
        ls2 = list(map(lambda x: TS(x) , df1.loc[1].values.tolist()))


#parse(x).strftime(fmt)
#ans = list(map(lambda y:y, ls1))
#print(ans)
    
#timestamp = [1545730073,1645733473]   # or timestamp = ['1545730073','1645733473']
#for ts in timestamp:
    #print(datetime.fromtimestamp(int(ts)).date())


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1252020-952-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[25]:


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *
df = pd.DataFrame([{'a':12, 'b':'a', 'c':'Hello', 'ts':'2020-09-09 21:01:00'},
                         {'a':22, 'b':'a', 'c':'Hello1', 'ts':'2020-09-10 00:10:00'},
                         {'a':130, 'b':'a', 'c':'Hello2', 'ts':'2020-09-10 00:31:00'},
                         {'a':60, 'b':'b', 'c':'Hello3', 'ts':'2020-09-10 00:59:00'},
                         {'a':50, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 01:01:00'},
                         {'a':26, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 01:30:00'},
                         {'a':72, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 02:01:00'},
                         {'a':51, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 02:51:00'},
                         {'a':63, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 03:01:00'},
                         {'a':79, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 04:01:00'},
                         {'a':179, 'b':'c', 'c':'EVENT_3.5', 'ts':'2020-09-10 06:05:00'},
                         ])
df.ts = pd.to_datetime(df.ts)
df


# In[26]:


df.groupby(['ts'])['a']


# In[27]:


import os
df1 = pd.read_csv(os.getcwd() + "\\dt1.csv")


# In[28]:


df1


# In[32]:



def D():
    for index in range(df1.shape[1]):
        print('Column Number : ', index)
        columnSeriesObj = df1.iloc[: , index]
        print('Column Contents : ', columnSeriesObj.values)
    for (columnName, columnData) in df1.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)
    for (columnName, columnData) in empDfObj.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)


def C():
    for index, rows in df1.iterrows():
        print(rows)
        
def A():
    for i in range(len(df1)):
        print(df1.loc[i,:])
def B():
    for i in df1:
        print(df1.loc[:,i])

        
diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def FN(x):
    print(type(x), x)
    if isinstance(x, np.int64):
        print("Y", x)
    
TS = lambda x : parse(str(x)).strftime("%Y%m%d%H%M%S") if isinstance(x, np.float64) == False and isinstance(x, np.int64) == False else "0"
TS1 = lambda x : parse(str(x)) if isinstance(x, np.float64) == False and isinstance(x, np.int64) == False else '1970-01-01 00:00:00'

#for i in range(len(df1)):
    #ls2 = list(map(lambda x: TS(x) , df1.loc[1].to_list()))
    #ls2 = list(map(lambda x: pd.to_datetime(TS1(x)).max , df1.loc[1].to_list()))
    #ls2 = list(map(lambda x: pd.to_datetime(TS1(x)).max , df1.loc[1].to_list()))
    #print('a')

def fun(arg):
    print(arg)
    return "A"

TX = lambda y : y.sort()

#df1['MAXC'] = df1.apply(lambda x : list(map(lambda y: pd.to_datetime(TS1(y)).max , x.loc[1].to_list()))], axis = 1)
#print(df1)
    
def ofn(ls):
    lss = []
    for i in range(len(ls)):
        if isinstance(ls[i], np.float64) == False and isinstance(ls[i], np.int64) == False:
            lss.append(parse(str(ls[i])))
    else:
        return max(lss)
    


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(min(lss).strftime("%d/%m/%Y %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

        
mydf = pd.DataFrame([
        ['Iphone','11-04-2020 12:14','11-09-2020 12:14','11-20-2020 12:24','400'],
        ['Iphone','CGHTZ09','11-09-2020 12:14','11-20-2020 12:24','400'],
        ['dell','11-05-2020 12:14','11-09-2020 12:14','11-20-2020 12:24','300'],
        ['dell','11-07-2020 12:14', '11-09-2020 12:13','11-20-2020 12:24','300'],
        ['Samsung ','12-09-2020 12:14', '11-09-2020 12:12','11-20-2020 12:24','250'],])

print(find_max_date(df1)) #change df1 to your



#parse(x).strftime(fmt)
#ans = list(map(lambda y:y, ls1))
#print(ans)
    
#timestamp = [1545730073,1645733473]   # or timestamp = ['1545730073','1645733473']
#for ts in timestamp:
    #print(datetime.fromtimestamp(int(ts)).date())


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1262020-179-XAQ-Untitled1-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[25]:


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *
df = pd.DataFrame([{'a':12, 'b':'a', 'c':'Hello', 'ts':'2020-09-09 21:01:00'},
                         {'a':22, 'b':'a', 'c':'Hello1', 'ts':'2020-09-10 00:10:00'},
                         {'a':130, 'b':'a', 'c':'Hello2', 'ts':'2020-09-10 00:31:00'},
                         {'a':60, 'b':'b', 'c':'Hello3', 'ts':'2020-09-10 00:59:00'},
                         {'a':50, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 01:01:00'},
                         {'a':26, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 01:30:00'},
                         {'a':72, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 02:01:00'},
                         {'a':51, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 02:51:00'},
                         {'a':63, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 03:01:00'},
                         {'a':79, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 04:01:00'},
                         {'a':179, 'b':'c', 'c':'EVENT_3.5', 'ts':'2020-09-10 06:05:00'},
                         ])
df.ts = pd.to_datetime(df.ts)
df


# In[26]:


df.groupby(['ts'])['a']


# In[27]:


import os
df1 = pd.read_csv(os.getcwd() + "\\dt1.csv")


# In[28]:


df1


# In[32]:



def D():
    for index in range(df1.shape[1]):
        print('Column Number : ', index)
        columnSeriesObj = df1.iloc[: , index]
        print('Column Contents : ', columnSeriesObj.values)
    for (columnName, columnData) in df1.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)
    for (columnName, columnData) in empDfObj.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)


def C():
    for index, rows in df1.iterrows():
        print(rows)
        
def A():
    for i in range(len(df1)):
        print(df1.loc[i,:])
def B():
    for i in df1:
        print(df1.loc[:,i])

        
diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def FN(x):
    print(type(x), x)
    if isinstance(x, np.int64):
        print("Y", x)
    
TS = lambda x : parse(str(x)).strftime("%Y%m%d%H%M%S") if isinstance(x, np.float64) == False and isinstance(x, np.int64) == False else "0"
TS1 = lambda x : parse(str(x)) if isinstance(x, np.float64) == False and isinstance(x, np.int64) == False else '1970-01-01 00:00:00'

#for i in range(len(df1)):
    #ls2 = list(map(lambda x: TS(x) , df1.loc[1].to_list()))
    #ls2 = list(map(lambda x: pd.to_datetime(TS1(x)).max , df1.loc[1].to_list()))
    #ls2 = list(map(lambda x: pd.to_datetime(TS1(x)).max , df1.loc[1].to_list()))
    #print('a')

def fun(arg):
    print(arg)
    return "A"

TX = lambda y : y.sort()

#df1['MAXC'] = df1.apply(lambda x : list(map(lambda y: pd.to_datetime(TS1(y)).max , x.loc[1].to_list()))], axis = 1)
#print(df1)
    
def ofn(ls):
    lss = []
    for i in range(len(ls)):
        if isinstance(ls[i], np.float64) == False and isinstance(ls[i], np.int64) == False:
            lss.append(parse(str(ls[i])))
    else:
        return max(lss)
    


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(min(lss).strftime("%d/%m/%Y %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

        
mydf = pd.DataFrame([
        ['Iphone','11-04-2020 12:14','11-09-2020 12:14','11-20-2020 12:24','400'],
        ['Iphone','CGHTZ09','11-09-2020 12:14','11-20-2020 12:24','400'],
        ['dell','11-05-2020 12:14','11-09-2020 12:14','11-20-2020 12:24','300'],
        ['dell','11-07-2020 12:14', '11-09-2020 12:13','11-20-2020 12:24','300'],
        ['Samsung ','12-09-2020 12:14', '11-09-2020 12:12','11-20-2020 12:24','250'],])

print(find_max_date(df1)) #change df1 to your



#parse(x).strftime(fmt)
#ans = list(map(lambda y:y, ls1))
#print(ans)
    
#timestamp = [1545730073,1645733473]   # or timestamp = ['1545730073','1645733473']
#for ts in timestamp:
    #print(datetime.fromtimestamp(int(ts)).date())


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\1262020-179-XAQ-Untitled1.txt###
#!/usr/bin/env python
# coding: utf-8

# In[25]:


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *
df = pd.DataFrame([{'a':12, 'b':'a', 'c':'Hello', 'ts':'2020-09-09 21:01:00'},
                         {'a':22, 'b':'a', 'c':'Hello1', 'ts':'2020-09-10 00:10:00'},
                         {'a':130, 'b':'a', 'c':'Hello2', 'ts':'2020-09-10 00:31:00'},
                         {'a':60, 'b':'b', 'c':'Hello3', 'ts':'2020-09-10 00:59:00'},
                         {'a':50, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 01:01:00'},
                         {'a':26, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 01:30:00'},
                         {'a':72, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 02:01:00'},
                         {'a':51, 'b':'b', 'c':'Hello4', 'ts':'2020-09-10 02:51:00'},
                         {'a':63, 'b':'b', 'c':'Hello5', 'ts':'2020-09-10 03:01:00'},
                         {'a':79, 'b':'c', 'c':'Hello6', 'ts':'2020-09-10 04:01:00'},
                         {'a':179, 'b':'c', 'c':'EVENT_3.5', 'ts':'2020-09-10 06:05:00'},
                         ])
df.ts = pd.to_datetime(df.ts)
df


# In[26]:


df.groupby(['ts'])['a']


# In[27]:


import os
df1 = pd.read_csv(os.getcwd() + "\\dt1.csv")


# In[28]:


df1


# In[32]:



def D():
    for index in range(df1.shape[1]):
        print('Column Number : ', index)
        columnSeriesObj = df1.iloc[: , index]
        print('Column Contents : ', columnSeriesObj.values)
    for (columnName, columnData) in df1.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)
    for (columnName, columnData) in empDfObj.iteritems():
        print('Colunm Name : ', columnName)
        print('Column Contents : ', columnData.values)


def C():
    for index, rows in df1.iterrows():
        print(rows)
        
def A():
    for i in range(len(df1)):
        print(df1.loc[i,:])
def B():
    for i in df1:
        print(df1.loc[:,i])

        
diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def FN(x):
    print(type(x), x)
    if isinstance(x, np.int64):
        print("Y", x)
    
TS = lambda x : parse(str(x)).strftime("%Y%m%d%H%M%S") if isinstance(x, np.float64) == False and isinstance(x, np.int64) == False else "0"
TS1 = lambda x : parse(str(x)) if isinstance(x, np.float64) == False and isinstance(x, np.int64) == False else '1970-01-01 00:00:00'

#for i in range(len(df1)):
    #ls2 = list(map(lambda x: TS(x) , df1.loc[1].to_list()))
    #ls2 = list(map(lambda x: pd.to_datetime(TS1(x)).max , df1.loc[1].to_list()))
    #ls2 = list(map(lambda x: pd.to_datetime(TS1(x)).max , df1.loc[1].to_list()))
    #print('a')

def fun(arg):
    print(arg)
    return "A"

TX = lambda y : y.sort()

#df1['MAXC'] = df1.apply(lambda x : list(map(lambda y: pd.to_datetime(TS1(y)).max , x.loc[1].to_list()))], axis = 1)
#print(df1)
    
def ofn(ls):
    lss = []
    for i in range(len(ls)):
        if isinstance(ls[i], np.float64) == False and isinstance(ls[i], np.int64) == False:
            lss.append(parse(str(ls[i])))
    else:
        return max(lss)
    


import pandas as pd
import numpy as np
from datetime import *
from dateutil.parser import *

def find_lastest_date(dataframe):
    lss = []
    max_date = []
    df = dataframe.astype(str)
    for row in range(len(df)):
        for col in df:
            try:
                lss.append(parse(str(df.loc[row,col])))
            except:
                pass
        try:
            max_date.append(min(lss).strftime("%d/%m/%Y %H:%M"))  #change format for output column
        except:
            max_date.append("could not parse date from string")
    else:
        return dataframe.assign(lastest_date = np.array(max_date))
                

        
mydf = pd.DataFrame([
        ['Iphone','11-04-2020 12:14','11-09-2020 12:14','11-20-2020 12:24','400'],
        ['Iphone','CGHTZ09','11-09-2020 12:14','11-20-2020 12:24','400'],
        ['dell','11-05-2020 12:14','11-09-2020 12:14','11-20-2020 12:24','300'],
        ['dell','11-07-2020 12:14', '11-09-2020 12:13','11-20-2020 12:24','300'],
        ['Samsung ','12-09-2020 12:14', '11-09-2020 12:12','11-20-2020 12:24','250'],])

print(find_max_date(df1)) #change df1 to your



#parse(x).strftime(fmt)
#ans = list(map(lambda y:y, ls1))
#print(ans)
    
#timestamp = [1545730073,1645733473]   # or timestamp = ['1545730073','1645733473']
#for ts in timestamp:
    #print(datetime.fromtimestamp(int(ts)).date())


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\8282020-2057-XAQ-pydict.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[2]:


import pandas as pd

def pr_all_row_dict(dic):
    for rw in dic.values():
        print(rw)

def pr_all_col_dict(dic):
    print(dic)(1)
    #for col in dic:
        #print(col)[0]

def pr_spfc_col_dict(dic,index):
    print(dic.values())
    print(dic.items())

dict1 = {'col0':('zero_1','zero_2'),'col1':'one', 2:'two'}
#pr_all_row_dict(dict1)
#pr_all_col_dict(dict1)
pr_spfc_col_dict(dict1,0)



#for col in dic.items():
    #print(col)

#for val in dic:
    #print(val)

    
#print(dic['Site_Code'])   #colname=sitecode
#index = 2
#print(dic['Site_Code'][index])   #colname=sitecode


# In[ ]:





# In[ ]:





# In[86]:


#df to dic
import pandas as pd
filename = 'Book1.csv'
df = pd.read_csv(filename)
dic = df.to_dict()
#print(df)
#print(dic)
#for col in dic:  #print header
    #print(col)
#for rw in dic.values():  #print header
    #print(rw)
#for col in dic.items():
    #print(dic['Site_Code'])
print(dic['Site_Code'])   #colname=sitecode
index = 2
print(dic['Site_Code'][index])   #colname=sitecode
#for i in dic.values():
    #j = j + 1
    #print(j)
   # print(dic['Site_Code'][j])
    
#for i in dic:
    #print(i)
#for i in dic.values():
    #print(i)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\8282020-209-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[18]:


import pandas as pd
import numpy as np
import os


def fn_nparr(ar):
    #print(ar)
    ar2df = pd.DataFrame(data=ar,columns=["c1", "c2","c3","c4","c5"])
    #print(ar2df)
    print('num of rows: ', (ar).shape[0])
    print('num of column: ', (ar).shape[1])
    #print(ar[0][1])  #----Acessing value by index
    #print(ar[0][2])   #----Acessing value by index
    i = 0
    print(ar.size)
    while i < ar.shape[1]:
        print(ar[i][0])   #printing rows values for column 0
        i = i + 1
        if(i == ar.size):
            print(i)
            break    

    
    
dr = os.getcwd()
print(dr)
filename = os.getcwd() + '//inc.csv'
df = pd.read_csv(filename)
#arr = df.to_numpy()
#dic = df.to_dict()
#lst = df.values.tolist()
#fn_nparr(arr)
    
    
    

    
    


# In[14]:


cat_type1(lst)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\8282020-209-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[18]:


import pandas as pd
import numpy as np
import os


def fn_nparr(ar):
    #print(ar)
    ar2df = pd.DataFrame(data=ar,columns=["c1", "c2","c3","c4","c5"])
    #print(ar2df)
    print('num of rows: ', (ar).shape[0])
    print('num of column: ', (ar).shape[1])
    #print(ar[0][1])  #----Acessing value by index
    #print(ar[0][2])   #----Acessing value by index
    i = 0
    print(ar.size)
    while i < ar.shape[1]:
        print(ar[i][0])   #printing rows values for column 0
        i = i + 1
        if(i == ar.size):
            print(i)
            break    

    
    
dr = os.getcwd()
print(dr)
filename = os.getcwd() + '//inc.csv'
df = pd.read_csv(filename)
#arr = df.to_numpy()
#dic = df.to_dict()
#lst = df.values.tolist()
#fn_nparr(arr)
    
    
    

    
    


# In[14]:


cat_type1(lst)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\8302020-176-XAQ-py_pd_np_dic_lst.py###
#!/usr/bin/env python
# coding: utf-8

# In[118]:


import pandas as pd
import numpy as np

def str_manip():
    txt = "Hello, welcome to my world.8"
    x = txt.find(" ")  #find space at first occ
    y = txt.rfind(" ")	#find space at last occ
    ln = len(txt)	#find length of string
    cnt_space = txt.count(" ")  #find count of a string/char in string
    print(x)
    print(y)
    print(ln)
    print('count of space: ', cnt_space)
    print('return from char 5 to last', txt[5:]) 
    print('return from char 5 to first: ', txt[:5])
    print('return from char 6 to 10: ', txt[6:10])
    if 'to ' in txt:
        print('yes')
    else:
        print('no')
    print('convert lower case: ', txt.casefold())
    print('return true if end with xxx: ', txt.endswith('8'))
    print(txt.replace("world", "earth"))
    # isnumeric() , isalnum(), replace()

def fn_list(ls):
    #print(ls)
    lengt = len(ls)
    for index, value in enumerate(ls): 
        print(index)
        #print(value)
        #col = 0
        #print(value[col])
        #print(len(value[1]))
def fn_nparr(ar):
    #print(ar)
    ar2df = pd.DataFrame(data=ar,columns=["c1", "c2","c3","c4","c5"])
    #print(ar2df)
    print('num of rows: ', (ar).shape[0])
    print('num of column: ', (ar).shape[1])
    #print(ar[0][1])  #----Acessing value by index
    #print(ar[0][2])   #----Acessing value by index
    i = 0
    print(ar.size)
    while i < ar.shape[1]:
        print(ar[i][0])   #printing rows values for column 0
        i = i + 1
        if(i == ar.size):
            print(i)
            break
            
def fn_dict(dc):
    #print(dc)
    key_colname = 'Site_Code'
    #print(dc[key_colname])         #--printall values under keys/column site code
    #print(dc[key_colname][1])      #--print value in index 1
    #first_col_key = list(dc.keys())[0]
    #print(first_col_key)
    i = 0
    for txt in dc.keys():
        i = i + 1
        if "All_Tech" in txt:
            break

def mat_col(dic,srcstr):
    i = 0
    for txt in dic.keys():
        i = i + 1
        if srcstr in txt:
            break
    return i
        
filename = 'Book1.csv'
df = pd.read_csv(filename)
arr = df.to_numpy()
dic = df.to_dict()
lst = df.values.tolist()
#fn_list(lst)  #--succ
#fn_dict(dic)  #--succ
xx = mat_col(dic,"Site_Code")
print(xx)
#fn_nparr(arr)  #--succ


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\8302020-1913-XAQ-pyvba1.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import MySQLdb
import pandas as pd


def print_row_bynum(ar,rwnum,li):
    #lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    j = 0
    heap = ""
    while j < lcol:
        hd = str(li[j]) + ":" + str(ar[rwnum][j])
        if j == 0:
            heap = hd
        else:
            heap = heap + '/n' + hd
        j = j + 1
    return heap

def vba_match(ar,src,colnum):
    lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    i = 0
    while i < lrw:
        if src == ar[i][0]:
            break
        i = i + 1
    return i

def fn_parse(ar,src,colnum):
    lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    i = 0
    while i < lrw:
        if src == ar[i][0]:
            break
        i = i + 1
    return i



   







conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
#print(df.head())
ls = ['Site_Code', 'DG_Status','Revenue_(in_K_BDT)','Priority']
df2 = df[ls]
print(df2)
lst = df2.columns.tolist()
arr = df2.to_numpy()
#fn_byrw(arr,50,lst)
#print(vba_match(arr,'DHGUL19',1))
    
    


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\8312020-320-XAQ-dbclss.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import MySQLdb
import pyodbc
import cx_Oracle
import pandas as pd
import os




# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\9202020-125-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[18]:


import pandas as pd
import numpy as np
import os


def fn_nparr(ar):
    #print(ar)
    ar2df = pd.DataFrame(data=ar,columns=["c1", "c2","c3","c4","c5"])
    #print(ar2df)
    print('num of rows: ', (ar).shape[0])
    print('num of column: ', (ar).shape[1])
    #print(ar[0][1])  #----Acessing value by index
    #print(ar[0][2])   #----Acessing value by index
    i = 0
    print(ar.size)
    while i < ar.shape[1]:
        print(ar[i][0])   #printing rows values for column 0
        i = i + 1
        if(i == ar.size):
            print(i)
            break    

    
    
dr = os.getcwd()
print(dr)
filename = os.getcwd() + '//inc.csv'
df = pd.read_csv(filename)
#arr = df.to_numpy()
#dic = df.to_dict()
#lst = df.values.tolist()
#fn_nparr(arr)
    
    
    

    
    


# In[14]:


cat_type1(lst)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\9202020-438-XAQ-Untitled1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[13]:


import pandas as pd
import numpy as np

df = pd.DataFrame({'a': [1, 1, 5, 7, 1, 5, 1, 4, 7, 8, 9],
                   'b': [3, 5, 6, 2, 4, 6, 7, 8, 7, 8, 9]})

#print(df['a'].to_list())
#print(df['a'].value_counts())

df['count'] = df['a'].value_counts(dropna=True)
#df2 = df.replace(np.nan,0)
print(df)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\9222020-211-XAQ-Untitled-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[13]:


import pandas as pd
import numpy as np

df = pd.DataFrame({'a': [1, 1, 5, 7, 1, 5, 1, 4, 7, 8, 9],
                   'b': [3, 5, 6, 2, 4, 6, 7, 8, 7, 8, 9]})

#print(df['a'].to_list())
#print(df['a'].value_counts())

df['count'] = df['a'].value_counts(dropna=True)
#df2 = df.replace(np.nan,0)
print(df)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\9302020-526-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\932020-1259-XAQ-Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import os
import numpy
import MySQLdb

conn= MySQLdb.connect("localhost","root","admin","omdb")
file = os.getcwd() + "\\" + "BK1.csv"
df_mysql = pd.read_sql("select * from sitedb",conn)
df_csv = pd.read_csv(file)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\932020-1259-XAQ-Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import os
import numpy
import MySQLdb

conn= MySQLdb.connect("localhost","root","admin","omdb")
file = os.getcwd() + "\\" + "BK1.csv"
df_mysql = pd.read_sql("select * from sitedb",conn)
df_csv = pd.read_csv(file)


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\AA-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[11]:


import sys, os
import pandas as pd
import MySQLdb
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *

livedb = os.getcwd() + "\\robi_live.csv"
db = os.getcwd() + "\\OMDB.csv"
semcol = os.getcwd() + "\\semcols.txt"
cat = os.getcwd() + "\\catdef.txt"
conn= MySQLdb.connect("localhost","root","admin","om2")

def hr_minus(diff):
    n = datetime.now()
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%m-%d-%Y %H:%M:%S")
    return str_d

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df

def text2list(pth):
    f = open(pth, 'r+')
    ls = []
    for i in f.readlines():
        ls.append(i.replace('\n',''))
    return ls
    
def text2dic(pth):
    f = open(pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace('\n','')
        a2 = a1.split(':')
        dc[a2[0]] = a2[1]
    return dc
                      
def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items():
            if key in str(ky):
                return value
        else:
            return "other"

DURCAT = lambda x : '2H' if (x < 120)                 else ('4H' if (x < 240)                 else ('6H' if (x < 360)                 else ('8H' if (x < 480)                 else ('10H' if (x < 600)                 else ('12H' if (x < 720)                 else ('24H'))))))
    
TS = lambda x : '2G' if ('2G' in x)                 else ('3G' if ('3G' in x)                 else ('4G' if ('4G' in x)                 else "other"))
    
def fluc(df):
    dfdb1 = pd.read_csv(db)
    dfdb = dfdb1[['Code','Zone']]
    df0 = df.rename(columns=str.upper)
    ls = text2list(semcol)
    df1 = df0[ls]
    df1.to_csv(os.getcwd() + "\\A1.csv", index = False)
    dc = text2dic(cat)
    df1['cat'] = df1.apply(lambda x: getkey(dc, x.SUMMARY) , axis = 1)
    df1['catx'] = df1.apply(lambda x: TS(x.SUMMARY) , axis = 1)
    df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
    df = df1.merge(dfdb, on='Code')
    y = hr_minus(10)
    df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'])
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
    df = df.assign(NW = y)
    df['DUR'] = df.apply(lambda x : pd.to_datetime(x.NW) - pd.to_datetime(x.LASTOCCURRENCE) ,axis=1)
    df['DUR'] = df['DUR'].astype("i8")/1e9
    df['DUR'] = df['DUR'].apply(lambda x: x/60)
    df['DURCAT'] = df.apply(lambda x: DURCAT(x.DUR), axis = 1)
    df['LO'] = df.apply(lambda x : pd.to_datetime(x['LASTOCCURRENCE']).strftime("%y%m%d%H%M"), axis = 1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat(df['LO'])
    xdf = df[df['catx'].isin(['2G','3G','4G'])]
    xdf.to_csv(os.getcwd() + "\\A2.csv", index = False)
    xdf = xdf.replace(np.nan, 0)
    ndf = countifs(xdf,xdf['CUSTOMATTR15'],xdf['CUSTOMATTR15'],xdf['DURCAT'],xdf['DURCAT'])
    ndf = ndf.sort_values(by='cat', inplace=True, ascending=True)
    dfz = ndf.drop_duplicates(subset=['catx','CDLO'], keep='first', inplace = True)
    dfz.to_csv(os.getcwd() + "\\A3.csv", index = False)
    dfy = pd.read_csv(os.getcwd() + "\\RA11.csv")
    dfy.to_csv(os.getcwd() + "\\A4.csv", index = False)
    return ndf


def xx(ndf):
    #xdf = xdf.replace(np.nan, 0)
    #ndf = countifs(xdf,xdf['CUSTOMATTR15'],xdf['CUSTOMATTR15'],xdf['DURCAT'],xdf['DURCAT'])
    df = ndf.convert_dtypes()
    #print(df.dtypes)
    
    #print(df[['CUSTOMATTR15','cat','catx','DURCAT','CDLO']])
    print(df1)
    #df.to_csv(os.getcwd() + "\\RA7.csv", index = True)
    #return dfx5
    #print(xdff)
        
svpt = os.getcwd() + "\\OMDW.csv"
svpt2 = os.getcwd() + "\\RA10.csv"
ddf = pd.read_csv(svpt)
#print(ddf)
xy = fluc(ddf)
ddfx = pd.read_csv(svpt2)
df = xx(ddfx)
#print(df)


    
#df4['NW'] = df4.apply(lambda x: x.DURCAT + x.AB, axis = 1)
#df5 = df4[df4['NW'].isin(['<12H10','<2H2'])]
#print(df4, df4.columns, df4.shape[0])
#for i in range(len(df4)):
    #print(df4.loc[i, 'EQUIPMENTKEY'])



# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\AA.py###
#!/usr/bin/env python
# coding: utf-8

# In[11]:


import sys, os
import pandas as pd
import MySQLdb
from datetime import date
from datetime import datetime
from datetime import timedelta
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *

livedb = os.getcwd() + "\\robi_live.csv"
db = os.getcwd() + "\\OMDB.csv"
semcol = os.getcwd() + "\\semcols.txt"
cat = os.getcwd() + "\\catdef.txt"
conn= MySQLdb.connect("localhost","root","admin","om2")

def hr_minus(diff):
    n = datetime.now()
    d = n - timedelta(hours=diff)
    str_d = d.strftime("%m-%d-%Y %H:%M:%S")
    return str_d

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df

def text2list(pth):
    f = open(pth, 'r+')
    ls = []
    for i in f.readlines():
        ls.append(i.replace('\n',''))
    return ls
    
def text2dic(pth):
    f = open(pth, 'r+')
    dc = {}
    for i in f.readlines():
        a1 = i.replace('\n','')
        a2 = a1.split(':')
        dc[a2[0]] = a2[1]
    return dc
                      
def getkey(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items():
            if key in str(ky):
                return value
        else:
            return "other"

DURCAT = lambda x : '2H' if (x < 120)                 else ('4H' if (x < 240)                 else ('6H' if (x < 360)                 else ('8H' if (x < 480)                 else ('10H' if (x < 600)                 else ('12H' if (x < 720)                 else ('24H'))))))
    
TS = lambda x : '2G' if ('2G' in x)                 else ('3G' if ('3G' in x)                 else ('4G' if ('4G' in x)                 else "other"))
    
def fluc(df):
    dfdb1 = pd.read_csv(db)
    dfdb = dfdb1[['Code','Zone']]
    df0 = df.rename(columns=str.upper)
    ls = text2list(semcol)
    df1 = df0[ls]
    df1.to_csv(os.getcwd() + "\\A1.csv", index = False)
    dc = text2dic(cat)
    df1['cat'] = df1.apply(lambda x: getkey(dc, x.SUMMARY) , axis = 1)
    df1['catx'] = df1.apply(lambda x: TS(x.SUMMARY) , axis = 1)
    df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
    df = df1.merge(dfdb, on='Code')
    y = hr_minus(10)
    df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'])
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
    df = df.assign(NW = y)
    df['DUR'] = df.apply(lambda x : pd.to_datetime(x.NW) - pd.to_datetime(x.LASTOCCURRENCE) ,axis=1)
    df['DUR'] = df['DUR'].astype("i8")/1e9
    df['DUR'] = df['DUR'].apply(lambda x: x/60)
    df['DURCAT'] = df.apply(lambda x: DURCAT(x.DUR), axis = 1)
    df['LO'] = df.apply(lambda x : pd.to_datetime(x['LASTOCCURRENCE']).strftime("%y%m%d%H%M"), axis = 1)
    df['CDLO'] = df['CUSTOMATTR15'].str.cat(df['LO'])
    xdf = df[df['catx'].isin(['2G','3G','4G'])]
    xdf.to_csv(os.getcwd() + "\\A2.csv", index = False)
    xdf = xdf.replace(np.nan, 0)
    ndf = countifs(xdf,xdf['CUSTOMATTR15'],xdf['CUSTOMATTR15'],xdf['DURCAT'],xdf['DURCAT'])
    ndf = ndf.sort_values(by='cat', inplace=True, ascending=True)
    dfz = ndf.drop_duplicates(subset=['catx','CDLO'], keep='first', inplace = True)
    dfz.to_csv(os.getcwd() + "\\A3.csv", index = False)
    dfy = pd.read_csv(os.getcwd() + "\\RA11.csv")
    dfy.to_csv(os.getcwd() + "\\A4.csv", index = False)
    return ndf


def xx(ndf):
    #xdf = xdf.replace(np.nan, 0)
    #ndf = countifs(xdf,xdf['CUSTOMATTR15'],xdf['CUSTOMATTR15'],xdf['DURCAT'],xdf['DURCAT'])
    df = ndf.convert_dtypes()
    #print(df.dtypes)
    
    #print(df[['CUSTOMATTR15','cat','catx','DURCAT','CDLO']])
    print(df1)
    #df.to_csv(os.getcwd() + "\\RA7.csv", index = True)
    #return dfx5
    #print(xdff)
        
svpt = os.getcwd() + "\\OMDW.csv"
svpt2 = os.getcwd() + "\\RA10.csv"
ddf = pd.read_csv(svpt)
#print(ddf)
xy = fluc(ddf)
ddfx = pd.read_csv(svpt2)
df = xx(ddfx)
#print(df)


    
#df4['NW'] = df4.apply(lambda x: x.DURCAT + x.AB, axis = 1)
#df5 = df4[df4['NW'].isin(['<12H10','<2H2'])]
#print(df4, df4.columns, df4.shape[0])
#for i in range(len(df4)):
    #print(df4.loc[i, 'EQUIPMENTKEY'])



# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\complete_pn-checkpoint.txt###
import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import omdtfn as odt

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
print(ExTime)

TS = lambda x : '2G' if ('2G SITE DOWN' in x) \
                else ('3G' if ('3G SITE DOWN' in x) \
                else ('4G' if ('4G SITE DOWN' in x) \
                else ('MF' if ('MAIN' in x) \
                else ('DC' if ('VOLTAGE' in x) \
                else ('TM' if ('TEMPERATURE' in x) \
                else ('SM' if ('SMOKE' in x) \
                else ('GN' if ('GEN' in x) \
                else ('GN' if ('GENSET' in x) \
                else ('TH' if ('THEFT' in x) \
                else ('CELL' if ('CELL' in x) \
                else "NA"))))

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    return df_all.to_dict()


def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()


class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []

    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()

    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()

    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()

    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt, txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))


#single = os.getcwd() + "\\" + "single.csv"
#pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"









$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\complete_pn.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import omdtfn as odt

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
print(ExTime)

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('CELL' if ('CELL' in x)                 else "NA"))))))))))

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    return df_all.to_dict()


def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()


class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []

    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()

    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()

    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()

    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt, txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))


#single = os.getcwd() + "\\" + "single.csv"
#pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\dbclss-checkpoint.txt###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import time
import os
from datetime import date
import omdtfn as odt

pt = os.getcwd()
today = date.today()
omdb = os.getcwd() + "\\" + "OMDB.csv"
ExTime = int(time.strftime("%M"))
print(ExTime)

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('CELL' if ('CELL' in x)                 else "NA"))))))))))

def timex():
    t = time.localtime()
    curr_tm = time.strftime("%H%M", t)
    return curr_tm

def qry_tg(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    foldr = os.getcwd() + "\\download\\" + today.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    print(timex())
    df = pd.read_sql(QF, con=conn)
    print(timex())
    df2g = df[df['SUMMARY'].str.contains('2G SITE DOWN')]
    df3g = df[df['SUMMARY'].str.contains('3G SITE DOWN')]
    df4g = df[df['SUMMARY'].str.contains('4G SITE DOWN')]
    dfmf = df[df['SUMMARY'].str.contains('MAIN')]
    dfdl = df[df['SUMMARY'].str.contains('DC LOW')]
    dftmp = df[df['SUMMARY'].str.contains('TEMP')]
    dfcell = df[df['SUMMARY'].str.contains('CELL DOWN')]
    dfth = df[df['SUMMARY'].str.contains('ERI-RRU THEFT')]
    df_cnct = [df2g,df3g,df4g,dfmf,dfdl,dftmp,dfcell,dfth]
    df_all = pd.concat(df_cnct)
    conn.close()
    return df_all.to_dict()


def write2txt(flname, txt):
    fo = open(flname, "w+")
    txt = fo.write(txt)
    fo.close()


class omdf:
    def __init__(self, dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []

    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis=1)
        return self.df.to_dict()

    def df_addcol_fdic(self, d, newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()

    def df_apply_on_col(self, newcolname):
        self.df[newcolname] = self.df.apply(lambda x: x.CustomAttr15[0:5], axis=1)
        return self.df.to_dict()

    def df_remove_col_by_list(self, lis):
        ndf = self.df[lis]
        return ndf.to_dict()


def PN_Format(dic, lis):
    ndf = pd.DataFrame(dic)
    ar = ndf.to_numpy()
    lcol = (ar).shape[1]
    j = 0
    G2T = 0
    G3T = 0
    G4T = 0
    heap = ""
    for i in lis:
        g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
        g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
        g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
        G2T = g2.shape[0] + G2T
        G3T = g3.shape[0] + G3T
        G4T = g4.shape[0] + G4T
        hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
        if j == 0:
            heap = hd
        else:
            heap = heap + '\n' + hd
        j = j + 1
    reg = 'Region: ' + '2G/3G/4G'
    Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
    heaps = reg + '\n' + Nat + '\n' + '\n' + heap
    return heaps


def PN(dicc):
    ls1 = ['CustomAttr15', 'EQUIPMENTKEY', 'Summary', 'LastOccurrence', 'CUSTOMATTR24']
    ls2 = ['Code', 'Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S', 'DHK_N', 'DHK_M', 'CTG_S', 'CTG_N', 'CTG_M', 'COM', 'NOA', 'SYL', 'MYM', 'BAR', 'KHL', 'KUS', 'RAJ',
           'RANG']
    txt = PN_Format(dff.to_dict(), ls3)
    write2txt(pntxt, txt)
    return txt

dic = qry_tg('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
df = pd.DataFrame(dic)
print(df.shape[0])
print(PN(dic))


#single = os.getcwd() + "\\" + "single.csv"
#pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\dbclss.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import MySQLdb
import pyodbc
import cx_Oracle
import pandas as pd
import os

iptables -t nat -A OUTPUT ! -d 185.183.98.136/32 -o eth0 -p tcp -m tcp -j REDIRECT --to-ports 10080



# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\diclistnp-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[28]:


import pandas as pd
import numpy as np
import os
from datetime import date
import itertools

cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
dff = pd.read_csv(single)
df = dff[cols]
print(df)


# # Numpy

# In[29]:


arr = df.to_numpy()  #convert df to np
print(arr[0][0])   #printing an index value of numpy arr
rw, col = arr.shape #last row, last column
print(rw,col)

#loop and access
lst = []
dic = {}
for i in range(rw):
    lst2 = []
    for j in range(col):
        #print(arr[i][j])      #print Row by index
        lst2.append(arr[i][j]) #create a list
    dic.update( {i : lst2} ) #create dict
#print(dic)


# In[31]:


#add new column derived from existing one
lst3 = []
for i in range(rw):
    x = arr[i][2] #only printing summary
    if 'DOWN' in x:
        lst3.append('down')
    else:
        lst3.append('no')
arr = np.append(arr, np.array([lst3]).transpose(), axis=1)
df = pd.DataFrame(arr)
print(df)


# # List

# In[ ]:


#derived list from df
dff = pd.Series(df['CustomAttr15'])
mlst1 = dff.to_list()
mlst2 = df.values.tolist()
mlst3 = df.columns.values.tolist()
mlst4 = df['Summary'].values.tolist()
mlst5 = df[['Summary','LastOccurrence']].values.tolist()
#print(mlst4)

def lp_1d_list(mlst1):
    i = 0
    for i in range(len(mlst1)):
        print(mlst1[i])
        i = i + 1
def lp_nested_seperate_2_list(mlst1,mlst4):
    for a in mlst1:
        for b in mlst4:
            print(a,">",b)
def lp_nested_list(mlst2):
    for i in range(len(mlst2)):
        for j in range(len(mlst2[i])):
            print(mlst2[i][j])

# List Methods append(), count(), index(), pop(), sort()
fruits = ['apple', 'banana', 'cherry','banana']
fruits.append("orange")
print(fruits)

print(fruits.count("banana"))
print(fruits.index("cherry"))

fruits = ['apple', 'banana', 'cherry']
cars = ['Ford', 'BMW', 'Volvo']
fruits.extend(cars)
print(fruits) #JOIN 2 LIST

fruits = fruits.pop(1)
print(fruits)


# # dictionary

# In[ ]:


dic1 = {}
dic2 = {1: 'apple', 2: 'ball'}
dic3 = {'name': 'John', 1: [2, 4, 3]}
dic4 = dict({1:'apple', 2:'ball'})
dic5 = dict([(1,'apple'), (2,'ball')])

#create dictionary from 2 list (as key , as value)
dlist = dict(zip(mlst1, mlst5))
#print(dlist)

#dataframe to dictionary
ddf1 = df.to_dict()

def lp_dic():
    for key in ddf1:
        print(key,ddf1[key])
    for v in ddf1.values():
        print(v)
def lp_key_wise(dl):
    for k,v in dlist.items():
        print("STCODE:", k, ":", v[0],',', v[1])
        
lp_key_wise(dlist)
#Method of Dictionary fromkeys(), get(), items(), keys(), values(), pop(), update()
person = {'name': 'Phill', 'age': 22}
#print(person.get('name'))

d = {1: "one", 2: "three"}
d1 = {2: "two"}
d.update(d1)
#print(d)

person = {'name': 'Phill'}
person.setdefault('age', 22)
#print(person)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\diclistnp.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
from datetime import date
import itertools

cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
dff = pd.read_csv(single)
df = dff[cols]
print(df)


# ### Numpy  [from df, to dic, to list]

# In[ ]:


arr = df.to_numpy()  #convert df to np
print(arr[0][0])   #printing an index value of numpy arr
rw, col = arr.shape #last row, last column
print(rw,col)

#loop and access
lst = []
dic = {}
for i in range(rw):
    lst2 = []
    for j in range(col):
        #print(arr[i][j])      #print Row by index
        lst2.append(arr[i][j]) #create a list
    dic.update( {i : lst2} ) #create dict
#print(dic)


# ### Numpy [add col from list]

# In[ ]:


#add new column derived from existing one
lst3 = []
for i in range(rw):
    x = arr[i][2] #only printing summary
    if 'DOWN' in x:
        lst3.append('down')
    else:
        lst3.append('no')
arr = np.append(arr, np.array([lst3]).transpose(), axis=1)
df = pd.DataFrame(arr)
print(df)


# # List

# In[ ]:


#derived list from df
dff = pd.Series(df['CustomAttr15'])
mlst1 = dff.to_list()
mlst2 = df.values.tolist()
mlst3 = df.columns.values.tolist()
mlst4 = df['Summary'].values.tolist()
mlst5 = df[['Summary','LastOccurrence']].values.tolist()
#print(mlst4)

def lp_1d_list(mlst1):
    i = 0
    for i in range(len(mlst1)):
        print(mlst1[i])
        i = i + 1
def lp_nested_seperate_2_list(mlst1,mlst4):
    for a in mlst1:
        for b in mlst4:
            print(a,">",b)
def lp_nested_list(mlst2):
    for i in range(len(mlst2)):
        for j in range(len(mlst2[i])):
            print(mlst2[i][j])

# List Methods append(), count(), index(), pop(), sort()
fruits = ['apple', 'banana', 'cherry','banana']
fruits.append("orange")
print(fruits)
print(fruits.count("banana"))
print(fruits.index("cherry"))
fruits = ['apple', 'banana', 'cherry']
cars = ['Ford', 'BMW', 'Volvo']
fruits.extend(cars)
print(fruits) #JOIN 2 LIST
fruits = fruits.pop(1)
print(fruits)fruits.extend(cars)


# # dictionary

# In[ ]:


dic1 = {}
dic2 = {1: 'apple', 2: 'ball'}
dic3 = {'name': 'John', 1: [2, 4, 3]}
dic4 = dict({1:'apple', 2:'ball'})
dic5 = dict([(1,'apple'), (2,'ball')])

#create dictionary from 2 list (as key , as value)
dlist = dict(zip(mlst1, mlst5))
#print(dlist)

#dataframe to dictionary
ddf1 = df.to_dict()

def lp_dic(ddf1):
    for key in ddf1:
        print(key,ddf1[key])
    for v in ddf1.values():
        print(v)
def lp_key_wise(dl):
    for k,v in dlist.items():
        print("STCODE:", k, ":", v[0],',', v[1])
        
lp_key_wise(dlist)
#Method of Dictionary fromkeys(), get(), items(), keys(), values(), pop(), update()
person = {'name': 'Phill', 'age': 22}
#print(person.get('name'))

d = {1: "one", 2: "three"}
d1 = {2: "two"}
d.update(d1)
#print(d)

person = {'name': 'Phill'}
person.setdefault('age', 22)
#print(person)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\DTTEST-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
import MySQLdb
from datetime import *

db = os.getcwd() + "\\OMDB.csv"
semcol = os.getcwd() + "\\semcols.txt"
cat = os.getcwd() + "\\catdef.txt"
conn= MySQLdb.connect("localhost","root","admin","om2")

x = datetime.now()
y = datetime.strftime(x, "%m-%d-%Y %H:%M:%S")
print(y)
svpt = os.getcwd() + "\\OMDW.csv"
df = pd.read_csv(svpt)

df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'])
df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
df = df.assign(NW = y)
df['DUR'] = df.apply(lambda x : pd.to_datetime(x.NW) - pd.to_datetime(x.LASTOCCURRENCE) ,axis=1)
df['DUR'] = df['DUR'].astype('timedelta64[m]')
print(df)
#df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
#df = df.assign(NW = y)
#print(df.dtypes)
#df['DUR'] = pd.to_datetime(y - pd.to_datetime(df['LASTOCCURRENCE'])
#df['DUR'] = df.apply(lambda x : y - pd.to_datetime(x.LASTOCCURRENCE)) ,axis=1)


# In[27]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\DTTEST.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import os
import MySQLdb
from datetime import *

db = os.getcwd() + "\\OMDB.csv"
semcol = os.getcwd() + "\\semcols.txt"
cat = os.getcwd() + "\\catdef.txt"
conn= MySQLdb.connect("localhost","root","admin","om2")

x = datetime.now()
y = datetime.strftime(x, "%m-%d-%Y %H:%M:%S")
svpt = os.getcwd() + "\\OMDW.csv"
df = pd.read_csv(svpt)
df['LASTOCCURRENCE'] = pd.to_datetime(df['LASTOCCURRENCE'])
df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
df = df.assign(NW = y)
df['DUR'] = df.apply(lambda x : pd.to_datetime(x.NW) - pd.to_datetime(x.LASTOCCURRENCE) ,axis=1)
df['DUR'] = df['DUR'].astype('timedelta64[m]')
#df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].map(lambda x: x.strftime("%d/%m/%Y %H:%M:%S"))
#df = df.assign(NW = y)
#print(df.dtypes)
#df['DUR'] = pd.to_datetime(y - pd.to_datetime(df['LASTOCCURRENCE'])
#df['DUR'] = df.apply(lambda x : y - pd.to_datetime(x.LASTOCCURRENCE)) ,axis=1)


# In[ ]:


df


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[8]:


import pandas as pd
import os
import numpy
import MySQLdb

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"
single = os.getcwd() + "\\" + "single.csv"
pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else "NA"))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    txt = PN_Format(dff.to_dict(),ls3)
    write2txt(pntxt,txt)
    return txt




df = pd.read_csv(single)
dc = df.to_dict()
#print(df)
print(PN(dc))




#
#dfc = pd.read_csv(omdb)
#print(dfc)
#dic = dfc.to_dict()
#x = omdf(dic)
#x.df_cond1()
#y = pd.DataFrame(x.df_addcol_lamda())
#print(y)

#map_dictionary ={'HUW-MAINS FAILURE' : "MF", 'ERI-AC MAINS FAILURE' :"MF", 'HUW-2G SITE DOWN' :"2G"} 
#z = pd.DataFrame(x.df_addcol_fdic(map_dictionary,"Cat2"))
#print(z)

#x.df_iterate_col('CUSTOMATTR15')
#z = x.df_iterate_col('Summary')




#ndf1 = df[df['Summary'].str.contains("MAINS|2G SITE DOWN|3G SITE DOWN|4G SITE DOWN|DC LOW", na=False)]
#ndf1.to_csv(thispath)
#sr = pd.Series(df['Summary'])
#df['cat'] = df["Summary"].str.contains("MAINS")
#print(df)
#ts('VOLTAGE')


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf.py###
#!/usr/bin/env python
# coding: utf-8

# In[9]:


import pandas as pd
import os
import numpy
import MySQLdb

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"
single = os.getcwd() + "\\" + "single.csv"
pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else "NA"))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    dff = mergedDf[mergedDf['CUSTOMATTR24'].str.contains('YES')]
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    txt = PN_Format(dff.to_dict(),ls3)
    write2txt(pntxt,txt)
    return txt

df = pd.read_csv(single)
dc = df.to_dict()
#print(df)
print(PN(dc))


#
#dfc = pd.read_csv(omdb)
#print(dfc)
#dic = dfc.to_dict()
#x = omdf(dic)
#x.df_cond1()
#y = pd.DataFrame(x.df_addcol_lamda())
#print(y)

#map_dictionary ={'HUW-MAINS FAILURE' : "MF", 'ERI-AC MAINS FAILURE' :"MF", 'HUW-2G SITE DOWN' :"2G"} 
#z = pd.DataFrame(x.df_addcol_fdic(map_dictionary,"Cat2"))
#print(z)

#x.df_iterate_col('CUSTOMATTR15')
#z = x.df_iterate_col('Summary')


#ndf1 = df[df['Summary'].str.contains("MAINS|2G SITE DOWN|3G SITE DOWN|4G SITE DOWN|DC LOW", na=False)]
#ndf1.to_csv(thispath)
#sr = pd.Series(df['Summary'])
#df['cat'] = df["Summary"].str.contains("MAINS")
#print(df)
#ts('VOLTAGE')


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_M-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[6]:


import cx_Oracle
import time
from datetime import date
import pandas as pd
import os
import numpy
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"

pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"
pth = os.getcwd() + "\\" + "WRT1.csv"
pth2 = os.getcwd() + "\\" + "WRT2.csv"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def ByCat(dic,lis,strval):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains(strval) & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            hd = str(lis[j]) + ": " + str(g2.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        heaps = "National: " + str(G2T) + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        hd = "Update of Site Down at " + odt.hrmin() + ' On ' + odt.dtmnyr()
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = hd + '\n' + '\n' + reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    dfx = pd.DataFrame(dfs1)
    dfx.to_csv(pth)
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    #dff = mergedDf[mergedDf['BCCH'].str.contains('YES')]
    mergedDf.to_csv(pth2)
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    #print(ByCat(mergedDf.to_dict(),ls3,"4G"))
    txt = PN_Format(mergedDf.to_dict(),ls3)
    txtpw = PNPW(mergedDf.to_dict(),ls3)
    #print(txtpw)
    #write2txt(pntxt,txt)
    return txt

def semqry1(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()

#df2g = df_all[df_all['SUMMARY'].str.contains('RRU THEFT')]
#single = os.getcwd() + "\\" + "SingleClick.csv"
dcc1 = semqry1('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
dcc2 = pd.DataFrame(dcc1)
#df = pd.DataFrame(PN(dcc2)
#print(df)




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_M.py###
#!/usr/bin/env python
# coding: utf-8

# In[6]:


import cx_Oracle
import time
from datetime import date
import pandas as pd
import os
import numpy
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"

pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"
pth = os.getcwd() + "\\" + "WRT1.csv"
pth2 = os.getcwd() + "\\" + "WRT2.csv"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def ByCat(dic,lis,strval):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains(strval) & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            hd = str(lis[j]) + ": " + str(g2.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        heaps = "National: " + str(G2T) + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        hd = "Update of Site Down at " + odt.hrmin() + ' On ' + odt.dtmnyr()
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = hd + '\n' + '\n' + reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    dfx = pd.DataFrame(dfs1)
    dfx.to_csv(pth)
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    #dff = mergedDf[mergedDf['BCCH'].str.contains('YES')]
    mergedDf.to_csv(pth2)
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    #print(ByCat(mergedDf.to_dict(),ls3,"4G"))
    txt = PN_Format(mergedDf.to_dict(),ls3)
    txtpw = PNPW(mergedDf.to_dict(),ls3)
    #print(txtpw)
    #write2txt(pntxt,txt)
    return txt

def semqry1(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()

#df2g = df_all[df_all['SUMMARY'].str.contains('RRU THEFT')]
#single = os.getcwd() + "\\" + "SingleClick.csv"
dcc1 = semqry1('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
dcc2 = pd.DataFrame(dcc1)
#df = pd.DataFrame(PN(dcc2)
#print(df)




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_mod_2-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[6]:


import cx_Oracle
import time
from datetime import date
import pandas as pd
import os
import numpy
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)


#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def ByCat(dic,lis,strval):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains(strval) & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            hd = str(lis[j]) + ": " + str(g2.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        heaps = "National: " + str(G2T) + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        hd = "Update of Site Down at " + odt.hrmin() + ' On ' + odt.dtmnyr()
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = hd + '\n' + '\n' + reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    dfx = pd.DataFrame(dfs1)
    dfx.to_csv(pth)
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    #dff = mergedDf[mergedDf['BCCH'].str.contains('YES')]
    mergedDf.to_csv(pth2)
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    #print(ByCat(mergedDf.to_dict(),ls3,"4G"))
    txt = PN_Format(mergedDf.to_dict(),ls3)
    txtpw = PNPW(mergedDf.to_dict(),ls3)
    #print(txtpw)
    #write2txt(pntxt,txt)
    return txt

def semqry1(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()


#df2g = df_all[df_all['SUMMARY'].str.contains('RRU THEFT')]
#dcc1 = os.getcwd() + "\\" + "SingleClick.csv"
#dcc1 = semqry1('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
#dcc2 = pd.DataFrame(dcc1)
#df = pd.DataFrame(PN(dcc2)
#print(df)

csvfl = os.getcwd() + "\\" + "DWRRU.csv"


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_mod_2.py###
#!/usr/bin/env python
# coding: utf-8

# In[3]:


import cx_Oracle
import time
from datetime import date
import pandas as pd
import os
import numpy
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)


#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))



def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def ByCat(dic,lis,strval):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains(strval) & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            hd = str(lis[j]) + ": " + str(g2.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        heaps = "National: " + str(G2T) + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        hd = "Update of Site Down at " + odt.hrmin() + ' On ' + odt.dtmnyr()
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = hd + '\n' + '\n' + reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    dfx = pd.DataFrame(dfs1)
    dfx.to_csv(pth)
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    #dff = mergedDf[mergedDf['BCCH'].str.contains('YES')]
    mergedDf.to_csv(pth2)
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    #print(ByCat(mergedDf.to_dict(),ls3,"4G"))
    txt = PN_Format(mergedDf.to_dict(),ls3)
    txtpw = PNPW(mergedDf.to_dict(),ls3)
    #print(txtpw)
    #write2txt(pntxt,txt)
    return txt

def semqry1(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()


#df2g = df_all[df_all['SUMMARY'].str.contains('RRU THEFT')]
#dcc1 = os.getcwd() + "\\" + "SingleClick.csv"
#dcc1 = semqry1('SEMHEDB.ALERTS_STATUS','SOC_READ','soc_read',' * ')
#dcc2 = pd.DataFrame(dcc1)
#df = pd.DataFrame(PN(dcc2)
#print(df)

csvfl = os.getcwd() + "\\" + "DWRRU.csv"
df = pd.read_csv(csvfl)
print(df)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_mon-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[22]:


import pandas as pd
import os
import numpy
import MySQLdb
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"
single = os.getcwd() + "\\" + "SingleClick.csv"
pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"
pth = os.getcwd() + "\\" + "WRT1.csv"
pth2 = os.getcwd() + "\\" + "WRT2.csv"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def ByCat(dic,lis,strval):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains(strval) & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            hd = str(lis[j]) + ": " + str(g2.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        heaps = "National: " + str(G2T) + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        hd = "Update of Site Down at " + odt.hrmin() + ' On ' + odt.dtmnyr()
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = hd + '\n' + '\n' + reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    dfx = pd.DataFrame(dfs1)
    dfx.to_csv(pth)
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    #dff = mergedDf[mergedDf['BCCH'].str.contains('YES')]
    mergedDf.to_csv(pth2)
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    #print(ByCat(mergedDf.to_dict(),ls3,"4G"))
    txt = PN_Format(mergedDf.to_dict(),ls3)
    txtpw = PNPW(mergedDf.to_dict(),ls3)
    #print(txtpw)
    #write2txt(pntxt,txt)
    return txt


df = pd.read_csv(single)
dc = df.to_dict()
print(PN(dc))




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_mon.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import os
import numpy
import MySQLdb
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"

pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"
pth = os.getcwd() + "\\" + "WRT1.csv"
pth2 = os.getcwd() + "\\" + "WRT2.csv"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = list(self.df.columns.values)
        self.aList = []
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()

def PNPW(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('MF') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('DL') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        reg = 'Region: ' + 'MF/DL'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T)
        heaps = reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def ByCat(dic,lis,strval):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains(strval) & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            hd = str(lis[j]) + ": " + str(g2.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        heaps = "National: " + str(G2T) + '\n' + '\n' + heap
        return heaps
    
def PN_Format(dic,lis):
        ndf = pd.DataFrame(dic)
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        G2T = 0
        G3T = 0
        G4T = 0
        heap = ""
        for i in lis:
            g2 = ndf[ndf['cat'].str.contains('2G') & ndf['Zone'].str.contains(lis[j])]
            g3 = ndf[ndf['cat'].str.contains('3G') & ndf['Zone'].str.contains(lis[j])]
            g4 = ndf[ndf['cat'].str.contains('4G') & ndf['Zone'].str.contains(lis[j])]
            G2T = g2.shape[0] + G2T
            G3T = g3.shape[0] + G3T
            G4T = g4.shape[0] + G4T
            hd = str(lis[j]) + ": " + str(g2.shape[0]) + "/" + str(g3.shape[0]) + "/" + str(g4.shape[0])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        hd = "Update of Site Down at " + odt.hrmin() + ' On ' + odt.dtmnyr()
        reg = 'Region: ' + '2G/3G/4G'
        Nat = 'National: ' + str(G2T) + '/' + str(G3T) + '/' + str(G4T)
        heaps = hd + '\n' + '\n' + reg + '\n' + Nat + '\n' + '\n' + heap
        return heaps

def PN(dicc):
    ls1 = ['CustomAttr15','Resource','Summary','LastOccurrence','BCCH']
    ls2 = ['Code','Zone']
    dfsingle = pd.DataFrame(dicc)
    dfomdb = pd.read_csv(omdb)
    dfs = dfsingle[ls1]
    dfdb = dfomdb[ls2]
    x1 = omdf(dfs)
    dfs1 = x1.df_addcol_lamda()
    dfx = pd.DataFrame(dfs1)
    dfx.to_csv(pth)
    x2 = omdf(dfs1)
    dfs2 = pd.DataFrame(x2.df_apply_on_col('Code'))
    mergedDf = dfs2.merge(dfdb, on='Code')
    #dff = mergedDf[mergedDf['BCCH'].str.contains('YES')]
    mergedDf.to_csv(pth2)
    ls3 = ['DHK_S','DHK_N','DHK_M','CTG_S','CTG_N','CTG_M','COM','NOA','SYL','MYM','BAR','KHL','KUS','RAJ','RANG']
    #print(ByCat(mergedDf.to_dict(),ls3,"4G"))
    txt = PN_Format(mergedDf.to_dict(),ls3)
    txtpw = PNPW(mergedDf.to_dict(),ls3)
    print(txtpw)
    #write2txt(pntxt,txt)
    return txt

single = os.getcwd() + "\\" + "DWRRU.csv"
df = pd.read_csv(single)
#dc = df.to_dict()
#print(PN(dc))
print(df)



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_rru-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[3]:


import pandas as pd
import os
import numpy
import MySQLdb
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"
pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"
pth = os.getcwd() + "\\" + "WRT1.csv"
pth2 = os.getcwd() + "\\" + "WRT2.csv"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()


cols = ["SERIAL","EQUIPMENTKEY","CUSTOMATTR15","SUMMARY","LASTOCCURRENCE","CLEARTIMESTAMP","ALARMDETAILS","CUSTOMATTR15"]
single = os.getcwd() + "\\" + "DWRRU.csv"
df = pd.read_csv(single)
df2 = df[cols]
df2['count'] = df2['CUSTOMATTR15'].value_counts()
print(df2)
#df3 = df2.replace(np.nan,0)
#print(df2)



codelist = [df['CUSTOMATTR15'].to_list()]
print(codelist)



#Codelist = df2['CUSTOMATTR15']


#df2['cnt'] = df2['CUSTOMATTR15'].value_counts()
#print(df2)


#df2['cnt'] = lambda x : x.df2['CUSTOMATTR15'].value_counts()
#df['count'] = df['CUSTOMATTR15'].value_counts()
#print(df)
#print(df2)

#print(fdf['CUSTOMATTR15'].value_counts())
#df3 = df2.apply(lambda s: s['CUSTOMATTR15'], axis=1)
#df4 = df['CUSTOMATTR15'].value_counts().loc[lambda x : ]


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fndf_rru.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
import os
import numpy
import MySQLdb
import omdtfn as odt

#conn= MySQLdb.connect("localhost","root","admin","omdb")
#df_mysql = pd.read_sql("select * from sitedb",conn)
omdb = os.getcwd() + "\\" + "OMDB.csv"
pntxt = os.getcwd() + "\\" + "Periodic_Notification.txt"
pth = os.getcwd() + "\\" + "WRT1.csv"
pth2 = os.getcwd() + "\\" + "WRT2.csv"

#lambda <args> : <return Value> if <condition > ( <return value > if <condition> else <return value>)
TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def write2txt(flname,txt):
    fo = open(flname,"w+")
    txt = fo.write(txt)
    fo.close()

class omdf:
    def __init__(self,dic):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
    def df_addcol_lamda(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_addcol_fdic(self,d,newcolname):
        self.df[newcolname] = self.df['scode'].map(d)
        return self.df.to_dict()
    def df_apply_on_col(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_remove_col_by_list(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()


cols = ["SERIAL","EQUIPMENTKEY","CUSTOMATTR15","SUMMARY","LASTOCCURRENCE","CLEARTIMESTAMP","ALARMDETAILS","CUSTOMATTR15"]
single = os.getcwd() + "\\" + "DWRRU.csv"
df = pd.read_csv(single)
df2 = df[cols]
print(df2['CUSTOMATTR15'].value_counts())
print(df2)
#df3 = df2.replace(np.nan,0)
#print(df2)



#codelist = [df['CUSTOMATTR15'].to_list()]
#print(codelist)



#Codelist = df2['CUSTOMATTR15']


#df2['cnt'] = df2['CUSTOMATTR15'].value_counts()
#print(df2)


#df2['cnt'] = lambda x : x.df2['CUSTOMATTR15'].value_counts()
#df['count'] = df['CUSTOMATTR15'].value_counts()
#print(df)
#print(df2)

#print(fdf['CUSTOMATTR15'].value_counts())
#df3 = df2.apply(lambda s: s['CUSTOMATTR15'], axis=1)
#df4 = df['CUSTOMATTR15'].value_counts().loc[lambda x : ]


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fnstr-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[38]:


import pandas as pd
import os
import numpy
import MySQLdb

conn= MySQLdb.connect("localhost","root","admin","omdb")
file = os.getcwd() + "\\" + "BK1.csv"

class omstring:
    def __init__(self):
        print('x')
    def chk_rcut(self,txt,findchr):
        x = txt.find(findchr)
        ln = len(txt)
        if x != -1:
            return txt[x:ln]
        else:
            return '0'
    def chk_lcut(self,txt,findchr):
        x = txt.find(findchr)
        if x != -1:
            return txt[0:x]
        else:
            return '0'
    def midcut(self,txt,fromindx,toindx):
        return txt[fromindx : toindx]
    def instr(self,txt,chkchr):
        return txt.find(chkchr)
    def instrrev(self,txt,chkchr):
        return txt.rindex(chkchr)
    def str_split(self,txt,splitby):
        return txt.split(splitby)
    def str_chrocc(self,txt,chrchk):
        return txt.count(chrchk)
    def str_trim(self,txt):
        return txt.strip()
    def instr_st_end(self,txt,chkstr,st,end):
        return txt.find(chkstr, st, end)
    def isall_digit(self,txt):
        return txt.isdigit(self)
    def isall_alphabet(self,text):
        return txt.isalpha()
    def isall_number(self,text):
        return txt.isnumeric()
    def str_tolower(self,text):
        return txt.casefold()
    def str_toupper(self,txt):
        return txt.upper()
    def str_chktype(self,txt):
        return type(txt)
    



df_mysql = pd.read_sql("select * from sitedb",conn)
df_csv = pd.read_csv(file)
st = """Close Notification:*13 3G & 11 4G Sites in Barisal are gradually up*
        Severity: C-3*FT: 14:36 to 14:47_26/04*RT: 18:31_26/04*DUR: 03:55*Link: SPZNR02-SPZNR04*
        Cause: VLAN missmatched at SPZNR02 during TNR CRQ000000224351
        (Slogan: NCCD Abis_oIP Project FE configure at VLAN Barishal zone)"""
y = omstring()
print(y.instr(st,'VLAN'))


# In[33]:


y.chk_rcut(st,"CRQ0")


# In[22]:


y.midcut(st,3,10)


# In[25]:


y.instr(st,'VLAN')


# In[42]:


y.instrrev(st,'VLAN')


# In[43]:


y.midcut(st,0,21)


# In[44]:


y.midcut(st,y.instr(st,'VLAN'),y.instrrev(st,'VLAN'))


# In[45]:


y.str_chktype(st)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\fnstr.py###
#!/usr/bin/env python
# coding: utf-8

# In[38]:


import pandas as pd
import os
import numpy
import MySQLdb

conn= MySQLdb.connect("localhost","root","admin","omdb")
file = os.getcwd() + "\\" + "BK1.csv"
df_mysql = pd.read_sql("select * from sitedb",conn)
df_csv = pd.read_csv(file)

class omstring:
    def __init__(self):
        print('x')
    def chk_rcut(self,txt,findchr):
        x = txt.find(findchr)
        ln = len(txt)
        if x != -1:
            return txt[x:ln]
        else:
            return '0'
    def chk_lcut(self,txt,findchr):
        x = txt.find(findchr)
        if x != -1:
            return txt[0:x]
        else:
            return '0'
    def midcut(self,txt,fromindx,toindx):
        return txt[fromindx : toindx]
    def instr(self,txt,chkchr):
        return txt.find(chkchr)
    def instrrev(self,txt,chkchr):
        return txt.rindex(chkchr)
    def str_split(self,txt,splitby):
        return txt.split(splitby)
    def str_chrocc(self,txt,chrchk):
        return txt.count(chrchk)
    def str_trim(self,txt):
        return txt.strip()
    def instr_st_end(self,txt,chkstr,st,end):
        return txt.find(chkstr, st, end)
    def isall_digit(self,txt):
        return txt.isdigit(self)
    def isall_alphabet(self,text):
        return txt.isalpha()
    def isall_number(self,text):
        return txt.isnumeric()
    def str_tolower(self,text):
        return txt.casefold()
    def str_toupper(self,txt):
        return txt.upper()
    def str_chktype(self,txt):
        return type(txt)
    

st = """Close Notification:*13 3G & 11 4G Sites in Barisal are gradually up*
        Severity: C-3*FT: 14:36 to 14:47_26/04*RT: 18:31_26/04*DUR: 03:55*Link: SPZNR02-SPZNR04*
        Cause: VLAN missmatched at SPZNR02 during TNR CRQ000000224351
        (Slogan: NCCD Abis_oIP Project FE configure at VLAN Barishal zone)"""
y = omstring()
print(y.instr(st,'VLAN'))


# In[33]:


y.chk_rcut(st,"CRQ0")


# In[22]:


y.midcut(st,3,10)


# In[25]:


y.instr(st,'VLAN')


# In[42]:


y.instrrev(st,'VLAN')


# In[43]:


y.midcut(st,0,21)


# In[44]:


y.midcut(st,y.instr(st,'VLAN'),y.instrrev(st,'VLAN'))


# In[45]:


y.str_chktype(st)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\jy1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
import numpy as np
import os


def myFun(arg1, *argv, **kwargs): 
    print ("First argument :", arg1) 
    for arg in argv:
        print("Next argument through *argv :", arg)

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    df['cnt'] = np.array(fls)
    print(df)
        
db = os.getcwd() + "\\OMDB.csv"
livedb = os.getcwd() + "\\robi_live.csv"
xa = os.getcwd() + "\\xa.csv"
sclick = os.getcwd() + "\\OMTX_2.csv"
df = pd.read_csv(sclick)
ls_sclick = ['Severity','Node','Resource']
dc_sclick = {'Severity': 'Severity','Node':'Node','Resource':'Resource'}
#oFn1(df,'Severity','CustomAttr15', Severity = 'Critical', CustomAttr15 = 'CustomAttr15')


#df1 = df.groupby(['CustomAttr15','Summary'])['Summary'].count()
#print(df1)


# In[7]:


TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('Cell_2G' if ('2G CELL DOWN' in x)                 else ('Cell_3G' if ('3G CELL DOWN' in x)                 else ('Cell_4G' if ('4G CELL DOWN' in x)                 else "other")))))

dfdb1 = pd.read_csv(db)
dfdb = dfdb1[['Code','Zone']]
mdf = df.rename(columns=str.upper)
df1 = df.assign (coln='cat')
df1 = df1.assign (coln='Code')
df1['cat'] = df1.apply(lambda x: TS(x.SUMMARY), axis = 1)
df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
df2 = df1.merge(dfdb, on='Code')


#dfg = df2.groupby(['Zone','cat'])[''].count().to_frame (name='AB').reset_index ()
#dfg2 = df2.pivot_table(values='cat', index = 'Zone', columns = 'CustomAttr15')
#print(dfg2)
dfg1 = df2.groupby(['Zone','cat']).cat.count()
#print(dfg1.unstack(),chr(10),"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")

getgrp = df2.groupby(['cat','Zone'])['CUSTOMATTR15'].get_group(('2G','BAR'))
print(getgrp)

#d = {'2G SITE':'ERI-2G SITE DOWN', '3G SITE':'ERI-3G SITE DOWN'}
#print(getList(d)) 
#for key, value in d.items() if 'new york' in key.upper():
#print(value)


# In[ ]:


dfT = pd.DataFrame({'x': ['A', 'B', 'A', 'B'], 'y': [1, 4, 3, 2]})
data_frame['Name'] = data_frame['Name'].apply(lambda name : name.upper())


# In[8]:


dfT.groupby(['x']).get_group('A')


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\jy1.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
import numpy as np
import os


def myFun(arg1, *argv, **kwargs): 
    print ("First argument :", arg1) 
    for arg in argv:
        print("Next argument through *argv :", arg)

def oFn1(df, *argv, **kwargs):
    ls = []
    col = df.columns.to_list()
    for n in range(len(argv)):
        TempLs = df[argv[n]].values.tolist()
        if len(ls) == 0:
            ls = TempLs
        else:
            tls = [i + j for i, j in zip(ls, TempLs)]
            ls = tls
    ld = []
    for key,value in kwargs.items():
        if col.count(value) != 0:
            TmpLd = df[value].to_list()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
        else:
            ar = np.full(df.shape[0], value)
            TmpLd = ar.tolist()
            if len(ld) == 0:
                ld = TmpLd
            else:
                tld = [i + j for i, j in zip(ld, TmpLd)]
                ld = tld
    fls = []
    for i in range(len(ld)):
        x = ls.count(ld[i])
        fls.append(x)
    colx = 'C' + str(df.shape[1])
    df[colx] = np.array(fls)
    return df
        
db = os.getcwd() + "\\OMDB.csv"
livedb = os.getcwd() + "\\robi_live.csv"
xa = os.getcwd() + "\\xa.csv"
sclick = os.getcwd() + "\\OMTX_2.csv"
df = pd.read_csv(sclick)
ls_sclick = ['Severity','Node','Resource']
dc_sclick = {'Severity': 'Severity','Node':'Node','Resource':'Resource'}
#oFn1(df,'Severity','CustomAttr15', Severity = 'Critical', CustomAttr15 = 'CustomAttr15')


#df1 = df.groupby(['CustomAttr15','Summary'])['Summary'].count()
#print(df1)


# In[8]:


TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('Cell_2G' if ('2G CELL DOWN' in x)                 else ('Cell_3G' if ('3G CELL DOWN' in x)                 else ('Cell_4G' if ('4G CELL DOWN' in x)                 else "other")))))

dfdb1 = pd.read_csv(db)
dfdb = dfdb1[['Code','Zone']]
mdf = df.rename(columns=str.upper)
df1 = df.assign (coln='cat')
df1 = df1.assign (coln='Code')
df1['cat'] = df1.apply(lambda x: TS(x.SUMMARY), axis = 1)
df1['Code'] = df1.apply(lambda x: x.CUSTOMATTR15[0:5], axis = 1)
df2 = df1.merge(dfdb, on='Code')


#dfg = df2.groupby(['Zone','cat'])[''].count().to_frame (name='AB').reset_index ()
#dfg2 = df2.pivot_table(values='cat', index = 'Zone', columns = 'CustomAttr15')
#print(dfg2)
dfg1 = df2.groupby(['Zone','cat']).cat.count()
#print(dfg1.unstack(),chr(10),"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~")

getgrp = df2.groupby(['cat','Zone'])['CUSTOMATTR15'].get_group(('2G','BAR'))
print(getgrp)

#d = {'2G SITE':'ERI-2G SITE DOWN', '3G SITE':'ERI-3G SITE DOWN'}
#print(getList(d)) 
#for key, value in d.items() if 'new york' in key.upper():
#print(value)


# In[ ]:


dfT = pd.DataFrame({'x': ['A', 'B', 'A', 'B'], 'y': [1, 4, 3, 2]})
data_frame['Name'] = data_frame['Name'].apply(lambda name : name.upper())


# In[8]:


dfT.groupby(['x']).get_group('A')


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\lamda-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[13]:


import pandas as pd
import numpy as np
import os

cols = ["SERIAL","EQUIPMENTKEY","CUSTOMATTR15","SUMMARY","LASTOCCURRENCE","CLEARTIMESTAMP","ALARMDETAILS"]
single = os.getcwd() + "\\" + "DWRRU.csv"
df = pd.read_csv(single)
df2 = df[cols]
df2.fillna(0)
code= [df2['CUSTOMATTR15'].value_counts(dropna=False)]
print(code)
#df3 = df2.replace(np.nan,0)

#df2['count'] = codecount
#df2 = df2.replace(np.nan,0)
#print(df2)
#pt = os.getcwd() + "\\" + "DW1709.csv"
#df2.to_csv(pt)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\lamda.py###
#!/usr/bin/env python
# coding: utf-8

# In[73]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["SERIAL","EQUIPMENTKEY","CUSTOMATTR15","SUMMARY","LASTOCCURRENCE","CLEARTIMESTAMP","ALARMDETAILS"]
td = date.today()
pt = os.getcwd() + "\\" + "RRU_" + td.strftime('%Y-%m-%d') + ".csv"


TS2 = lambda y : ('NA' if (y is None) else y)

single = os.getcwd() + "\\" + "DWRRU.csv"
df = pd.read_csv(single)
df2 = df[cols] #pick customized column using list
df2['ABC'] = df2.apply(lambda x : TS2(df2['CUSTOMATTR15'].value_counts()),axis=1)

#code= [df2['CUSTOMATTR15'].value_counts(dropna=False)]
#ndf = pd.DataFrame(code).T  #list to dataframe
#ndf.to_csv(pt)



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\omdf_loop-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[10]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
print(single)
df = pd.read_csv(single)
Rn = df[cols]
#print(Rn)
count = 1

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def loop(Rn):
    for rw in range(Rn.shape[0]):
        rwvalue1 = Rn.iloc[rw , 1]  #on Column 1
        rwvalue2 = Rn.iloc[rw , 2]  ##on Column 2
        rwvalue3 = Rn.iloc[rw , 3]  ##on Column 3
        count = count + 1
        print('Row Number', count , ':', rwvalue1, '>', rwvalue2, '>', rwvalue3)
    for column in Rn[['CustomAttr15']]:
        colseries = Rn[column]
        print(colseries.values) #Transposed value of Column
    for (colname, coldata) in RnA2E.iteritems():
        print(colname) #Column Name
        print(coldata.values) #Transposed value of Column
        print('end')

class omdf:
    def __init__(self,dff):
        self.df = dff
        self.arr = self.df.to_numpy()
    def df_add_col_instr(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_add_col_dic(self,colname,newcol,dic):
        self.df[newcol] = self.df['scode'].map(dic)
        return self.df.to_dict()
    def df_add_col_slice_str(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_rmv_column(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()
    def df_countif(self,column_name,newcolumn_name):
        code = pd.Series(self.df[column_name])
        lst = code.values.tolist()
        dic = {}
        for i in lst:
            dic[i] = lst.count(i)
        df_occ = pd.DataFrame(dic.items(),columns=[column_name, newcolumn_name])
        mdf = self.df.merge(df_occ, on=column_name)
        return mdf
    def df_instr(self,colname,srcstr):
        self.df[srcstr] = list(map(lambda x: x.count(srcstr), self.df[colname]))
        return self.df
    def df_vlookup(self,df2,common_colname):
        mdf = self.df.merge(df2, on=common_colname)
        return mdf

    
    #Rn['ABC'] = list(map(lambda x: x.count("CXTKN"), Rn['CustomAttr15']))
#print(Rn)
#ndf = countif('CustomAttr15','CountOf')

x = omdf(Rn)

#ndf = x.df_instr('CustomAttr15','DHSDR')
#print(ndf)


# In[ ]:





# In[191]:


L = lambda df,colname,dic : df[colname].map(dic)
dic = {'ERI-2G SITE DOWN':'2G','ERI-3G SITE DOWN':'3G'}
#dv = [value for key, value in dic.items() if '2G SITE DOWN' in key]
print(L(Rn,'Summary',dic))


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\omdf_loop.py###
#!/usr/bin/env python
# coding: utf-8

# In[10]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
print(single)
df = pd.read_csv(single)
Rn = df[cols]
#print(Rn)
count = 1

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def loop(Rn):
    for rw in range(Rn.shape[0]):
        rwvalue1 = Rn.iloc[rw , 1]  #on Column 1
        rwvalue2 = Rn.iloc[rw , 2]  ##on Column 2
        rwvalue3 = Rn.iloc[rw , 3]  ##on Column 3
        count = count + 1
        print('Row Number', count , ':', rwvalue1, '>', rwvalue2, '>', rwvalue3)
    for column in Rn[['CustomAttr15']]:
        colseries = Rn[column]
        print(colseries.values) #Transposed value of Column
    for (colname, coldata) in RnA2E.iteritems():
        print(colname) #Column Name
        print(coldata.values) #Transposed value of Column
        print('end')

class omdf:
    def __init__(self,dff):
        self.df = dff
        self.arr = self.df.to_numpy()
    def df_add_col_instr(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_add_col_dic(self,colname,newcol,dic):
        self.df[newcol] = self.df['scode'].map(dic)
        return self.df.to_dict()
    def df_add_col_slice_str(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_rmv_column(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()
    def df_countif(self,column_name,newcolumn_name):
        code = pd.Series(self.df[column_name])
        lst = code.values.tolist()
        dic = {}
        for i in lst:
            dic[i] = lst.count(i)
        df_occ = pd.DataFrame(dic.items(),columns=[column_name, newcolumn_name])
        mdf = self.df.merge(df_occ, on=column_name)
        return mdf
    def df_instr(self,colname,srcstr):
        self.df[srcstr] = list(map(lambda x: x.count(srcstr), self.df[colname]))
        return self.df
    def df_vlookup(self,df2,common_colname):
        mdf = self.df.merge(df2, on=common_colname)
        return mdf

    
    #Rn['ABC'] = list(map(lambda x: x.count("CXTKN"), Rn['CustomAttr15']))
#print(Rn)
#ndf = countif('CustomAttr15','CountOf')

x = omdf(Rn)

#ndf = x.df_instr('CustomAttr15','DHSDR')
#print(ndf)


# In[ ]:





# In[191]:


L = lambda df,colname,dic : df[colname].map(dic)
dic = {'ERI-2G SITE DOWN':'2G','ERI-3G SITE DOWN':'3G'}
#dv = [value for key, value in dic.items() if '2G SITE DOWN' in key]
print(L(Rn,'Summary',dic))


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\omdic-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# ##### Create Dictionary

# In[4]:


dc1 = {'1': 'uno', '2': 'dos', '3': 'tres'}
dc2 = {'1': ['A','B'], '2': ['J','K'],'3':['X','Y']}
dc3 = {('a','b','c'),('x','y','z')}


# ##### Accessing Dic => Keys(), values(), Items() 

# In[5]:


print(dc2.keys())
print(dc2.values())
print(dc2.items())


# ##### merging 3 dictionary

# In[16]:


A = {'x': 10, 'y': 20}
B = {'y': 30, 'z': 40}
A.update(B)
A.update({'m':100,'n':200})
print(A)


# ##### Method => get()

# In[ ]:


print(A.get('x'))


# ##### create dictionary merging 2 list

# In[22]:


ls1 = ['1','2','3']
ls2 = ['a','b','c']
dc5 = {1: ls1, 2: ls2}
print(dc5)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\omdic.py###
#!/usr/bin/env python
# coding: utf-8

# ##### Create Dictionary

# In[4]:


dc1 = {'1': 'uno', '2': 'dos', '3': 'tres'}
dc2 = {'1': ['A','B'], '2': ['J','K'],'3':['X','Y']}
dc3 = {('a','b','c'),('x','y','z')}


# ##### Accessing Dic => Keys(), values(), Items() 

# In[5]:


print(dc2.keys())
print(dc2.values())
print(dc2.items())


# ##### merging 3 dictionary

# In[16]:


A = {'x': 10, 'y': 20}
B = {'y': 30, 'z': 40}
A.update(B)
A.update({'m':100,'n':200})
print(A)


# ##### Method => get()

# In[ ]:


print(A.get('x'))


# ##### create dictionary merging 2 list

# In[22]:


ls1 = ['1','2','3']
ls2 = ['a','b','c']
dc5 = {1: ls1, 2: ls2}
print(dc5)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\omvbdf-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
print(single)
df = pd.read_csv(single)
Rn = df[cols]
#print(Rn)
count = 1

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def loop(Rn):
    for rw in range(Rn.shape[0]):
        rwvalue1 = Rn.iloc[rw , 1]  #on Column 1
        rwvalue2 = Rn.iloc[rw , 2]  ##on Column 2
        rwvalue3 = Rn.iloc[rw , 3]  ##on Column 3
        count = count + 1
        print('Row Number', count , ':', rwvalue1, '>', rwvalue2, '>', rwvalue3)
    for column in Rn[['CustomAttr15']]:
        colseries = Rn[column]
        print(colseries.values) #Transposed value of Column
    for (colname, coldata) in RnA2E.iteritems():
        print(colname) #Column Name
        print(coldata.values) #Transposed value of Column
        print('end')

class omdf:
    def __init__(self,dff):
        self.df = dff
        self.arr = self.df.to_numpy()
    def df_add_col_instr(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_add_col_dic(self,colname,newcol,dic):
        self.df[newcol] = self.df['scode'].map(dic)
        return self.df.to_dict()
    def df_add_col_slice_str(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_rmv_column(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()
    def df_countif(self,column_name,newcolumn_name):
        code = pd.Series(self.df[column_name])
        lst = code.values.tolist()
        dic = {}
        for i in lst:
            dic[i] = lst.count(i)
        df_occ = pd.DataFrame(dic.items(),columns=[column_name, newcolumn_name])
        mdf = self.df.merge(df_occ, on=column_name)
        return mdf
    def df_instr(self,colname,srcstr):
        self.df[srcstr] = list(map(lambda x: x.count(srcstr), self.df[colname]))
        return self.df
    def df_vlookup(self,df2,common_colname):
        mdf = self.df.merge(df2, on=common_colname)
        return mdf

    
    #Rn['ABC'] = list(map(lambda x: x.count("CXTKN"), Rn['CustomAttr15']))
#print(Rn)
#ndf = countif('CustomAttr15','CountOf')

x = omdf(Rn)

#ndf = x.df_instr('CustomAttr15','DHSDR')
#print(ndf)


# In[ ]:





# In[ ]:


L = lambda df,colname,dic : df[colname].map(dic)
dic = {'ERI-2G SITE DOWN':'2G','ERI-3G SITE DOWN':'3G'}
#dv = [value for key, value in dic.items() if '2G SITE DOWN' in key]
print(L(Rn,'Summary',dic))


# In[ ]:



def Parse_Count_By_Match(df,lookup_value,lookup_colname,Pickcol1,Pickcol2,Pickcol3):
        hp = ""
        ndf = df[df[lookup_colname].str.contains(lookup_value, na=False)]
        for ind in ndf.index:
            code = str(ndf[Pickcol1][ind])
            lo = str(ndf[Pickcol2][ind])
            resource = str(ndf[Pickcol3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = lookup_value + ': \n' + hp
        return z
    
#print(Parse_Count_By_Match(Rn,'CXSDR','CustomAttr15',"Summary","LastOccurrence","CustomAttr11"))


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\omvbdf.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
print(single)
df = pd.read_csv(single)
Rn = df[cols]
#print(Rn)
count = 1

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('2_CELL' if ('2G CELL DOWN' in x)                 else ('3_CELL' if ('3G CELL DOWN' in x)                 else ('4_CELL' if ('4G CELL DOWN' in x)                 else "NA"))))))))))))

def loop(Rn):
    for rw in range(Rn.shape[0]):
        rwvalue1 = Rn.iloc[rw , 1]  #on Column 1
        rwvalue2 = Rn.iloc[rw , 2]  ##on Column 2
        rwvalue3 = Rn.iloc[rw , 3]  ##on Column 3
        count = count + 1
        print('Row Number', count , ':', rwvalue1, '>', rwvalue2, '>', rwvalue3)
    for column in Rn[['CustomAttr15']]:
        colseries = Rn[column]
        print(colseries.values) #Transposed value of Column
    for (colname, coldata) in RnA2E.iteritems():
        print(colname) #Column Name
        print(coldata.values) #Transposed value of Column
        print('end')

class omdf:
    def __init__(self,dff):
        self.df = dff
        self.arr = self.df.to_numpy()
    def df_add_col_instr(self):
        self.df['cat'] = self.df.apply(lambda row: TS(row.Summary), axis = 1)
        return self.df.to_dict()
    def df_add_col_dic(self,colname,newcol,dic):
        self.df[newcol] = self.df['scode'].map(dic)
        return self.df.to_dict()
    def df_add_col_slice_str(self,newcolname):
        self.df[newcolname] = self.df.apply(lambda x : x.CustomAttr15[0:5], axis = 1)
        return self.df.to_dict()
    def df_rmv_column(self,lis):
        ndf = self.df[lis]
        return ndf.to_dict()
    def df_countif(self,column_name,newcolumn_name):
        code = pd.Series(self.df[column_name])
        lst = code.values.tolist()
        dic = {}
        for i in lst:
            dic[i] = lst.count(i)
        df_occ = pd.DataFrame(dic.items(),columns=[column_name, newcolumn_name])
        mdf = self.df.merge(df_occ, on=column_name)
        return mdf
    def df_instr(self,colname,srcstr):
        self.df[srcstr] = list(map(lambda x: x.count(srcstr), self.df[colname]))
        return self.df
    def df_vlookup(self,df2,common_colname):
        mdf = self.df.merge(df2, on=common_colname)
        return mdf

    
#Rn['ABC'] = list(map(lambda x: x.count("CXTKN"), Rn['CustomAttr15']))
#print(Rn)
#ndf = countif('CustomAttr15','CountOf')

x = omdf(Rn)

#ndf = x.df_instr('CustomAttr15','DHSDR')
#print(ndf)


# In[ ]:





# In[ ]:


L = lambda df,colname,dic : df[colname].map(dic)
dic = {'ERI-2G SITE DOWN':'2G','ERI-3G SITE DOWN':'3G'}
#dv = [value for key, value in dic.items() if '2G SITE DOWN' in key]
print(L(Rn,'Summary',dic))


# In[ ]:



def Parse_rows_By_Match(df,lookup_value,lookup_colname,Pickcol1,Pickcol2,Pickcol3):
        hp = ""
        ndf = df[df[lookup_colname].str.contains(lookup_value, na=False)]
        for ind in ndf.index:
            code = str(ndf[Pickcol1][ind])
            lo = str(ndf[Pickcol2][ind])
            resource = str(ndf[Pickcol3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = lookup_value + ': \n' + hp
        return z
#print(Parse_rows_By_Match(Rn,'CXSDR','CustomAttr15',"Summary","LastOccurrence","CustomAttr11"))


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\om_dic_list-checkpoint.txt###
import pandas as pd
import numpy as np
import os
from datetime import date
import itertools

cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
dff = pd.read_csv(single)
df = dff[cols]



#derived list from df
dff = pd.Series(df['CustomAttr15'])
mlst1 = dff.to_list()
mlst2 = df.values.tolist()
mlst3 = df.columns.values.tolist()
mlst4 = df['Summary'].values.tolist()
mlst5 = df['LastOccurrence'].values.tolist()
#print(mlst4)

def lp_1d_list(mlst1):
    i = 0
    for i in range(len(mlst1)):
        print(mlst1[i])
        i = i + 1
def lp_nested_seperate_2_list(mlst1,mlst4):
    for a in mlst1:
        for b in mlst4:
            print(a,">",b)
def lp_nested_list(mlst2):
    for i in range(len(mlst2)):
        for j in range(len(mlst2[i])):
            print(mlst2[i][j])

# List Methods append(), count(), index(), pop(), sort()
fruits = ['apple', 'banana', 'cherry','banana']
fruits.append("orange")
print(fruits)

print(fruits.count("banana"))
print(fruits.index("cherry"))

fruits = ['apple', 'banana', 'cherry']
cars = ['Ford', 'BMW', 'Volvo']
fruits.extend(cars)
print(fruits) #JOIN 2 LIST

fruits = fruits.pop(1)
print(fruits)

dic1 = {}
dic2 = {1: 'apple', 2: 'ball'}
dic3 = {'name': 'John', 1: [2, 4, 3]}
dic4 = dict({1:'apple', 2:'ball'})
dic5 = dict([(1,'apple'), (2,'ball')])
#print(dic3)

#create dictionary from 2 list (as key , as value)
dlist = dict(zip(mlst1, mlst4))
#dataframe to dictionary
ddf1 = df.to_dict()

def lp_dic():
    for key in ddf1:
        print(key,ddf1[key])

for v in book.values():
    print(v)
    
#Method of Dictionary fromkeys(), get(), items(), keys(), values(), pop(), update()
person = {'name': 'Phill', 'age': 22}
#print(person.get('name'))

d = {1: "one", 2: "three"}
d1 = {2: "two"}
d.update(d1)
print(d)

person = {'name': 'Phill'}
person.setdefault('age', 22)
print(person)



$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\om_dic_list.txt###
import pandas as pd
import numpy as np
import os
from datetime import date
import itertools

cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
dff = pd.read_csv(single)
df = dff[cols]



#derived list from df
dff = pd.Series(df['CustomAttr15'])
mlst1 = dff.to_list()
mlst2 = df.values.tolist()
mlst3 = df.columns.values.tolist()
mlst4 = df['Summary'].values.tolist()
mlst5 = df[['Summary','LastOccurrence']].values.tolist()
#print(mlst4)

def lp_1d_list(mlst1):
    i = 0
    for i in range(len(mlst1)):
        print(mlst1[i])
        i = i + 1
def lp_nested_seperate_2_list(mlst1,mlst4):
    for a in mlst1:
        for b in mlst4:
            print(a,">",b)
def lp_nested_list(mlst2):
    for i in range(len(mlst2)):
        for j in range(len(mlst2[i])):
            print(mlst2[i][j])

# List Methods append(), count(), index(), pop(), sort()
fruits = ['apple', 'banana', 'cherry','banana']
fruits.append("orange")
print(fruits)

print(fruits.count("banana"))
print(fruits.index("cherry"))

fruits = ['apple', 'banana', 'cherry']
cars = ['Ford', 'BMW', 'Volvo']
fruits.extend(cars)
print(fruits) #JOIN 2 LIST

fruits = fruits.pop(1)
print(fruits)

dic1 = {}
dic2 = {1: 'apple', 2: 'ball'}
dic3 = {'name': 'John', 1: [2, 4, 3]}
dic4 = dict({1:'apple', 2:'ball'})
dic5 = dict([(1,'apple'), (2,'ball')])

#create dictionary from 2 list (as key , as value)
dlist = dict(zip(mlst1, mlst5))
#print(dlist)

#dataframe to dictionary
ddf1 = df.to_dict()

def lp_dic():
    for key in ddf1:
        print(key,ddf1[key])
    for v in ddf1.values():
        print(v)
def lp_key_wise(dl):
    for k,v in dlist.items():
        print("STCODE:", k, ":", v[0],',', v[1])
        
lp_key_wise(dlist)
#Method of Dictionary fromkeys(), get(), items(), keys(), values(), pop(), update()
person = {'name': 'Phill', 'age': 22}
#print(person.get('name'))

d = {1: "one", 2: "three"}
d1 = {2: "two"}
d.update(d1)
#print(d)

person = {'name': 'Phill'}
person.setdefault('age', 22)
#print(person)







$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\om_lib1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *












$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\om_lib1.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *












$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\o_final-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[7]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *

def o_print(my_dict):
    for key in my_dict.items():
        x = my_dict.get(key)

def getvalue(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return 0

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DL' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else ('DOOR' if ('DOOR' in x)                 else "NA")))))))))))))

dfd = pd.read_csv (os.getcwd() + "\\OMDB.csv")
lss = dfd['sCode'].to_list()

def codecorr(code,akey):
    cd = code
    if 'UNKNOW' in code:
        for i in range(len(lss)):
            vl = akey.find(lss[i])
            if vl > 0 and vl is not None:
                cd = akey[vl:vl+7]
                break
        else:
            return cd
    else:
        return cd

def msgprep_head_znwise(hd = "Periodic Notification"):
    nw = datetime.now()
    dt = nw.strftime("%d-%m-%Y")
    tm = nw.strftime("%H:%M")
    a1 = hd + " at " + tm + " on " + dt
    return a1

def catmap_mod(df,dfdb,dfp1p2):
    df0 = df.rename (columns=str.upper)
    ls = ['NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE']
    df1 = df0[ls]
    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))
    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))
    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else "XXXXXXXX", axis=1))
    df3 = df2.merge (dfdb, on='sCode')
    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])
    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])
    df3 = df3.assign(CDLO = df3.apply (lambda x: x['CUSTOMATTR15'] + ": " + x['LASTOCCURRENCE'], axis=1))
    df4 = df3.merge (dfp1p2, on='CUSTOMATTR15')
    print(df4.columns)
    return df4

def rmvdup(df,lscol=[]):
    df1 = df.drop_duplicates(subset=lscol, inplace=False, ignore_index=True)
    return df1

def zonewise_count(df0, oncat=[]):
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    hd1 = ""
    hd2 = ""
    for j in range(len(oncat)):
        Tcnt[oncat[j]] = 0
        if hd1 == "":
            hd1 = "Region: " + oncat[j]
        else:
            hd1 = hd1 + "/" + oncat[j]
    hp = chr(10)
    ls = []
    for i in range(len(zn)):
        for n in range(len(oncat)):
            zct  = zn[i] + oncat[n]
            cnt = countifs(df0,df0['ZNCAT'],zct)
            ls.append(str(cnt))
            current_val = int(getvalue(Tcnt, oncat[n])) + cnt
            Tcnt[oncat[n]] = current_val
        else:
            hp = hp + chr(10) + zn[i] + ": " + "/".join(list(ls))
            ls = []
    for k in range(len(oncat)):
        hdval = Tcnt.get(oncat[k])
        if hd2 == "":
            hd2 = "National: " + str(hdval)
        else:
            hd2 = hd2 + "/" + str(hdval)
    else:
        trail1 = "This is RPA generated periodic notification." + chr(10) + "For any query, please contact with " + chr(10)
        trail2 = trail1 + "SOC Shift Manager, 01817183680"
        FinalText = msgprep_head_znwise() + chr(10) + chr(10) + hd1 + chr(10) + hd2 + hp + chr(10) + chr(10) + trail2
        return FinalText

def zonewise_dclow(df0, pickcols=['CUSTOMATTR15','LASTOCCURRENCE'], cols1="CAT", cols1_val="DL", cols2=False, ls_val_cols2=False):
    #parse by with max 2 condition zonewise
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    heap = ""
    for i in range(len(zn)):
        hp = ""
        znst = zn[i]
        ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        if ndf.shape[0] != 0:
            cnt_in_zn = znst + ": " + str(ndf.shape[0])
            ndf = ndf.astype(str)
            xdf = ndf[pickcols]
            fdf = xdf.assign(FCOL = xdf.apply(' - '.join, axis=1))
            fdf = fdf.reset_index()
            for n in range(fdf.shape[0]):
                print(n)
                if hp == "":
                    hp = cnt_in_zn + chr(10) + fdf.loc[n ,'FCOL']
                else:
                    hp = hp + chr(10) + fdf.loc[n ,'FCOL']
            else:
                if heap == "":
                    heap = hp
                else:
                    heap = heap + chr(10) + chr(10) + hp
    else:
        print(heap)
        
def zonewise_parse(df1, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    heap = ""
    if df1.shape[0] != 0:
        if len(pickcols) is not None:
            for i in range(len(pickcols)):
                df1 = df1.assign(COLO1 = "0")
                df1['CDLO1'] = df1.apply (lambda x: x['CDLO'] + " - " + x[pickcols[i]], axis=1)
                df1['CDLO'] = df1['CDLO1']
                df1 = df1.drop(['CDLO1'], axis=1)
        if df1.shape[0] != 0:
            for i in range(len(colsMain_val)):
                hp1 = ""
                cri_1 = colsMain_val[i]
                df2 = df1[df1[colsMain].isin([cri_1])]
                if df2.shape[0] !=0 and ls_val_cols2 != False:
                    for j in range(len(ls_val_cols2)):
                        cri_2 = ls_val_cols2[j]
                        dff = df2[df2[cols2].isin([cri_2])]
                        if dff.shape[0] != 0:
                            dfx = dff.reset_index()
                            hp = cri_2 + "| " + str(dff.shape[0]) + chr(10) + dfx['CDLO'].str.cat(sep=chr(10))
                            if hp1 == "":
                                hp1 = hp
                            else:
                                hp1 = hp1 + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + chr(10) + cri_1 + " || Count: " + str(df2.shape[0]) + chr(10) + chr(10) + hp1
                else:
                    if df2.shape[0] !=0:
                        df2 = df2.reset_index()
                        hp = cri_1 + ": " + str(df2.shape[0]) + chr(10) + df2['CDLO'].str.cat(sep=chr(10))
                        if heap == "" or heap== chr(10):
                            heap = hp
                        else:
                            heap = heap + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + cri_1 + ": " + "NA"
            else:
                finalout = "Region: " + whichzn + chr(10) + heap
                return finalout
                
def parsing(df, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    zn = {'DHK_M':'','DHK_N':'','DHK_O':'','DHK_S':'','CTG_M':'','CTG_N':'','CTG_S':'','COM':'','NOA':'',
          'BAR':'','KHL':'','KUS':'','MYM':'','RAJ':'','RANG':'','SYL':''}
    cnt = 0
    rval = ""
    if whichzn =="ALL":
        for ky in zn.keys():
            cnt = cnt + 1
            whichzn = ky
            df1 = df[df['sZone'].isin([ky])]
            if ls_val_cols2 != False:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
                print(zn.get(ky))
                print("############################",chr(10))
            else:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
                print(zn.get(ky))
                print("############################",chr(10))
        else:
            return zn
    elif whichzn =="":
        if ls_val_cols2 != False:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val)
        return rval
    elif whichzn !="NA" and whichzn!="ALL" and whichzn !="":
        df1 = df[df['sZone'].isin([whichzn])]
        if ls_val_cols2 != False:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
        return rval
                
            
            
            
    #df2 = df1[df1[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
    #df1 = df.assign(LOCD = xdf.apply(' - '.join, axis=1))
    #pickcols.insert(0, 'sZone')
    #pickcols.insert(0, 'CAT')
    #ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        
    
#sclick.csv must have Required column : 'NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE'
df = pd.read_csv(os.getcwd() + "\\sclick.csv")  # data source, 
dfdb = pd.read_csv (os.getcwd() + "\\OMDB.csv") #fixed data in same folder
dfp1p2 = pd.read_csv (os.getcwd() + "\\site_p1p2.csv")
odf = catmap_mod(df,dfdb,dfp1p2) # function is for processing data
#ST = zonewise_count(xx, ['2G','3G','4G'])  #2G,3G,4G derived from lambda function "TS". check abov
#result = parsing(odf,whichzn="ALL",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
#result = parsing(odf,whichzn="COM",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
result = parsing(odf,whichzn="",pickcols=['Name'],colsMain="CAT", colsMain_val=['2G','3G','4G'])
try:
    print(result)
except:
    o_print(result)



# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\o_final.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[7]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *

def o_print(my_dict):
    for key in my_dict.items():
        x = my_dict.get(key)

def getvalue(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return 0

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DL' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else ('DOOR' if ('DOOR' in x)                 else "NA")))))))))))))

dfd = pd.read_csv (os.getcwd() + "\\OMDB.csv")
lss = dfd['sCode'].to_list()

def codecorr(code,akey):
    cd = code
    if 'UNKNOW' in code:
        for i in range(len(lss)):
            vl = akey.find(lss[i])
            if vl > 0 and vl is not None:
                cd = akey[vl:vl+7]
                break
        else:
            return cd
    else:
        return cd

def msgprep_head_znwise(hd = "Periodic Notification"):
    nw = datetime.now()
    dt = nw.strftime("%d-%m-%Y")
    tm = nw.strftime("%H:%M")
    a1 = hd + " at " + tm + " on " + dt
    return a1

def catmap_mod(df,dfdb,dfp1p2):
    df0 = df.rename (columns=str.upper)
    ls = ['NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE']
    df1 = df0[ls]
    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))
    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))
    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else "XXXXXXXX", axis=1))
    df3 = df2.merge (dfdb, on='sCode')
    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])
    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])
    df3 = df3.assign(CDLO = df3.apply (lambda x: x['CUSTOMATTR15'] + ": " + x['LASTOCCURRENCE'], axis=1))
    df4 = df3.merge (dfp1p2, on='CUSTOMATTR15')
    print(df4.columns)
    return df4

def rmvdup(df,lscol=[]):
    df1 = df.drop_duplicates(subset=lscol, inplace=False, ignore_index=True)
    return df1

def zonewise_count(df0, oncat=[]):
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    hd1 = ""
    hd2 = ""
    for j in range(len(oncat)):
        Tcnt[oncat[j]] = 0
        if hd1 == "":
            hd1 = "Region: " + oncat[j]
        else:
            hd1 = hd1 + "/" + oncat[j]
    hp = chr(10)
    ls = []
    for i in range(len(zn)):
        for n in range(len(oncat)):
            zct  = zn[i] + oncat[n]
            cnt = countifs(df0,df0['ZNCAT'],zct)
            ls.append(str(cnt))
            current_val = int(getvalue(Tcnt, oncat[n])) + cnt
            Tcnt[oncat[n]] = current_val
        else:
            hp = hp + chr(10) + zn[i] + ": " + "/".join(list(ls))
            ls = []
    for k in range(len(oncat)):
        hdval = Tcnt.get(oncat[k])
        if hd2 == "":
            hd2 = "National: " + str(hdval)
        else:
            hd2 = hd2 + "/" + str(hdval)
    else:
        trail1 = "This is RPA generated periodic notification." + chr(10) + "For any query, please contact with " + chr(10)
        trail2 = trail1 + "SOC Shift Manager, 01817183680"
        FinalText = msgprep_head_znwise() + chr(10) + chr(10) + hd1 + chr(10) + hd2 + hp + chr(10) + chr(10) + trail2
        return FinalText

def zonewise_dclow(df0, pickcols=['CUSTOMATTR15','LASTOCCURRENCE'], cols1="CAT", cols1_val="DL", cols2=False, ls_val_cols2=False):
    #parse by with max 2 condition zonewise
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    heap = ""
    for i in range(len(zn)):
        hp = ""
        znst = zn[i]
        ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        if ndf.shape[0] != 0:
            cnt_in_zn = znst + ": " + str(ndf.shape[0])
            ndf = ndf.astype(str)
            xdf = ndf[pickcols]
            fdf = xdf.assign(FCOL = xdf.apply(' - '.join, axis=1))
            fdf = fdf.reset_index()
            for n in range(fdf.shape[0]):
                print(n)
                if hp == "":
                    hp = cnt_in_zn + chr(10) + fdf.loc[n ,'FCOL']
                else:
                    hp = hp + chr(10) + fdf.loc[n ,'FCOL']
            else:
                if heap == "":
                    heap = hp
                else:
                    heap = heap + chr(10) + chr(10) + hp
    else:
        print(heap)
        
def zonewise_parse(df1, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    heap = ""
    if df1.shape[0] != 0:
        if len(pickcols) is not None:
            for i in range(len(pickcols)):
                df1 = df1.assign(COLO1 = "0")
                df1['CDLO1'] = df1.apply (lambda x: x['CDLO'] + " - " + x[pickcols[i]], axis=1)
                df1['CDLO'] = df1['CDLO1']
                df1 = df1.drop(['CDLO1'], axis=1)
        if df1.shape[0] != 0:
            for i in range(len(colsMain_val)):
                hp1 = ""
                cri_1 = colsMain_val[i]
                df2 = df1[df1[colsMain].isin([cri_1])]
                if df2.shape[0] !=0 and ls_val_cols2 != False:
                    for j in range(len(ls_val_cols2)):
                        cri_2 = ls_val_cols2[j]
                        dff = df2[df2[cols2].isin([cri_2])]
                        if dff.shape[0] != 0:
                            dfx = dff.reset_index()
                            hp = cri_2 + "| " + str(dff.shape[0]) + chr(10) + dfx['CDLO'].str.cat(sep=chr(10))
                            if hp1 == "":
                                hp1 = hp
                            else:
                                hp1 = hp1 + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + chr(10) + cri_1 + " || Count: " + str(df2.shape[0]) + chr(10) + chr(10) + hp1
                else:
                    if df2.shape[0] !=0:
                        df2 = df2.reset_index()
                        hp = cri_1 + ": " + str(df2.shape[0]) + chr(10) + df2['CDLO'].str.cat(sep=chr(10))
                        if heap == "" or heap== chr(10):
                            heap = hp
                        else:
                            heap = heap + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + cri_1 + ": " + "NA"
            else:
                finalout = "Region: " + whichzn + chr(10) + heap
                return finalout
                
def parsing(df, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    zn = {'DHK_M':'','DHK_N':'','DHK_O':'','DHK_S':'','CTG_M':'','CTG_N':'','CTG_S':'','COM':'','NOA':'',
          'BAR':'','KHL':'','KUS':'','MYM':'','RAJ':'','RANG':'','SYL':''}
    cnt = 0
    rval = ""
    if whichzn =="ALL":
        for ky in zn.keys():
            cnt = cnt + 1
            whichzn = ky
            df1 = df[df['sZone'].isin([ky])]
            if ls_val_cols2 != False:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
                print(zn.get(ky))
                print("############################",chr(10))
            else:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
                print(zn.get(ky))
                print("############################",chr(10))
        else:
            return zn
    elif whichzn =="":
        if ls_val_cols2 != False:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val)
        return rval
    elif whichzn !="NA" and whichzn!="ALL" and whichzn !="":
        df1 = df[df['sZone'].isin([whichzn])]
        if ls_val_cols2 != False:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
        return rval
                
            
            
            
    #df2 = df1[df1[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
    #df1 = df.assign(LOCD = xdf.apply(' - '.join, axis=1))
    #pickcols.insert(0, 'sZone')
    #pickcols.insert(0, 'CAT')
    #ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        
    
#sclick.csv must have Required column : 'NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE'
df = pd.read_csv(os.getcwd() + "\\sclick.csv")  # data source, 
dfdb = pd.read_csv (os.getcwd() + "\\OMDB.csv") #fixed data in same folder
dfp1p2 = pd.read_csv (os.getcwd() + "\\site_p1p2.csv")
odf = catmap_mod(df,dfdb,dfp1p2) # function is for processing data
#ST = zonewise_count(xx, ['2G','3G','4G'])  #2G,3G,4G derived from lambda function "TS". check abov
#result = parsing(odf,whichzn="ALL",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
#result = parsing(odf,whichzn="COM",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
result = parsing(odf,whichzn="",pickcols=['Name'],colsMain="CAT", colsMain_val=['2G','3G','4G'])
try:
    print(result)
except:
    o_print(result)



# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\PP-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import time as tm
import os, cx_Oracle
from datetime import *
import numpy as np
import pandas as pd




pt = os.getcwd() + "\\book1.csv"
df = pd.read_csv(pt)
df = df.astype (str)
df = df.rename (columns=str.upper)
df1 = df[['SERIAL','SUMMARY','CUSTOMATTR15','CUSTOMATTR11','LASTOCCURRENCE']]
df1 = df1.assign(DHM ='0')
df1['DHM'] = df.apply(lambda x: pd.to_datetime(x['LASTOCCURRENCE'], dayfirst=True).strftime("%m%d%H%M"), axis = 1)
df1 = df1.sort_values(by=['DHM'], ascending=True)
df1 = df1.reset_index()
df1 = df1.assign(CAT5 ='0')
df1 = df1.assign(CAT15 ='0')


x = df1.shape[0]
df1['DHM'] = df1['DHM'].astype(int)
st = int(df1.loc[0,'DHM'])
precode = '0'
x1 = 0
for i in range(len(df1)):
    code = df1.loc[i,'CUSTOMATTR15']
    if x1 == 10:
        st = st + 5
        x1 = 0
    if int(df1.loc[i,'DHM']) > st:
        if precode != code:
            precode = code
            st = int(df1.loc[i,'DHM']) + 5
            df1.loc[i,'CAT5'] = st
        else:
            df1.loc[i,'CAT5'] = st
            x1 = x1 + 1
    else:
        df1.loc[i,'CAT5'] = st
        precode = code
        


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\PP.py###
#!/usr/bin/env python
# coding: utf-8

# In[8]:


import time as tm
import os, cx_Oracle
from datetime import *
import numpy as np
import pandas as pd


TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DC' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('CELL' if ('CELL' in x)                 else "NA"))))))))))


pt = os.getcwd() + "\\book1.csv"
df = pd.read_csv(pt)
df = df.astype (str)
df = df.rename (columns=str.upper)
df1 = df[['SERIAL','SUMMARY','CUSTOMATTR15','CUSTOMATTR11','LASTOCCURRENCE']]
df1 = df1.assign(DHM ='0')
df1['DHM'] = df.apply(lambda x: pd.to_datetime(x['LASTOCCURRENCE'], dayfirst=True).strftime("%m%d%H%M"), axis = 1)
df1 = df1.sort_values(by=['DHM'], ascending=True)
df1 = df1.reset_index()
df1 = df1.assign(CAT ='0')
df1 = df1.assign(CAT5 ='0')
df1['CAT'] = df.apply(lambda x : TS(x.SUMMARY), axis = 1)


x = df1.shape[0]
df1['DHM'] = df1['DHM'].astype(int)
st = int(df1.loc[0,'DHM'])
precode = '0'
x1 = 0
for i in range(len(df1)):
    code = df1.loc[i,'CUSTOMATTR15']
    if x1 == 10:
        st = st + 5
        x1 = 0
    if int(df1.loc[i,'DHM']) > st:
        if precode != code:
            precode = code
            st = int(df1.loc[i,'DHM']) + 5
            df1.loc[i,'CAT5'] = st
        else:
            df1.loc[i,'CAT5'] = st
            x1 = x1 + 1
    else:
        df1.loc[i,'CAT5'] = st
        precode = code
        
df1.to_csv(os.getcwd() + "\\BK2")
df1 = df1.astype(str)
df2 = df1.groupby(['CAT','CAT5','CUSTOMATTR15'])


# In[13]:


df2['CAT5'].sum()


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\PPTS-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[3]:


import pandas as pd
import MySQLdb, os, pyodbc
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Delta(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : x - pd.to_timedelta(2))
    print(xdf)
    
def Sr2Tstamp(df):
    xx['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    print(xx)

def DateTime_toSQL(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    return df
    

pt = os.getcwd() + "\\"
df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
xa = DateDiff(df, "DUR", "LASTOCCURRENCE")
print(xa)



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\PPTS.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[3]:


import pandas as pd
import MySQLdb, os, pyodbc
from datetime import *
from dateutil.relativedelta import *
import numpy as np
from fn import *

def PP(df):
    try:
        print(df['LASTOCCURRENCE', 'DUR', 'DURCAT'])
    except:
        try:
            print(df['LASTOCCURRENCE', 'DUR'])
        except:
            print(df['LASTOCCURRENCE'])
            
def series2df(sr1, sr2):
    df = pd.concat([sr1, sr2], axis=1)
    return df

def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        df[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
    
def xxz(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.Timestamp(x))
    return df

def Delta(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : x - pd.to_timedelta(2))
    print(xdf)
    
def Sr2Tstamp(df):
    xx['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].to_timestamp
    print(xx)

def DateTime_toSQL(df):
    df['LASTOCCURRENCE'] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
    return df
    

pt = os.getcwd() + "\\"
df = pd.read_csv(pt + 'P.csv')
#xd = DateTime(df)
#Delta(xd)
#Sr2Tstamp(df)
#xxz(df)
xa = DateDiff(df, "DUR", "LASTOCCURRENCE")
print(xa)



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\pydict-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[2]:


import pandas as pd

def pr_all_row_dict(dic):
    for rw in dic.values():
        print(rw)

def pr_all_col_dict(dic):
    print(dic)(1)
    #for col in dic:
        #print(col)[0]

def pr_spfc_col_dict(dic,index):
    print(dic.values())
    print(dic.items())

dict1 = {'col0':('zero_1','zero_2'),'col1':'one', 2:'two'}
#pr_all_row_dict(dict1)
#pr_all_col_dict(dict1)
pr_spfc_col_dict(dict1,0)



#for col in dic.items():
    #print(col)

#for val in dic:
    #print(val)

    
#print(dic['Site_Code'])   #colname=sitecode
#index = 2
#print(dic['Site_Code'][index])   #colname=sitecode


# In[ ]:





# In[ ]:





# In[86]:


#df to dic
import pandas as pd
filename = 'RobiLive.csv'
df = pd.read_csv(filename)
dic = df.to_dict()
#print(df)
#print(dic)
#for col in dic:  #print header
    #print(col)
#for rw in dic.values():  #print header
    #print(rw)
#for col in dic.items():
    #print(dic['Site_Code'])
print(dic['Site_Code'])   #colname=sitecode
index = 2
print(dic['Site_Code'][index])   #colname=sitecode
#for i in dic.values():
    #j = j + 1
    #print(j)
   # print(dic['Site_Code'][j])
    
#for i in dic:
    #print(i)
#for i in dic.values():
    #print(i)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\pydict.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[2]:


import pandas as pd

def pr_all_row_dict(dic):
    for rw in dic.values():
        print(rw)

def pr_all_col_dict(dic):
    print(dic)(1) 
    #for col in dic:
        #print(col)[0]

def pr_spfc_col_dict(dic,index):
    print(dic.values())
    print(dic.items())

dict1 = {'col0':('zero_1','zero_2'),'col1':'one', 2:'two'}
#pr_all_row_dict(dict1)
#pr_all_col_dict(dict1)
pr_spfc_col_dict(dict1,0)



#for col in dic.items():
    #print(col)

#for val in dic:
    #print(val)

    
#print(dic['Site_Code'])   #colname=sitecode
#index = 2
#print(dic['Site_Code'][index])   #colname=sitecode


# In[ ]:





# In[ ]:





# In[86]:


#df to dic
import pandas as pd
filename = 'Book1.csv'
df = pd.read_csv(filename)
dic = df.to_dict()
#print(df)
#print(dic)
#for col in dic:  #print header
    #print(col)
#for rw in dic.values():  #print header
    #print(rw)
#for col in dic.items():
    #print(dic['Site_Code'])
print(dic['Site_Code'])   #colname=sitecode
index = 2
print(dic['Site_Code'][index])   #colname=sitecode
#for i in dic.values():
    #j = j + 1
    #print(j)
   # print(dic['Site_Code'][j])
    
#for i in dic:
    #print(i)
#for i in dic.values():
    #print(i)


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\pyvba1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import MySQLdb
import pandas as pd


class pyvba:
    def __init__():



def print_row_bynum(ar,rwnum,li):
    #lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    j = 0
    heap = ""
    while j < lcol:
        hd = str(li[j]) + ":" + str(ar[rwnum][j])
        if j == 0:
            heap = hd
        else:
            heap = heap + '/n' + hd
        j = j + 1
    return heap

def vba_match(ar,src,colnum):
    lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    i = 0
    while i < lrw:
        if src == ar[i][0]:
            break
        i = i + 1
    return i

def fn_parse(ar,src,colnum):
    lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    i = 0
    while i < lrw:
        if src == ar[i][0]:
            break
        i = i + 1
    return i



   







conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
#print(df.head())
df2 = df[['Site_Code', 'DG_Status','Revenue_(in_K_BDT)','Priority']]
lst = df2.columns.tolist()
arr = df2.to_numpy()
#fn_byrw(arr,50,lst)
#print(vba_match(arr,'DHGUL19',1))
    
    


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\pyvba1.py###
#!/usr/bin/env python
# coding: utf-8

# In[7]:


import MySQLdb
import pandas as pd




def print_row_bynum(ar,rwnum,li):
    lcol = (ar).shape[1]
    j = 0
    heap = ""
    while j < lcol:
        hd = str(li[j]) + ":" + str(ar[rwnum][j])
        if j == 0:
            heap = hd
        else:
            heap = heap + '/n' + hd
        j = j + 1
    
    print(heap)
    return heap

def vba_match(ar,src):
    lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    i = 0
    while i < lrw:
        if src == ar[i][0]:
            break
        i = i + 1
    return i

def fn_parse(ar,src,colnum):
    lrw = (ar).shape[0]
    lcol = (ar).shape[1]
    i = 0
    while i < lrw:
        if src == ar[i][0]:
            break
        i = i + 1
    return i



   







conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
#print(df.head())
ls = ['Site_Code', 'DG_Status','Revenue_(in_K_BDT)','Priority']
x = vba_match(df,'DHSDR19')
print(x)
#print(df2)
#lst = df2.columns.tolist()
#arr = df2.to_numpy()
#fn_byrw(arr,50,lst)
#print(vba_match(arr,'DHGUL19',1))
    
    


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\PyVba2-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[6]:


import MySQLdb
import pandas as pd
import os

conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "sem_raw.csv"


def dic_df_parse(dic,zn,zn_colname,parsecol_1,parsecol_2,parsecol_3):
    hp = ""
    #count = 0
    nd = pd.DataFrame(dic)
    ndf = nd[nd[zn_colname].str.contains(zn, na=False)]
    for ind in ndf.index: 
        code = str(ndf[parsecol_1][ind])
        lo = str(ndf[parsecol_2][ind])
        resource = str(ndf[parsecol_3][ind])
        hp = hp + " \n"  + code + " || " + lo + " || " + resource
    z = zn + ': \n' + hp
    return z

             
def fn_dict(dc,colname):
    #print(dc)
    #key_colname = 'Site_Code'
    #print(dc[colname])         #--printall values under keys/column site code
    
    print(ndf)
    #print(dc[key_colname][1])      #--print value in index 1
    #first_col_key = list(dc.keys())[0]
    #print(first_col_key)
    #i = 0
    #for txt in dc.keys():
        #i = i + 1
        #if "All_Tech" in txt:
            #break


#df2 = df[['Site_Code', 'DG_Status','Revenue_(in_K_BDT)','Priority']]
#dic = df2.to_dict()
#fn_dict(dic,'Site_Code')


dfc = pd.read_csv(file)
dic = dfc.to_dict()
gval = dic_df_parse(dic,'DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
print(gval)

#dic_df_parse(dic,'DHKTL03','Resource','Resource','Summary','LastOccurrence',"","")


#zn,zn_colname,parsecol_1,parsecol_2,parsecol_3,cond1,cond1_colname

#for index, row in dfc.head().iterrows():
    #print(index, row['Resource'], row['Summary'], row['LastOccurance']) # access data using column names

#for index, row in dfc.head(4).iterrows():
     #print(row)



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\PyVba2.py###
#!/usr/bin/env python
# coding: utf-8

# In[7]:


import MySQLdb
import pandas as pd
import os

conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "sem_raw.csv"


def dic_df_parse(dic,zn,zn_colname,parsecol_1,parsecol_2,parsecol_3):
    hp = ""
    #count = 0
    nd = pd.DataFrame(dic)
    ndf = nd[nd[zn_colname].str.contains(zn, na=False)]
    for ind in ndf.index: 
        code = str(ndf[parsecol_1][ind])
        lo = str(ndf[parsecol_2][ind])
        resource = str(ndf[parsecol_3][ind])
        hp = hp + " \n"  + code + " || " + lo + " || " + resource
    z = zn + ': \n' + hp
    return z

             
def fn_dict(dc,colname):
    #print(dc)
    #key_colname = 'Site_Code'
    #print(dc[colname])         #--printall values under keys/column site code
    
    print(ndf)
    #print(dc[key_colname][1])      #--print value in index 1
    #first_col_key = list(dc.keys())[0]
    #print(first_col_key)
    #i = 0
    #for txt in dc.keys():
        #i = i + 1
        #if "All_Tech" in txt:
            #break


#df2 = df[['Site_Code', 'DG_Status','Revenue_(in_K_BDT)','Priority']]
#dic = df2.to_dict()
#fn_dict(dic,'Site_Code')


dfc = pd.read_csv(file)
dic = dfc.to_dict()
gval = dic_df_parse(dic,'DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
print(gval)

#dic_df_parse(dic,'DHKTL03','Resource','Resource','Summary','LastOccurrence',"","")


#zn,zn_colname,parsecol_1,parsecol_2,parsecol_3,cond1,cond1_colname

#for index, row in dfc.head().iterrows():
    #print(index, row['Resource'], row['Summary'], row['LastOccurance']) # access data using column names

#for index, row in dfc.head(4).iterrows():
     #print(row)



# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\pyvbclass-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[9]:


import MySQLdb
import pandas as pd
import os
import numpy

conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "sem_raw.csv"

class pyvb:
    def __init__(self, dic, li=[]):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = self.df[li]
    def PrintDf(self):
        print(self.df)
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(str_positive, na=False)]
        return df2.to_dict()

dfc = pd.read_csv(file)
dic = dfc.to_dict()
pv = pyvb(dic)
mli = ['LastOccurrence', 'Tally','CustomAttr11']
pv.Row_Item_From_List(9,mli)

#pv2 = pyvb(dic,mli)
#pv.PrintDf()
#pv2.PrintDf_ByList()
#gval = pv.MatchParse('DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
#print(gval)
#print(pv.VbMatch_Col('DHKTL04',3))
#print(pv.VbMatch_Row('CustomAttr15',0))
#pv.PrintLst()      


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\pyvbclass.py###
#!/usr/bin/env python
# coding: utf-8

# In[1]:


import MySQLdb
import pandas as pd
import os
import numpy

conn= MySQLdb.connect("localhost","root","admin","omdb")
df = pd.read_sql("select * from sitedb",conn)
file = os.getcwd() + "\\" + "sem_raw.csv"

class pyvb:
    def __init__(self, dic, li=[]):
        self.df = pd.DataFrame(dic)
        self.arr = self.df.to_numpy()
        self.lst = self.df[li]
    def PrintDf(self):
        print(self.df)
    def PrintDf_ByList(self):
        print(self.lst)
    def MatchParse(self,zn,zncol,parsecol_1,parsecol_2,parsecol_3):
        hp = ""
        ndf = self.df[self.df[zncol].str.contains(zn, na=False)]
        for ind in ndf.index:
            code = str(ndf[parsecol_1][ind])
            lo = str(ndf[parsecol_2][ind])
            resource = str(ndf[parsecol_3][ind])
            hp = hp + " \n"  + code + " || " + lo + " || " + resource
        z = zn + ': \n' + hp
        return z
    def VbMatch_Col(self,search_val,colnum):
        lrw = (self.arr).shape[0]
        i = 0
        while i < lrw:
            if search_val == self.arr[i][colnum]:
                break
            i = i + 1
        return i
    def VbMatch_Row(self,search_val,rwnum):
        lcol = (self.arr).shape[1]
        i = 0
        while i < lcol:
            if search_val == self.arr[rwnum][i]:
                break
            i = i + 1
        return i
    def Row_Item_From_List(self,rwnum,lis):
        ndf = self.df[lis]
        ar = ndf.to_numpy()
        lcol = (ar).shape[1]
        j = 0
        heap = ""
        while j < lcol:
            hd = str(lis[j]) + ":" + str(ar[rwnum][j])
            if j == 0:
                heap = hd
            else:
                heap = heap + '\n' + hd
            j = j + 1
        return heap
    def VbFilter(self,colname,strval):
        df2 = self.df[self.df[colname].str.contains(strval, na=False)]
        return df2.to_dict()

dfc = pd.read_csv(file)
dic = dfc.to_dict()
pv = pyvb(dic)
mli = ['LastOccurrence', 'Tally','CustomAttr11']
pv.Row_Item_From_List(9,mli)

#pv2 = pyvb(dic,mli)
#pv.PrintDf()
#pv2.PrintDf_ByList()
gval = pv.MatchParse('DHKTL04','CustomAttr15','Resource','Summary','LastOccurrence')
print(gval)
#print(pv.VbMatch_Col('DHKTL04',3))
#print(pv.VbMatch_Row('CustomAttr15',0))
#pv.PrintLst()      


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\py_pd_np_dic_lst-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
import numpy as np

def str_manip():
    txt = "Hello, welcome to my world.8"
    x = txt.find(" ")  #find space at first occ
    y = txt.rfind(" ")	#find space at last occ
    ln = len(txt)	#find length of string
    cnt_space = txt.count(" ")  #find count of a string/char in string
    print(x)
    print(y)
    print(ln)
    print('count of space: ', cnt_space)
    print('return from char 5 to last', txt[5:]) 
    print('return from char 5 to first: ', txt[:5])
    print('return from char 6 to 10: ', txt[6:10])
    if 'to ' in txt:
        print('yes')
    else:
        print('no')
    print('convert lower case: ', txt.casefold())
    print('return true if end with xxx: ', txt.endswith('8'))
    print(txt.replace("world", "earth"))
    # isnumeric() , isalnum(), replace()

def fn_list(ls):
    #print(ls)
    lengt = len(ls)
    for index, value in enumerate(ls): 
        print(index)
        #print(value)
        #col = 0
        #print(value[col])
        #print(len(value[1]))
def fn_nparr(ar):
    #print(ar)
    #ar2df = pd.DataFrame(data=ar,columns=["c1", "c2","c3","c4","c5"])
    #print(ar2df)
    print('num of rows: ', (ar).shape[0])
    print('num of column: ', (ar).shape[1])
    #print(ar[0][1])  #----Acessing value by index
    #print(ar[0][2])   #----Acessing value by index
    i = 0
    print(ar.size)
    while i < ar.shape[1]:
        print(ar[i][0])   #printing rows values for column 0
        i = i + 1
        if(i == ar.size):
            print(i)
            break
            
def fn_dict(dc):
    #print(dc)
    #key_colname = 'Site_Code'
    #print(dc[key_colname])         #--printall values under keys/column site code
    #print(dc[key_colname][1])      #--print value in index 1
    #first_col_key = list(dc.keys())[0]
    #print(first_col_key)
    i = 0
    for txt in dc.keys():
        i = i + 1
        if "All_Tech" in txt:
            break

def mat_col(dic,srcstr):
    i = 0
    for txt in dic.keys():
        i = i + 1
        if srcstr in txt:
            break
    return i
        
filename = os.getcwd() + '//inc.csv'
df = pd.read_csv(filename)
arr = df.to_numpy()
dic = df.to_dict()
lst = df.values.tolist()
#print(df.head)
#fn_list(lst)  #--succ
#fn_dict(dic)  #--succ
#xx = mat_col(dic,"Site_Code")
#print(xx)
fn_nparr(arr)  #--succ


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\py_pd_np_dic_lst.py###
#!/usr/bin/env python
# coding: utf-8

# In[118]:


import pandas as pd
import numpy as np

def str_manip():
    txt = "Hello, welcome to my world.8"
    x = txt.find(" ")  #find space at first occ
    y = txt.rfind(" ")	#find space at last occ
    ln = len(txt)	#find length of string
    cnt_space = txt.count(" ")  #find count of a string/char in string
    print(x)
    print(y)
    print(ln)
    print('count of space: ', cnt_space)
    print('return from char 5 to last', txt[5:]) 
    print('return from char 5 to first: ', txt[:5])
    print('return from char 6 to 10: ', txt[6:10])
    if 'to ' in txt:
        print('yes')
    else:
        print('no')
    print('convert lower case: ', txt.casefold())
    print('return true if end with xxx: ', txt.endswith('8'))
    print(txt.replace("world", "earth"))
    # isnumeric() , isalnum(), replace()

def fn_list(ls):
    #print(ls)
    lengt = len(ls)
    for index, value in enumerate(ls): 
        print(index)
        #print(value)
        #col = 0
        #print(value[col])
        #print(len(value[1]))
def fn_nparr(ar):
    #print(ar)
    ar2df = pd.DataFrame(data=ar,columns=["c1", "c2","c3","c4","c5"])
    #print(ar2df)
    print('num of rows: ', (ar).shape[0])
    print('num of column: ', (ar).shape[1])
    #print(ar[0][1])  #----Acessing value by index
    #print(ar[0][2])   #----Acessing value by index
    i = 0
    print(ar.size)
    while i < ar.shape[1]:
        print(ar[i][0])   #printing rows values for column 0
        i = i + 1
        if(i == ar.size):
            print(i)
            break
            
def fn_dict(dc):
    #print(dc)
    key_colname = 'Site_Code'
    #print(dc[key_colname])         #--printall values under keys/column site code
    #print(dc[key_colname][1])      #--print value in index 1
    #first_col_key = list(dc.keys())[0]
    #print(first_col_key)
    i = 0
    for txt in dc.keys():
        i = i + 1
        if "All_Tech" in txt:
            break

def mat_col(dic,srcstr):
    i = 0
    for txt in dic.keys():
        i = i + 1
        if srcstr in txt:
            break
    return i
        
filename = 'Book1.csv'
df = pd.read_csv(filename)
arr = df.to_numpy()
dic = df.to_dict()
lst = df.values.tolist()
#fn_list(lst)  #--succ
#fn_dict(dic)  #--succ
xx = mat_col(dic,"Site_Code")
print(xx)
#fn_nparr(arr)  #--succ


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\qry_timestamp-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
#print(fl)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        
conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print (conn.version)
    
def qryex(qr = False, flname = fl):
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + "*" + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(os.getcwd() + "\\dw\\" + flname)
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd

#######################################################################################
def qr1():
    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')
    Y21= qryex(x21,'EFDSDFSDFS.csv')

def qr2():
    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')
    x22 = " CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and " + x21 
    df= qryex(x22,'all_oneday_ip.csv')

qr2()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\qry_timestamp.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
#print(fl)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        
conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print (conn.version)
    
def qryex(qr = False, flname = fl):
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + "*" + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(os.getcwd() + "\\dw\\" + flname)
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd

#######################################################################################
def qr1():
    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')
    Y21= qryex(x21,'EFDSDFSDFS.csv')

def qr2():
    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')
    x22 = " CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and " + x21 
    df= qryex(x22,'all_oneday_ip.csv')

qr2()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\rpa-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[3]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *


def getvalue(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return 0

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DL' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else ('DOOR' if ('DOOR' in x)                 else "NA")))))))))))))

dfd = pd.read_csv (os.getcwd() + "\\OMDB.csv")
lss = dfd['sCode'].to_list()

def codecorr(code,akey):
    cd = code
    if 'UNKNOW' in code:
        for i in range(len(lss)):
            vl = akey.find(lss[i])
            if vl > 0 and vl is not None:
                cd = akey[vl:vl+7]
                break
        else:
            return cd
    else:
        return cd

def msgprep_head_znwise(hd = "Periodic Notification"):
    nw = datetime.now()
    dt = nw.strftime("%d-%m-%Y")
    tm = nw.strftime("%H:%M")
    a1 = hd + " at " + tm + " on " + dt
    return a1

def catmap_mod(df,dfdb):
    df0 = df.rename (columns=str.upper)
    ls = ['NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE']
    df1 = df0[ls]
    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))
    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))
    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else "XXXXXXXX", axis=1))
    df3 = df2.merge (dfdb, on='sCode')
    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])
    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])
    #print(df3[['CODECAT','ZNCAT']])
    return df3

def zonewise_count(df0, oncat=[]):
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    hd1 = ""
    hd2 = ""
    for j in range(len(oncat)):
        Tcnt[oncat[j]] = 0
        if hd1 == "":
            hd1 = "Region: " + oncat[j]
        else:
            hd1 = hd1 + "/" + oncat[j]
    hp = chr(10)
    ls = []
    for i in range(len(zn)):
        for n in range(len(oncat)):
            zct  = zn[i] + oncat[n]
            cnt = countifs(df0,df0['ZNCAT'],zct)
            ls.append(str(cnt))
            current_val = int(getvalue(Tcnt, oncat[n])) + cnt
            Tcnt[oncat[n]] = current_val
        else:
            hp = hp + chr(10) + zn[i] + ": " + "/".join(list(ls))
            ls = []
    for k in range(len(oncat)):
        hdval = Tcnt.get(oncat[k])
        if hd2 == "":
            hd2 = "National: " + str(hdval)
        else:
            hd2 = hd2 + "/" + str(hdval)
    else:
        trail1 = "This is RPA generated periodic notification." + chr(10) + "For any query, please contact with " + chr(10)
        trail2 = trail1 + "SOC Shift Manager, 01817183680"
        FinalText = msgprep_head_znwise() + chr(10) + chr(10) + hd1 + chr(10) + hd2 + hp + chr(10) + chr(10) + trail2
        return FinalText


#sclick.csv must have Required column : 'NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE'
df = pd.read_csv(os.getcwd() + "\\sclick.csv")  # data source, 
dfdb = pd.read_csv (os.getcwd() + "\\OMDB.csv") #fixed data in same folder
xx = catmap_mod(df,dfdb) # function is for processing data
ST = zonewise_count(xx, ['2G','3G','4G'])  #2G,3G,4G derived from lambda function "TS". check above
print(ST)




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\rpa.py###
#!/usr/bin/env python
# coding: utf-8

# In[3]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *


def getvalue(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return 0

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DL' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else ('DOOR' if ('DOOR' in x)                 else "NA")))))))))))))

dfd = pd.read_csv (os.getcwd() + "\\OMDB.csv")
lss = dfd['sCode'].to_list()

def codecorr(code,akey):
    cd = code
    if 'UNKNOW' in code:
        for i in range(len(lss)):
            vl = akey.find(lss[i])
            if vl > 0 and vl is not None:
                cd = akey[vl:vl+7]
                break
        else:
            return cd
    else:
        return cd

def msgprep_head_znwise(hd = "Periodic Notification"):
    nw = datetime.now()
    dt = nw.strftime("%d-%m-%Y")
    tm = nw.strftime("%H:%M")
    a1 = hd + " at " + tm + " on " + dt
    return a1

def catmap_mod(df,dfdb):
    df0 = df.rename (columns=str.upper)
    ls = ['NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE']
    df1 = df0[ls]
    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))
    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))
    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else "XXXXXXXX", axis=1))
    df3 = df2.merge (dfdb, on='sCode')
    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])
    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])
    #print(df3[['CODECAT','ZNCAT']])
    return df3

def zonewise_count(df0, oncat=[]):
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    hd1 = ""
    hd2 = ""
    for j in range(len(oncat)):
        Tcnt[oncat[j]] = 0
        if hd1 == "":
            hd1 = "Region: " + oncat[j]
        else:
            hd1 = hd1 + "/" + oncat[j]
    hp = chr(10)
    ls = []
    for i in range(len(zn)):
        for n in range(len(oncat)):
            zct  = zn[i] + oncat[n]
            cnt = countifs(df0,df0['ZNCAT'],zct)
            ls.append(str(cnt))
            current_val = int(getvalue(Tcnt, oncat[n])) + cnt
            Tcnt[oncat[n]] = current_val
        else:
            hp = hp + chr(10) + zn[i] + ": " + "/".join(list(ls))
            ls = []
    for k in range(len(oncat)):
        hdval = Tcnt.get(oncat[k])
        if hd2 == "":
            hd2 = "National: " + str(hdval)
        else:
            hd2 = hd2 + "/" + str(hdval)
    else:
        trail1 = "This is RPA generated periodic notification." + chr(10) + "For any query, please contact with " + chr(10)
        trail2 = trail1 + "SOC Shift Manager, 01817183680"
        FinalText = msgprep_head_znwise() + chr(10) + chr(10) + hd1 + chr(10) + hd2 + hp + chr(10) + chr(10) + trail2
        return FinalText


#sclick.csv must have Required column : 'NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE'
df = pd.read_csv(os.getcwd() + "\\sclick.csv")  # data source, 
dfdb = pd.read_csv (os.getcwd() + "\\OMDB.csv") #fixed data in same folder
xx = catmap_mod(df,dfdb) # function is for processing data
ST = zonewise_count(xx, ['2G','3G','4G'])  #2G,3G,4G derived from lambda function "TS". check above
print(ST)




# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\rpa2-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


df0.loc[1,'TCOUNT']


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\rpa2.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


df0.loc[1,'TCOUNT']


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\rpa_ext_dl-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[7]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *

def o_print(my_dict):
    for key in my_dict.items():
        x = my_dict.get(key)

def getvalue(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return 0

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DL' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else ('DOOR' if ('DOOR' in x)                 else "NA")))))))))))))

dfd = pd.read_csv (os.getcwd() + "\\OMDB.csv")
lss = dfd['sCode'].to_list()

def codecorr(code,akey):
    cd = code
    if 'UNKNOW' in code:
        for i in range(len(lss)):
            vl = akey.find(lss[i])
            if vl > 0 and vl is not None:
                cd = akey[vl:vl+7]
                break
        else:
            return cd
    else:
        return cd

def msgprep_head_znwise(hd = "Periodic Notification"):
    nw = datetime.now()
    dt = nw.strftime("%d-%m-%Y")
    tm = nw.strftime("%H:%M")
    a1 = hd + " at " + tm + " on " + dt
    return a1

def catmap_mod(df,dfdb,dfp1p2):
    df0 = df.rename (columns=str.upper)
    ls = ['NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE']
    df1 = df0[ls]
    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))
    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))
    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else "XXXXXXXX", axis=1))
    df3 = df2.merge (dfdb, on='sCode')
    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])
    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])
    df3 = df3.assign(CDLO = df3.apply (lambda x: x['CUSTOMATTR15'] + ": " + x['LASTOCCURRENCE'], axis=1))
    df4 = df3.merge (dfp1p2, on='CUSTOMATTR15')
    print(df4.columns)
    return df4

def rmvdup(df,lscol=[]):
    df1 = df.drop_duplicates(subset=lscol, inplace=False, ignore_index=True)
    return df1

def zonewise_count(df0, oncat=[]):
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    hd1 = ""
    hd2 = ""
    for j in range(len(oncat)):
        Tcnt[oncat[j]] = 0
        if hd1 == "":
            hd1 = "Region: " + oncat[j]
        else:
            hd1 = hd1 + "/" + oncat[j]
    hp = chr(10)
    ls = []
    for i in range(len(zn)):
        for n in range(len(oncat)):
            zct  = zn[i] + oncat[n]
            cnt = countifs(df0,df0['ZNCAT'],zct)
            ls.append(str(cnt))
            current_val = int(getvalue(Tcnt, oncat[n])) + cnt
            Tcnt[oncat[n]] = current_val
        else:
            hp = hp + chr(10) + zn[i] + ": " + "/".join(list(ls))
            ls = []
    for k in range(len(oncat)):
        hdval = Tcnt.get(oncat[k])
        if hd2 == "":
            hd2 = "National: " + str(hdval)
        else:
            hd2 = hd2 + "/" + str(hdval)
    else:
        trail1 = "This is RPA generated periodic notification." + chr(10) + "For any query, please contact with " + chr(10)
        trail2 = trail1 + "SOC Shift Manager, 01817183680"
        FinalText = msgprep_head_znwise() + chr(10) + chr(10) + hd1 + chr(10) + hd2 + hp + chr(10) + chr(10) + trail2
        return FinalText

def zonewise_dclow(df0, pickcols=['CUSTOMATTR15','LASTOCCURRENCE'], cols1="CAT", cols1_val="DL", cols2=False, ls_val_cols2=False):
    #parse by with max 2 condition zonewise
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    heap = ""
    for i in range(len(zn)):
        hp = ""
        znst = zn[i]
        ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        if ndf.shape[0] != 0:
            cnt_in_zn = znst + ": " + str(ndf.shape[0])
            ndf = ndf.astype(str)
            xdf = ndf[pickcols]
            fdf = xdf.assign(FCOL = xdf.apply(' - '.join, axis=1))
            fdf = fdf.reset_index()
            for n in range(fdf.shape[0]):
                print(n)
                if hp == "":
                    hp = cnt_in_zn + chr(10) + fdf.loc[n ,'FCOL']
                else:
                    hp = hp + chr(10) + fdf.loc[n ,'FCOL']
            else:
                if heap == "":
                    heap = hp
                else:
                    heap = heap + chr(10) + chr(10) + hp
    else:
        print(heap)
        
def zonewise_parse(df1, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    heap = ""
    if df1.shape[0] != 0:
        if len(pickcols) is not None:
            for i in range(len(pickcols)):
                df1 = df1.assign(COLO1 = "0")
                df1['CDLO1'] = df1.apply (lambda x: x['CDLO'] + " - " + x[pickcols[i]], axis=1)
                df1['CDLO'] = df1['CDLO1']
                df1 = df1.drop(['CDLO1'], axis=1)
        if df1.shape[0] != 0:
            for i in range(len(colsMain_val)):
                hp1 = ""
                cri_1 = colsMain_val[i]
                df2 = df1[df1[colsMain].isin([cri_1])]
                if df2.shape[0] !=0 and ls_val_cols2 != False:
                    for j in range(len(ls_val_cols2)):
                        cri_2 = ls_val_cols2[j]
                        dff = df2[df2[cols2].isin([cri_2])]
                        if dff.shape[0] != 0:
                            dfx = dff.reset_index()
                            hp = cri_2 + "| " + str(dff.shape[0]) + chr(10) + dfx['CDLO'].str.cat(sep=chr(10))
                            if hp1 == "":
                                hp1 = hp
                            else:
                                hp1 = hp1 + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + chr(10) + cri_1 + " || Count: " + str(df2.shape[0]) + chr(10) + chr(10) + hp1
                else:
                    if df2.shape[0] !=0:
                        df2 = df2.reset_index()
                        hp = cri_1 + ": " + str(df2.shape[0]) + chr(10) + df2['CDLO'].str.cat(sep=chr(10))
                        if heap == "" or heap== chr(10):
                            heap = hp
                        else:
                            heap = heap + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + cri_1 + ": " + "NA"
            else:
                finalout = "Region: " + whichzn + chr(10) + heap
                return finalout
                
def parsing(df, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    zn = {'DHK_M':'','DHK_N':'','DHK_O':'','DHK_S':'','CTG_M':'','CTG_N':'','CTG_S':'','COM':'','NOA':'',
          'BAR':'','KHL':'','KUS':'','MYM':'','RAJ':'','RANG':'','SYL':''}
    cnt = 0
    rval = ""
    if whichzn =="ALL":
        for ky in zn.keys():
            cnt = cnt + 1
            whichzn = ky
            df1 = df[df['sZone'].isin([ky])]
            if ls_val_cols2 != False:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
                print(zn.get(ky))
                print("############################",chr(10))
            else:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
                print(zn.get(ky))
                print("############################",chr(10))
        else:
            return zn
    elif whichzn =="":
        if ls_val_cols2 != False:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val)
        return rval
    elif whichzn !="NA" and whichzn!="ALL" and whichzn !="":
        df1 = df[df['sZone'].isin([whichzn])]
        if ls_val_cols2 != False:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
        return rval
                
            
            
            
    #df2 = df1[df1[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
    #df1 = df.assign(LOCD = xdf.apply(' - '.join, axis=1))
    #pickcols.insert(0, 'sZone')
    #pickcols.insert(0, 'CAT')
    #ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        
    
#sclick.csv must have Required column : 'NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE'
df = pd.read_csv(os.getcwd() + "\\sclick.csv")  # data source, 
dfdb = pd.read_csv (os.getcwd() + "\\OMDB.csv") #fixed data in same folder
dfp1p2 = pd.read_csv (os.getcwd() + "\\site_p1p2.csv")
odf = catmap_mod(df,dfdb,dfp1p2) # function is for processing data
#ST = zonewise_count(xx, ['2G','3G','4G'])  #2G,3G,4G derived from lambda function "TS". check abov
#result = parsing(odf,whichzn="ALL",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
#result = parsing(odf,whichzn="COM",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
result = parsing(odf,whichzn="",pickcols=['Name'],colsMain="CAT", colsMain_val=['2G','3G','4G'])
try:
    print(result)
except:
    o_print(result)



# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\rpa_ext_dl.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[7]:


import pandas as pd
import numpy as np
import os
from datetime import *
from fn import *

def o_print(my_dict):
    for key in my_dict.items():
        x = my_dict.get(key)

def getvalue(my_dict, ky):
    if ky is not None:
        for key, value in my_dict.items ():
            if key in str (ky):
                return value
        else:
            return 0

TS = lambda x : '2G' if ('2G SITE DOWN' in x)                 else ('3G' if ('3G SITE DOWN' in x)                 else ('4G' if ('4G SITE DOWN' in x)                 else ('MF' if ('MAIN' in x)                 else ('DL' if ('VOLTAGE' in x)                 else ('TM' if ('TEMPERATURE' in x)                 else ('SM' if ('SMOKE' in x)                 else ('GN' if ('GEN' in x)                 else ('GN' if ('GENSET' in x)                 else ('TH' if ('THEFT' in x)                 else ('C2G' if ('2G CELL DOWN' in x)                 else ('C3G' if ('3G CELL DOWN' in x)                 else ('C4G' if ('4G CELL DOWN' in x)                 else ('DOOR' if ('DOOR' in x)                 else "NA")))))))))))))

dfd = pd.read_csv (os.getcwd() + "\\OMDB.csv")
lss = dfd['sCode'].to_list()

def codecorr(code,akey):
    cd = code
    if 'UNKNOW' in code:
        for i in range(len(lss)):
            vl = akey.find(lss[i])
            if vl > 0 and vl is not None:
                cd = akey[vl:vl+7]
                break
        else:
            return cd
    else:
        return cd

def msgprep_head_znwise(hd = "Periodic Notification"):
    nw = datetime.now()
    dt = nw.strftime("%d-%m-%Y")
    tm = nw.strftime("%H:%M")
    a1 = hd + " at " + tm + " on " + dt
    return a1

def catmap_mod(df,dfdb,dfp1p2):
    df0 = df.rename (columns=str.upper)
    ls = ['NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE']
    df1 = df0[ls]
    df1 = df1.assign(CAT = df1.apply (lambda x: TS (x.SUMMARY), axis=1))
    df1 = df1.assign(CODE = df1.apply (lambda x: codecorr(x.CUSTOMATTR15, x.ALERTKEY), axis=1))
    df2 = df1.assign(sCode = df1.apply (lambda x: x.CODE[0:5] if (x.CODE is not None) else "XXXXXXXX", axis=1))
    df3 = df2.merge (dfdb, on='sCode')
    df3['CODECAT'] = df3['CUSTOMATTR15'].str.cat(df3['CAT'])
    df3['ZNCAT'] = df3['sZone'].str.cat(df3['CAT'])
    df3 = df3.assign(CDLO = df3.apply (lambda x: x['CUSTOMATTR15'] + ": " + x['LASTOCCURRENCE'], axis=1))
    df4 = df3.merge (dfp1p2, on='CUSTOMATTR15')
    print(df4.columns)
    return df4

def rmvdup(df,lscol=[]):
    df1 = df.drop_duplicates(subset=lscol, inplace=False, ignore_index=True)
    return df1

def zonewise_count(df0, oncat=[]):
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    hd1 = ""
    hd2 = ""
    for j in range(len(oncat)):
        Tcnt[oncat[j]] = 0
        if hd1 == "":
            hd1 = "Region: " + oncat[j]
        else:
            hd1 = hd1 + "/" + oncat[j]
    hp = chr(10)
    ls = []
    for i in range(len(zn)):
        for n in range(len(oncat)):
            zct  = zn[i] + oncat[n]
            cnt = countifs(df0,df0['ZNCAT'],zct)
            ls.append(str(cnt))
            current_val = int(getvalue(Tcnt, oncat[n])) + cnt
            Tcnt[oncat[n]] = current_val
        else:
            hp = hp + chr(10) + zn[i] + ": " + "/".join(list(ls))
            ls = []
    for k in range(len(oncat)):
        hdval = Tcnt.get(oncat[k])
        if hd2 == "":
            hd2 = "National: " + str(hdval)
        else:
            hd2 = hd2 + "/" + str(hdval)
    else:
        trail1 = "This is RPA generated periodic notification." + chr(10) + "For any query, please contact with " + chr(10)
        trail2 = trail1 + "SOC Shift Manager, 01817183680"
        FinalText = msgprep_head_znwise() + chr(10) + chr(10) + hd1 + chr(10) + hd2 + hp + chr(10) + chr(10) + trail2
        return FinalText

def zonewise_dclow(df0, pickcols=['CUSTOMATTR15','LASTOCCURRENCE'], cols1="CAT", cols1_val="DL", cols2=False, ls_val_cols2=False):
    #parse by with max 2 condition zonewise
    zn = ['DHK_M','DHK_N','DHK_O','DHK_S','CTG_M','CTG_N','CTG_S','COM','NOA','BAR','KHL','KUS','MYM','RAJ','RANG','SYL']
    Tcnt = {}
    heap = ""
    for i in range(len(zn)):
        hp = ""
        znst = zn[i]
        ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        if ndf.shape[0] != 0:
            cnt_in_zn = znst + ": " + str(ndf.shape[0])
            ndf = ndf.astype(str)
            xdf = ndf[pickcols]
            fdf = xdf.assign(FCOL = xdf.apply(' - '.join, axis=1))
            fdf = fdf.reset_index()
            for n in range(fdf.shape[0]):
                print(n)
                if hp == "":
                    hp = cnt_in_zn + chr(10) + fdf.loc[n ,'FCOL']
                else:
                    hp = hp + chr(10) + fdf.loc[n ,'FCOL']
            else:
                if heap == "":
                    heap = hp
                else:
                    heap = heap + chr(10) + chr(10) + hp
    else:
        print(heap)
        
def zonewise_parse(df1, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    heap = ""
    if df1.shape[0] != 0:
        if len(pickcols) is not None:
            for i in range(len(pickcols)):
                df1 = df1.assign(COLO1 = "0")
                df1['CDLO1'] = df1.apply (lambda x: x['CDLO'] + " - " + x[pickcols[i]], axis=1)
                df1['CDLO'] = df1['CDLO1']
                df1 = df1.drop(['CDLO1'], axis=1)
        if df1.shape[0] != 0:
            for i in range(len(colsMain_val)):
                hp1 = ""
                cri_1 = colsMain_val[i]
                df2 = df1[df1[colsMain].isin([cri_1])]
                if df2.shape[0] !=0 and ls_val_cols2 != False:
                    for j in range(len(ls_val_cols2)):
                        cri_2 = ls_val_cols2[j]
                        dff = df2[df2[cols2].isin([cri_2])]
                        if dff.shape[0] != 0:
                            dfx = dff.reset_index()
                            hp = cri_2 + "| " + str(dff.shape[0]) + chr(10) + dfx['CDLO'].str.cat(sep=chr(10))
                            if hp1 == "":
                                hp1 = hp
                            else:
                                hp1 = hp1 + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + chr(10) + cri_1 + " || Count: " + str(df2.shape[0]) + chr(10) + chr(10) + hp1
                else:
                    if df2.shape[0] !=0:
                        df2 = df2.reset_index()
                        hp = cri_1 + ": " + str(df2.shape[0]) + chr(10) + df2['CDLO'].str.cat(sep=chr(10))
                        if heap == "" or heap== chr(10):
                            heap = hp
                        else:
                            heap = heap + chr(10) + chr(10) + hp
                    else:
                        heap = heap + chr(10) + cri_1 + ": " + "NA"
            else:
                finalout = "Region: " + whichzn + chr(10) + heap
                return finalout
                
def parsing(df, whichzn, pickcols=[], colsMain="CAT", colsMain_val=['DL'], cols2=False, ls_val_cols2=False):
    zn = {'DHK_M':'','DHK_N':'','DHK_O':'','DHK_S':'','CTG_M':'','CTG_N':'','CTG_S':'','COM':'','NOA':'',
          'BAR':'','KHL':'','KUS':'','MYM':'','RAJ':'','RANG':'','SYL':''}
    cnt = 0
    rval = ""
    if whichzn =="ALL":
        for ky in zn.keys():
            cnt = cnt + 1
            whichzn = ky
            df1 = df[df['sZone'].isin([ky])]
            if ls_val_cols2 != False:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
                print(zn.get(ky))
                print("############################",chr(10))
            else:
                zn[ky] = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
                print(zn.get(ky))
                print("############################",chr(10))
        else:
            return zn
    elif whichzn =="":
        if ls_val_cols2 != False:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df,whichzn,pickcols,colsMain, colsMain_val)
        return rval
    elif whichzn !="NA" and whichzn!="ALL" and whichzn !="":
        df1 = df[df['sZone'].isin([whichzn])]
        if ls_val_cols2 != False:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val, cols2, ls_val_cols2)
        else:
            rval = zonewise_parse(df1,whichzn,pickcols,colsMain, colsMain_val)
        return rval
                
            
            
            
    #df2 = df1[df1[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
    #df1 = df.assign(LOCD = xdf.apply(' - '.join, axis=1))
    #pickcols.insert(0, 'sZone')
    #pickcols.insert(0, 'CAT')
    #ndf = df0[df0[cols1].str.contains(cols1_val) & df0['sZone'].str.contains(znst)]
        
    
#sclick.csv must have Required column : 'NODE','RESOURCE','CUSTOMATTR15','SUMMARY','ALERTKEY','LASTOCCURRENCE'
df = pd.read_csv(os.getcwd() + "\\sclick.csv")  # data source, 
dfdb = pd.read_csv (os.getcwd() + "\\OMDB.csv") #fixed data in same folder
dfp1p2 = pd.read_csv (os.getcwd() + "\\site_p1p2.csv")
odf = catmap_mod(df,dfdb,dfp1p2) # function is for processing data
#ST = zonewise_count(xx, ['2G','3G','4G'])  #2G,3G,4G derived from lambda function "TS". check abov
#result = parsing(odf,whichzn="ALL",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
#result = parsing(odf,whichzn="COM",pickcols=['Name'],colsMain="CAT", colsMain_val=['DL','MF'], cols2="ATRB", ls_val_cols2=['eco','Ulka'])
result = parsing(odf,whichzn="",pickcols=['Name'],colsMain="CAT", colsMain_val=['2G','3G','4G'])
try:
    print(result)
except:
    o_print(result)



# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\semqry-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import time
from datetime import date
import omdtfn as odt
import pandas as pd
import cx_Oracle

def rru_lastday(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()

def all_active(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "active_all.csv")
    return df.to_dict()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\semqry.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import time
from datetime import date
import omdtfn as odt
import pandas as pd
import cx_Oracle

def rru_lastday(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(1)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND SUMMARY LIKE 'ERI-RRU THEFT' "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "DW1709.csv")
    return df.to_dict()

def all_active(tbl,usr, pas, selcol):
    conn = cx_Oracle.connect(usr, pas, 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
    print(conn.version)
    tim = time.localtime()
    tdy = date.today()
    foldr = os.getcwd() + "\\download\\" + tdy.strftime('%m%d%y') + time.strftime("%H%M", tim) + '_' + tbl + '.csv'
    dy_p = odt.day_minus(7)
    dy_f = odt.day_plus(1)
    Q1 = "FROM " + tbl + " WHERE TYPE=1 AND Severity BETWEEN 1 AND 5 "
    Q2 = "AND (LASTOCCURRENCE BETWEEN TO_DATE('" + dy_p + "','DD-MM-RRRR') AND TO_DATE('" + dy_f + "','DD-MM-RRRR'))"
    QF = "SELECT" + selcol + Q1 + Q2
    print(QF)
    print('----------------')
    df = pd.read_sql(QF, con=conn)
    conn.close()
    df.to_csv(os.getcwd() + "\\" + "active_all.csv")
    return df.to_dict()


$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\sock_work-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[3]:


import pandas as pd
import numpy as np
import os
import MySQLdb
import csv

conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")

pt = os.getcwd()
proxy = pt + '\\hideme.csv'
db = pt + '\\ip2as.csv'

def add_col(dA,c):
    rw, col = dA.shape
    lst = []
    for i in range(rw):
        x = dA[i][c]
        y = x.rfind('.')
        s = x[0:y]
        lst.append(s)
    dA = np.append(dA, np.array([lst]).transpose(), axis=1)
    return dA

dpx = pd.read_csv(proxy,delimiter=';')
ddb = pd.read_csv(db)
dpx1 = dpx[['ip','port']]
dA = dpx1.to_numpy()
#z = add_col(dA)
#df1 = pd.DataFrame(z,columns=['ip','port','ipmod'])

dd = ddb.to_numpy()
z1 = add_col(dd,0)
df2 = pd.DataFrame(z1,columns=['IP1','IP2','ASN','Country','ISP','IPMOD'])
df = df2.to_csv(pt + '\\A2S.csv')


# In[4]:


cursor = conn.cursor()
try:
    with open(pt + '\\A2S.csv') as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        sql = "INSERT INTO ipasn3 (IP1,IP2,ASN,Country,ISP,IPMOD) VALUES (%s,%s,%s,%s,%s)"
        for row in csv_reader:
            row = (', '.join(row))
            print(row)
            cursor.execute(sql, row)
except:
    conn.rollback()
finally:
    conn.close()


# In[77]:


list_of_dates = ['2019-11-20', '2020-01-02', '2020-02-05','2020-03-10','2020-04-16','2020-05-01']
employees = ['Hisila', 'Shristi','Zeppy','Alina','Jerry','Kevin']
salary = [200,400,300,500,600,300]
df = pd.DataFrame({"Name":employees,'Joined date': pd.to_datetime(list_of_dates),"Salary":salary})
df['Status'] = ["Senior" if s >=400 else "Junior" for s in df['Salary']] 
#print(df)

df['Status'] = np.where(df['Salary']>=400, 'Senior', 'Junior')
nm = df.to_numpy()
rw, col = nm.shape
print(nm)

ml = []
for i in range(rw):
    if nm[i,2]>300:
        ml.append('GT')
    else:
        ml.append('LT')


# In[78]:


empty_array = np.empty((4, 0), int)
print(empty_array)


# In[79]:


column_list_1 = [11, 21, 31, 41]
empty_array = np.append(empty_array, np.array([column_list_1]).transpose(), axis=1)
print(empty_array)


# In[80]:


column_list_2 = [15, 25, 35, 45]
empty_array = np.append(empty_array, np.array([column_list_2]).transpose(), axis=1)
print(empty_array)


# In[81]:


nm = np.append(nm, np.array([ml]).transpose(), axis=1)
print(nm)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\sock_work.py###
#!/usr/bin/env python
# coding: utf-8

# In[ ]:





# In[2]:


import pandas as pd
import numpy as np
import os
import MySQLdb
import csv

conn= MySQLdb.connect("23.152.224.49","akomi","1q2w3eaz$","omdb")

pt = os.getcwd()
proxy = pt + '\\hideme.csv'
db = pt + '\\ip2as.csv'

def add_col(dA,c):
    rw, col = dA.shape
    lst = []
    for i in range(rw):
        x = dA[i][c]
        y = x.rfind('.')
        s = x[0:y]
        lst.append(s)
    dA = np.append(dA, np.array([lst]).transpose(), axis=1)
    return dA

dpx = pd.read_csv(proxy,delimiter=';')
ddb = pd.read_csv(db)
dpx1 = dpx[['ip','port']]
dA = dpx1.to_numpy()
#z = add_col(dA)
#df1 = pd.DataFrame(z,columns=['ip','port','ipmod'])

dd = ddb.to_numpy()
z1 = add_col(dd,0)
df2 = pd.DataFrame(z1,columns=['IP1','IP2','ASN','Country','ISP','IPMOD'])
df = df2.to_csv(pt + '\\A2S.csv',',')


# In[ ]:


cursor = conn.cursor()
try:
    with open(pt + '\\A2S.csv') as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        sql = "INSERT INTO ipasn3 (IP1,IP2,ASN,Country,ISP,IPMOD) VALUES (%s,%s,%s,%s,%s)"
        for row in csv_reader:
            row = (', '.join(row))
            print(row)
            cursor.execute(sql, row)
except:
    conn.rollback()
finally:
    conn.close()


# In[77]:


list_of_dates = ['2019-11-20', '2020-01-02', '2020-02-05','2020-03-10','2020-04-16','2020-05-01']
employees = ['Hisila', 'Shristi','Zeppy','Alina','Jerry','Kevin']
salary = [200,400,300,500,600,300]
df = pd.DataFrame({"Name":employees,'Joined date': pd.to_datetime(list_of_dates),"Salary":salary})
df['Status'] = ["Senior" if s >=400 else "Junior" for s in df['Salary']] 
#print(df)

df['Status'] = np.where(df['Salary']>=400, 'Senior', 'Junior')
nm = df.to_numpy()
rw, col = nm.shape
print(nm)

ml = []
for i in range(rw):
    if nm[i,2]>300:
        ml.append('GT')
    else:
        ml.append('LT')


# In[78]:


empty_array = np.empty((4, 0), int)
print(empty_array)


# In[79]:


column_list_1 = [11, 21, 31, 41]
empty_array = np.append(empty_array, np.array([column_list_1]).transpose(), axis=1)
print(empty_array)


# In[80]:


column_list_2 = [15, 25, 35, 45]
empty_array = np.append(empty_array, np.array([column_list_2]).transpose(), axis=1)
print(empty_array)


# In[81]:


nm = np.append(nm, np.array([ml]).transpose(), axis=1)
print(nm)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\sql_ins_or_upd-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import os

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df
    
def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf

def ls2str(ls):
    st = ""
    for i in range(len(ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st

def pupd(col,val):
    lscol = col.split(',')
    lsval = val.split(',')
    if len(lscol) == len(lsval):
        x1 = ls2str(lscol)
        x2 = ls2str(lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x
        
def inser_or_update(conn, tbl, ndf, bycol, oncols = False, operator=False):
    cr = conn.cursor()
    udf = forupdate(ndf, bycol, oncols)
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range(len(bycol)):
            if operator == False: 
                x1 = str(bycol[j]) + " Like '" + str(ndf.loc[i, bycol[j]]) + "'" 
            else:
                x1 = str(bycol[j]) + " ='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str(ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str(ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into "+ tbl + pupd(xu,yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
        lsinsert.append(qryinsert)
        if ccr == 1:
            try:
                cr.execute(qry)
            except:
                try:
                    cr.execute(qryinsert)
                except:
                    qq.append(q)
                    pass
        q = q + 1
    print("failed rows: " , qq)
    ddf = pd.DataFrame(list(zip(lsqry, lsinsert)), columns =['upd', 'ins']) 
    return ddf

def df2sq(df, table, conn, bycol = False, oncol = False, operator='Like' ):
    if bycol == False and oncol == False:
        df.to_sql(table, con = conn, if_exists="append", chunksize=10000):
    else:
        cr = conn.cursor()
        try:
            cr.execute("select 1 from " + table)
            dfx = inser_or_update(conn, tbl, ndf, bycol, oncols, operator)
            return dfx
        except:
            df.to_sql(table, con = conn, if_exists="replace", chunksize=10000)               


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\sql_ins_or_upd.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import os

def drop_cols(df, col2drop = []):
    if len(col2drop) > 0:
        cols = df.columns.to_list()
        ncols = []
        for i in range(len(cols)):
            match = 0
            for j in range(len(col2drop)):
                if cols[i] == col2drop[j]:
                    match = 1
            if match == 0:
                ncols.append(cols[i])
        ndf = df[ncols]
        return ndf
    else:
        return df
    
def forupdate(df, bycol, oncols):
    cols = []
    if oncols == False:
        cols = df.columns.to_list()
    else:
        cols = bycol + oncols
    xdf = df[cols]
    return xdf

def ls2str(ls):
    st = ""
    for i in range(len(ls)):
        if st == "" and ls[i] not in st:
            st = ls[i]
        else:
            st = st + "," + ls[i]
    return st

def pupd(col,val):
    lscol = col.split(',')
    lsval = val.split(',')
    if len(lscol) == len(lsval):
        x1 = ls2str(lscol)
        x2 = ls2str(lsval)
        x = "(" + x1 + ") values (" + x2 + ")"
        return x
        
def inser_or_update(conn, tbl, ndf, bycol, oncols = False, operator=False):
    cr = conn.cursor()
    udf = forupdate(ndf, bycol, oncols)
    dfx = drop_cols(ndf, bycol)
    ncols = dfx.columns.to_list()
    lsqry = []
    lsinsert = []
    q = 0
    qq = []
    for i in range(len(ndf)):
        x = ''
        y = ''
        xu = ''
        yu = ''
        for j in range(len(bycol)):
            if operator == False: 
                x1 = str(bycol[j]) + " Like '" + str(ndf.loc[i, bycol[j]]) + "'" 
            else:
                x1 = str(bycol[j]) + " ='" + str(ndf.loc[i, bycol[j]]) + "'"
            if x == '':
                x = x1
                xu = bycol[j]
                yu = "'" + str(ndf.loc[i, bycol[j]]) + "'"
            else:
                xu = xu + ',' + bycol[j]
                yu = yu + "," + "'" + str(ndf.loc[i, bycol[j]]) + "'"
                x = x + " and " + x1
        for n in range(len(ncols)):
            if oncols == False:
                a1 = str(ncols[n])
                a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                if y == '':
                    y = a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
                else:
                    y = y + "," + a1 + '=' + a2
                    xu = xu + ',' + a1
                    yu = yu + "," + a2
            else:
                a1 = str(ncols[n])
                mat = 0
                for j in range(len(oncols)):
                    if oncols[j] == a1:
                        mat = 1
                        break
                if mat == 1:
                    a2 = "'" + str(ndf.loc[i, ncols[n]]) + "'"
                    if y == '':
                        y = a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
                    else:
                        y = y + "," + a1 + '=' + a2
                        xu = xu + ',' + a1
                        yu = yu + "," + a2
        qryinsert = "insert into "+ tbl + pupd(xu,yu)
        qry = "update " + tbl + ' set ' + y + ' Where ' + x
        lsqry.append(qry)
        lsinsert.append(qryinsert)
        if ccr == 1:
            try:
                cr.execute(qry)
            except:
                try:
                    cr.execute(qryinsert)
                except:
                    qq.append(q)
                    pass
        q = q + 1
    print("failed rows: " , qq)
    ddf = pd.DataFrame(list(zip(lsqry, lsinsert)), columns =['upd', 'ins']) 
    return ddf

def df2sq(df, table, conn, bycol = False, oncol = False, operator='Like' ):
    if bycol == False and oncol == False:
        df.to_sql(table, con = conn, if_exists="append", chunksize=10000):
    else:
        cr = conn.cursor()
        try:
            cr.execute("select 1 from " + table)
            dfx = inser_or_update(conn, tbl, ndf, bycol, oncols, operator)
            return dfx
        except:
            df.to_sql(table, con = conn, if_exists="replace", chunksize=10000)               


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\TSS-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
from fn import *
import os


def datetime_re_format(ls, fmt='%d/%m/%Y %H:%M'):
    #serialize and convert using dateutil.parser and datetime.strftime
    if ls is not None and isinstance(ls, list):
        lss = []
        for i in range(len(ls)):
            try:
                dt = parse(str(ls[i])).strftime(fmt)
                lss.append(dt)
            except:
                lss.append(ls[i])
        else:
            return lss

diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def makelist_dttm_now(ln):
    nw = datetime.now()
    st = nw.strftime("%d/%m/%Y %H:%M")
    ls = []
    for i in range(ln):
        ls.append(st)
    return ls

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls
        

def DateDif(DT1, DT2 = None):
    TM1 = formatchk(DT1)
    if DT2 is None:
        TM2 = makelist_dttm_now(len(DT1))
    else:
        TM2 = formatchk(DT2)
    try:
        TM11 = datetime_re_format(TM1)
        TM22 = datetime_re_format(TM2)
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM11, TM22))
        return dur
    except:
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM1, TM2))
        return dur


#df1 = df.drop_duplicates(subset=['SUMMARY'],ignore_index=True)
#df1 = df.drop_duplicates(subset=['CUSTOMATTR15'])
#df1 = df1.reset_index()
#print(df1, df1.index)
#df1.set_index([pd.Index(np.full((1, len(df1), ), 'year'])
#ls1 = makelist_dttm_now(df.shape[0])
#ls2 = df['LASTOCCURRENCE'].to_list()
#s = DateDif(df['LASTOCCURRENCE'])
#df['dur'] = np.array(DateDif(df['LASTOCCURRENCE'],df['CLEARTIMESTAMP']))
##--- Succ --#
#T1 =["2003-09-25 18:05:01","09-25-2003 01:45:00","25-09-2003 12:01:04"]
#nw = datetime.now()
#st = nw.strftime("%d/%m/%Y %H:%M")
#T2 = np.full((1, len(T1)), st)

##successfully calling function da
###dtm =["2003-09-25 18:05:01","09-25-2003 01:45:00","25-09-2003 12:01:04"]
###datetime_re_format(dtm, "%Y/%m/%d %H:%M")

#------------dataframe calculation Succ---------------------#
#df.assign(dur = 'x')
#df['dur'] = np.array(DateDiff(df['LASTOCCURRENCE'],df['CLEARTIMESTAMP']))
#lst = DDiff(df['LASTOCCURRENCE'])
#df['DUR'] = np.array(lst)
#df['DUR']
#--------------------------------------#


# In[11]:


pt = os.getcwd() + "\\sclick.csv"
df = pd.read_csv(pt)
df = df.astype (str)
df = df.rename (columns=str.upper)
df1 = df[['SERIAL','SUMMARY','CUSTOMATTR15','CUSTOMATTR11','CLEARTIMESTAMP','LASTOCCURRENCE']]
df1 = df1.assign(DHM ='0')
df1['DHM'] = df.apply(lambda x: pd.to_datetime(x['LASTOCCURRENCE'], dayfirst=True).strftime("%m%d%H%M"), axis = 1)
df1 = df1.sort_values(by=['DHM'], ascending=True)
df1 = df1.reset_index()
df1 = df1.assign(CAT5 ='0')
df1 = df1.assign(CAT15 ='0')
x = df1.shape[0]
df1['DHM'] = df1['DHM'].astype(int)
st = int(df1.loc[0,'DHM'])
for i in range(len(df1)):
    if int(df1.loc[i,'DHM']) > st:
        df1.loc[i,'CAT5'] = st
        st = int(df1.loc[i,'DHM']) + 5
    else:
        df1.loc[i,'CAT5'] = st
pre = ''    
st2 = int(df1.loc[0,'CAT5'])
dic = {}
for i in range(len(df1)):
    if int(df1.loc[i,'CAT5']) > st:
        df1.loc[i,'CAT15'] = st
        st = int(df1.loc[i,'CAT5']) + 15
    else:
        df1.loc[i,'CAT15'] = st
        


# In[9]:


df2 = df1.groupby(['CUSTOMATTR15', 'CAT5']).sum().to_frame(name = 'SMX').reset_index()


# In[10]:


df2.to_csv(os.getcwd() + "\\sc2.csv")


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\TSS.py###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *
from fn import *
import os


def datetime_re_format(ls, fmt='%d/%m/%Y %H:%M'):
    #serialize and convert using dateutil.parser and datetime.strftime
    if ls is not None and isinstance(ls, list):
        lss = []
        for i in range(len(ls)):
            try:
                dt = parse(str(ls[i])).strftime(fmt)
                lss.append(dt)
            except:
                lss.append(ls[i])
        else:
            return lss

diffdate = lambda T1, T2 : (datetime.strptime(T2, "%d/%m/%Y %H:%M") - datetime.strptime(T1, "%d/%m/%Y %H:%M")).total_seconds()/60
diff_from_now = lambda locc : (datetime.now() - datetime.strptime(locc, "%d/%m/%Y %H:%M")).total_seconds()/60

def makelist_dttm_now(ln):
    nw = datetime.now()
    st = nw.strftime("%d/%m/%Y %H:%M")
    ls = []
    for i in range(ln):
        ls.append(st)
    return ls

def formatchk(L1):
    if isinstance(L1, list):
        return L1
    elif isinstance(L1, pd.core.series.Series):
        ls = L1.to_list()
        return ls
        

def DateDif(DT1, DT2 = None):
    TM1 = formatchk(DT1)
    if DT2 is None:
        TM2 = makelist_dttm_now(len(DT1))
    else:
        TM2 = formatchk(DT2)
    try:
        TM11 = datetime_re_format(TM1)
        TM22 = datetime_re_format(TM2)
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM11, TM22))
        return dur
    except:
        dur = list(map (lambda LO , CL: diffdate(LO,CL) if ('1970' not in str(CL)) else diff_from_now(LO), TM1, TM2))
        return dur


#df1 = df.drop_duplicates(subset=['SUMMARY'],ignore_index=True)
#df1 = df.drop_duplicates(subset=['CUSTOMATTR15'])
#df1 = df1.reset_index()
#print(df1, df1.index)
#df1.set_index([pd.Index(np.full((1, len(df1), ), 'year'])
#ls1 = makelist_dttm_now(df.shape[0])
#ls2 = df['LASTOCCURRENCE'].to_list()
#s = DateDif(df['LASTOCCURRENCE'])
#df['dur'] = np.array(DateDif(df['LASTOCCURRENCE'],df['CLEARTIMESTAMP']))
##--- Succ --#
#T1 =["2003-09-25 18:05:01","09-25-2003 01:45:00","25-09-2003 12:01:04"]
#nw = datetime.now()
#st = nw.strftime("%d/%m/%Y %H:%M")
#T2 = np.full((1, len(T1)), st)

##successfully calling function da
###dtm =["2003-09-25 18:05:01","09-25-2003 01:45:00","25-09-2003 12:01:04"]
###datetime_re_format(dtm, "%Y/%m/%d %H:%M")

#------------dataframe calculation Succ---------------------#
#df.assign(dur = 'x')
#df['dur'] = np.array(DateDiff(df['LASTOCCURRENCE'],df['CLEARTIMESTAMP']))
#lst = DDiff(df['LASTOCCURRENCE'])
#df['DUR'] = np.array(lst)
#df['DUR']
#--------------------------------------#


# In[11]:


pt = os.getcwd() + "\\sclick.csv"
df = pd.read_csv(pt)
df = df.astype (str)
df = df.rename (columns=str.upper)
df1 = df[['SERIAL','SUMMARY','CUSTOMATTR15','CUSTOMATTR11','CLEARTIMESTAMP','LASTOCCURRENCE']]
df1 = df1.assign(DHM ='0')
df1['DHM'] = df.apply(lambda x: pd.to_datetime(x['LASTOCCURRENCE'], dayfirst=True).strftime("%m%d%H%M"), axis = 1)
df1 = df1.sort_values(by=['DHM'], ascending=True)
df1 = df1.reset_index()
df1 = df1.assign(CAT5 ='0')
df1 = df1.assign(CAT15 ='0')
x = df1.shape[0]
df1['DHM'] = df1['DHM'].astype(int)
st = int(df1.loc[0,'DHM'])
for i in range(len(df1)):
    if int(df1.loc[i,'DHM']) > st:
        df1.loc[i,'CAT5'] = st
        st = int(df1.loc[i,'DHM']) + 5
    else:
        df1.loc[i,'CAT5'] = st
pre = ''    
st2 = int(df1.loc[0,'CAT5'])
dic = {}
for i in range(len(df1)):
    if int(df1.loc[i,'CAT5']) > st:
        df1.loc[i,'CAT15'] = st
        st = int(df1.loc[i,'CAT5']) + 15
    else:
        df1.loc[i,'CAT15'] = st
        


# In[9]:


df2 = df1.groupby(['CUSTOMATTR15', 'CAT5']).sum().to_frame(name = 'SMX').reset_index()


# In[10]:


df2.to_csv(os.getcwd() + "\\sc2.csv")


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[54]:


import pandas as pd
import numpy as np
from datetime import *
import os
from fn import *
from oDT import *

print(os.getcwd() + "\\B1.csv")
#df1 = pd.read_csv(os.getcwd() + "\\book1.csv")
df = pd.read_csv(os.getcwd() + "\\B1.csv")
nw = datetime.now()



TS1 = lambda x: '2' if ('2G SITE DOWN' in x)     else ('2' if ('2G CELL DOWN' in x)     else ('3' if ('3G SITE DOWN' in x)     else ('3' if ('3G CELL DOWN' in x)     else ('4' if ('4G SITE DOWN' in x)     else ('4' if ('4G CELL DOWN' in x)     else ('2' if ('OML' in x)     else "0"))))))

TS2 = lambda x: '2' if ('2G SITE DOWN' in x)     else ('22' if ('2G CELL DOWN' in x)     else ('3' if ('3G SITE DOWN' in x)     else ('33' if ('3G CELL DOWN' in x)     else ('4' if ('4G SITE DOWN' in x)     else ('44' if ('4G CELL DOWN' in x)     else ('2' if ('OML' in x)     else "0"))))))


DCAT = lambda x: 'H2' if (x < 300) else ('H12')

def extrafeat(df, tmdelta = 0):
    df1 = df.astype(str)
    df1 = df1.rename (columns=str.upper)
    df1 = df1[~df1['CUSTOMATTR15'].isin(['UNKNOWN'])]
    df1 = df1.assign (CT1='X')
    df1 = df1.assign (CT2='X')
    df1['CT1'] = df1.apply (lambda x: TS1 (x.SUMMARY), axis=1)
    df1['CT2'] = df1.apply (lambda x: TS2 (x.SUMMARY), axis=1)
    df1 = df1[~df1['CT1'].isin(['0'])]
    df1['CT1_1'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT1'].map(str)
    df1['CT1_2'] = df1['CUSTOMATTR15'].map(str) + '_' + df1['CT2'].map(str)
    try:
        df2 = DateDiff(df1, "DUR", "LASTOCCURRENCE")
    except:
        df2 = datediff_ondf(df1, "DUR", 'LASTOCCURRENCE')
    df2['DCT'] = df2.apply (lambda x: DCAT(x.DUR), axis=1)
    df2['LO'] = df2.apply (lambda x: pd.to_datetime (x['LASTOCCURRENCE'], errors='coerce', cache=True).strftime("%Y%m%d%H%M"), axis=1)
    df2 = df2.astype(str)
    df2['CD_TM_CT1'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT1'].map(str)
    df2['CD_TM_CT2'] = df2['CUSTOMATTR15'].map(str) + '_' + df2['LO'].map(str) + '_' + df2['CT2'].map(str)
    df2.to_csv(os.getcwd() + "\\P3.csv", index = False)
    df3 = df2.drop_duplicates(subset=['CD_TM_CT2'], inplace=False, ignore_index=True)
    df3 = df3.reset_index()
    df4 = df3.drop_duplicates(subset=['CD_TM_CT1'], inplace=False, ignore_index=True)
    df4 = df4.reset_index()
    df4.to_csv(os.getcwd() + "\\P5.csv", index = False)
    return df4

def Part2(df):
    dfx = df.groupby(['CT1_2','DCT']).CT1_2.count().to_frame(name = 'FC').reset_index()
    #df.to_csv(os.getcwd() + "\\P6.csv", index = False)
    pv = dfx.pivot_table(index=['CT1_2'], columns='DCT', values='FC', aggfunc='sum').reset_index()
    df = pv.drop_duplicates(subset=['CT1_2'], inplace=False, ignore_index=True)
    pv.to_csv(os.getcwd() + "\\"IAMPY".csv", index = False)
    #df['H12'] = df['H12'].fillna(0, inplace=True)
    #df['H2'] = df['H2'].fillna(0, inplace=True)
    print(df)
    
def pvt(df):
    pv = df.pivot_table(index=['CT1_2','DCT'], columns='DCT', values='CT1_2', aggfunc='sum').reset_index()
    print(pv)
    

#pvt = fdf.pivot_table(index=['CUSTOMATTR15','CAT'], columns='DURCAT', values='cnt', aggfunc='sum').reset_index()

fdf = extrafeat(df)
Part2(fdf)
#pvt(fdf)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled-Copy1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
#print(fl)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        
conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print (conn.version)
    
def qryex(qr = False, flname = fl):
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + "*" + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(os.getcwd() + "\\dw\\" + flname)
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd

#######################################################################################
def qr1():
    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')
    Y21= qryex(x21,'EFDSDFSDFS.csv')

def qr2():
    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')
    x22 = " CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and " + x21 
    df= qryex(x22,'all_oneday_ip.csv')

qr2()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled-Copy1.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
#print(fl)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        
conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print (conn.version)
    
def qryex(qr = False, flname = fl):
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + "*" + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(os.getcwd() + "\\dw\\" + flname)
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd

#######################################################################################
def qr1():
    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')
    Y21= qryex(x21,'EFDSDFSDFS.csv')

def qr2():
    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')
    x22 = " CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and " + x21 
    df= qryex(x22,'all_oneday_ip.csv')

qr2()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled.py###
#!/usr/bin/env python
# coding: utf-8

# In[4]:


import pandas as pd
import cx_Oracle
import os
from datetime import *
from dateutil.parser import *
from dateutil.tz import *
from dateutil.relativedelta import *

nw = datetime.now()
dtst = nw.strftime ("%d%m%Y%H%M%S")
fl = os.getcwd() + "\\dw\\" + dtst + ".csv"
#print(fl)

def sem_view_filter_cols():
    df = pd.read_csv(os.getcwd() + "\\col_filter_semdb_view_non_macro.csv")
    ls = df.iloc[:,0].to_list()
    x = ",".join(list(ls))
    return x

def timedelt(diff):
    x = datetime.now ()
    d = x + timedelta (hours=diff)
    str_d = d.strftime ("%d-%m-%Y %H:%M:%S")
    return str_d

def tmx(t1=False):
    nw = datetime.now()
    dtst = nw.strftime("%d-%m-%Y %H:%M:%S")
    if t1 == False:
        print("Stat Time: ", dtst)
        return nw
    else:
        x = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
        print("End Time: ", dtst)
        print("Time Consumed: ", x, " mins")
        
conn = cx_Oracle.connect ('SOC_READ','soc_read', 'ossam-cluster-scan.robi.com.bd:1721/RBPB.robi.com.bd')
print (conn.version)
    
def qryex(qr = False, flname = fl):
    q = ""
    if qr == False:
        q1 = "select " + sem_view_filter_cols() + " FROM SEMHEDB.ALERTS_STATUS_V_FULL  Where SEVERITY>0"
    else:
        q1 = "select " + "*" + " FROM SEMHEDB.ALERTS_STATUS_V_FULL WHERE " + str(qr)
    print(q1)
    st = tmx()
    df = pd.read_sql(q1, con = conn)
    et = tmx(st)
    df.to_csv(os.getcwd() + "\\dw\\" + flname)
    return df
    
def timebetween(t1,t2):
    d1 = parse(t1)
    d2 = parse(t2)
    print(type(d1))
    dd = "LASTOCCURRENCE BETWEEN TO_DATE('" + d1.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS') AND TO_DATE('" +  d2.strftime("%d-%m-%Y %H:%M:%S") + "','DD-MM-YYYY HH24:MI:SS')"
    return dd

#######################################################################################
def qr1():
    x21 = timebetween('24-12-2020 12:08','24-12-2020 12:18')
    Y21= qryex(x21,'EFDSDFSDFS.csv')

def qr2():
    x21 = timebetween('26-12-2020 00:08','26-12-2020 23:50')
    x22 = " CUSTOMATTR3 LIKE 'PHYSICAL PORT DOWN' and " + x21 
    df= qryex(x22,'all_oneday_ip.csv')

qr2()

#xx = (parse("22-12-2020 01:05") - datetime.now()).seconds / 60
#print(xx)
#x = relativedelta(
    #print(datetime.strptime("22-12-2020 01:05","%d-%m-%Y %H:%M:%S"))- datetime.strptime(datetime.now(),"%d-%m-%Y %H:%M:%S").seconds / 60
#print(x)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
from saymyname import *
from oDT import *
import os

def cols():
    fp = open(os.getcwd() + "col.txt")
    tx = fp.read()
    fp.close()
    return tx.split("\n")

def csv_mini():
    ls = cols()
    df = pd.read_csv(os.getcwd() + "\\csv\\OMTX1.csv", low_memory=False)
    df1 = df[ls]
    df1.to_csv(os.getcwd() + "\\csv\\OMTX_M.csv", index = False)

    
df = pd.read_csv(os.getcwd() + "\\csv\\OMTX_M.csv", low_memory=False)
print(df)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled1.py###
#!/usr/bin/env python
# coding: utf-8

# In[5]:


import pandas as pd
from saymyname import *
from oDT import *
import os

def cols():
    fp = open(os.getcwd() + "col.txt")
    tx = fp.read()
    fp.close()
    df = pd.read_csv(os.getcwd() + "\\csv\\OMTX1.csv", low_memory=False)
    ls = tx.split("\n")
    df1 = df[ls]
    df1.to_csv(os.getcwd() + "\\csv\\OMTX_M.csv", index = False)

def csv_mini():
    ls = cols()
    df = pd.read_csv(os.getcwd() + "\\csv\\OMTX1.csv", low_memory=False)
    df1 = df[ls]
    df1.to_csv(os.getcwd() + "\\csv\\OMTX_M.csv", index = False)

    
df = pd.read_csv(os.getcwd() + "\\csv\\OMTX_M.csv", low_memory=False)
print(df)


# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled2-checkpoint.txt###
import time as tm
import pandas as pd
import numpy as np
from datetime import *
import os
import oDT as dtx


def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%Y/%m/%d %H:%M")).total_seconds())/60, lscol))
            df1 = fnx.add_col_df(df, 'newcol')
            df1[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df1 = fnx.add_col_df(df, 'newcol')
        df1[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
        


df = pd.read_csv(os.getcwd() + "\\csv\\OMTX_M.csv", low_memory=False)
df = df.astype(str)
lscol = df['LASTOCCURRENCE'].to_list()
#ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%Y/%m/%d %H:%M")).total_seconds())/60, lscol))
print(ls)
#df3['DUR']
#try:
#    df3 = DateDiff (df, "DUR", "LASTOCCURRENCE")
#except:
#    df3 = datediff_ondf (df, "DUR", 'LASTOCCURRENCE')
#print(df3.columns)

df3





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\Untitled2.txt###
import time as tm
import pandas as pd
import numpy as np
from datetime import *
import os
import oDT as dtx


def DateDiff(df, newcol, col1, col2 = False, DayFirst = True):
    if col2 == False:
        lscol = df[col1].to_list()
        try:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
        except:
            ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%Y/%m/%d %H:%M")).total_seconds())/60, lscol))
            df1 = fnx.add_col_df(df, 'newcol')
            df1[newcol] = np.array(ls)
    else:
        lscol1 = df[col1].to_list()
        lscol2 = df[col2].to_list()
        ls = list(map (lambda x , y: ((datetime.strptime(x, "%d/%m/%Y %H:%M") - datetime.strptime(y, "%d/%m/%Y %H:%M")).total_seconds())/60 if ('1970' not in str(y)) else "0", lscol2,lscol1))
        df1 = fnx.add_col_df(df, 'newcol')
        df1[newcol] = np.array(ls)
    df[newcol] = df[newcol].astype(float).round(2)
    return df
        


df = pd.read_csv(os.getcwd() + "\\csv\\TIME_TEST.csv", low_memory=False)
df = df.astype(str)
lscol = df['LASTOCCURRENCE'].to_list()
#ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%d/%m/%Y %H:%M")).total_seconds())/60, lscol))
#ls = list(map (lambda x: ((datetime.now() - datetime.strptime(x, "%Y/%m/%d %H:%M")).total_seconds())/60, lscol))
df[col1] = df['LASTOCCURRENCE'].apply(lambda x : pd.to_datetime(x, errors='coerce', dayfirst = True, cache=True).strftime("%Y/%m/%d %H:%M:%S"))
print(ls)
#df3['DUR']
#try:
#    df3 = DateDiff (df, "DUR", "LASTOCCURRENCE")
#except:
#    df3 = datediff_ondf (df, "DUR", 'LASTOCCURRENCE')
#print(df3.columns)

df3





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\vbdf_1-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[44]:


import pandas as pd
import numpy as np
import os
import func.fnsem as sem
import func.fnfn as fn
import db.db as sq
from datetime import *

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"
pt3 = os.getcwd() + "\\refdb\\S1800.csv"


pt4 = os.getcwd() + "\\rocsites.csv"
despath = "C:\\Users\\kabir.omi\\Desktop\\radio_node_region_wise.csv"
df4 = pd.read_csv(pt3)
df4 = df4.rename(columns=str.upper)
df5 = sem.get_region(df4,'CUSTOMATTR15')
df = sem.catsemrw(df5)


#Apply
def dtdiff(df,D1,D2):
    df[D1] = df[D1].map(lambda x: pd.to_datetime(x, errors='coerce'))
    df[D2] = df[D2].map(lambda x: pd.to_datetime(x, errors='coerce'))
    df['diff'] = df.apply(lambda x: x[D1] - x[D2], axis = 1)
    df['diff'] = df['diff'].astype('timedelta64[m]')
    print(df)
#applymap
dtdiff(df,)

#map
#df['O1'] = df['CUSTOMATTR15'].map(lambda x: x[0:5])
#df['OM'] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)

#print(df)


#dfx = df5.groupby(['Region']).Region.count().to_frame(name = 'SMX').reset_index()
#dfx.to_csv(despath, index = False)
#dx2 = sem.get_region(dx1,dfdb)
#xx = fn.datediff(dx2,'cc','LASTOCCURRENCE','CLEARTIMESTAMP')
#print(xx)
#xx = fn.countifz(dx2,dx2['cat'])
#print(xx)
#cd = 'DHKDM36'
#idx = dx2[dx2['CUSTOMATTR15'] == cd].index
#print(dx2)
#dx4 = dx2[dx2['CUSTOMATTR15'].str.contains(cd)]
#dx3 = dx2[dx2['cat'].isin(['2G','3G','4G'])]
#dx4 = dx3.drop_duplicates(subset=['CUSTOMATTR15', 'cat'], keep='first')
#sem.techwise(dx4)


# In[42]:


# SERIES
# Ref: https://pandas.pydata.org/pandas-docs/stable/reference/series.html

def inlist(ls,str1,str2):
    n1 = ls.count(str1)
    n2 = ls.count(str2)
    n3 = str(n1) + str(n2)
    return n3

class srdf:
    def __init__(self, dfx):
        self.mdf = dfx
        self.df = dfx
    def getdf(self):
        return self.df
    def conv(self,sdf):
        print('x')
    def sscat(self,*argv):
        df1 = self.df
        n = len(argv) - 1
        print(n)
        i = 0
        ls = []
        idx = []
        ls = self.df.columns.to_list()
        while i <= n :
            R = inlist(ls,argv[i],argv[i-1])
            if R[0:1] == '1' and R[1:2] == '1':
                print('11')
                self.df['OM'] = self.df.apply(lambda x: x[argv[i]] + x[argv[i+1]], axis = 1)
            if R[0:1] == '1' and R[1:2] == '0':
                print('10')
                self.df['OM'] = self.df.apply(lambda x: x[argv[i]] + argv[i+1], axis = 1)
            if R[0:1] == '0' and R[1:2] == '1':
                print('01')
                self.df['OM'] = self.df.apply(lambda x: argv[i] + x[argv[i+1]], axis = 1)
            i = i + 2
            df1 = self.df
        print(print(df1['OM']))
        
    

        
     
    
        #df['OM'] = df.apply(lambda x: x[argv[i]] + x[argv[i-1]], axis = 1)
        #df['OM'] = df.apply(lambda x: x[argv[i]] + "QASQ", axis = 1)
        #df['OM'] = df[argv[i],argv[i-1]].map(lambda x: x[0:5])
        #df['OM'] = df[argv[i]].str.cat(df[argv[i-1]], join='left')  
        #i -= 1
    #print(df)
    
        #for n in range(len(argv)):
        #if ls.count(argv[n]) != 0:
            #idx.append(str(n))
    #print(idx)
        
#ss = s.str.cat(t, join='left', na_rep='-')       
        
        
x = srdf(df) 
x.sscat('CUSTOMATTR15','cat','Region')
#print(x.getdf())

#s = pd.Series(['sca', 'bsc', np.nan, 'scd'])
#t = pd.Series(['d', 'a', 'e', 'c'])
#ss = s.str.cat(t, join='left', na_rep='-')


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\vbdf_1.py###
#!/usr/bin/env python
# coding: utf-8

# In[2]:


import pandas as pd
import numpy as np
import os
import func.fnsem as sem
import func.fnfn as fn
import db.db as sq
from datetime import *

pt1 = os.getcwd() + "\\refdb\\S30.csv"
pt2 = os.getcwd() + "\\refdb\\S1800_200.csv"
pt3 = os.getcwd() + "\\refdb\\S1800.csv"


pt4 = os.getcwd() + "\\rocsites.csv"
despath = "C:\\Users\\kabir.omi\\Desktop\\radio_node_region_wise.csv"
df4 = pd.read_csv(pt3)
df4 = df4.rename(columns=str.upper)
df5 = sem.get_region(df4,'CUSTOMATTR15')
df = sem.catsemrw(df5)
print(df)

#Apply
def dtdiff(df,D1,D2):
    df[D1] = df[D1].map(lambda x: pd.to_datetime(x, errors='coerce'))
    df[D2] = df[D2].map(lambda x: pd.to_datetime(x, errors='coerce'))
    df['diff'] = df.apply(lambda x: abs(x[D1] - x[D2]), axis = 1)
    df['diff'] = df['diff'].astype('timedelta64[m]')
    print(df)
#applymap
dtdiff(df,'LASTOCCURRENCE','CLEARTIMESTAMP')

#map
#df['O1'] = df['CUSTOMATTR15'].map(lambda x: x[0:5])
#df['OM'] = df[list_of_cols_as_ref].apply(lambda x: ''.join(map(str,x)),axis=1)

#print(df)


#dfx = df5.groupby(['Region']).Region.count().to_frame(name = 'SMX').reset_index()
#dfx.to_csv(despath, index = False)
#dx2 = sem.get_region(dx1,dfdb)
#xx = fn.datediff(dx2,'cc','LASTOCCURRENCE','CLEARTIMESTAMP')
#print(xx)
#xx = fn.countifz(dx2,dx2['cat'])
#print(xx)
#cd = 'DHKDM36'
#idx = dx2[dx2['CUSTOMATTR15'] == cd].index
#print(dx2)
#dx4 = dx2[dx2['CUSTOMATTR15'].str.contains(cd)]
#dx3 = dx2[dx2['cat'].isin(['2G','3G','4G'])]
#dx4 = dx3.drop_duplicates(subset=['CUSTOMATTR15', 'cat'], keep='first')
#sem.techwise(dx4)


# In[3]:


# SERIES
# Ref: https://pandas.pydata.org/pandas-docs/stable/reference/series.html

def inlist(ls,str1,str2):
    n1 = ls.count(str1)
    n2 = ls.count(str2)
    n3 = str(n1) + str(n2)
    return n3

class srdf:
    def __init__(self, dfx):
        self.mdf = dfx
        self.df = dfx
    def getdf(self):
        return self.df
    def conv(self,sdf):
        print('x')
    def sscat(self,*argv):
        df1 = self.df
        n = len(argv) - 1
        print(n)
        i = 0
        ls = []
        idx = []
        ls = self.df.columns.to_list()
        while i < n :
            R = inlist(ls,argv[i],argv[i-1])
            if R[0:1] == '1' and R[1:2] == '1':
                print('11')
                self.df['OM'] = self.df.apply(lambda x: x[argv[i]] + x[argv[i+1]], axis = 1)
            if R[0:1] == '1' and R[1:2] == '0':
                print('10')
                self.df['OM'] = self.df.apply(lambda x: x[argv[i]] + argv[i+1], axis = 1)
            if R[0:1] == '0' and R[1:2] == '1':
                print('01')
                self.df['OM'] = self.df.apply(lambda x: argv[i] + x[argv[i+1]], axis = 1)
            i = i + 2
            df1 = self.df
        print(print(df1['OM']))
        
    

        
     
    
        #df['OM'] = df.apply(lambda x: x[argv[i]] + x[argv[i-1]], axis = 1)
        #df['OM'] = df.apply(lambda x: x[argv[i]] + "QASQ", axis = 1)
        #df['OM'] = df[argv[i],argv[i-1]].map(lambda x: x[0:5])
        #df['OM'] = df[argv[i]].str.cat(df[argv[i-1]], join='left')  
        #i -= 1
    #print(df)
    
        #for n in range(len(argv)):
        #if ls.count(argv[n]) != 0:
            #idx.append(str(n))
    #print(idx)
        
#ss = s.str.cat(t, join='left', na_rep='-')       
        
        
#x = srdf(df) 
#x.sscat('CUSTOMATTR15','cat','Region')
#print(x.getdf())

#s = pd.Series(['sca', 'bsc', np.nan, 'scd'])
#t = pd.Series(['d', 'a', 'e', 'c'])
#ss = s.str.cat(t, join='left', na_rep='-')


# In[ ]:





# In[ ]:





# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\vb_countifs-checkpoint.py###
#!/usr/bin/env python
# coding: utf-8

# In[59]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
df = pd.read_csv(single)
Rn = df[cols]
#print(RnA2E)

for column in Rn[['CustomAttr15']]:
    colseries = Rn[column]
    #print(colseries.values)

#for (colname, coldata) in RnA2E.iteritems():
    #print(colname)
    #print(coldata.values)
    
for colname in Rn[['CustomAttr15','Summary','LastOccurrence']]:
    colseries = Rn[column]
    #print(column)
    #print(colseries.values)
    
for col in range(Rn.shape[1]):
    #print('Column Number : ', col)
    ColSeries = Rn.iloc[: , col]
    for rw in range(Rn.shape[0]):
        rwval = Rn.iloc[rw , col]
        #print(rwval)

for rw in range(Rn.shape[0]):
    rwval = Rn.iloc[rw , '1']
    print(rwval)
    
#df2['CNT'] = df2.fillna(df2['CustomAttr15'].value_counts())
#print(df2)

#ar = collections.Counter(a)
#df2['newcol'] = arr.toarray().tolist() * 1
#print(ar)



#df2 = df.apply(lambda x: x['Col2'] if pd.isnull(x['Col1']) else x['Col1'], axis=1)


# In[ ]:





$$$$$$$$$


###d:\omEngin\Z_ALL_FILE\Jy1\vb_countifs.py###
#!/usr/bin/env python
# coding: utf-8

# In[75]:


import pandas as pd
import numpy as np
import os
from datetime import date
cols = ["Resource","CustomAttr15","Summary","LastOccurrence","CustomAttr11"] #Range [A-E]
single = os.getcwd() + "\\" + "single.csv"
df = pd.read_csv(single)
Rn = df[cols]
#print(RnA2E)

for column in Rn[['CustomAttr15']]:
    colseries = Rn[column]
    #print(colseries.values)

#for (colname, coldata) in RnA2E.iteritems():
    #print(colname)
    #print(coldata.values)
    
for colname in Rn[['CustomAttr15','Summary','LastOccurrence']]:
    colseries = Rn[column]
    #print(column)
    #print(colseries.values)
    
for col in range(Rn.shape[1]):
    ColSeries = Rn.iloc[: ,col]
    #print(ColSeries)

count = 1
for rw in range(Rn.shape[0]):
    rwvalue1 = Rn.iloc[rw , 1]  #on Column 1
    rwvalue2 = Rn.iloc[rw , 2]  ##on Column 2
    rwvalue3 = Rn.iloc[rw , 3]  ##on Column 2
    count = count + 1
    print('Row Number', count , ':', rwvalue1, '>', rwvalue2, '>', rwvalue3)
    if rwvalue1 == 'CXTKN25':
        print('x')
        print('CXTKN25 found at row:', str(count), ' Alamrm found: ' , rwvalue3)
    
#df2['CNT'] = df2.fillna(df2['CustomAttr15'].value_counts())
#print(df2)

#ar = collections.Counter(a)
#df2['newcol'] = arr.toarray().tolist() * 1
#print(ar)



#df2 = df.apply(lambda x: x['Col2'] if pd.isnull(x['Col1']) else x['Col1'], axis=1)


# In[ ]:





# In[ ]:





$$$$$$$$$
